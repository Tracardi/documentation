{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#what-is-tracardi","title":"What is Tracardi?","text":"<p>Tracardi is an open-source Customer Data Platform (CDP) designed to help businesses manage and utilize customer data effectively. It provides a low-code/no-code solution, making it accessible for organizations of all sizes to integrate and leverage customer data for various purposes. As an API-first platform, Tracardi ensures seamless integration with both new and legacy systems.</p>"},{"location":"#key-features-of-tracardi","title":"Key Features of Tracardi","text":""},{"location":"#real-time-data-ingestion-and-storage","title":"Real-Time Data Ingestion and Storage","text":"<p>Tracardi excels in ingesting, aggregating, and storing customer data from multiple sources in real-time. This capability allows businesses to manage customer data at any scale, ensuring they always have access to the most up-to-date and comprehensive information.</p>"},{"location":"#customer-data-management-and-modeling","title":"Customer Data Management and Modeling","text":"<p>Tracardi offers robust tools for managing and modeling customer data. Businesses can define rules that shape the data as it is delivered, allowing for effective customer segmentation and targeting. This helps in creating custom customer groups for more precise marketing efforts.</p>"},{"location":"#personalization-and-customer-experience","title":"Personalization and Customer Experience","text":"<p>Through real-time customer segmentation and targeting, Tracardi enables businesses to personalize the user experience. This ensures that customers receive relevant and targeted content, improving their overall experience with the brand.</p>"},{"location":"#unified-customer-profiles","title":"Unified Customer Profiles","text":"<p>Tracardi provides tools for unifying customer data from various sources into a single profile. This includes de-duplicating records and blending multiple accounts, making it easier to manage and understand customer data comprehensively.</p>"},{"location":"#marketing-automation-framework","title":"Marketing Automation Framework","text":"<p>Tracardi serves as a powerful framework for creating marketing automation apps. It facilitates the easy sending of data to other systems and automates various processes, streamlining marketing operations.</p>"},{"location":"#how-tracardi-performs-its-services","title":"How Tracardi Performs Its Services","text":"<p>Tracardi collects data throughout customer journeys<sup>1</sup>, capturing this information in the form of events<sup>2</sup> that include both context and event-specific data. Each event is linked to a profile that is maintained over the entire interaction period with the customer, whether through a website, mobile application, or other platforms.</p> <p>Customer data is aggregated into a profile[^3], and the process of attaching this data to profiles is defined using the graphical editor within the Tracardi system. This editor allows administrators to specify how data is linked to profiles, ensuring a comprehensive view of each customer's interactions.</p> <p>By integrating Tracardi with your system, such as a SaaS service, you can track each customer's interactions with your company. The information collected may encompass various consumer decisions, including:</p> <ul> <li>Whether the customer decides to subscribe to your services</li> <li>The circumstances under which they make these decisions (event context)</li> <li>Whether the customer is satisfied with your service or considers canceling it</li> </ul> <p>This detailed tracking and aggregation of customer data enable businesses to better understand and respond to customer behavior and preferences.</p>"},{"location":"#why-we-created-tracardi","title":"Why We Created Tracardi","text":"<p>Tracardi was developed to help companies gain deeper insights into and foster better engagement with their customers. As businesses increasingly recognize the crucial role of customer experience and engagement, Tracardi offers a comprehensive set of tools and features that enable them to track and analyze customer behavior, delivering personalized and seamless experiences across various channels.</p> <p>A significant portion of Tracardi's customer base is in the retail and financial industry, where companies have found it to be an invaluable resource for understanding customer interactions with their products and services. By leveraging Tracardi, retailers can achieve a competitive edge, enhancing the customer experience in ways that drive engagement and loyalty. This is accomplished through strategies such as personalization, cross-channel integration, and omnichannel services.</p> <p>Tracardi can help retailers to:</p> <ul> <li>Understand their customers better</li> <li>Improve customer experience and provide timely assistance</li> <li>Optimize website content and navigation</li> <li>Enhance search functionality to help customers find information easily</li> <li>Reduce unsolicited messaging</li> <li>Integrate data from various sources</li> </ul> <p>By utilizing these capabilities, Tracardi empowers businesses to create more meaningful and effective customer interactions, ultimately leading to increased satisfaction and loyalty.</p> <ol> <li> <p>A customer journey is an entire experience a customer has while communicating with a brand. It considers the complete interaction roadmap from brand discovery to purchasing and beyond. The focus isn't on transactions, but rather how the customer feels after interactions with the brand.\u00a0\u21a9</p> </li> <li> <p>In programming and software design, an event is an action or occurrence recognized by software, often originating asynchronously from the external environment, that may be handled by the software. Computer events can be generated or triggered by the system, by the user, or in other ways.\u00a0\u21a9</p> </li> <li> <p>A user profile is a collection of settings and information associated with a user. It can be defined as the explicit digital representation of the identity of the user with respect to the operating environment, which could be operating systems, software applications or websites. The user profile helps in associating characteristics with a user and helps in ascertaining the interactive behavior of the user along with preferences.\u00a0\u21a9</p> </li> </ol>"},{"location":"documentation_license/","title":"Documentation license","text":"<p>Copyright 2021 Risto Kowaczewski</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"support_us/","title":"Support us","text":"<p>If you would like to support us please follow us on  Facebook or  Twitter, tag us and leave your comments. Subscribe to our : material-youtube: YouTube channel to see development process and new upcoming features.</p> <p>Spread the news about TRACARDI so anyone interested get to know TRACARDI.</p> <p>We appreciate any help that helps make TRACARDI popular. </p>"},{"location":"architecture/","title":"Architecture of Tracardi","text":"<p>Tracardi uses Docker as a containerization platform. For production installation, we recommend using Kubernetes to manage Tracardi Docker instances securely and efficiently.</p> <p>The Tracardi stack requires an operating system capable of hosting a Kubernetes (K8s) cluster. On top of this, Kubernetes and all Tracardi dependencies need to be installed. These dependencies include Elasticsearch, MySQL, Redis, and Apache Pulsar, which can be hosted either within the Kubernetes cluster or externally. Scaling Tracardi effectively relies on the scaling of these dependencies.</p> <p>Tracardi is a distributed system designed to track and analyze customer data. It consists of several core components:</p> <ol> <li>Database: Stores events and other data.</li> <li>API: A RESTful interface for interacting with the system.</li> <li>GUI: A graphical user interface for end users.</li> <li>Background Workers: Handle background processes such as profile merging and tenant management.</li> </ol>"},{"location":"architecture/#components","title":"Components","text":"<ul> <li>Data Processing Library: This key component of the Tracardi API handles workflow for selected events and transfers   them to external systems. Programmers can use this library to develop Tracardi plugins.</li> <li>GUI: A graphical interface that runs in the user's browser, allowing end users to interact with the system.</li> <li>Background Workers: Perform background processes such as merging profiles and managing tenants.</li> </ul> <p>Tracardi components can be installed and run separately, and multiple instances of each component can be activated to meet business needs. For the system to function fully, at least four elements must be activated:</p> <ul> <li>Database</li> <li>API</li> <li>GUI</li> <li>Background Workers</li> </ul> <p>The GUI connects to the API, which in turn connects to the database.</p> <p>In addition to the core components, Tracardi may also include additional elements such as:</p> <ul> <li>Background processes for profile merging</li> <li>Data bridges for connecting to external systems</li> <li>Multitenancy controllers</li> </ul> <p>These auxiliary services enhance Tracardi's functionality.</p>"},{"location":"architecture/#open-source-vs-commercial","title":"Open-Source vs Commercial","text":"<p>The commercial version of Tracardi requires more services than the open-source one. Unlike the open-source version, the commercial version relies on Apache Pulsar and includes additional features such as multitenancy controllers, new data collection bridges, and enhanced profile management workers. In contrast, the open-source version does not depend on Apache Pulsar and features an extended API, offering a different set of capabilities tailored to commercial use cases.</p>"},{"location":"configuration/","title":"Tracardi configuration","text":"<p>Tracardi configuration is performed via environment variables. You might want to use environment variables to change the default system configuration, especially if you intend to run Tracardi inside a Docker container. You can find the list of all the environment variable names below.</p>"},{"location":"configuration/#elastic-configuration","title":"Elastic configuration","text":"<ul> <li><code>ELASTIC_HOST</code> - Default: 127.0.0.1. This setting defines an IP address of elastic search instance.   See <code>Connecting to elastic cluster</code> for more information how to connect to a cluster of servers.</li> <li><code>ELASTIC_SNIFF_ON_START</code> - Default: None. When you enable this option, the client will attempt to execute an   Elasticsearch sniff request during the client initialization or first usage. Search documentation for sniffing to get   more information.</li> <li><code>ELASTIC_SNIFF_ON_CONNECTION_FAIL</code> - Default: None. If you enable this option, the client will attempt to execute a   sniff request every time a node is faulty, which means a broken connection or a dead node.</li> <li><code>ELASTIC_SNIFFER_TIMEOUT</code> - Default: None, Time out for sniff operation.</li> <li><code>ELASTIC_HTTP_AUTH_USERNAME</code> - Default: None. Elastic search username. Search for elastic authentication for more   information on how to configure connection to elastic.</li> <li><code>ELASTIC_HTTP_AUTH_PASSWORD</code> - Default: None. Elastic search password. Search for elastic authentication for more   information on how to configure connection to elastic.</li> <li><code>ELASTIC_SCHEME</code> - Default: http. Available options http, https.</li> <li><code>ELASTIC_CA_FILE</code> - Default: None. Elastic CA file. Search for elastic authentication for more information on how to   configure connection to elastic.</li> <li><code>ELASTIC_API_KEY</code> - Default: None. Elastic API key. Search for elastic authentication for more information on how to   configure connection to elastic.</li> <li><code>ELASTIC_CLOUD_ID</code> - Default: None. Search for elastic authentication for more information on how to configure   connection to elastic.</li> <li><code>ELASTIC_MAX_CONN</code> - Default: None. Defines max connection to elastic cluster. It defaults to elastic default value.</li> <li><code>ELASTIC_HTTP_COMPRESS</code>- default value: None. Set compression on data when the client calls the server.</li> <li><code>ELASTIC_VERIFY_CERTS</code> - default value: None. Verify certificates when https schema is set. Set it to no if   certificates has no CA.</li> <li><code>TENANT_NAME</code> - Default: None. It defines prefix for all elastic indexes. This can be used to run multiple   instances of Tracardi on one elastic instance.</li> <li><code>ELASTIC_LOGGING_LEVEL</code> - Default WARNING. Sets logging level of elastic requests. It may be useful to set it to INFO   when debugging Tracardi.</li> </ul>"},{"location":"configuration/#api-settings","title":"API settings","text":"<ul> <li><code>USER_NAME</code> - Default: admin. Login to Tracardi API</li> <li><code>PASSWORD</code> - Default: admin. Password to Tracardi API</li> <li><code>DEBUG_MAKE_SLOWER_RESPONSES</code> - Default: 0. This variable is for testing purposes only. It sets the number of seconds   each endpoint should be slowed in order to see the GUI responses.</li> <li><code>AUTOLOAD_PAGE_SIZE</code> - Default: 25. Chunks of data that are loaded with one request.</li> <li><code>EXPOSE_GUI_API</code> - Default: yes. It exposes the GUI API on the started Tracardi API instance.</li> </ul>"},{"location":"configuration/#plugins-settings","title":"Plugins settings","text":"<ul> <li><code>RESET_PLUGINS</code> - Default: no. If set to yes it will remove plugins index with every start of Tracardi instance. This   setting is used in development mode only.</li> <li><code>UPDATE_PLUGINS_ON_STARTUP</code> - Default: no. If equals <code>yes</code> it will update all installed plugins on Tracardi start.</li> </ul>"},{"location":"configuration/#cache-settings","title":"Cache settings","text":"<ul> <li><code>REDIS_HOST</code> - Default: redis://localhost:6379. This setting is used only when <code>SYNC_PROFILE_TRACKS</code> is equal to yes.   This is the host URI of Redis instance that is required to synchronize profile tracks. Available only in commercial   version of Tracardi.</li> <li><code>SOURCE_CACHE_TTL</code> - Default: 60. Each resource read is cached for given seconds. That means that when you change any   resource data, e.g. credentials it wil be available with max 60 seconds.</li> <li><code>CACHE_PROFILE</code> - Default: no. Profiles can be cached, but it is not recommended as this option is experimental.</li> </ul>"},{"location":"configuration/#debugging-settings","title":"Debugging settings","text":"<ul> <li><code>TRACK_DEBUG</code> - Default: no.</li> <li><code>LOGGING_LEVEL</code> - Default: WARNING</li> </ul>"},{"location":"configuration/#event-server-configuration","title":"Event server configuration","text":"<ul> <li><code>SYNC_PROFILE_TRACKS</code> - Default: False. Available only in commercial version of Tracardi.</li> <li><code>RUN_HEARTBEAT_EVERY</code> - Default: 300. The time each worker reports its health.</li> </ul>"},{"location":"configuration/#storage-settings","title":"Storage settings","text":"<ul> <li><code>STORAGE_DRIVER</code> - Default: elastic. There is only one storage driver available at this moment, and it is elastic.</li> </ul>"},{"location":"configuration/best_practises/","title":"Configuration Best Practises","text":"<p>To enhance security, consider setting up encrypted connections for Tracardi API access. You can encode external traffic to the load balancer while keeping internal cluster communication unencoded, ensuring both security and efficiency. Alternatively, encrypt the entire cluster by creating HTTPS versions of Tracardi Docker images for comprehensive encryption.</p>"},{"location":"configuration/best_practises/#set-strong-admin-password","title":"Set strong admin password","text":"<p>Having a strong admin password is especially important for systems that handle sensitive or confidential data, such as personal information. If an admin password is weak or easily guessed, it could be exploited by attackers or unauthorized individuals, who could gain access to sensitive data or disrupt the system's operation.</p> <p>By setting a strong admin password, you can help to prevent unauthorized access and protect the security and integrity of the system or application. This can help to ensure that your data and systems are safe from unauthorized access and tampering, and that you can trust the security and reliability of your system or application.</p>"},{"location":"configuration/best_practises/#separation-of-track-server-and-gui-api","title":"Separation of track server and GUI API","text":""},{"location":"configuration/best_practises/#api","title":"API","text":"<p>A recommended approach involves having two Tracardi API instances: one for the GUI and another for event collection.</p> <ol> <li> <p>Event Collection Cluster: This cluster is accessible over the Internet and handles event collection. To achieve    this:</p> <ul> <li>Set the environment variable <code>EXPOSE_GUI_API</code> to <code>no</code>.</li> <li>Only the <code>/track</code> endpoint is accessible publicly, while other GUI-specific endpoints are disabled.</li> <li>This cluster is designed to gather data from websites and other online sources.</li> </ul> </li> <li> <p>GUI Control Cluster: This separate cluster operates within the internal network or is accessible over the    Internet but limited to specific IP addresses. This setup is for GUI control of Tracardi:</p> <ul> <li>Configure the environment variable <code>EXPOSE_GUI_API</code> as <code>yes</code>.</li> <li>This cluster is utilized by the GUI to control Tracardi.</li> </ul> </li> </ol>"},{"location":"configuration/best_practises/#gui","title":"GUI","text":"<p>GUI and GUI API should be accessible only from trusted network for security reasons.</p>"},{"location":"configuration/best_practises/#q-a","title":"Q &amp; A","text":"<p>Q: What is the minimal number of instances? A: This all depends on your traffic. If you do not have big traffic you could run one cluster of APIs with 3 instances and install GUI on your local machine.</p> <p>Q: Do tracardi need any particular routing inside cluster? A: The internal routing from load balancer to Tracardi instances can be for example: round-robin. Tracardi do not require long-lasting sticky sessions.</p>"},{"location":"configuration/elasticsearch/connecting_elasticsearch_cluster/","title":"Connecting elasticsearch cluster","text":""},{"location":"configuration/elasticsearch/connecting_elasticsearch_cluster/#connecting-to-elastic-cluster","title":"Connecting to elastic cluster","text":"<p>To connect to elastic cluster you must provide location to all cluster nodes. To configure Tracardi connection to elastic change ELASTIC_HOST in docker-standalone.yaml file.</p> <pre><code>    ELASTIC_HOST: \"node-1,node-2,node-3\"\n</code></pre> <p>If your cluster is behind a reverse proxy you will need only one url.</p>"},{"location":"configuration/elasticsearch/connecting_elasticsearch_cluster/#ssl-and-authentication","title":"SSL and Authentication","text":"<p>You can configure Tracardi to use SSL for connecting to your elasticsearch cluster. Use RFC-1738 to specify the urls:</p> <pre><code>    ELASTIC_HOST: \"https://user:secret@node-1:443,https://user:secret@node-2:443,https://user:secret@node-3:443\"\n</code></pre> <p>There is another way to connect to elastic cluster.</p> <pre><code>    ELASTIC_HOST: \"node-1,node-2,node-3\",\n    ELASTIC_PORT: 443,\n    ELASTIC_SCHEME: \"https\",\n    ELASTIC_HTTP_AUTH_USERNAME: \"user\",\n    ELASTIC_HTTP_AUTH_PASSWORD: \"pass\",\n</code></pre> <p>To include certificate verification and HTTP type the following line:</p> <pre><code>    ELASTIC_CA_FILE: \"path to certificate\",\n</code></pre>"},{"location":"configuration/elasticsearch/connecting_elasticsearch_cluster/#connect-using-api_key","title":"Connect using API_KEY","text":"<p>Elasticsearch Service supports API key-based authentication.</p> <p>To obtain an API key:</p> <ul> <li>Log in to the Elasticsearch Service Console.</li> <li>Select your deployment on the home page in the Elasticsearch Service card or go to the deployments page.</li> <li>Under the Features tab, open the API keys page. Any keys currently associated with your account are listed.</li> <li>Select Generate API key.</li> <li>Provide a name and select Generate API key.</li> <li>Copy the generated API key and store it in a safe place. You can also download the key as a CSV file.</li> </ul> <p>The API key has no expiration, so it may be used indefinitely. The API key has the same permissions as the API key owner. You may have multiple API keys for different purposes and you can revoke them when you no longer need them.</p> <p>Here is the configuration for connection with API_KEY</p> <pre><code>    ELASTIC_HOST: \"site-1.local,site-2,site-3.com\",\n    ELASTIC_PORT: 443,\n    ELASTIC_SCHEME: \"https\",\n    ELASTIC_API_KEY_ID: 'api-key-id',\n    ELASTIC_API_KEY: 'api-key'\n</code></pre>"},{"location":"configuration/elasticsearch/connecting_elasticsearch_cluster/#connect-using-cloud_id","title":"Connect using CLOUD_ID","text":"<p>Here is the configuration for connection with CLOUD_ID. With COULD_ID you do not need the hosts or port number.</p> <pre><code>    ELASTIC_CLOUD_ID: 'cluster-1:dXMa5Fx...',\n    ELASTIC_HTTP_AUTH_USERNAME: \"user\",\n    ELASTIC_HTTP_AUTH_PASSWORD: \"pass\"\n</code></pre>"},{"location":"configuration/elasticsearch/connecting_elasticsearch_cluster/#cert-verification","title":"CERT Verification","text":"<p>If your instance of elasticsearch or opensearch has certs that can not be verified set ELASTIC_VERIFY_CERTS to <code>no</code>.</p> <pre><code>    ELASTIC_VERIFY_CERTS: \"no\",\n</code></pre>"},{"location":"configuration/elasticsearch/connecting_elasticsearch_cluster/#other-connection-types","title":"Other connection types","text":"<p>If there is a need for more advanced connection configuration the change in /app/globals/elastic_client.py should handle all mare advanced connection types from Tracardi to elastic. </p>"},{"location":"configuration/elasticsearch/elastic_authentication/","title":"Elastic search authentication","text":"<p>When preparing on you production installation you may need to authenticate to  elastic search.</p> <p>We provide different types of elastic search authentication. If you experience  Authentication Error please take a closer look at the Tracardi configuration.  You probably need to provide a username and password for an elastic-search  connection. </p>"},{"location":"configuration/elasticsearch/elastic_authentication/#basic-authentication","title":"Basic Authentication","text":"<p>Example of elastic search URI for authenticated access.</p>"},{"location":"configuration/elasticsearch/elastic_authentication/#encrypted-authentication","title":"Encrypted authentication","text":"<p>File docker-standalone.yaml <pre><code>  tracardi:\n    build: .\n    environment:\n      ELASTIC_HOST: https://user:name@elastic-search-ip:443  &lt;- change here for ssl connection\n    ports:\n      - 80:80  \n    depends_on:\n      - elasticsearch\n</code></pre></p>"},{"location":"configuration/elasticsearch/elastic_authentication/#unencrypted-authentication","title":"Unencrypted authentication","text":"<p>For unencrypted connection set ELASTIC_HOST in docker-standalone.yaml to:</p> <pre><code>  tracardi:\n    ...\n    environment:\n      ELASTIC_HOST: user:name@elastic-search-ip:9200\n    ...\n</code></pre> <p>If you still experience problems with connection to elastic search, you can find the section on how to configure a connection to elastic search cluster below. </p>"},{"location":"configuration/elasticsearch/elastic_https/","title":"Connecting Tracardi to ElasticSearch via SSL","text":"<p>If you have an elasticsearch instance and you would like to connect to it via HTTPS this is the command you may find useful.</p> <pre><code>docker run -p 8686:80 -e ELASTIC_HOST=https://user:password@&lt;your-laptop-ip&gt;:9200 -e ELASTIC_VERIFY_CERTS=no -e REDIS_HOST=redis://&lt;your-laptop-ip&gt;:6379 tracardi/tracardi-api #(1)\n</code></pre> <ol> <li>If you want a certain version of docker image add version tag, e.g. <code>tracardi/tracardi-api:0.8.1</code></li> </ol> <p>ELASTIC_VERIFY_CERTS set to No</p> <p>Notice that the above command does not verify SSL certificates. If you would like certificates to be validated set  ELASTIC_VERIFY_CERTS to yes.</p>"},{"location":"configuration/elasticsearch/elastic_max_connections/","title":"Max connections to elastic","text":"<p>By default, there are open up to 10 connections to each node,  if you require more  calls the ELASTIC_MAX_CONN parameter to raise the limit:</p> <p>Add the following to Tracardi configuration.</p> <pre><code>    ELASTIC_MAX_CONN: 10\n</code></pre>"},{"location":"configuration/elasticsearch/elastic_sniffing/","title":"Elastic sniffing","text":"<p>Elasticsearch is a distributed system, which means its indices live in multiple nodes connected to each other, forming a cluster. One of the main advantages of being a distributed system \u2014 other than fault tolerance \u2014 is data is sharded into multiple nodes, allowing searches to run much faster than searches run through a huge single node.</p> <p>A typical client configuration is a single URL that points to one node of the Elasticsearch cluster. While this is the simplest configuration, the main disadvantage of this setup is all of the requests you make will be sent to that specific coordination node. Since this puts a single node under stress, overall performance may be affected.</p> <p>One solution is to pass a static list of nodes to the client, so your requests will be equally distributed among the nodes.</p> <p>Or you can enable a feature called sniffing.</p> <p>With a static list of nodes, there\u2019s no guarantee that the nodes will always be up and running. For example, what happens if you take a node down to upgrade \u2014 or you add new nodes?</p> <p>If you enable sniffing, the client will start calling the <code>_nodes/_all/http</code> endpoint, and the response will be a list of all the nodes that are present in the cluster along with their IP addresses. Then the client will update its connection pool to use all of the new nodes and keep the state of the cluster in sync with the client\u2019s connection pool. Note that even if the clients download the full list of nodes, the master-only nodes will not be used for generic API calls.</p> <p>Sniffing solves this discovery issue.</p> <p>When you enable sniffing, you\u2019ll make your application more resilient and able to adapt to the changes. Before doing so, you should know your infrastructure, so you can decide what the best solution to adopt is. The best solution might even be to not adopt sniffing.</p> <p>Tracardi has some configuration that can be adopted to turn on of off sniffing. See <code>tracardi configuration</code> to get more information on how to configure sniffing.</p>"},{"location":"configuration/elasticsearch/elastic_sniffing/#sniffing-at-startup","title":"Sniffing at startup","text":"<p>As the name suggests, when you enable this option, the client will attempt to execute a sniff request one time only during the client initialization or first usage. It will call all nodes to obtain a list of active nodes.</p>"},{"location":"configuration/elasticsearch/elastic_sniffing/#sniffing-on-connection-failure","title":"Sniffing on connection failure","text":"<p>If you enable this option, the client will attempt to execute a sniff request every time a node is faulty, which means a broken connection or a dead node. </p>"},{"location":"configuration/multi-tenant/","title":"Multi tenant configuration","text":"<p>Multitenant set-up requires a service called TMS (Tenant Management System) to run. This service offers an API-only access to create, update and delete tenants.</p>"},{"location":"configuration/multi-tenant/#creating-a-new-tenant-using-api-call","title":"Creating a New Tenant using API Call","text":"<p>This documentation outlines the process of automating the creation of a new tenant through the Tracardi API. To achieve this, you'll need an API Key associated with the TMS, which is generated during the installation of the TMS.</p>"},{"location":"configuration/multi-tenant/#prerequisites","title":"Prerequisites","text":"<ul> <li>Tenant Management Service (TMS) API Key</li> </ul>"},{"location":"configuration/multi-tenant/#api-endpoint-and-method","title":"API Endpoint and Method","text":"<p>Make an API call to the Tracardi API using the POST method and the endpoint <code>/tenant/install</code>.</p>"},{"location":"configuration/multi-tenant/#payload","title":"Payload","text":"<p>Send the following payload in JSON format along with the API call:</p> <pre><code>{\n  \"name\": \"name-of-the-tenant\",\n  \"tms_api_key\": \"TMS-API-KEY\",\n  \"email\": \"tenant@email\",\n  \"password\": \"Admin account password\",\n  \"needs_admin\": true,\n  \"update_mapping\": false\n}\n</code></pre>"},{"location":"configuration/multi-tenant/#example-curl","title":"Example CURL","text":"<p>Here's an example of how to make the API call using the CURL command:</p> <pre><code>curl -X POST \\\n  https://tracardi-api-url/tenant/install \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"name\": \"name-of-the-tenant\",\n    \"tms_api_key\": \"TMS-API-KEY\",\n    \"email\": \"tenant@email\",\n    \"password\": \"Admin account password\",\n    \"needs_admin\": true,\n    \"update_mapping\": false\n}'\n</code></pre>"},{"location":"configuration/multi-tenant/#result","title":"Result","text":"<p>Upon successfully making the API call, a new tenant will be created with the provided name. This name will form the initial part of the tenant's URL, such as <code>name-of-the-tenant.mydomain.com</code>. An admin account will also be created using the provided email as the login and the provided password. The account will have administrative privileges. </p>"},{"location":"configuration/preconfiguration/","title":"Preconfiguration","text":"<p>Note</p> <p>This process is not required if you do not want to preconfigure Tracardi installation. Preconfiguration is  done for multitenant installation when you want to preconfigure each tenant's instance with some event-sources, resources and destinations.</p> <p>Info</p> <p>This feature is available from version 1.0.1</p>"},{"location":"configuration/preconfiguration/#overview","title":"Overview","text":"<p>This guide details the process of preconfiguring event sources, destinations, and resources using Helm values. By doing so, every new instance of Tracardi will have predefined sources, resources, and destinations that are locked and cannot be changed or deleted. This commercial feature facilitates the setup of these configurations in advance, ensuring smooth deployment and consistent operation.</p>"},{"location":"configuration/preconfiguration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Helm installed on your system.</li> <li>Access to the graphical user interface (GUI) to retrieve the JSON configuration for resources, event sources, and   destinations.</li> </ul>"},{"location":"configuration/preconfiguration/#steps-to-preconfigure-resources-event-sources-and-destinations","title":"Steps to Preconfigure Resources, Event Sources, and Destinations","text":""},{"location":"configuration/preconfiguration/#step-1-retrieve-json-configuration","title":"Step 1: Retrieve JSON Configuration","text":"<p>First, obtain the JSON configuration for your resources, event sources, and destinations from the GUI. Ensure your system is properly configured and running smoothly. For example, to get the configuration for event sources, navigate to the event sources section, select the desired event source, and click the \"JSON\" button to display the current configuration. You will need this JSON configuration to predefine your system settings. </p>"},{"location":"configuration/preconfiguration/#step-2-define-helm-values","title":"Step 2: Define Helm Values","text":"<p>To preconfigure these settings using Helm, you will need to modify your Helm custom values file. Here is how you can do it:</p> <ol> <li>Configuration Structure: Example of preconfiguration<pre><code>config:\n  preConfiguration:\n    eventSources: |-\n      {\n        \"4e755b56-3bd6-4da2-897a-d6de654881c1\": {\n          \"id\": \"4e755b56-3bd6-4da2-897a-d6de654881c1\",\n          \"name\": \"Tracardi.com\",\n          \"production\": true,\n          \"running\": true,\n          \"type\": [\n            \"rest\"\n          ],\n          \"bridge\": {\n            \"id\": \"778ded05-4ff3-4e08-9a86-72c0195fa95d\",\n            \"name\": \"REST API Bridge\"\n          },\n          \"timestamp\": \"2024-01-16T16:20:18\",\n          \"description\": \"Collector to Tracardi.com web page\",\n          \"channel\": \"Webpage\",\n          \"enabled\": true,\n          \"transitional\": false,\n          \"tags\": [\n            \"rest\",\n            \"api\"\n          ],\n          \"groups\": [],\n          \"permanent_profile_id\": false,\n          \"requires_consent\": false,\n          \"manual\": null,\n          \"locked\": true,\n          \"synchronize_profiles\": true,\n          \"config\": {\n            \"static_profile_id\": false\n          }\n        }\n      }\n    resources: |-\n      {\n        \"resource_id_1\": {\n          \"id\": \"resource_id_1\",\n          // Configuration\n          \"locked\": true\n        }\n      }\n    destinations: |-\n      {\n        \"destination_id_1\": {\n          \"id\": \"destination_id_1\",\n          // Configuration\n          \"locked\": true\n        }\n      }\n</code></pre></li> </ol> <p>Note that each element in the preconfiguration, such as a destination, has a key that matches the destination ID and includes a locked attribute set to true.</p> How to index configurations.<pre><code>    config:\n       preConfiguration:\n          destinations: |-\n             {\n               \"destination_id_1\": {\n                 \"id\": \"destination_id_1\",\n                 // Configuration\n                 \"locked\": true\n               }\n             }\n</code></pre> <p>Explanation:</p> <ul> <li>config.preConfiguration: Contains the JSON configuration for event sources, resources, and destinations.</li> <li>eventSources: JSON object defining the event sources. Each event source must have a unique key (ID) and its     configuration.</li> <li>resources: JSON object defining the resources. Each resource must have a unique key (ID) and its     configuration.</li> <li>destinations: JSON object defining the destinations. Each destination must have a unique key (ID) and its     configuration.</li> <li>locked: Attribute must be set to <code>true</code> to ensure the configuration cannot be modified post-deployment.</li> </ul>"},{"location":"configuration/scaling/data_partitioning/","title":"Data Partitioning","text":""},{"location":"configuration/scaling/data_partitioning/#overview","title":"Overview","text":"<p>Data partitioning is a critical strategy for managing large datasets. It involves dividing a database into distinct, independent parts to improve manageability, performance, and availability. Tracardi utilizes this technique by segmenting indices that contain substantial amounts of data into separate time-based indices.</p>"},{"location":"configuration/scaling/data_partitioning/#benefits-of-data-partitioning","title":"Benefits of Data Partitioning","text":"<p>Partitioning in Tracardi allows for:</p> <ul> <li>Efficient Data Management: Simplifies data operations, including maintenance and deletion.</li> <li>Scalability: Supports growing data volumes by distributing them across multiple indices.</li> <li>Cost Optimization: Old data can be moved to cost-effective storage solutions.</li> </ul>"},{"location":"configuration/scaling/data_partitioning/#time-based-partitioning-in-tracardi","title":"Time-based Partitioning in Tracardi","text":"<p>Tracardi implements time-based partitioning for the following indices:</p> <ul> <li>Events</li> <li>Profiles</li> <li>Sessions</li> <li>Logs</li> </ul> <p>Each of these indices can be subdivided into different time frames, such as:</p> <ul> <li>Year: Groups all data collected within a single year into one index.</li> <li>Quarter: Segregates data into indices for each quarter within a year.</li> <li>Month: Divides data monthly, creating a separate index for each month.</li> <li>Day: Creates daily indices for a more granular approach to data segmentation.</li> </ul>"},{"location":"configuration/scaling/data_partitioning/#setting-up-partitioning","title":"Setting Up Partitioning","text":"<p>Partitioning is configured during the initial system setup through environmental variables and remains constant throughout the lifecycle of the system. Below are the default values for each partitioning strategy:</p> <ol> <li> <p><code>EVENT_PARTITIONING</code></p> <ul> <li>Description: This environment variable is used to determine the partitioning interval for event data.</li> <li>Default Value: <code>'month'</code> - If not set, events will be partitioned monthly.</li> </ul> </li> <li> <p><code>PROFILE_PARTITIONING</code></p> <ul> <li>Description: This variable sets the partitioning frequency for user profiles.</li> <li>Default Value: <code>'quarter'</code> - User profiles are partitioned quarterly by default.</li> </ul> </li> <li> <p><code>SESSION_PARTITIONING</code></p> <ul> <li>Description: This environment variable dictates the partitioning interval for session data.</li> <li>Default Value: <code>'quarter'</code> - Sessions will be partitioned every quarter if no other value is provided.</li> </ul> </li> <li> <p><code>ENTITY_PARTITIONING</code></p> <ul> <li>Description: It configures the partitioning strategy for entities.</li> <li>Default Value: <code>'quarter'</code> - Entities are set to be partitioned quarterly.</li> </ul> </li> <li> <p><code>ITEM_PARTITIONING</code></p> <ul> <li>Description: This environment variable specifies the partitioning schedule for items.</li> <li>Default Value: <code>'year'</code> - Items are partitioned annually.</li> </ul> </li> <li> <p><code>LOG_PARTITIONING</code></p> <ul> <li>Description: Determines how log data is partitioned.</li> <li>Default Value: <code>'month'</code> - Logs are partitioned on a monthly basis.</li> </ul> </li> <li> <p><code>DISPATCH_LOG_PARTITIONING</code></p> <ul> <li>Description: Configures the partitioning of dispatch logs, which likely refer to logs that record the   dispatching of events or profiles.</li> <li>Default Value: <code>'month'</code> - Dispatch logs follow a monthly partitioning strategy.</li> </ul> </li> <li> <p><code>CONSOLE_LOG_PARTITIONING</code></p> <ul> <li>Description: Sets the partitioning interval for console logs, possibly related to logs generated from a   workflow operations.</li> <li>Default Value: <code>'month'</code> - Console logs are partitioned monthly.</li> </ul> </li> <li> <p><code>USER_LOG_PARTITIONING</code></p> <ul> <li>Description: This variable is for partitioning logs related to user activities.</li> <li>Default Value: <code>'year'</code> - User activity logs are partitioned yearly.</li> </ul> </li> </ol> <p>These environment variables are designed to control the granularity of data partitioning in an application, with default values providing a fallback in case specific settings are not provided. The partitioning strategy can impact the performance and manageability of data, especially in systems that handle large volumes or require efficient querying capabilities.</p> <p>These environment variables control the time frame at which new indices are created and subsequently how the data is partitioned.</p>"},{"location":"configuration/scaling/data_partitioning/#considerations-for-data-volume","title":"Considerations for Data Volume","text":"<p>The frequency of data partitioning should correlate with the volume of data being processed:</p> <ul> <li>Higher Volumes: For larger datasets, it is recommended to partition more frequently to maintain optimal   performance and manageability.</li> <li>Lower Volumes: For smaller datasets, less frequent partitioning may be adequate and more cost-effective.</li> </ul> <p>Remember, once set, the partitioning intervals cannot be altered without reconfiguring and redeploying the system.</p>"},{"location":"configuration/scaling/installation_scaling/","title":"Scaling Commercial Tracardi","text":"<p>Scaling Tracardi involves three main aspects: Data Bulking, Tracardi Scaling, and Infrastructure Scaling. Understanding how Tracardi is built is essential for effectively scaling it. Tracardi ingests data through API calls, so the more data you send, the more it can process in one run.</p>"},{"location":"configuration/scaling/installation_scaling/#data-bulking","title":"Data Bulking","text":"<p>Tracardi allows multiple events to be sent per profile in one API call. This helps in optimizing the data ingestion process. If you gather events for one profile, you can send them in one API call. Tracardi's JavaScript library, by default, bulks the events registered on one page.</p>"},{"location":"configuration/scaling/installation_scaling/#how-to-send-bulk-events","title":"How to Send Bulk Events","text":"<p>Tracardi's API schema supports sending multiple events for one profile. Here is an example of an API bulk payload:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\"\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\"\n  },\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      }\n    },\n    // Multiple events for one profile\n    ...\n  ]\n}\n</code></pre>"},{"location":"configuration/scaling/installation_scaling/#tracardi-scaling","title":"Tracardi Scaling","text":"<p>Note</p> <p>Scaling may require several rounds of system adjustments. Please thoroughly test the configurations before going live. </p>"},{"location":"configuration/scaling/installation_scaling/#api-scaling","title":"API Scaling","text":"<p>Each API call takes time to process, so a single API instance has a limited number of calls it can handle. To handle more API calls, replicate the <code>tracardi-api</code> Docker container. Starting with at least 10 replicas is a good approach. The API sends data to Apache Pulsar, which is then consumed by background workers.</p> Example of Helm Chart values file. Param replicas will scale the number of private/public API<pre><code># API configuration\napi:\n  private:\n    replicas: 1  # Number of replicas for the private API\n\n  public:\n    replicas: 1  # Number of replicas for the public API (This is the API you need to scale for consumption) \n</code></pre>"},{"location":"configuration/scaling/installation_scaling/#scaling-background-workers","title":"Scaling Background Workers","text":"<p>To process data quickly, scale the number of background workers. Ensure there are enough workers to process data so that no data is left in the Apache Pulsar topic. Depending on the number of bulked events, you may need different numbers of background worker replicas.</p> Example of Helm Chart values file. Param replicas will scale the number of worker<pre><code># Worker configuration\nworker:\n  background:\n    replicas: 1  # Number of replicas for the background worker\n</code></pre> <p>Run a test and monitor the backlog of Apache Pulsar via the Tracardi API using the <code>/queue/{namespace}/{topic}/backlog</code> endpoint. This will tell you how quickly the data is consumed. The namespace and topic you want to monitor are <code>system</code> and <code>functions</code>, respectively. The response will look something like this:</p> <pre><code>{\n  \"total\": 0,\n  \"backlog\": [\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-0\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-2\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    ...\n  ]\n}\n</code></pre> <p>Ensure the <code>count</code> on each partition is low or equal to 0. This number tells how many messages are not consumed. Near realtime consumption will keep this number low.</p>"},{"location":"configuration/scaling/installation_scaling/#infrastructure-scaling","title":"Infrastructure Scaling","text":""},{"location":"configuration/scaling/installation_scaling/#apache-pulsar","title":"Apache Pulsar","text":"<p>Begin by scaling Pulsar. Refer to Apache Pulsar documentation for detailed scaling instructions.</p> <p>To scale Apache Pulsar, you need to focus on scaling its main components: brokers, bookies, and ZooKeeper nodes. Brokers handle client connections and manage topic partitions, so increasing the number of brokers improves load distribution and fault tolerance. Bookies store message data, so adding more bookies enhances storage capacity and write/read throughput. ZooKeeper nodes manage metadata and coordination; scaling them ensures higher availability and resilience of the cluster. Properly balancing and scaling these components ensures Apache Pulsar can efficiently handle increased traffic and data loads.</p>"},{"location":"configuration/scaling/installation_scaling/#elasticsearch","title":"Elasticsearch","text":"<p>By default, Tracardi saves events in bulks to Elasticsearch with a bulk size of 500 events. Monitor if the background workers are filling the predefined bulk size or if they trigger saving due to buffer timeout. Tracardi will save 500 events at once if they arrive within a specific timeframe (e.g., 30 seconds). If not, the buffer will be emptied, and only the collected events will be saved.</p> <p>To ensure Elasticsearch can handle the data, define the number of nodes and the number of shards for the event index. Changing the number of shards post-setup is not possible. When installing Tracardi use environment variables to configure at least one data replica and set up shards for each index. Look for <code>ELASTIC_INDEX_REPLICAS</code> and <code>ELASTIC_INDEX_SHARDS</code>.</p> <p>Proper scaling ensures that Tracardi can efficiently handle large volumes of data, providing a robust solution for commercial needs.</p>"},{"location":"configuration/scaling/installation_scaling/#production-installation-check-list","title":"Production installation check-list","text":"<p>Deploying a production environment of Tracardi requires careful planning and optimization to ensure that the system is efficient, scalable, and reliable. This article provides recommendations for deploying Tracardi in a production setting, covering key considerations to help you achieve an optimal setup.</p>"},{"location":"configuration/scaling/installation_scaling/#1-initial-production-setup-is-not-final","title":"1. Initial Production Setup Is Not Final","text":"<p>The first deployment of Tracardi in a production environment should be seen as a starting point rather than a final setup. It's crucial to continuously measure and tweak performance based on Key Performance Indicators (KPIs). This iterative process helps in identifying optimization opportunities in various components as discussed below.</p>"},{"location":"configuration/scaling/installation_scaling/#2-event-consumption","title":"2. Event Consumption","text":"<p>Understanding the volume of events your system will consume is foundational. The database, Tracardi's interaction with Apache Pulsar, API replicas, and worker configurations must all be adjusted based on the peak performance requirements. Start by establishing the maximum number of events you expect to process.</p>"},{"location":"configuration/scaling/installation_scaling/#3-elasticsearch-configuration","title":"3. ElasticSearch Configuration","text":"<p>ElasticSearch plays a critical role in Tracardi's performance. Deciding on the number of nodes, shards per index, and data replicas is essential. Remember, altering the number of shards post-setup can be challenging. Utilize Tracardi environment variables to configure at least one data replica and set up shards for each index. Please look for <code>ELASTIC_INDEX_REPLICAS</code>, and <code>ELASTIC_INDEX_SHARDS</code>.</p>"},{"location":"configuration/scaling/installation_scaling/#4-data-backup","title":"4. Data Backup","text":"<p>For ElasticSearch data, using S3 storage for backups is recommended. This should be defined during the ElasticSearch installation process to ensure data durability and availability. Please see Elasticsearch documentation for backup settings.</p>"},{"location":"configuration/scaling/installation_scaling/#5-data-partitioning","title":"5. Data Partitioning","text":"<p>Data partitioning is a critical strategy for managing large datasets. It involves dividing a database into distinct, parts to improve manageability, performance, and availability. Please see this documentation on data partitioning.</p>"},{"location":"configuration/scaling/installation_scaling/#5-data-retention-in-elasticsearch","title":"5. Data Retention in ElasticSearch","text":"<p>Determine how long data should reside on hot nodes, considering that ElasticSearch doesn't define cold nodes by default. Plan the transition of data from hot to warm and cold nodes, setting up a comprehensive data retention policy within ElasticSearch. Please see Elasticsearch documentation for nodes settings.</p>"},{"location":"configuration/scaling/installation_scaling/#6-apache-pulsar-data-policy","title":"6. Apache Pulsar Data Policy","text":"<p>Like ElasticSearch, Apache Pulsar requires a data retention policy that specifies the duration data is stored and the offloading process when data is no longer needed. S3 storage is a good option for offloading, with considerations for data deletion over time. Default retention policy is set to 30 days and 1GB of storage.</p>"},{"location":"configuration/scaling/installation_scaling/#7-apache-pulsar-configuration","title":"7. Apache Pulsar Configuration","text":"<p>Based on your traffic, decide on the number of brokers and bookies needed to handle the load efficiently. Regularly monitor Apache Pulsar's performance against your traffic to ensure it meets your requirements.</p>"},{"location":"configuration/scaling/installation_scaling/#8-tracardi-api-and-storage-workers","title":"8. Tracardi API and Storage Workers","text":"<p>Optimize the number of Tracardi API and storage workers based on your workload. These configurations directly impact data processing and storage efficiency.</p>"},{"location":"configuration/scaling/installation_scaling/#9-cache-and-database-connections","title":"9. Cache and Database Connections","text":"<p>Adjust cache times and MySQL connection pools as needed. For instance, modifying the <code>MYSQL_CONNECTION__POOL</code> variable and increasing MySQL connections can help manage load. Balancing API connections and cache TTLs can optimize performance.</p>"},{"location":"configuration/scaling/installation_scaling/#10-distributed-cache-configuration","title":"10. Distributed Cache Configuration","text":"<p>Ensure your Redis distributed cache has sufficient memory to handle the anticipated load. Testing with an estimated number of user profiles can help determine the required memory capacity.</p>"},{"location":"configuration/scaling/installation_scaling/#11-storage-workers-settings","title":"11. Storage Workers Settings","text":"<p>Define the optimal number of storage workers, which bulk and batch data for storage. The default setting is 500 records per batch, but this may need adjustment based on your specific needs.</p>"},{"location":"configuration/scaling/installation_scaling/#12-logging-level","title":"12. Logging Level","text":"<p>Set the logging level to \"warning\" by default to minimize data overhead. Detailed logging can significantly increase data volume and should be used selectively during system tuning phases. Please see <code>LOGGING_LEVEL</code> env variable.</p>"},{"location":"configuration/scaling/installation_scaling/#13-security","title":"13. Security","text":"<p>Set the <code>AUTO_PROFILE_MERGING</code> and <code>INSTALLATION_TOKEN</code> to your custom values.</p>"},{"location":"configuration/scaling/installation_scaling/#conclusion","title":"Conclusion","text":"<p>Deploying Tracardi in a production environment requires a detailed understanding of your performance needs and careful configuration of various components. By following these recommendations, you can create a robust and scalable system capable of handling your event processing and data management requirements efficiently. Continuously monitor and adjust your setup to ensure optimal performance as your needs evolve.</p>"},{"location":"configuration/staging/","title":"Staging server","text":"<p>A staging server is a type of server environment that is used to test and debug new settings/configuration changes before they are deployed to a production server. Tracardi has a clear separation of a test and production data. This allows developers to test and refine new settings in a safe and controlled environment, without impacting the performance or functionality of the live production website or application. It also allows QA Team to test the application before it goes to the production. This helps ensure that the configuration is stable and functioning properly before it is made available to end users. Overall, using a staging server helps to minimize the risk of errors or disruptions in a live production environment, and helps to ensure the quality and stability of the final product.</p>"},{"location":"configuration/staging/#tracardi-staging-server-deployment","title":"Tracardi staging server deployment","text":"<p>To deploy Tracardi on a staging server, a separate copy of the system must be installed and designated as such. This involves setting the \"PRODUCTION\" environment variable to \"no,\" which creates a new set of Elasticsearch indices. Additionally, the staging server should be exposed on a different port than the production server and ideally not accessible from the internet.</p>"},{"location":"configuration/staging/#tracardi-production-server-deployment","title":"Tracardi production server deployment","text":"<p>To deploy Tracardi on a production server, another copy of the system must be installed and configured with the \" PRODUCTION\" environment variable set to \"yes.\" This creates a new set of Elasticsearch indices prefixed with \"prod-\".</p>"},{"location":"configuration/staging/#staging-server-security-and-networking","title":"Staging server security and networking","text":"<p>The preferred settings for networking a staging server involve separating the staging and production servers by assigning different API IP addresses. This is done for security reasons, as the staging server should not be exposed to the internet and should only be accessible within the internal network, preferably through a VPN. This ensures that only the production collector endpoints are publicly available.</p> <p>Additionally, it is important to limit access to the production server by not having accounts with roles that allow changes to the server configuration. The best practice is to have a single admin account and only marketing accounts that can view data but not change any settings. This helps to prevent unauthorized access or changes that could potentially disrupt the production environment.</p>"},{"location":"configuration/staging/#licensing-commercial-version-of-tracardi","title":"Licensing commercial version of Tracardi","text":"<p>No need to worry about separate licenses for staging and production servers, all commercial licenses cover both servers.</p> <p>Tip</p> <p>When working with Tracardi the production server should not be edited directly. Instead, all changes should be made on the staging server and thoroughly tested before being deployed to the production system. This helps to minimize the risk of errors or disruptions in the live production environment.</p> <p>Once changes have been tested on the staging server, they can then be deployed to the production system. This is done by copying the data from the staging server to the production server. However, certain data such as events, profiles, or error logs will not be copied over during this process to ensure that the production server data remains intact.</p>"},{"location":"configuration/staging/#more-information","title":"More information","text":"<p>More information can be found at https://youtu.be/10W7OzezF_k</p>"},{"location":"development/","title":"Developing in Tracardi","text":"<p>Tracardi consists of multiple services and extension points that may require different development environments. Please review the list of available environments and select the one that aligns with your needs to extend Tracardi.</p>"},{"location":"development/#development-environments","title":"Development Environments","text":"<ul> <li>Tracardi API development environment</li> <li>Tracardi GUI development environment</li> </ul>"},{"location":"development/#building-docker","title":"Building docker","text":"<ul> <li>Building Tracardi Docker</li> <li>Building Tracardi Docker with SSL</li> </ul>"},{"location":"development/#tutorials","title":"Tutorials","text":"<ul> <li>Building Plugin</li> <li>Building Widget</li> <li>Building Resource</li> <li>Building Destination</li> </ul>"},{"location":"development/building_docker/","title":"Building Docker Image","text":"<p>Sometimes you will need to build a docker container yourself.  It is usually needed when you would like your docker server to run https requests. </p> <p>To build a docker container from source clone our repository</p> <pre><code>git clone https://github.com/tracardi/tracardi-api.git\n</code></pre> <p>Go to tracardi folder and run docker build</p> <pre><code>cd tracardi-api/\ndocker build . -t tracardi-api\n</code></pre> <p>After a while the docker will be built. It is on your computer, so you can run it like this.</p> <pre><code>docker run -p 8686:80 \\\n-e ELASTIC_HOST=http://&lt;elasticsearch-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\ntracardi/tracardi-api:&lt;last-version&gt; #(1)\n</code></pre> <ol> <li>Replace &lt;...-ip&gt; with your local laptop IP if the service is installed locally or with server IP where the service is installed. Replace  with the latest version. Do not use latest. <p>Replace &lt;...-ip&gt; with your laptop IP</p> <p>Notice that that you can not type <code>http://localhost:9200</code>. This means that you're connecting to the docker itself as localhost means local in docker. Obviously elastic  is not there, so Tracardi will never connect. Pass external ip for elastic.  This may be your laptop IP if you are running Tracardi locally.</p> <p>Tip</p> <p>On windows you can use <code>ipconfig</code> command to find out your laptop IP.</p>"},{"location":"development/building_ssl_docker/","title":"Build SSL Docker","text":""},{"location":"development/building_ssl_docker/#building-tracardi-api-with-ssl-certificates-embedded-into-docker","title":"Building Tracardi API with SSL certificates embedded into docker","text":"<p>Clone repository <code>tracardi/tracardi-api.git</code>.</p> <pre><code>git clone https://github.com/tracardi/tracardi-api.git\n</code></pre> <p>Next go to tracardi folder and find file Dockerfile.ssl-internal and type path to your SSL certificate and key file. </p> <ul> <li>Find and replace <code>ssl/key.pem</code> with a path to your key file</li> <li>Find and replace <code>ssl/cert.pem</code> with a path to your certificate</li> </ul> <p>This is how the Dockerfile.ssl-internal looks like</p> <pre><code>FROM tiangolo/uvicorn-gunicorn-fastapi\n\nRUN apt-get update\nRUN apt-get install -y git\n\n# set the working directory in the container\nRUN mkdir app/\nWORKDIR /app\n\n## Install dependencies\nCOPY app/requirements.txt .\nRUN pip install -r requirements.txt\n\n## Copy application\nCOPY app app/\nCOPY ssl ssl/\nCOPY docs manual/\nENV VARIABLE_NAME=\"application\"\n\nEXPOSE 443\nCMD [\"gunicorn\", \"-b\", \"0.0.0.0:443\", \"--workers\", \"25,\"--keyfile\", \"ssl/key.pem\", \"--certfile\", \"ssl/cert.pem\", \"-k\", \"uvicorn.workers.UvicornWorker\", \"app.main:application\"]\n</code></pre> <p>If you would like to tweak the number of workers running change <code>--workers</code> option in <code>gunicorn</code>.</p> <p>Then run</p> <pre><code>cd tracardi-api/\ndocker build . -f Dockerfile.ssl-internal -t tracardi-api-ssl\n</code></pre> <p>Once built you can run Tracardi with the following command:</p> Run docker and open port 8686<pre><code>docker run -p 8686:443 \\\n-e ELASTIC_HOST=http://&lt;elasticsearch-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\ntracardi/tracardi-api-ssl:&lt;last-version&gt; #(1)\n</code></pre> <ol> <li>Replace &lt;...-ip&gt; with your local laptop IP if the service is installed locally or with server IP where the service is installed. Replace  with the latest version. Do not use latest. <p>This will make API available at https://localhost:8686. If you want it on the standard HTTPS port run:</p> Run docker and open port 443<pre><code>docker run -p 443:443 \\\n-e ELASTIC_HOST=http://&lt;elasticsearch-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\ntracardi/tracardi-api-ssl:&lt;last-version&gt; #(1)\n</code></pre> <ol> <li>Replace &lt;...-ip&gt; with your local laptop IP if the service is installed locally or with server IP where the service is installed. Replace  with the latest version. Do not use latest. <p>And the API will be available https://localhost.</p>"},{"location":"development/tutorial/destination/","title":"Code Destination","text":"<p>Integrating a new destination type in Tracardi enhances its functionality and customizability. This comprehensive guide provides a step-by-step approach to adding a new destination type, using Apache Pulsar as an example.</p>"},{"location":"development/tutorial/destination/#detailed-steps","title":"Detailed Steps","text":""},{"location":"development/tutorial/destination/#step-1-locate-the-destination-code","title":"Step 1: Locate the Destination Code","text":"<ul> <li>The destination code resides in <code>tracardi/process_engine/destination</code>.</li> </ul>"},{"location":"development/tutorial/destination/#step-2-extend-destinationinterface","title":"Step 2: Extend <code>DestinationInterface</code>","text":"<ul> <li>Your new destination class should extend <code>DestinationInterface</code>.</li> <li>This interface offers a foundational structure for your destination class.</li> </ul> <pre><code>class DestinationInterface:\n    # Constructor with essential parameters\n    def __init__(self, debug: bool, resource: Resource, destination: Destination):\n        # Initialization of properties\n        self.destination = destination\n        self.debug = debug\n        self.resource = resource\n\n    # Method to dispatch data to profiles\n    async def dispatch_profile(self, data, profile: Profile, session: Session):\n        pass\n\n    # Method to dispatch data on events\n    async def dispatch_event(self, data, profile: Profile, session: Session, event: Event):\n        pass\n</code></pre>"},{"location":"development/tutorial/destination/#step-3-implement-required-methods","title":"Step 3: Implement Required Methods","text":"<ul> <li>Implement <code>dispatch_profile</code> and <code>dispatch_event</code> methods to manage data dispatching to the destination.</li> </ul>"},{"location":"development/tutorial/destination/#step-4-understand-the-class-properties","title":"Step 4: Understand the Class Properties","text":"<ul> <li><code>Resource</code>: Manages user-selected resource settings. See How to add resource for more details on how to add new resources if they are not defined already in the system.</li> <li><code>Destination</code>: Handles user-defined destination details.</li> <li><code>debug</code>: Indicates the debug mode status.</li> </ul>"},{"location":"development/tutorial/destination/#step-5-utilize-destination-object-properties","title":"Step 5: Utilize Destination Object Properties","text":"<ul> <li><code>package</code>: Name of the destination package.</li> <li><code>init</code>: Parameters for initializing destination configuration.</li> <li><code>form</code>: Form data structure.</li> <li><code>description</code>: Describes the destination.</li> <li><code>enabled</code>: Status of activation.</li> <li><code>tags</code>: Tags for categorization.</li> <li><code>mapping</code>: Details of data mapping.</li> <li><code>condition</code>: Conditions for triggering.</li> <li><code>on_profile_change_only</code>: Triggers on profile changes.</li> <li><code>resource</code>: Linked resource information.</li> <li><code>event_type</code>: Type of associated event.</li> <li><code>source</code>: Source entity details.</li> </ul>"},{"location":"development/tutorial/destination/#step-6-create-a-pulsar-credentials-object-and-pulsar-topic","title":"Step 6: Create a Pulsar Credentials Object and Pulsar topic.","text":"<p>We will need some objects in our example to keep the necessary data. We will need pulsar credentials to connect to credential server, and pulsar topic.</p> <ul> <li>Define an object to store Apache Pulsar connection details.</li> </ul> <pre><code>class PulsarCredentials(BaseModel):\n    host: str\n    token: Optional[str] = None\n</code></pre> <ul> <li>Create an object for configuring Apache Pulsar topics.</li> </ul> <pre><code>class PulsarTopicConfiguration(BaseModel):\n    topic: str\n</code></pre>"},{"location":"development/tutorial/destination/#step-7-develop-the-pulsar-connector","title":"Step 7: Develop the Pulsar Connector","text":"<ul> <li>Implement the Pulsar connector class to handle communication with Apache Pulsar.</li> </ul> <pre><code>class PulsarConnector(DestinationInterface):\n    def _dispatch(self, payload):\n        # Exception handling and setup for Pulsar client\n        try:\n            # Credential selection based on debug mode\n            credentials = self.resource.credentials.test if self.debug else self.resource.credentials.production\n            credentials = PulsarCredentials(**credentials)\n\n            # Retrieve and apply destination configuration\n            init = self.destination.destination.init\n            config = PulsarTopicConfiguration(**init)\n\n            # Setting up the Apache Pulsar client\n            if credentials.token:\n                client = pulsar.Client(\n                    credentials.host,\n                    authentication=pulsar.AuthenticationToken(credentials.token)\n                )\n            else:\n                client = pulsar.Client(\n                    credentials.host\n                )\n            producer = client.create_producer(config.topic)\n            payload = json.dumps(\n                    payload,\n                    default=str\n                ).encode('utf-8')\n            producer.send(payload)\n\n        except Exception as e:\n            logger.error(str(e))\n            raise e\n\n    async def dispatch_profile(self, mapped_data, profile: Profile, session: Session):\n        self._dispatch(mapped_data)\n\n    async def dispatch_event(self, mapped_data, profile: Profile, session: Session, event: Event):\n        self._dispatch(mapped_data)\n</code></pre>"},{"location":"development/tutorial/destination/#detailed-description","title":"Detailed Description","text":"<ul> <li><code>_dispatch</code> method: Manages the data sending process to Pulsar. When you develop your destination here you may code the logic of your destination plugin. Usually it will be some connection to external system. </li> <li>Authentication: Uses <code>PulsarCredentials</code> for Pulsar connection.</li> <li>Credential Selection: Chooses credentials based on <code>debug</code> mode.</li> <li>Configuration: Retrieves settings from <code>PulsarTopicConfiguration</code>.</li> <li>Connection: Establishes a Pulsar client and sends the payload.</li> </ul>"},{"location":"development/tutorial/destination/#sending-message-to-pulsar","title":"Sending Message to Pulsar","text":"<pre><code># Get Client\nif credentials.token:\n    client = pulsar.Client(\n        credentials.host,\n        authentication=pulsar.AuthenticationToken(credentials.token)\n    )\nelse:\n    client = pulsar.Client(\n        credentials.host\n    )\n\n# Get producer\nproducer = client.create_producer(config.topic)\n\n# Encode payload\npayload = json.dumps(\n    payload,\n    default=str\n).encode('utf-8')\n\n# Send\nproducer.send(payload)\n</code></pre> <ul> <li>This code establishes the Apache Pulsar client and dispatches the payload to the specified topic.</li> </ul>"},{"location":"development/tutorial/destination/#conclusion","title":"Conclusion","text":"<p>Following this tutorial, you can effectively set up a new destination type in Tracardi, exemplified here with Apache Pulsar. Ensure your implementation complies with the <code>DestinationInterface</code> and its requirements. For further guidance, consult existing destination types or the Tracardi documentation for more insights.</p>"},{"location":"development/tutorial/resource/","title":"Code Resource","text":"<p>This tutorial will guide you through adding a new resource setting to Tracardi. As an example, we will add a setting for an Apache Pulsar client, which connects to a queue and publishes messages. This is part of a larger tutorial on adding a destination, another extension of the system.</p>"},{"location":"development/tutorial/resource/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"development/tutorial/resource/#1-understanding-resource-configuration","title":"1. Understanding Resource Configuration","text":"<p>All resources in Tracardi are defined in a file called <code>setup_resource</code>, which contains the schema for resource settings. This file is located in the <code>tracardi/service/setup</code> folder.</p>"},{"location":"development/tutorial/resource/#2-examining-an-example","title":"2. Examining an Example","text":"<p>Here's an example function that shows available resources:</p> <pre><code>def get_resource_types() -&gt; List[ResourceSettings]:\n    os_resource_types = [\n        ResourceSettings(id=\"api-key\", ...),\n        ResourceSettings(id=\"web-page\", ...),\n        ...\n    ]\n</code></pre>"},{"location":"development/tutorial/resource/#3-determining-required-data","title":"3. Determining Required Data","text":"<p>First, figure out the data needed to connect your resource. For Apache Pulsar, the client needs a host and token:</p> <p>This is the example code that we will need to run later when using the resource setting. We can see that host and token are required.</p> <pre><code>client = pulsar.Client(\n    host,\n    authentication=pulsar.AuthenticationToken(token)\n)\n</code></pre>"},{"location":"development/tutorial/resource/#4-adding-a-resource-setting","title":"4. Adding a Resource Setting","text":"<p>Now, add a resource setting for Apache Pulsar at the end of <code>os_resource_types</code>:</p> <pre><code>ResourceSettings(\n    id='apache-pulsar',\n    config={\n        'host': '&lt;host:port&gt;',\n        'token': '&lt;token&gt;'\n    },\n    icon='pulsar',\n    tags=['pulsar', 'apache', 'queue'],\n    name='Apache Pulsar',\n    manual='apache_pulsar_resource',\n)\n</code></pre>"},{"location":"development/tutorial/resource/#5-finalizing-the-list","title":"5. Finalizing the List","text":"<p>The updated list of resources will now include Apache Pulsar:</p> <pre><code>def get_resource_types() -&gt; List[ResourceSettings]:\n    os_resource_types = [\n        ResourceSettings(id=\"api-key\", ...),\n        ResourceSettings(id=\"web-page\", ...),\n        ...\n        ResourceSettings(\n            id='apache-pulsar',\n            config={\n                'host': '&lt;host:port&gt;',\n                'token': '&lt;token&gt;'\n            },\n            icon='pulsar',\n            tags=['pulsar', 'apache', 'queue'],\n            name='Apache Pulsar',\n            manual='apache_pulsar_resource'\n        )\n    ]\n</code></pre>"},{"location":"development/tutorial/resource/#6-configuring-resourcesettings","title":"6. Configuring <code>ResourceSettings</code>","text":"<ul> <li><code>id</code>: Unique identifier, use resource name with dashes.</li> <li><code>config</code>: The required data. This will be resented to the user to fill out.</li> <li><code>icon</code>: Name of the resource.</li> <li><code>tags</code>: Keywords for searching the resource.</li> <li><code>manual</code>: Location of the resource documentation.</li> </ul>"},{"location":"development/tutorial/resource/#7-creating-documentation","title":"7. Creating Documentation","text":"<p>Create a simple documentation file named <code>apache_pulsar_resource.md</code> with the following content:</p> <pre><code>Apache Pulsar is a free, open-source platform for distributed messaging and data streaming...\n</code></pre> <p>Place this file in the <code>tracardi-api</code> repository under <code>docs/resources</code>. It's referenced in <code>ResourceSettings</code> and displayed when creating the resource.</p>"},{"location":"development/tutorial/resource/#conclusion","title":"Conclusion","text":"<p>That's it! You've successfully added a new resource to Tracardi. Now, when you go to resources, you should see your new resource in the dropdown list. If you need any additional resources for your plugin or destination, follow these steps to add them to the system.</p>"},{"location":"development/tutorial/widget/","title":"Code Widgets","text":"<p>Tracardi uses micro application (widgets) to interact with customers. Micro-apps are regular ReactJs, or Angular, or plain Javascript apps that can be bundled into single javascript file and injected into the webpage.</p> <p>We use a ReactJs template repo for new ReactJs app.</p> <p>To start developing Micro Frontend App use the tracardi-uix-template on http://github.com/tracardi/tracardi-uix-template</p> <ol> <li>Goto http://github.com/tracardi/tracardi-uix-template</li> <li>Click button Use this template. Big green button at the top right side of the screen. </li> <li>Enter the name of your repository</li> </ol> <p>This will create a repo with files needed to start working on the app. Now its time to clone the repo and enter its folder and type</p> <p><code>npm install</code></p> <p>This will install all the required dependencies.</p> <p>Tip</p> <p>If you would like to cooperate with other contributors on this app or want the repo to be part of Tracardi organization on the GitHub let us know (on our Slack workspace). We will create a repo that you can fork.</p>"},{"location":"development/tutorial/widget/#source-code","title":"Source code","text":"<p>Now, let's inspect the repo folders and find out what we have here:</p> <p>There are two main folders:</p> <ul> <li>public - it holds the index.html file that you can use later for testing your micro-frontend-app</li> <li>src - this is where is your code. We will inspect this folder further below</li> </ul> <p>The other files are <code>package.js</code> and <code>README.md</code> with installation tips. </p> <p>Tip</p> <p>Please edit the app name in package.js.  <code>{\"name\": \"&lt;name-widget&gt;\", ...}</code></p>"},{"location":"development/tutorial/widget/#source-folder","title":"Source folder","text":"<p>Inside <code>src</code> folder you will find a <code>index.js</code> file. This is where your app starts. Please change the </p> <pre><code>const widgetName = 'tracardi-uix-your-name'\n</code></pre> <p>to have the name of your app. </p> <p>Then there is <code>App.js</code>. This is the injected micro-frontend-app. Notice that it takes the domElement.</p> App.js<pre><code>import React from 'react';\nimport \"regenerator-runtime/runtime\";\n\nfunction App({domElement}) {  // (1)\n\n    const attribute = domElement.getAttribute(\"data-attribute1\") || \"I am test attribute\"\n    return &lt;h1&gt;\"Hello world \" + {attribute}&lt;/h1&gt;\n\n}\n\nexport default App;\n</code></pre> <ol> <li>Dom parameter used to read the configuration of the micro-frontend-app. The configuration will be filled in Tracardi and passed as data attributes.  </li> </ol> <p>This is because we need some way to pass the parameters to the app. And it is done by defining them inside the dom elements like this.</p> This is the example form index.html<pre><code>&lt;div class=\"tracardi-uix-your-name\" data-attribute1=\"my-attribute1\" data-attribute2=\"my-attribute1\"&gt;&lt;/div&gt;\n&lt;script src=\"widget/index.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Tip</p> <p>Please notice that the class of the <code>div</code> must be the same as the application name defined in the <code>index.js</code> file. See below.</p>"},{"location":"development/tutorial/widget/#connecting-the-app-container-with-the-code","title":"Connecting the app container with the code","text":"<p>You will need to define connection between the HTML and your app. The <code>src/index.js</code> file is responsible for this. It is done in <code>const widgetName = 'tracardi-uix-your-name'</code> and <code>const widgetDivs = document.querySelectorAll('.'+widgetName)</code> line. You also need to reference this name in <code>index.html</code>. See the class of a div.</p> src/index.jspublic/index.html <pre><code>import React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\n\nconst widgetName = 'tracardi-uix-your-name'  // (1)\nconst widgetDivs = document.querySelectorAll('.'+widgetName)\n\nwidgetDivs.forEach(Div =&gt; {\n    ReactDOM.render(\n        &lt;React.StrictMode&gt;\n            &lt;App domElement={Div} /&gt;\n        &lt;/React.StrictMode&gt;,\n        Div\n    );\n})\n</code></pre> <ol> <li>Your app placeholder class name. Please change it to yout app name and prefix it with: <code>tracardi-uix-</code>. This name must also be a class name for div tag in <code>index.html</code></li> </ol> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;!-- (1) --&gt;\n    &lt;div class=\"tracardi-uix-your-name\" data-attribute=\"my-attribute\"&gt;&lt;/div&gt; \n    &lt;script src=\"../widget/index.js\"&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <ol> <li>Class name of <code>div</code> must be the same as <code>widgetName</code> in src/index.js</li> </ol>"},{"location":"development/tutorial/widget/#building-micro-frontend-app","title":"Building micro frontend app","text":"<p>When you are done, use <code>yarn build:widget</code> to generate the micro frontend JS file. The build operation should create index.js file in a widget folder.</p>"},{"location":"development/tutorial/widget/#micro-frontend-app-design","title":"Micro frontend app design","text":"<p>Most apps triggered on the customers pages are popup apps so make sure you use some popup canvas, or a drawer where you place your app.</p> <p>Info</p> <p>We use material-ui for this but this is up to you how you handle it.</p> <p>Here is a simple example of an App where we use Snackbar from material-ui to display content.</p> <pre><code>import React, {useState} from 'react';\nimport Snackbar from '@mui/material/Snackbar';\nimport Box from \"@mui/material/Box\";\nimport {Button, Typography} from \"@mui/material\";\n\nfunction App({domElement}) {\n\n    const title = domElement.getAttribute(\"data-title\") || null\n    const message = domElement.getAttribute(\"data-message\") || null\n    const ctaLabel = domElement.getAttribute(\"data-cta-button\") || null\n    const ctaLink = domElement.getAttribute(\"data-cta-link\") || null\n    const cancelLabel = domElement.getAttribute(\"data-cancel-button\") || null\n    const vertical = domElement.getAttribute(\"data-vertical\") || \"bottom\"\n    const horizontal = domElement.getAttribute(\"data-horizontal\") || \"right\"\n    const autoHide = domElement.getAttribute(\"data-auto-hide\") || \"60000\"\n    const borderRadius = domElement.getAttribute(\"data-border-radius\") || \"2\"\n    const borderShadow = domElement.getAttribute(\"data-border-shadow\") || \"1\"\n    const minWidth = domElement.getAttribute(\"data-min-width\") || \"300\"\n    const maxWidth = domElement.getAttribute(\"data-max-width\") || \"500\"\n\n    const [open, setOpen] = useState(true)\n\n    const handleClose = (event, reason) =&gt; {\n        if (reason === 'clickaway') {\n            return;\n        }\n\n        setOpen(false);\n    };\n\n    return (\n        &lt;Snackbar open={open} autoHideDuration={autoHide}\n                  onClose={handleClose}\n                  anchorOrigin={{vertical, horizontal}}\n        &gt;\n            &lt;Box\n                sx={{\n                    bgcolor: 'background.paper',\n                    boxShadow: parseInt(borderShadow),\n                    borderRadius: parseInt(borderRadius),\n                    p: 2,\n                    minWidth: parseInt(minWidth),\n                    maxWidth: parseInt(maxWidth)\n                }}\n            &gt;\n                &lt;Box sx={{padding: 1}}&gt;\n                    {title &amp;&amp; &lt;Typography variant=\"h5\" style={{color: \"black\"}}&gt;{title}&lt;/Typography&gt;}\n                    {message &amp;&amp; &lt;Typography style={{color: \"black\"}}&gt;{message}&lt;/Typography&gt;}\n                &lt;/Box&gt;\n\n                {ctaLabel &amp;&amp; &lt;Box sx={{\n                    display: \"flex\",\n                    justifyContent: \"center\",\n                    padding: 1\n                }}&gt;\n                    {ctaLabel &amp;&amp; &lt;Button variant={\"contained\"} href={ctaLink} style={{margin: \"0 5px\"}}&gt;\n                        {ctaLabel}\n                    &lt;/Button&gt;}\n                    {cancelLabel &amp;&amp; &lt;Button variant={\"outlined\"} onClick={handleClose}&gt;\n                        {cancelLabel}\n                    &lt;/Button&gt;}\n                &lt;/Box&gt;}\n\n            &lt;/Box&gt;\n        &lt;/Snackbar&gt;\n    );\n}\n\nexport default App;\n</code></pre> <p>You can also use other overlays from material design like modal,etc. If material-ui is not your thing you may use any other library. It is your choice.</p>"},{"location":"development/tutorial/widget/#testing","title":"Testing","text":"<p>You can also test the react app as regular app with <code>yarn start</code>. When the app is finished, you will have to bundle it and open on the <code>index.html</code> in your browser and see if it loads.</p>"},{"location":"development/tutorial/widget/#testing-bundled-app-file","title":"Testing bundled app file","text":"<p>First you will have to build the app with <code>yarn build:widget</code>. It will create a index.js file in widget folder. </p> <p>To test if your app works as micro-app paste the bundled file <code>widget/index.js</code> into a regular HTML page. </p> <p>Tip</p> <p>You do not have to create index.html by your self. We have one created for you in the repo in the public directory. It is called <code>index.html</code>. Paste the script tag together with the configuration inside  the body of the <code>index.html</code> and open the file. </p> This is an example public/index.html from one of our micro-apps<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\" /&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;noscript&gt;You need to enable JavaScript to run this app.&lt;/noscript&gt;\n\n    &lt;!-- (1) --&gt;\n    &lt;div class=\"tracardi-uix-cta-message\"\n         data-title=\"title\"\n         data-message=\"message\"\n         data-cta=\"visit\" data-cancel=\"\"\n         data-auto-hide=\"50000\"\n    &gt;&lt;/div&gt;\n\n    &lt;!-- (2) --&gt;\n    &lt;script src=\"../widget/index.js\"&gt;&lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <ol> <li>The app container with the configuration in data attributes. Please notice that the class of the <code>div</code> must be    the same as the application name defined in the <code>index.js</code> file.</li> <li>The bundled app script</li> </ol> <p>Now open the index.html in the browser, and it should load your app and display it on top of the existing index.html. If the index.html does not have any html then it will be empty as in our example.</p>"},{"location":"development/tutorial/widget/#how-tracardi-injects-the-app","title":"How Tracardi injects the app","text":"<p>Tracardi loads the app the same as we did it in the test example above. That means with a script tag and a div container. It appends the needed tags at the bottom of the page. Like this.</p> This is the example form index.html<pre><code>&lt;div class=\"tracardi-uix-your-name\" data-attribute=\"my-attribute\"&gt;&lt;/div&gt;\n&lt;script src=\"widget/index.js\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"development/tutorial/widget/#passing-data-from-tracardi-to-micro-app","title":"Passing data from Tracardi to micro app","text":"<p>The micro app may need configuration. For example the pop-up message app needs message and maybe location of the pop-up window. To configure the app and pass data from Tracardi use <code>data attributes</code>. It can be done in <code>src/App.js</code></p> src/App.jsindex.html <pre><code>import React from 'react';\nimport \"regenerator-runtime/runtime\";  // (3)\n\nfunction App({domElement}) {\n\n    const attribute1 = domElement.getAttribute(\"data-attribute-1\") || \"I am test attribute 1\"  // (1)\n    const attribute2 = domElement.getAttribute(\"data-attribute-2\") || \"I am test attribute 2\"  // (2)\n    return &lt;h1&gt;\"Hello world \" + {attribute}&lt;/h1&gt;\n\n}\n\nexport default App;\n</code></pre> <ol> <li>This is your app input data. Read it like this, and then you can use <code>attribute1</code> variable in you app. See index.html on how to pass data.</li> <li>This is your app input data. Read it like this, and then you can use <code>attribute2</code> variable in you app.</li> <li>This import may be needed when you use async functions. See Trouble-shooting below.</li> </ol> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;div class=\"tracardi-uix-your-name\" \n         data-attribute-1=\"my-attribute-1\"\n         data-attribute-2=\"my-attribute-2\"&gt;&lt;/div&gt;\n    &lt;script src=\"widget/index.js\"&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"development/tutorial/widget/#troubleshooting","title":"Troubleshooting","text":"<p>If you use async functions in your app (what is very probable) you may encounter the problem that the app does not build when build with <code>yarn build:widget</code>. Then follow the tip below.</p> <p>regeneratorRuntime is not defined error</p> <p>When you see \"regeneratorRuntime is not defined\" that means you have to add <code>import \"regenerator-runtime/runtime\";</code> to your component.</p>"},{"location":"development/tutorial/plugin/","title":"Code Workflow Plug-ins","text":"<p>Plug-ins are python classes which can be installed in Tracardi and become a part of Tracardi workflow. Plug-ins are sometimes called actions or action plug-ins.</p> <p>Below you will find information how to write plug-ins and how to install them in the system.</p>"},{"location":"development/tutorial/plugin/#plug-in-prerequisites","title":"Plug-in prerequisites","text":"<ul> <li>Plug-in must return <code>Result</code> object. </li> <li>Value inside <code>Result</code> object must be serializable to json.</li> <li>Value can not be bigger than x bytes.</li> <li>Value inside <code>Result</code> should be <code>dict</code> in order to be processed by other nodes.</li> <li>Plug-in must extend <code>ActionRunner</code> class.</li> <li>Resources that need closing should be closed in <code>close()</code> method.</li> <li>Async Method <code>set_up</code> should be used to initiate async objects.</li> </ul>"},{"location":"development/tutorial/plugin/#plugin-tutorials","title":"Plugin tutorials","text":"<ul> <li>Coding a plugin</li> <li>Configuring the plugin</li> <li>Referencing data in the plugin</li> </ul>"},{"location":"development/tutorial/plugin/form/list_of_field_types/","title":"List of available form field types","text":"<p>The following field types can be used in plugin's forms:</p> <ul> <li>readOnlyTags</li> <li>eventTypes</li> <li>eventType</li> <li>resource</li> <li>dotPath</li> <li>forceDotPath</li> <li>keyValueList</li> <li>copyTraitsInput</li> <li>listOfDotPaths</li> <li>text</li> <li>json</li> <li>sql         </li> <li>textarea      </li> <li>select</li> <li>bool          </li> <li>contentInput</li> </ul> <p>The list of form fields is getting bigger with every Tracardi release.</p>"},{"location":"development/tutorial/plugin/part/part1/","title":"Part 1: Code simple plugin in Tracardi","text":"<p>Beginner Programmer's Guide</p> <p>So, you would like to know how to add a new item to a workflow in the Tracardi system. This article describes how a python programmer can extend Tracardi with new functions with so-called plugins.</p>"},{"location":"development/tutorial/plugin/part/part1/#introduction","title":"Introduction","text":"<p>Event handling in Tracardi is based on a workflow, which consists of individual actions visualized as nodes in the workflow. Workflow control when each action/node should be triggered. The action consists of an input, a program that computes the input data, and an output (the result of the program computation). In tracardi, an action can have one input and many outputs. In addition, the action has a configuration, it is a set of data that define how the program should behave, Let's assume that we want to connect to external resources of some database, it is in the configuration that we will have information about where this database is, and what username and password to use to connect to the resource.</p> <p>Due to the fact that Tracardi can have many outputs, we must somehow indicate on which output our data should appear. That's why Tracardi introduces concepts such as a port. Thanks to them, we can indicate where the data will be returned. The port that will not receive the data (returns the None value) causes that the workflow will not be performed in this branch of the workflow.</p>"},{"location":"development/tutorial/plugin/part/part1/#development-environment","title":"Development environment","text":"<p>Info</p> <p>To start working with the system, we need to prepare a development environment. Refer to the Python development environment and read how to do this.</p>"},{"location":"development/tutorial/plugin/part/part1/#plugin-life-cycle","title":"Plugin life-cycle","text":"<p>Plugins go through a life-cycle in which they are created, executed and recycled.</p> <p>Workflow controls this process. When a workflow is created, the system recognizes which classes will be needed to start the process defined in the data flow graph.</p> <p>The process is as follows. The workflow checks what class is assigned to the node in the graph and checks if it exists. It then creates its instances by running the parameterless <code>__init__</code> method of that class.</p> <p>It then checks to see if there is an async set_up method. It passes the plug-in configuration to it. The configuration is stored inside the node and is defined during plug-in registration (more on that in a moment). Then the workflow executes nodes in the graph one by one and runs the <code>run(self, payload: dict, in_edge=None)</code> method, passing to it the parameters that appeared at the input to the node and the additional information on the connection from the previous node.</p> <p>When the workflow exits, it executes the close method on each node.</p> <p>In summary, we have the following methods in the plugin class.</p> <pre><code>    __init__()  # (1)\n    async set_up(config)  # (2)\n    async run(input_payload)  # (3)\n    async close()  # (4)\n</code></pre> <ol> <li>Initializes the plugin object</li> <li>Set-ups the configuration and async resources</li> <li>Gets the input payload as dictionary and runs the plugin, also returns results on ports</li> <li>Closes async resources</li> </ol> <p>Info</p> <p>Please click (+) to see the comments for the code</p>"},{"location":"development/tutorial/plugin/part/part1/#our-first-plugin","title":"Our first plugin","text":"<p>We already have all the information so let's try to write the first plugin.</p> <p>All plugins inherit from the ActionRunner class. This class stores the internal state of the workflow, i.e. elements such as event data, profiles, etc. They can be useful for us while writing our plugin. Let's assume the simplest case, we would like our workflow to react to the type of event that is sent to our system. It will check if the event is of the type \"my-event\" and then it will return data from the input on the output named \"MyEvent\" otherwise it will return empty data on the port \"NotMyEvent\". Of-course we could use the built-in IF node, but we want to write our own.</p>"},{"location":"development/tutorial/plugin/part/part1/#lets-begin","title":"Let\u2019s begin","text":"<p>Theoretically, we should complete all the methods described above, but in our case not all are needed. We don't have configuration, so set_up method is not needed, we don't have connection to external systems, so close method is not needed either, we don't have an internal state of class, so <code>__init__</code> will be empty.</p> <p>Before we start, let's create a file in which we will write the code. The Tracardi plugins are in the directory: <code>/tracardi/process_engine/action/v1</code>. You can create your own catalog there or use an existing one. I will create my_plugin_folder directory and put my_plugin.py file in it.</p>"},{"location":"development/tutorial/plugin/part/part1/#now-the-code","title":"Now the code.","text":"<p>Our plugin could look like this:</p> /tracardi/process_engine/action/v1/my_plugin_folder/my_plugin.py <pre><code>from tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\n\nclass MyPlugin(ActionRunner):  # (1)\n    async def run(self, payload: dict, in_edge=None):  # (2)\n        if self.event.type == \"my-event\":\n            return Result(port=\"MyEvent\", value=payload)  # (3)\n        else:\n            return Result(port=\"NotMyEvent\", value={})  # (4)\n</code></pre> <ol> <li>Extends ActionRunner class</li> <li>Runs the plugin</li> <li>Returns the input payload data on the \"MyEvent\" port </li> <li>Returns the empty dictionary on the \"NotMyEvent\" port </li> </ol> <p>Note that we return the data using the <code>Result</code> class in which we provide the port name and value.</p> <p>The only thing left for us to do is to describe the plugin in the system. This is done by defining a function called <code>register</code>. It contains the specification of the plugin that we wrote (it returns the plugin class) and the type metadata, with the input and output ports, the name of the plugin, etc.</p> <p>The register function can be placed in the same file as the plugin or in any other file. I am placing it in the same file.</p>"},{"location":"development/tutorial/plugin/part/part1/#example","title":"Example:","text":"/tracardi/process_engine/action/v1/my_plugin_folder/my_plugin.py <pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData\n\ndef register() -&gt; Plugin:\n    return Plugin(   # (1)\n        start=False,\n        spec=Spec(  # (2)\n            module=__name__,  # (4)\n            className=MyPlugin.__name__,\n            inputs=[\"payload\"],\n            outputs=[\"MyEvent\", \"NotMyEvent\"],\n            version='0.1',\n            license=\"MIT\",\n            author=\"Your Name\"\n        ),\n        metadata=MetaData(  # (3)\n            name=\"My first plugin\",\n            desc='Checks if the event type is equal to my-event.',\n            group=[\"Test plugin\"]\n        )\n    )\n</code></pre> <ol> <li>Returns Plugin class</li> <li>Sets spec property as Spec class</li> <li>Sets metadata property as Metadata class</li> <li>Sets <code>__name__</code> because refister is in the same file as plugin: e.i. <code>/tracardi/process_engine/action/v1/my_plugin_folder/my_plugin.py</code></li> </ol> <p>Let's analyze this code. It returns a plugin class that has the following properties.</p> <ul> <li>start - sets whether the workflow can start from this node. In 99% of cases, we put <code>False</code> here. The startup   nodes are already built into the system.</li> <li>spec - describes the plugin specification, i.e. what class is to be run and what ports it contains on input and   output. There can only be one port on input. In our case, we have the following data:<ul> <li>module - where is the class package. <code>__name__</code> means that the class is in the same file as the register   method.   If we separate the plugin and register function, then you need to enter the package name of the plugin here, e.g.   <code>tracardi.process_engine.action.v1.my_plugin_folder</code></li> <li>className - the name of the class. We named it MyPlugin. See class <code>MyPlugin (ActionRunner)</code></li> <li>inputs - list with the names of the input ports. There can only be one input port.</li> <li>outputs - list with names of output ports. Here we define what ports we have. Port names can have any name you   like. Remember, however, that they must correspond to what the code returns and our code returns, one   time: <code>Result (port=\"MyEvent\", value=payload)</code> and another time <code>Result (port=\"NotMyEvent\", value={})</code>, i.e.    possible output ports are <code>[\"MyEvent\", \"NotMyEvent\"]</code></li> <li>version - enter the plugin version here</li> <li>license - license type, Tracardi is able to attach the plug-in only under the <code>MIT</code> or <code>Apache 2.0</code> license</li> <li>author - author's first and last name</li> </ul> </li> <li>metadata - contains additional data about the plugin.<ul> <li>name - the name of the plugin to be displayed on the workflow graph</li> <li>desc - a short description of what the plugin does</li> <li>group - plugins are displayed in groups. The name of the group in which the plug-in is to be displayed on the   plug-in list. The name can be any or one of the existing names.</li> </ul> </li> </ul>"},{"location":"development/tutorial/plugin/part/part1/#automatic-plug-in-loading","title":"Automatic plug-in loading.","text":"<p>The only thing left is to register the plug-in on the list of available plug-ins for installation. We do this by pointing to the file with the register function.</p> <p>To do that, go to the directory: <code>/tracardi/service/setup</code> and find the file <code>setup_plugins.py</code> This is the list of all available plugins in the system.</p> <p>At the top of this file you will find the variable <code>installed_plugins: Dict [str, PluginTestTemplate]</code> which is a dictionary where the key is the location of the register function. The value is an object of the <code>PluginTestTemplate</code> type, it is responsible for the test data for the plug-in. We will not write tests, so our block of code should look like this:</p> /tracardi/service/setup/setup_plugins.py <pre><code>\"tracardi.process_engine.action.v1.my_plugin_folder.my_plugin\": PluginMetadata(  # (1)\n    test=PluginTest(init=None, resource=None)\n),\n</code></pre> <ol> <li>Key is the package of the register function</li> </ol> <p>Type this into the <code>installed_plugins</code> dictionary, and we are ready to install the plugin.</p> <p>Restart the Tracardi API so the changes are activated and go to <code>Processing/Workflows</code>, open any workflow and click the <code>Reinstall Plugins</code> button. Alternatively you can go to <code>Maintenance/Plug-ins</code> and click the <code>Reinstall Plugins</code> button.</p>"},{"location":"development/tutorial/plugin/part/part1/#wrap-up","title":"Wrap-up","text":"<p>And this concludes the first part of the tutorial. We added the first plugin and installed it. In the second part we will extend our plugin with the configuration form.</p>"},{"location":"development/tutorial/plugin/part/part2/","title":"Part 2: Configuring the plugin in Tracardi","text":"<p>In the next part of our tutorial, we will learn how to configure a plugin and how to add a configuration form to that plugin.</p> <p>In the previous tutorial we wrote the plugin that performs a simple action and checks if the event we are processing is equal to \"my-type\". Our code looked like this:</p> <p>Info</p> <p>Please click (+) to see the comments for the code</p> <pre><code>if self.event.type == \"my-event\":  # (1)\n    return Result(port=\"MyEvent\", value=payload)\nelse:\n    return Result(port=\"NotMyEvent\", value={})\n</code></pre> <ol> <li><code>self.event</code> gets the event that is being processed from the internal workflow state.</li> </ol> <p>You can see that such plugin is not very useful, because the user cannot configure it to change \"my-event\" to any defined event type. Let's try to change that.</p> <p>From the previous tutorial, we remember that the plugin has the following life cycle:</p> <pre><code>__init __ ()\nasync set_up (config)\nasync run (input_payload)\nasync close ()\n</code></pre> <p>It is easy to notice that it has a <code>set_up</code> method that accepts the <code>config</code> parameter, which is the plug-in's configuration. In the Tracardi system, the configuration is performed while editing the plug-in. We can do this in two ways.</p> <p>The first by providing a dictionary with configuration values (Below is a screenshot showing such a configuration in the JSON Editor and Configuration Form)</p> JSON configuration editorConfiguration form <p></p> <p></p> <p>The second way is to complete the form. It is related to the JSON configuration in such a way that when filling in the form fields, we automatically fill/change the JSON object.</p> <p>The first way is available out-of-the-box. Developer defines the default JSON object when registering the plugin and this is it. This object will appear in the <code>set_up</code> method as a <code>config</code> parameter.</p> <p>So let's expand our plugin with configuration.</p>"},{"location":"development/tutorial/plugin/part/part2/#json-configuration","title":"JSON Configuration","text":"<p>In the register function, we add the following entry in the spec:</p> <pre><code>init = {\n    \"event_type\": \"\"  # (1)\n}\n</code></pre> <ol> <li>We set up <code>event_type</code> as empty string. Later user inside the system can change it to something meaningful. The init    serves as a default configuration value.</li> </ol> <p>This way we define that the object should have the \"event_type\" property, which we will use later in the plugin.</p> <p>The entire register function should look like this:</p> <pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData\n\n\ndef register() -&gt; Plugin:\n    return Plugin(\n\n        start=False,\n        spec=Spec(\n            module=__name__,\n            className=MyPlugin.__name__,\n            init={  # (1)\n                \"event_type\": \"\"\n            },\n            inputs=[\"payload\"],\n            outputs=[\"MyEvent\", \"NotMyEvent\"],\n            version='0.1',\n            license=\"MIT\",\n            author=\"Your Name\"\n        ),\n        metadata=MetaData(\n            name=\"My first plugin\",\n            desc='Checks if the event type is equal to my-event.',\n            group=[\"Test plugin\"]\n        )\n    )\n</code></pre> <ol> <li>Configuration initialisation</li> </ol> <p>OK now let's use <code>event_type</code> in the plugin. First, we will have to read the initialized configuration and save it to the object.</p> <p>We will use the <code>set_up</code> method for this.</p> <pre><code>from tracardi.service.plugin.runner import ActionRunner\n\n\nclass MyPlugin(ActionRunner):\n    config: dict\n\n    async def set_up(self, config):\n        self.config = config\n\n    ...  # (1)\n</code></pre> <ol> <li>The rest of the code</li> </ol> <p>This way we saved the configuration data in the plugin class.</p> <p>Now let's use the <code>self.config</code> property in the run method and replace \"my-event\" with it.</p> <pre><code>from tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\n\n\nclass MyPlugin(ActionRunner):\n    config: dict\n\n    async def set_up(self, config):\n        self.config = config\n\n    async def run(self, payload: dict, in_edge=None):\n        if self.event.type == self.config['event-type']:\n            return Result(port=\"MyEvent\", value=payload)\n        else:\n            return Result(port=\"NotMyEvent\", value={})\n</code></pre> <p>That's it for the moment.</p> <p>The whole process is as follows. The system registers the plugin and saves in it the default configuration from the <code>Spec.init</code> property. In our case it is:</p> <pre><code>{\n  \"event_type\": \"\"\n}\n</code></pre> <p>When the user moves the plug-in to the workflow and starts it, the configuration from the plug-in is put as a parameter to the <code>set_up</code> method. In the method, we set <code>self.config</code> to the value from the parameter (i.e. the one from <code>spec.init</code>). If the user changed the configuration in the editor before the first run, the changed values are of course substituted as the config parameter.</p> <p>Then <code>self.config</code> is used to read the value of <code>event-type</code> and perform a comparison <code>if self.event.type == self.config['event-type']</code> in the run method.</p> <p>Complete code looks like this:</p> /tracardi/process_engine/action/v1/my_plugin_folder/my_plugin.py <pre><code>from tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\nfrom tracardi.service.plugin.domain.register import Plugin, Spec, MetaData\n\nclass MyPlugin (ActionRunner):\n\n    config: dict\n\n    async def set_up(self, config):\n      self.config = config\n\n    async def run(self, payload: dict, in_edge = None):\n        if self.event.type == self.config['event-type']:\n            return Result(port = \"MyEvent\", value = payload)\n\n        else:\n            return Result(port = \"NotMyEvent\", value = {})\n\ndef register () -&gt; Plugin:\n    return Plugin (\n\n        start = False,\n        spec = Spec (\n            module = __name__,\n            className = 'MyPlugin',\n            init = {\n               \"event_type\": \"\"\n            },\n            inputs = [\"payload\"],\n            outputs = [\"MyEvent\", \"NotMyEvent\"],\n            version = '0.1',\n            license = \"MIT\",\n            author = \"Your Name\"\n        ),\n        metadata = MetaData (\n            name = \"My first plugin\",\n            desc = 'Checks if the event type is equal to my-event.',\n            group = [\"Test plugin\"]\n        )\n    )\n</code></pre> <p>Info</p> <p>Please check if the code works step by step. You do not have to implement everything to check if the code works. Every time you complete some part of the tutorial you may save the changes and reinstall plugins and see how it works in the workflow editor. Installation of the changed plugin can be done in the workflow editor by clicking the <code>Reinstall plugins</code> button.</p>"},{"location":"development/tutorial/plugin/part/part2/#validation","title":"Validation","text":"<p>Note that although the code works, there may be a situation in which the user in the json editor deletes the initialized value</p> <pre><code>{\n  \"event_type\": \"\"\n}\n</code></pre> <p>and puts any other, for example:</p> <pre><code>{\n  \"Type\": \"\",\n  \"Position\": 1\n}\n</code></pre> <p>Then our code will not work, and we will get <code>KeyError</code> when trying to read the value in <code>self.config['event_type']</code>. So we need a validation that will not allow the user to enter incorrect values.</p> <p>For this we will use the <code>PluginConfig</code> object.</p> <pre><code>from pydantic import validator\nfrom tracardi.service.plugin.domain.config import PluginConfig\n\n\nclass Configuration(PluginConfig):\n    event_type: str  # (1)\n\n    @validator(\"event_type\")  # (2)\n    def must_not_be_empty(cls, value):\n        if len(value) == 0:\n            raise ValueError(\"Event type can not be empty.\")\n        return value\n</code></pre> <ol> <li>Tells that the object has a property named <code>event_type</code> and it is of type string. <code>None</code> value is not allowed.</li> <li><code>@validator(\"event_type\")</code> and the method below checks if the value of event_type is not empty.</li> </ol> <p>The above class defines what our configuration object should look like.</p> <ol> <li><code>event_type: str</code> tells that the object has a property named event_type and it is of type string. <code>None</code> value is not    allowed.</li> <li><code>@validator(\"event_type\")</code> and the method below checks if the value of event_type is not empty.</li> </ol> <p>Let's use a validator to validate the configuration. For this we need to create a validate function.</p> <pre><code>def validate(config: dict):\n    return Configuration(**config)\n</code></pre> <p>And we'll use it when setting up <code>self.config</code>.</p> <pre><code>from tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\nfrom pydantic import validator\nfrom tracardi.service.plugin.domain.config import PluginConfig\n\n\nclass Configuration(PluginConfig):  # (1)\n    event_type: str\n\n    @validator(\"event_type\")\n    def must_not_be_empty(cls, value):\n        if len(value) == 0:\n            raise ValueError(\"Event type can not be empty.\")\n        return value\n\n\ndef validate(config: dict):  # (2)\n    return Configuration(**config)\n\n\nclass MyPlugin(ActionRunner):\n    config: Configuration  # (3)\n\n    async def set_up(self, config):\n        self.config = validate(config)  # (4)\n\n    async def run(self, payload: dict, in_edge=None):\n        if self.event.type == self.config.event_type:  # (5)\n            return Result(port=\"MyEvent\", value=payload)\n        else:\n            return Result(port=\"NotMyEvent\", value={})\n</code></pre> <ol> <li>Definition of configuration schema. Any data passed to this object will be automatically validated.</li> <li>Validation function. The name of this function must be <code>validate</code>. The system GUI use it internally for validation of    any Form and JSON data.</li> <li>Notice a change in the type of config. Now it is not dict but <code>Configuration</code> type</li> <li>Here we use the validation function when we validate the passed data.</li> <li>Here we use the Configuration object to compare values.</li> </ol> <p>Info</p> <p>Please click (+) to see the comments for the code</p> <p>Now it is time to see if the code works.</p> <p>Info</p> <p>Please check if the code works step by step. You do not have to implement everything to check if the code works. Every time you complete some part of the tutorial you may save the changes and reinstall plugins and see how it works in the workflow editor. Installation of the changed plugin can be done in the workflow editor by clicking the <code>Reinstall plugins</code> button.</p>"},{"location":"development/tutorial/plugin/part/part2/#plugin-form","title":"Plugin form","text":"<p>Setting the configuration with the JSON editor is not very convenient. That's why we should add a form to make the process of plugin configuration easier.</p> <p>As you probably guessed, it is done by adding another parameter to the register function.</p> <pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData\nfrom tracardi.service.plugin.domain.register import Form, FormGroup, FormField, FormComponent  # (1)\n\n\ndef register() -&gt; Plugin:\n    return Plugin(\n\n        start=False,\n        spec=Spec(\n            module=__name__,\n            className='MyPlugin',\n            init={\n                \"event_type\": \"\"\n            },\n            form=Form(groups=[  # (2)\n                FormGroup(\n                    name=\"Event type plugin configuration\",\n                    description=\"Define required event type\",\n                    fields=[\n                        FormField(\n                            id=\"event_type\",  # (3)\n                            name=\"Event type\",\n                            description=\"Event type to check\",\n                            component=FormComponent(type=\"text\", props={\"label\": \"Event type\"})  # (4)\n                        )\n                    ]\n                ),\n            ]),\n            inputs=[\"payload\"],\n            outputs=[\"MyEvent\", \"NotMyEvent\"],\n            version='0.1',\n            license=\"MIT\",\n            author=\"Your Name\"\n        ),\n        metadata=MetaData(\n            name=\"My first plugin\",\n            desc='Checks if the event type is equal to my-event.',\n            group=[\"Test plugin\"]\n        )\n    )\n</code></pre> <ol> <li>Notice that we imported new classes</li> <li>Form declaration. It consists of <code>FormGroups</code> and <code>FormFields</code> inside a <code>FormGroup</code></li> <li>Notice that <code>FormField</code> id is equal to init property. This is how you bind configuration with the form field.</li> <li>THis defines what kind of component to use in the field. This one is text.</li> </ol> <p>The form property defines a form that will be build automatically and will bind form fields with JSON configuration object. Form consists of <code>FormGroups</code> and <code>FormFields</code> inside a <code>FormGroup</code>. <code>FormGroup</code> is just a type of grouping to make forms more readable. You may have any number of groups you want. It consists of name and description and a list of <code>FormField</code> objects. Form field defines the type of field we display and an id. ID must be equal to one of the configuration properties. Here we bind first field with the <code>event_type</code> property of the JSON configuration object. Property <code>component</code> defines the field component to use to edit the <code>event_type</code>.</p> <p>The list of available components can be found here.</p> <p>When you reinstall the plugin you should see the form in the plugin configuration. Everytime you change something in the form it should be visible in the JSON configuration and vice-versa.</p>"},{"location":"development/tutorial/plugin/part/part2/#wrap-up","title":"Wrap-up","text":"<p>And this concludes the second part of the tutorial. We added the plugin configuration and attached a from to it. In the third part we will extend our plugin with the resource and reference the data with dot notation.  </p>"},{"location":"development/tutorial/plugin/part/part3/","title":"Part 3. Data reference and resource in plugins","text":"<p>In the third part of the tutorial, we will learn how to use data references, how to use resources and how to connect to external services. We will extend our plugin with the following functionality. </p> <p>The plugin needs to send the user defined data to be sent to user defined API. We will also have to extend our form with the above data (data, and API endpoint).</p>"},{"location":"development/tutorial/plugin/part/part3/#lets-get-started","title":"Let's get started","text":"<p>Often when coding a plugin, we want to use the data defined by the user. For example, the user references some data from the internal state of the workflow that he wants to an external API. To do this he uses so-called dot notation.  Dot notation is a way of specifying the location of the data. It looks like this. </p> <pre><code>&lt;source&gt;@&lt;path.to.data&gt;\n</code></pre> <p>This is a working example:</p> <pre><code>event@properties.email\n</code></pre> <p>It means get the data from the event from its <code>properties.email</code>. A full description of all sources and how the data reference works can be found here.</p> <p>In this tutorial we are interested in how to use this entry and retrieve data, and how to put a field in the form that will require a dot notation entry.</p>"},{"location":"development/tutorial/plugin/part/part3/#data-reference","title":"Data reference","text":"<p>Let's start with the form. To add a new field to the form we will use the <code>dotPath</code> component and in the <code>form / FromGroup / FormFields</code> section we will add the following code:</p> <pre><code>FormField (\n   id = \"data\",\n   name = \"Data to send\",\n   description = \"Please provide data to send\",\n   component = FormComponent (type = \"dotPath\", props = {\"label\": \"Data to send\"})\n)\n</code></pre> <p>This way we get: <pre><code>form = Form(groups=[\n    FormGroup(\n        name=\"Event type plugin configuration\",\n        description=\"Define required event type\",\n        fields=[\n            FormField(\n                id=\"event_type\", name=\"Event type\",\n                description=\"Event type to check\",\n                component=FormComponent(type=\"text\", props={\"label\": \"Event type\"})),\n            FormField(\n                id=\"data\",\n                name=\"Data to send\",\n                description=\"Please provide data to send\",\n                component=FormComponent(type=\"dotPath\", props={\"label\": \"Data to send\"})\n            )\n        ]\n    ),\n]),\n</code></pre></p> <p>With this, we will get a field of this type in the form.</p> <p></p> <p>Then we need to extend <code>init</code> in register function with a <code>data</code> field and extend an object that will store the data and verify its correctness at the same time.</p> <p>So I would add to init:</p> <pre><code>init = {\n  \"event_type\": \"\",\n  \"data\": \"\"\n}\n</code></pre> <p>and add to the <code>Configuration</code> object:</p> <pre><code>class Configuration(PluginConfig):\n    event_type: str\n    data: str\n\n    @validator(\"event_type\")\n    def must_not_be_empty(cls, value):\n        if len(value) == 0:\n            raise ValueError(\"Event type can not be empty.\")\n        return value\n\n\n    @validator(\"data\")  # (1)\n    def data_must_not_be_empty(cls, value):\n        if len(value) == 0:\n            raise ValueError(\"Data can not be empty. \")\n        return value\n</code></pre> <ol> <li>Validates the data property. It is defined as string, but it may not be empty string</li> </ol> <p>We have configuration data, now it's time to read data entered in the form and read data from dot notation.</p> <p>We do it as follows:</p> <p>In the run method:</p> <pre><code>async def run(self, payload: dict, in_edge=None):\n    dot = self._get_dot_accessor(payload)  # (1)\n    data_to_send = dot[self.config.data]  # (2)\n\n    if self.event.type == self.config.event_type:\n        return Result(port=\"MyEvent\", value=data_to_send)\n    else:\n        return Result(port=\"NotMyEvent\", value={})\n</code></pre> <ol> <li>Get the DotAccessor object that will convert the dot notation to the data. </li> <li>Convert anything that is defined in <code>config.data</code> to the real data from the workflow and assign it to data_to_send</li> </ol>"},{"location":"development/tutorial/plugin/part/part3/#resource","title":"Resource","text":"<p>In many cases, it is necessary to link the plug-in to some resource. It can be e.g. a database, API, etc. Usually, such resources need login credentials. We don't want to keep them in a plugin as they can be used in many plugins. For this purpose, it is necessary to create a resource. The resource consists of credential data and sometimes a URL.</p> <p>For example, let's add a functionality to our plugin that will send the data pointed by the user to the defined API (a resource).</p> <p>For this purpose, we will create a resource that will have the following data</p> <pre><code>{\n  \"url\": \"api-url\",\n  \"method\": \"api-method\",\n  \"api_key\": \"api-key\"\n}\n</code></pre> <p>The resources are created in the <code>tracardi/service/setup/setup_resources.py</code> directory</p> <p>We add the following code to the <code>get_resource_types()</code> function</p> <pre><code>ResourceSettings(\n    id=\"my-api-url\",  # (1)\n    name=\"Custom API URL\",  # (2)\n    icon=\"web\",  # (3)\n    tags=[\"api\"],  # (4)\n    config={  # (5)\n        \"url\": \"&lt;api-url&gt;\",\n        \"method\": \"&lt;api-method&gt;\",\n        \"api_key\": \"&lt;api-key&gt;\"\n        },\n    manual=\"custom_api_url_resource\"  # (6)\n),\n</code></pre> <ol> <li>Resource Id. A unique string that identifies the resource.</li> <li>Resource name</li> <li>Resource icon.</li> <li>The tag that describes the resource. It is used to filter the resources in the plugin form.</li> <li>Resource configuration <code>*.md</code> file name containing documentation on how to get authorization data, e.g.     when the resource is an external system. </li> <li>The documentation file is located in the tracardi-api/docs/resources directory</li> </ol> <p>This is the set of data the system needs to add a resource. After restarting the server, we can click on <code>Resources</code> in the Tracardi GUI menu, then <code>Add new resource</code> and the list of resources will include <code>Custom API URL</code>. The resource we just created. The form will also include an object:</p> <pre><code>{\n  \"url\": \"&lt;api-url&gt;\",\n  \"method\": \"&lt;api-method&gt;\",\n  \"api_key\": \"&lt;api-key&gt;\"\n}\n</code></pre> <p>which we defined in the config property and which should be filled by the user.</p>"},{"location":"development/tutorial/plugin/part/part3/#loading-resource","title":"Loading resource","text":"<p>Once we have a resource, we can load it in our plugin. We do this in the <code>set_up</code> method. We add the following two lines to the <code>set_up</code> method</p> <pre><code>from tracardi.service.domain import resource as resource_db\n\nresource = await resource_db.load (config.resource.id) # (1)\nself.credentials = resource.credentials.get_credentials (self, output = MyResourceConfig) # (2)\n</code></pre> <ol> <li>Read resource id from <code>config.resource.id</code>. Note the object <code>config.resource</code> must be defined in the config </li> <li>Get data for authorization (credentials), which is an object defined in <code>ResourceSettings</code> in the <code>config</code> property,    and filled in by the user when creating the resource.</li> </ol> <p>The first line reads the resource id from <code>config.resource.id</code>. Note that we do not have such field in the config yet and we need to add it (we'll do it in a moment)</p> <p>The second line reads <code>credentials</code> from the resource, i.e. the object that we defined in the <code>config</code> property of the <code>ResourceSettings</code> object above and a user filled when creating the resource.</p> <p>The whole <code>set_up</code> method should look like this:</p> <pre><code>from tracardi.service.domain import resource as resource_db\n\nclass MyPlugin (ActionRunner):\n\n    config: dict\n    credentials: MyResourceConfig # (1)\n\n\n    async def set_up (self, config):\n      self.config = config\n      resource = await resource_db.load (config.resource.id)\n      self.credentials = resource.credentials.get_credentials (self, output = MyResourceConfig)\n\n\n    # (2)\n</code></pre> <ol> <li>We have added the credentials' property of type <code>MyResourceConfig</code>. We'll have to define it yet.</li> <li>Rest of plugin code.</li> </ol>"},{"location":"development/tutorial/plugin/part/part3/#validating-the-resource","title":"Validating the resource","text":"<p>We still have some parts missing. We need to validate the data from the resource and extend the configuration so that the user can select the appropriate resource in the form.</p> <p>To verify the data from the resource and make it readable, we need to create the <code>MyResourceConfig</code> object. I named it in this line:</p> <pre><code> self.credentials = resource.credentials.get_credentials(self, output=MyResourceConfig) # (1)\n</code></pre> <ol> <li>See <code>output = MyResourceConfig</code></li> </ol> <p>In <code>output=MyResourceConfig</code>, I requested that the credentials loaded from the resource be in the form of a <code>MyResourceConfig</code> object. I don't have it yet, so let's create it. We usually store resource objects in the directory: <code>tracardi/domain/resources</code></p> tracardi/domain/resources/my_resource_config.py <pre><code>from pydantic import BaseModel, AnyHttpUrl\nfrom typing import Optional \n\n\nclass MyResourceConfig(BaseModel):\n    url: AnyHttpUrl\n    method: str\n    api_key: Optional[str] = None\n</code></pre> <p>Tip</p> <p>It must have the same schema as defined in config in <code>ResourceSettings</code>. Note that I defined <code>url</code> as<code>AnyHttpUrl</code> this  means it can only accept a string that looks like a URL. On the other hand, <code>api_key</code> is of type <code>Optional[str]</code>, which  means that such a property may not be available or be None.</p> <p>We already have an object, so we have to extend the plug-in configuration with the resource. The resource will be selected from the list of available resources, and it will be identified as the resource name and id.</p> <p>Example</p> <pre><code>{\n  \"id\": \"9bb2a926-b6ae-4cad-9b3c-9380ea7bfede\",\n  \"name\": \"My API\"\n}\n</code></pre> <p>For this purpose, we will add a resource to the plug-in configuration, which, let me remind you, is in the <code>register</code> function under the <code>init</code> property.</p> <p>It should look like this:</p> <pre><code>def register () -&gt; Plugin:\n    return Plugin (\n        start = False,\n        spec = Spec (\n            module = __name__,\n            className = MyPlugin.__name__,\n            init = {\n                \"resource\": {\n                    \"id\": \"\",\n                    \"name\": \"\"\n                },\n                \"event_type\": \"\",\n                \"data\": \"\"\n            },\n            inputs = [\"payload\"],\n            outputs = [\"MyEvent\", \"NotMyEvent\"],\n            version = '0.1',\n            license = \"MIT\",\n            author = \"Your Name\"\n        ),\n        metadata = MetaData (\n            name = \"My first plugin\",\n            desc = 'Checks if the event type is equal to my-event.',\n            group = [\"Test plugin\"]\n        )\n    )\n</code></pre> <p>We also need to extend the configuration validation object.</p> <pre><code>from tracardi.domain.named_entity import NamedEntity\n\nclass Configuration(PluginConfig):\n    resource: NamedEntity # (1)\n    event_type: str\n    data: str\n\n    @validator(\"event_type\")\n    def must_not_be_empty (cls, value):\n        if len (value) == 0:\n            raise ValueError (\"Event type can not be empty.\")\n        return value\n\n    @validator(\"data\") \n    def data_must_not_be_empty(cls, value):\n        if len(value) == 0:\n            raise ValueError(\"Data can not be empty. \")\n        return value    \n</code></pre> <ol> <li>NamedEntity is an object containing id and name. It is already defined in Tracardi.</li> </ol>"},{"location":"development/tutorial/plugin/part/part3/#resource-select-field","title":"Resource select field","text":"<p>It remains to add a field to the form that will allow user to select a resource from the list of defined resources. Remember that there may be different types of resources created in the system, so we need to filter them so that only those related to our plugin are on the list of resources.</p> <p>This is done by pointing to the tag we defined in <code>ResourceSettings</code>. In our case it is <code>api</code> (tags=[\"api\"]).</p> <p>Now we have all the information. We must extend the form with the resource select field that displays available resources, so the user will be able to select one.</p> <p>Please add this code to <code>form</code> in the <code>register</code> function.</p> <pre><code>FormField(\n    id=\"resource\",\n    name=\"Resource\",\n    description=\"Select your API resource.\",\n    component=FormComponent(type=\"resource\", props={\"label\": \"API Resource\", \"tag\": \"api\"})  # (1)\n),\n</code></pre> <ol> <li>Notice tag property equal to <code>api</code></li> </ol> <p>The <code>form</code> property should look like this.</p> <pre><code>form = Form(groups=[\n    FormGroup(\n        name=\"Event type plugin configuration\",\n        description=\"Define required event type\",\n        fields=[\n            FormField(\n                id=\"resource\",\n                name=\"Resource\",\n                description=\"Select your API resource.\",\n                component=FormComponent(type=\"resource\", props={\"label\": \"API Resource\", \"tag\": \"api\"})\n            ),\n            FormField(\n                id=\"event_type\",\n                name=\"Event type\",\n                description=\"Event type to check\",\n                component=FormComponent(type=\"text\", props={\"label\": \"Event type\"})  # \n            )\n        ]\n    )\n])\n</code></pre> <p>Up till now:</p> <ul> <li>We created a resource and resource validation object</li> <li>Extended the configuration and validation of plugin initial configuration</li> <li>Extended the plugin form with the resource select field. </li> </ul> <p>The last part is connecting to the API</p> <p>Info</p> <p>This will be described soon</p>"},{"location":"errors/C0001/","title":"WARNING: No MULTI_TENANT_MANAGER_URL set for MULTI_TENANT mode. Either set the MULTI_TENANT_MANAGER_URL or set MULTI_TENANT to \"no\"","text":"<p>Code: C0001 Origin: Configuration Level: WARNING</p>"},{"location":"errors/C0001/#description","title":"Description:","text":"<p>This warning is logged if the system is configured to operate in MULTI_TENANT mode (<code>MULTI_TENANT</code> is set to \"yes\"), but the <code>MULTI_TENANT_MANAGER_URL</code> is not specified. This configuration is necessary for managing multiple tenants within the system.</p>"},{"location":"errors/C0001/#solution","title":"Solution","text":"<p>Ensure that <code>MULTI_TENANT_MANAGER_URL</code> is set to a valid URL when <code>MULTI_TENANT</code> mode is enabled, or disable <code>MULTI_TENANT</code> mode by setting it to \"no\" if multi-tenancy is not required.</p>"},{"location":"errors/C0002/","title":"WARNING: No MULTI_TENANT_MANAGER_API_KEY set for MULTI_TENANT mode. Either set the MULTI_TENANT_MANAGER_API_KEY or set MULTI_TENANT to \"no\"","text":"<p>Code: C0002 Origin: Configuration Level: WARNING</p>"},{"location":"errors/C0002/#description","title":"Description:","text":"<p>This warning is issued when the application is in MULTI_TENANT mode (<code>MULTI_TENANT</code> is \"yes\"), but the <code>MULTI_TENANT_MANAGER_API_KEY</code> is not provided. The API key is essential for authenticating requests to the multi-tenant manager.</p>"},{"location":"errors/C0002/#solution","title":"Solution","text":"<p>Provide a valid <code>MULTI_TENANT_MANAGER_API_KEY</code> when MULTI_TENANT mode is enabled, or set <code>MULTI_TENANT</code> to \"no\" if not operating in multi-tenant mode.</p>"},{"location":"errors/C0003/","title":"WARNING: Env MULTI_TENANT_MANAGER_URL is not valid URL.","text":"<p>Code: C0003 Origin: Configuration Level: WARNING</p>"},{"location":"errors/C0003/#description","title":"Description:","text":"<p>This warning logs when the <code>MULTI_TENANT_MANAGER_URL</code> environment variable is set but does not represent a valid URL format. It is crucial for this URL to be correct as it is used to manage tenant-specific configurations and data.</p>"},{"location":"errors/C0003/#solution","title":"Solution","text":"<p>Verify and correct the <code>MULTI_TENANT_MANAGER_URL</code> value to ensure it is a valid URL.</p>"},{"location":"errors/C0004/","title":"WARNING: Env MULTI_TENANT_MANAGER_URL is not valid URL.","text":"<p>Code: C0003 Origin: Configuration Level: WARNING</p>"},{"location":"errors/C0004/#description","title":"Description:","text":"<p>This warning logs when the <code>MULTI_TENANT_MANAGER_URL</code> environment variable is set but does not represent a valid URL format. It is crucial for this URL to be correct as it is used to manage tenant-specific configurations and data.</p>"},{"location":"errors/C0004/#solution","title":"Solution","text":"<p>Verify and correct the <code>MULTI_TENANT_MANAGER_URL</code> value to ensure it is a valid URL.</p>"},{"location":"errors/M0001/","title":"WARNING: Can't find the index X. Migration for this index will be stopped.","text":"<p>Code: M0001 Origin: migration Level: WARNING</p>"},{"location":"errors/M0001/#description","title":"Description:","text":"<p>This warning is logged when a specified index to migrate from does not exist in the Elasticsearch database. It means the migration script identified an index that should be migrated but could not find it in the database, leading to the cessation of migration activities for that specific index.</p>"},{"location":"errors/M0001/#solution","title":"Solution","text":"<p>Verify the existence of the index specified by <code>schema.copy_index.from_index</code> in the Elasticsearch database. Ensure that the index name is correct and exists before attempting the migration again. If the index is not needed or the reference is incorrect, update the migration script to exclude this index or correct the index name.</p>"},{"location":"errors/M0002/","title":"ERROR: Installed system version is X for tenant A, but migration script is for version Z for tenant B.","text":"<p>Code: M0002 Origin: migration Level: ERROR</p>"},{"location":"errors/M0002/#description","title":"Description:","text":"<p>This error is logged when there is a mismatch between the installed system version (or tenant) and the version (or tenant) for which the migration script is intended. It indicates that the migration cannot proceed because the target version or tenant does not match the system's current configuration.</p>"},{"location":"errors/M0002/#solution","title":"Solution","text":"<p>Ensure that the system version and tenant match the intended target version and tenant specified in the migration script. Update the system or select the appropriate migration script that matches the system's current version and tenant.</p>"},{"location":"errors/M0003/","title":"ERROR: Could not find multi indices for X","text":"<p>Code: M0002 Origin: migration Level: ERROR</p>"},{"location":"errors/M0003/#description","title":"Description:","text":"<p>This error occurs when the migration script expects to find indices matching a specific pattern (multi indices) for migration purposes but fails to locate them. It suggests that the anticipated partitioned or time-series indices do not exist or do not follow the expected naming convention.</p>"},{"location":"errors/M0003/#solution","title":"Solution","text":"<p>Ensure that the indices intended for migration exist and match the expected naming convention or pattern. Verify the Elasticsearch index patterns and adjust the migration script or Elasticsearch indices as necessary to align with the expected multi-index patterns.</p>"},{"location":"errors/R0001/","title":"ERROR: Rule to workflow does not exist. This may happen when you debug a workflow that has no routing rules set but you use <code>Background task</code> or <code>Pause and Resume</code> plugin that gets rescheduled and it could not find the routing to the workflow. Set a routing rule and this error will be solved automatically.","text":"<p>Code: R0001 Origin: rule Level: ERROR</p>"},{"location":"errors/R0001/#description","title":"Description:","text":"<p>This error is logged when a rule that is supposed to route an event to a workflow cannot be found. The error is critical because it signifies a gap in the workflow's configuration, potentially leading to execution failures or unintended behavior. This error will be linked to events, workflows, and profiles due to the potential for it to disrupt the intended flow of data processing within the system.</p>"},{"location":"errors/R0001/#solution","title":"Solution","text":"<p>To resolve this issue, ensure that a routing trigger rule is explicitly defined for every workflow. Check the workflow's configuration to identify missing routing rules and add them as necessary to establish clear pathways for event processing. </p>"},{"location":"errors/R0002/","title":"ERROR: Rule 'name:id' validation error: Description","text":"<p>Code: R0002 Origin: rule Level: ERROR</p>"},{"location":"errors/R0002/#description","title":"Description:","text":"<p>This error occurs during the validation phase of a rule, indicating a problem with the rule's configuration or its applicability to the current context. Such errors can stem from various issues, including but not limited to, incorrect rule setup, failure to meet predefined conditions, or issues with the rule's internal logic. This error is critical as it prevents the rule from executing as intended, potentially halting the workflow's progression or leading to incorrect data processing. This error is associated with events, workflows, and profiles, highlighting its impact across different stages of data handling within the system.</p>"},{"location":"errors/R0002/#solution","title":"Solution","text":"<p>To address this error, closely examine the rule's configuration and the conditions under which it is triggered. Validate the rule's logic against the intended outcomes and ensure that all conditions for its execution are correctly defined and met. Reviewing the specific error message provided can offer insights into the nature of the validation failure, guiding the necessary corrections.</p>"},{"location":"errors/R0003/","title":"ERROR: Could not find flow X","text":"<p>Code: R0003 Origin: workflow Level: ERROR</p>"},{"location":"errors/R0003/#description","title":"Description:","text":"<p>This error signifies a significant issue where a specified flow, essential for processing an event according to a rule, cannot be located within the system. This situation might arise due to incorrect flow identifiers, deletion or unavailability of the flow leading to a disconnect between rules and their intended workflows. The absence of the required flow disrupts the event processing pipeline, preventing the execution of tasks and actions defined within the missing workflow. This error affects the handling of events, workflows, and profiles, underlining its potential to impact the operational efficiency of the system significantly.</p>"},{"location":"errors/R0003/#solution","title":"Solution","text":"<p>To mitigate this issue, verify the existence and accessibility of the flow intended to be invoked by the rule. Ensure that the flow ID referenced by the rule matches an existing, active workflow within the system. If the flow has been deleted or moved, update the rule with the correct flow ID or recreate the missing flow as needed. </p>"},{"location":"errors/S0001/","title":"ERROR: Entity X does not have index set. And it is not new.","text":"<p>Code: S0001 Origin: storage Level: ERROR</p>"},{"location":"errors/S0001/#description","title":"Description:","text":"<p>This error is logged when an entity, which is not new, does not have its corresponding index set. This is a critical system error indicating that the entity is expected to be stored in a specific index in the database, but the index information is missing. This situation could lead to data not being stored or retrieved correctly. The error is tied to the storage system's operations, affecting the processing of entities and potentially impacting data integrity.</p>"},{"location":"errors/S0001/#solution","title":"Solution","text":"<p>Ensure that the system is installed properly. report this error to the vendor.</p>"},{"location":"errors/S0002/","title":"WARNING: Entity X converts to index-less storage record.","text":"<p>Code: S0002 Origin: storage Level: WARNING</p>"},{"location":"errors/S0002/#description","title":"Description:","text":"<p>This warning is issued when an entity is converted into a storage record without specifying an index. This scenario is considered critical because it may lead to the entity being stored without proper index association, complicating data retrieval and organization. The warning suggests that the system might be attempting to handle an entity in a way that bypasses the usual indexing process, which could result in inefficiencies or data loss. </p>"},{"location":"errors/S0002/#solution","title":"Solution","text":"<p>Report this warning to the vendor. Document the error for easy fixing. </p>"},{"location":"getting_started/","title":"Tracardi Getting Started","text":""},{"location":"getting_started/#what-is-tracardi","title":"What is Tracardi","text":"<p>Tracardi is a Customer Data Platform (CDP) designed to collect, analyze, and act on customer data. It provides tools for managing and leveraging customer information to improve engagement and drive business growth. Here\u2019s a detailed explanation of Tracardi and its purposes: What is Tracardi?</p> <p>Tracardi is an open-source Customer Data Platform (CDP) that consolidates customer data from various sources, processes this data, and enables businesses to create personalized customer experiences. It integrates seamlessly with websites, applications, and other platforms to gather user interactions, profile data, and behavioral data. Purpose of Installing Tracardi</p> <p>The primary purposes of installing Tracardi include:</p> <ul> <li> <p>Data Collection and Integration:   Unified Data Repository: Tracardi collects data from multiple touchpoints such as websites, mobile apps, and CRM   systems, storing it in a unified repository.   Real-Time Data Processing: It processes data in real-time, allowing businesses to respond to customer actions as they   happen.</p> </li> <li> <p>Customer Profiling:   360-Degree View: Tracardi builds comprehensive customer profiles by combining data from various sources, giving a   360-degree view of each customer.   Identity Resolution: It resolves customer identities across different channels, ensuring accurate and consistent data.</p> </li> <li> <p>Personalization and Engagement:   Tailored Experiences: Tracardi enables personalized marketing and communication by leveraging detailed customer   profiles and behaviors.   Automated Workflows: It supports the creation of automated workflows to trigger personalized messages, offers, and   content based on customer actions.</p> </li> <li> <p>Analytics and Insights:   Behavioral Analysis: Tracardi analyzes customer behavior to identify patterns, preferences, and trends.   Segmentation: It segments customers into different groups based on various criteria, allowing targeted marketing   efforts.</p> </li> <li> <p>Data Orchestration:   Integration with External Systems: Tracardi can route processed data to external systems like CRM, marketing   automation platforms, and data warehouses.   Data Enrichment: It enhances raw data with additional context and information, improving its value for   decision-making.</p> </li> </ul>"},{"location":"getting_started/#getting-started","title":"Getting Started","text":"<p>To start collecting data in Tracardi, you need to set up the system, integrate it with your website or application, and configure event sources and event tracking. Here's a step-by-step guide to get you started:</p>"},{"location":"getting_started/#1-install-tracardi","title":"1. Install Tracardi","text":"<p>You need to have Tracardi installed and running. This can be done using Docker, Helm, or directly from the source code. Ensure that all necessary components, such as the backend, frontend, and optional modules, are installed.</p>"},{"location":"getting_started/#2-configure-event-sources","title":"2. Configure Event Sources","text":"<p>Event sources are the points where data enters Tracardi. You need to define these sources in the Tracardi system to start collecting data from them.</p> <ul> <li>Creating an Event Source: Go to the Tracardi GUI, navigate to Inbound Traffic, and add a new event source. You'll   need to provide details such as the name, type, and URL of the event source.</li> </ul>"},{"location":"getting_started/#3-integrate-tracardi-javascript-snippet","title":"3. Integrate Tracardi JavaScript Snippet","text":"<p>To collect data from your website, you need to integrate the Tracardi JavaScript snippet into your web pages. Add the JavaScript Snippet. You can find the snippet by clicking the event source and selecting <code>Use &amp; Javascript</code> Tab:</p> Example configuration snippet, that should be placed on all pages<pre><code>&lt;script&gt;\n    !function(e){\"object\"==typeof exports&amp;&amp;\"undefined\"!=typeof module..\n&lt;/script&gt;\n&lt;script&gt;\n    const options = {\n        tracker: {\n            url: {\n                script: 'http://your-tracardi-url/tracker',\n                api: 'http://your-tracardi-url'\n            },\n            source: {\n                id: \"&lt;your-event-source-id&gt;\"\n            }\n        }\n    }\n&lt;/script&gt;\n</code></pre> <p>Tip</p> <p>Do not forget to replace your-tracardi-url with the URL of your Tracardi API server and your-event-source-id with the ID of your event source.</p>"},{"location":"getting_started/#4-send-events-via-javascript","title":"4. Send Events via JavaScript","text":"<p>Define and send events from your web pages using JavaScript. Events can represent various user actions such as page views, clicks, form submissions, etc. Events properties are the data that is associated with the event, e.g. page url, form data, etc.</p> Example snippet for data collection<pre><code>    window.tracker.track(\"page-view\", {\n      \"url\": window.location.href, \n      \"title\": document.title, \n      \"category\": \"product details\"\n    });\n    window.tracker.track(\"button-click\", {\n      \"button-id\": \"subscribe-button\"\n    });\n</code></pre>"},{"location":"getting_started/#5-verify-integration","title":"5. Verify Integration","text":"<p>After adding the JavaScript code and sending events, verify that the data is being collected properly in Tracardi.</p> <ul> <li>Check Event Data: Navigate to the Tracardi GUI and check the Events section to see if the events from your web   pages are being captured. Data should appear withing 3 to 5 seconds.</li> </ul>"},{"location":"getting_started/#6-configure-workflows","title":"6. Configure Workflows","text":"<p>Workflows define how events are processed in Tracardi. You can set up workflows to act on the collected data. Workflows are not necessary to collect user data. They can automate the customer journey and allow messaging user or personalizing their customer journey.</p> <ul> <li>Create Workflows: Go to the Processing section, create a new workflow, and define the nodes and actions based on   your requirements.</li> </ul> <p>If you would like more details about Tracardi, please follow these documents:</p> <ul> <li>Installation: How to install Tracardi</li> <li>Core elements<ul> <li>Tracardi Components: Data objects used in Tracardi.</li> <li>Tracardi Definitions: Definitions used in Tracardi.</li> <li>Tracardi Processes: Processes in Tracardi</li> <li>Tracardi Codings: Processes in Tracardi</li> </ul> </li> </ul>"},{"location":"getting_started/core_concepts/","title":"Tracardi Concepts","text":"<p>Tracardi is build around 5 major processes.</p>"},{"location":"getting_started/core_concepts/#key-processes-in-tracardi","title":"Key Processes in Tracardi","text":"<ul> <li> <p>Integration: Integration is not a process within Tracardi. Instead, it occurs within a company and involves integrating systems       with Tracardi to send data from various systems, websites, and databases to Tracardi.</p> </li> <li> <p>Collection: Collection is the process responsible for gathering and ingesting data. It consists of several subprocesses:</p> <ul> <li>Tracking: The process of maintaining a consistent single Profile ID across all customer interactions on a single device. It is the responsibility of the device/client to keep the Profile ID unchanged.</li> <li>Identity Resolution and Merging: The process of maintaining a consistent single profile across all customer devices. It is Tracardi's responsibility to merge all profiles created on different devices whenever possible.</li> <li>Storing Data: This process involves storing collected data in one profile record and referencing all historical events and sessions.</li> </ul> </li> <li> <p>Automation: This process automates the customer journey, enhances customer profiles, personalizes customer experiences, and triggers messaging.</p> </li> <li> <p>Audiences and Activations: The process of creating audiences/segments and orchestrating them to external systems such as Marketing Automation platforms.</p> </li> <li> <p>Orchestrator/Router: The process responsible for sending customer data to external systems.</p> </li> </ul>"},{"location":"getting_started/core_concepts/#core-definitions","title":"Core Definitions","text":"<p>In order to understand how Tracardi CPD works you will need to learn the following definitions.</p>"},{"location":"getting_started/core_concepts/#traffic","title":"Traffic","text":"<p>Tracardi is capable of both receiving and sending data, thus defining two types of traffic:</p> <ol> <li> <p>Inbound Traffic: This includes systems that send data to Tracardi, such as websites, internal systems, and    services. The incoming traffic is usually associated with event source and identified    by an Source ID defined in Tracardi.</p> </li> <li> <p>Outgoing Traffic: This involves external systems or services to which Tracardi can sends data. Outgoing Traffic    is usually associated destinations.</p> </li> </ol> <p>Tip</p> <p>In the system, we call inbound traffic - event sources. In the system, we call outbound traffic - destinations.</p>"},{"location":"getting_started/core_concepts/#bridge","title":"Bridge","text":"<p>A bridge is a piece of software that connects two separate systems or applications, allowing them to communicate and exchange data. In Tracardi a bridge is a piece of software that collects data from a particular event source using particular protocol, such as a API call, queue, email, and transfer to the system collector. For example, Tracardi come with an open source API bridge that allows it to collect data from an API <code>/track</code> endpoint and transfer it to the system. Commercial versions of Tracardi may come with other types of bridges, such as a Kafka bridge, which allows it to collect data from a Kafka message broker.</p> <p>Bridge is strictly related to Event Source, when a new event source is created, the appropriate bridge must be selected to facilitate the collection and transfer of data.</p>"},{"location":"getting_started/core_concepts/#event-source-inbound-traffic","title":"Event Source - Inbound Traffic","text":"<p>In order to kick-start your new project with Tracardi, you must create a new event source. That source will give you an identifier which when attached to your track calls will start collecting data about your users. Event source needs a bridge that will transfer data to the system.</p> <p>Note</p> <p>An event source can be configured as ephemeral, meaning that data received from this type of event source  is not permanently saved in the system but is only processed by the workflow. Ephemeral event sources handle  data temporarily, using it solely for the duration of the workflow. This enables real-time data processing  and analysis without the need for long-term storage.</p>"},{"location":"getting_started/core_concepts/#destination-outbound-traffic","title":"Destination - Outbound Traffic","text":"<p>In Tracardi, a destination is an external system where profile or event data is sent. To function, a destination requires a specific resource, such as an API endpoint or queue service, to receive and process the data.</p> <p>A resource in this context acts similarly to a bridge in the Event Source, facilitating the connection to the external system.</p> <p>Note</p> <p>Not all resources are available as destinations in Tracardi. </p> <p>In summary, a destination is a system or service where data is forwarded for further processing or storage, enabling data transfer and integration between different platforms.</p>"},{"location":"getting_started/core_concepts/#data","title":"Data","text":""},{"location":"getting_started/core_concepts/#resource","title":"Resource","text":"<p>A service resource refers to a service or application accessed over a network or the Internet, providing functions such as data storage, communication, and computation.</p> <p>In Tracardi, resources are credentials to datasets or services that can be queried for data, often requiring authentication (e.g., passwords or tokens) for access. When creating a resource in Tracardi, you may need to provide access details for both test and production environments.</p> <p>Info</p> <p>Tracardi allows you to test your internal processes by running workflows in test mode. In this mode, workflows connect with test resources to prevent any changes that could impact the production environment.</p>"},{"location":"getting_started/core_concepts/#session","title":"Session","text":"<p>In Tracardi, a session represents a period during which a user actively interacts with a website or application. It is often associated with a visit to the site or app. The session remains active as long as there is ongoing interaction. The session ID is assigned when data is sent to Tracardi and is typically managed by the client program. Session data is immutable for the entire duration of the session and contains information about the user's visit, such as the operating system, application, browser, screen resolution, and device used.</p>"},{"location":"getting_started/core_concepts/#event","title":"Event","text":"<p>In Tracardi, events are representations of actions or occurrences at a specific moment in time. Events can be used to track visitor behavior on a website or application, capturing a wide range of actions and interactions. Examples include clicks on links, logins, form submissions, page views, and purchase orders. Events can carry additional data such as usernames, purchased items, or viewed pages, depending on the type of event and the information being tracked.</p> <p>Website events in Tracardi are typically triggered when JavaScript is executed on a selected page or when an API query is made to the <code>/track</code> endpoint. Since the tracking code is present on every page, it can emit events as users interact with the site. The events and their types are configurable, allowing for customization of the data sent for each event.</p> <p>Events can either be stored inside Tracardi and passed to a workflow for external processing. This provides flexibility in how events are tracked and utilized within the Tracardi system.</p>"},{"location":"getting_started/core_concepts/#profile","title":"Profile","text":"<p>In Tracardi, a profile represents an aggregated and comprehensive set of data about a customer, built dynamically as events are processed by the system. The profile is essentially the central data structure that captures all relevant information and interactions pertaining to a user/customer, allowing for personalized and context-aware actions within Tracardi workflows.</p> <p>A profile in Tracardi comprises several key components, including data, custom traits, metadata, etc. Profile is referenced in sessions, and events. Data are key-value pairs that store personal details such as name, email, and preferences, forming the core attributes of the profile. Custom traits represend custom data stored for profile. Metadata provides additional context about the profile, such as creation and update timestamps, source information, and tags that help categorize the profile.</p> <p>Profiles are built through the processing of events. When an event occurs, it is sent to Tracardi along with relevant data, which may include initial profile information. Tracardi then identifies whether the profile already exists using unique identifiers such as email or user ID. If the profile exists, it is retrieved and updated; if not, a new profile is created.</p> <p>The profile's data and custom traits are then enriched with new data from the event, updating or adding new attributes as necessary. Session management ensures that new sessions are created or existing ones are updated to reflect ongoing interactions. The metadata is updated to reflect the latest changes, maintaining an accurate record of profile modifications and their sources.</p>"},{"location":"getting_started/core_concepts/#automation","title":"Automation","text":""},{"location":"getting_started/core_concepts/#triggers","title":"Triggers","text":"<p>In the Tracardi system, triggers determine which workflow should be executed when an event arrives. A rule consists of a condition and a workflow name. When an event is received, the system evaluates the rule's condition to determine if it is met. If the condition is met, the associated workflow is executed.</p> <p>The condition of a trigger includes two required elements and one optional element: the event type and the event source are required. The condition is considered met if the event is of a specified type and originates from a specified source. Optionally, the triggering can be restricted based on user consents. For example, if a user has not consented to data enhancement, the workflow responsible for enhancing profiles will not be executed.</p> <p>Triggers in Tracardi create a direct link between incoming events and the workflows that should be triggered in response. By defining appropriate rules, you can automate workflow execution based on the arrival of specific events in the system. This automation enables efficient and responsive handling of various event-driven scenarios.</p>"},{"location":"getting_started/core_concepts/#workflow","title":"Workflow","text":"<p>A workflow is a series of actions that are executed in response to an event. When an event is matched with a workflow , the actions in the workflow are executed according to the defined graph of nodes and connections.</p> <p>In Tracardi a workflow is represented as a graph of nodes, with actions being assigned to individual nodes. The connections between nodes represent the flow of data from one action to another. Actions may perform a variety of tasks, such as copying data from the event to a user profile, saving the profile, querying for additional data, sending data to another system, or emitting a new event.</p> <p>Actions in a workflow may be executed one after another, or they may be run in parallel. This allows for a high degree of flexibility in defining the sequence and execution of actions within a workflow. By constructing the appropriate graph of nodes and connections, it is possible to create complex, multi-step workflows that perform a wide range of tasks in response to events.</p>"},{"location":"getting_started/core_concepts/#actions","title":"Actions","text":"<p>In the Tracardi system, an action is a single task that is performed as part of a workflow. An action consists of input and output ports, which are used to receive and send data, respectively. The input ports of an action are used to receive data from other actions or from external sources, while the output ports are used to send data to other actions or external systems.</p> <p>An action is essentially a piece of code that performs a specific task within the Tracardi system. The input ports of an action are mapped to the input parameters of a function in the code, while the output ports are mapped to the return values of the function. This allows actions to be chained together in a workflow, with the output of one action being passed as the input to the next.</p> <p>Tracardi can be extended by programmers who write custom code and map it to an action, which is then visible as a node in the workflow editor. An action may also be referred to as a node or an [action plugin] within Tracardi.</p>"},{"location":"getting_started/core_concepts/#other-definitions","title":"Other definitions","text":""},{"location":"getting_started/core_concepts/#customer-consent","title":"Customer consent","text":"<p>Customer consent refers to the process of obtaining permission from an individual to collect, use, or share their personal data. This can be done through a variety of means, such as a written or oral agreement, a click-through on a website, or through the use of a consent form. User/Customer consent is an important principle in data privacy laws, as it allows individuals to control their own personal information and to make informed decisions about how it is used.</p> <p>Tracardi can store different types of user consents. It is used to automatically enforce data compliance with customer consents.</p>"},{"location":"getting_started/core_concepts/#data-compliance","title":"Data compliance","text":"<p>Data compliance refers to the practice of adhering to laws, regulations, and guidelines related to the handling, processing, and storing of data. This includes protecting the privacy and security of individuals' personal information, as well as ensuring that data is collected, used, and shared in a transparent and ethical manner. Data compliance is important because it helps to build trust and confidence in the way that organizations use data, and it helps to prevent data breaches, misuse, and abuse.</p> <p>Tracardi can ensure data compliance on the event property level. Meaning you can set a rule that will erase data if user did not allow you to store certain data in Tracardi.</p>"},{"location":"getting_started/core_concepts/#identification-point","title":"Identification point","text":"<p>An identification point is a feature that allows the system to identify customers during their journey. When this point is set, the system will monitor for events that can be used to match the anonymous customer's identified profile.</p> <p>To give an analogy, think of an identification point like the ones at an airport or during a police check. You stay anonymous until there is a moment when you need to show your ID. This is an identification point. At this point, you are no longer anonymous. The same goes for Tracardi, once you identify yourself, all your past events become part of your identified profile. If identification happens multiple times on different communication channels, all the anonymous actions will become not anonymous anymore.</p> <p>For example, if a customer's profile in the system has an email address that matches the email delivered in a new event, then the system can match anonymous customer data with the existing profile and merge all previous interactions/events.</p> <p>In simpler terms, an identification point is a method the system uses to recognize customers and maintain consistent information about them throughout their journey. It's also called a custom identification point to differentiate it from automatic identification. Automatic identification is used by the Automatic Profile Merging mechanism, which employs predefined keys like email addresses to detect and merge duplicate profiles.</p>"},{"location":"getting_started/core_concepts/#automatic-profile-merging-apm","title":"Automatic Profile Merging (APM)","text":"<p>Automatic Profile Merging (APM) in Tracardi is a background service that identifies and consolidates duplicate user profiles automatically. This mechanism ensures that the information related to a user remains consistent and comprehensive, improving the quality of the data and providing a unified view of each user. APM uses predefined keys such as email addresses, phone numbers, or other unique identifiers to detect duplicate profiles. These keys are critical pieces of information that are likely to be unique to each user.Example: An email address is used as a merging key to identify if two profiles belong to the same user.</p>"},{"location":"getting_started/core_concepts/#event-validation","title":"Event Validation","text":"<p>Event validation is the process of ensuring that incoming event data meets predefined criteria and conforms to expected formats before it is processed, stored, or used within workflows. This is a crucial step to maintain data integrity, consistency, and reliability across the system.</p>"},{"location":"getting_started/core_concepts/#event-reshaping","title":"Event Reshaping","text":"<p>Event reshaping refers to the process of transforming or modifying event data to fit specific requirements or formats before further processing or storage. This functionality is critical for ensuring that events captured from various sources are standardized, enriched, and made consistent for analytics, personalization, or any other downstream processing.</p>"},{"location":"getting_started/core_concepts/#event-mapping","title":"Event Mapping","text":"<p>Event mapping involves transforming the event properties into event traits. Traits are index within the system and properties are not. Mapping events cause the data to be searchable when put in to the event traits. Mapping may include renaming fields, converting data schema, etc.</p>"},{"location":"getting_started/core_concepts/#event-to-profile-mapping","title":"Event to Profile Mapping","text":"<p>Event to Profile Mapping in the context of Tracardi (or similar customer data platforms) refers to the process of associating incoming events with user profiles. This mapping ensures that the actions and behaviors recorded in the events are accurately reflected in the corresponding user profiles. Events are referenced in profile history automatically.</p> <p>Once an event is mapped connected with a profile, it can be used to enrich the profile with additional information. This could include updating the profile with new attributes, preferences, interests, or any other relevant data points derived from the event properties or traits.</p> <p>Profiles are continuously updated as new events are collected. This dynamic updating ensures that the profiles remain current and reflect the latest customer data and interests.</p>"},{"location":"getting_started/core_concepts/#audience","title":"Audience","text":"<p>An audience is a group of users or profiles that have been segmented based on specific criteria or behaviors. Audiences are created to target users more effectively for marketing campaigns, personalized content, and other customer engagement strategies. Audiences are defined by setting criteria that profiles must meet to be included. These criteria can be based on various attributes such as demographic information, behaviors, interactions, or any other data points collected in the customer profiles. Example: An audience could be defined as users who have made a purchase in the last 30 days and have an email address.</p>"},{"location":"getting_started/codings/","title":"Tracardi Notations and Codings","text":"<ul> <li>Dot Notation</li> <li>Logic Coding</li> <li>Object Templates</li> <li>Templates</li> <li>Event Validator Schema</li> </ul>"},{"location":"getting_started/codings/dot_notation/","title":"Dot notation","text":"<p>Dot notation is a way to access data in internal state of workflow. It is a standard  way to reference data in Tracardi. It is used across many places in Tracardi such as  plugins, destinations, etc. </p>"},{"location":"getting_started/codings/dot_notation/#example-of-dot-notation","title":"Example of dot notation","text":"<pre><code>event@properties.name\n</code></pre> <p>Dot notation is build from source and path to data. Available sources are:</p> <ul> <li>profile</li> <li>event</li> <li>payload</li> <li>flow</li> <li>session</li> <li>memory</li> </ul> <p>Path is a string of keys that indicate where the data is placed.</p> <p>For example if your profile data looks like this</p> <pre><code>{\n   \"key\": {\n        \"data\": \"value\"\n   }\n}\n</code></pre> <p>To access \"value\" your path will need to look like this: key.data.</p> <p>The full access dot notation is profile@key.data.</p> <p>Warning</p> <p>If there is an error in dot notation or it is not in a right format e.g <code>profile.data.name</code> instead of  <code>profile@data.name</code> then the result is the typed value, in this example <code>profile.data.name</code>. That means that any  value that is not a valid dot notation will be returned as is.</p>"},{"location":"getting_started/codings/dot_notation/#path-to-part-of-data","title":"Path to part of data","text":"<p>There is also a way to access a part of data. </p> <p>A path like profile@key will return:</p> <pre><code>{\n  \"data\": \"value\"\n}\n</code></pre> <p>To access all data from profile type:</p> <pre><code>profile@... #(1)\n</code></pre> <ol> <li>Return the whole profile object</li> </ol> <p>If you would like to retrieve a sub-object form some bigger object. For example everything below key. (see below).</p> <pre><code>{\n   \"key\": {\n        \"data\": \"value\"\n   }\n}\n</code></pre> <p>Then you need to use the following dot notation:</p> <pre><code>profile@key #(1)\n</code></pre> <ol> <li>Return everything below key. The result will be <code>{\"data\": \"value\"}</code></li> </ol>"},{"location":"getting_started/codings/dot_notation/#path-to-array-items","title":"Path to array items","text":""},{"location":"getting_started/codings/dot_notation/#arrays","title":"Arrays","text":"<p>Items in array can be accessed like this. For the payload data:</p> <pre><code>{\n  \"data\": [\"value1\", \"value2\"]\n}\n</code></pre> <p>accessor that get <code>value1</code> should look like this.</p> <pre><code>payload@data.0\n</code></pre> <p>Tip</p> <p>Also objects embeded inside arrays can be retrieved the same way.</p>"},{"location":"getting_started/codings/dot_notation/#object-with-spaces-in-the-keys","title":"Object with spaces in the keys","text":"<p>There are rare cases when you have an object with the keys that contain spaces.</p> Example<pre><code>{\n   \"key\": {\n        \"My key with spaces\": \"value\"\n   }\n}\n</code></pre> <p>To access this data you will need to use the following dot notation:</p> <pre><code>profile@key[\"My key with spaces\"]\n</code></pre> <p>Tip</p> <p>Also objects embeded inside arrays can be retrieved the same way. For exampel <code>profile@key.0[\"My key with spaces\"]</code></p>"},{"location":"getting_started/codings/dot_notation/#read-also-about","title":"Read also about:","text":"<p>Notations that use dot notation:</p> <ul> <li>Templates</li> <li>Object templates</li> <li>Logic notation</li> </ul> <p>This documentation answers the following questions:</p> <ul> <li>What is dot notation?</li> <li>What is the purpose of dot notation in Tracardi?</li> <li>What are the available sources for dot notation in Tracardi?</li> <li>What is the format of dot notation in Tracardi?</li> <li>What is the warning associated with dot notation in Tracardi?</li> <li>How can a part of data be accessed using dot notation in Tracardi?</li> <li>How can items in an array be accessed using dot notation in Tracardi?</li> <li>Can objects embedded inside arrays be retrieved using dot notation in Tracardi?</li> <li>How can I access profile data in tracardi?</li> <li>How can I access event data in tracardi?</li> <li>How can I access session data in tracardi?</li> </ul>"},{"location":"getting_started/codings/event_validation/","title":"Event validation schema","text":"<p>To add new event validation schema that you will need to provide a Json Schema object that defines the model of event, or event session or loaded profile.</p> <p>Validator consist of 2 elements. Data to be validated - expressed in a dotted notation, and a json schema itself.</p> <pre><code>{\n  \"event@properties\": {\n    ...json-schema\n  },\n  \"profile@traits.my-data\": {\n    ...json-schema\n  }\n}\n</code></pre>"},{"location":"getting_started/codings/event_validation/#example","title":"Example","text":"Real example - for event@properties<pre><code>{\n  \"validation\": {\n    \"json_schema\": {\n      \"event@properties\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"price\": {\n            \"type\": \"number\"\n          },\n          \"name\": {\n            \"type\": \"string\"\n          }\n        },\n        \"required\": [\n          \"name\"\n        ]\n      }\n    }\n  },\n  \"event_type\": \"test\"\n}\n</code></pre>"},{"location":"getting_started/codings/logic_notation/","title":"Logic notation","text":"<p>Logic notation is the way in which logical concepts and their interpretations are expressed in natural languages. Tracardi uses logic notation in segment configuration, IF plugin action,or other conditional statements.</p>"},{"location":"getting_started/codings/logic_notation/#syntax","title":"Syntax","text":"<p>The following grammar define logic expression syntax.</p> <pre><code>expr:\n  | expr OR (expr AND expr)\n  | expr AND (expr OR expr)\n</code></pre> <p>that means that expressions with similar operators e.g. OR must be in brackets.</p> <p>Remember...</p> <p>The following conditional statement is forbidden:</p> <pre><code>field1=1 AND field2=2 OR field3=3\n</code></pre> <p>correct statement is either:</p> <pre><code>field1=1 AND (field2=2 OR field3=3)\n</code></pre> <p>or</p> <pre><code>(field1=1 AND field2=2) OR field3=3\n</code></pre> <p>There is no auto resolution of priority operations</p>"},{"location":"getting_started/codings/logic_notation/#condition-resolution","title":"Condition resolution","text":"<p>Each condition consist of a field, operator, and value. An operator is used to manipulate individual data items and return a result. Operators are represented by special characters or by keywords. List of operators is available below.</p> Example<pre><code>payload@numberOfPurchases == 1\n</code></pre> <p>This example will return true if numberOfPurchases in payload equals 1. The data within our system is organized into fields that are accessed using dot notation. </p> <p>Tip</p> <p>Possible ways to access data: <code>payload@numberOfPurchases, payload@..., payload@numberOfPurchases.0, payload@numberOfPurchases[\"some key\"]</code> For detailed instructions on how to access data using this notation, please refer to the  dot notation documentation.</p> <p>Operations can be joined by AND/OR.</p> Example<pre><code>payload@numberOfPurchases == 1 AND payload@title == \"Title\"\n</code></pre> <p>This example will return True if numberOfPurchases in payload equals 1 and title in payload equals \"Title\".</p>"},{"location":"getting_started/codings/logic_notation/#operator-order","title":"Operator order","text":"<p>If there is a data missing. For example:</p> <pre><code>profile@missing.data == 1\n</code></pre> <p>then you will see an error: Missing Value. To prevent it you will need to check if the data exists or is not empty. To do so type:</p> <pre><code>profile@missing.data NOT EMPTY AND profile@missing.data == 1\n</code></pre> <p>This way when data does not exist or is empty then the rest of the condition will not be checked and the result will be FALSE. Otherwise, when the <code>profile@missing.data</code> exists and is equal 1 then the result is TRUE.</p> <p>The order in the condition does mather.</p>"},{"location":"getting_started/codings/logic_notation/#type-of-operators","title":"Type of operators","text":"<p>There are other operators possible like:</p> <ul> <li>less then (&lt;)</li> <li>greater then (&gt;)</li> <li>less or equal then (&lt;=)</li> <li>greater or equal then (&gt;=)</li> <li>not equal (!=)</li> <li>exists (field_name EXISTS)</li> <li>not exists (field_name NOT EXISTS)</li> <li>empty (field_name EMPTY)</li> <li>not empty (field_name NOT EMPTY)</li> <li>consists (field_name CONSIST \"text\" )</li> <li>starts with (field_name STARTS WITH \"text\" )</li> <li>ends with (field_name ENDS WITH \"text\" )</li> </ul>"},{"location":"getting_started/codings/logic_notation/#example-of-operator-use","title":"Example of operator use","text":"Example<pre><code>payload@path.to.data NOT EMPTY\n</code></pre>"},{"location":"getting_started/codings/logic_notation/#value-types","title":"Value types","text":"<p>In the example:</p> Example<pre><code>payload@numberOfPurchases == 1 AND payload@title == \"Title\"\n</code></pre> <p>Field payload@numberOfPurchases is considered an integer number while payload@title is considered a string.</p> <p>Warning</p> <p>Values of differnet types can not be compared. </p>"},{"location":"getting_started/codings/logic_notation/#functions","title":"Functions","text":"<p>Functions can be used to convert value, for example to certain types.</p> <ul> <li>now() - returns current date and time</li> <li>utcnow() - returns current UTC date and time</li> <li>datetime(field_name) - returns field_name field content as date and time</li> <li>now(time_zone) - returns current date and time with given timezone info</li> <li>now.offset(offset) - returns current date and time with given offset (e.g. -15m)</li> <li>now.timezone.offset(timezone, offset) - returns current date and time with given   timezone info with applied offset</li> <li>datetime.offset(field_name, offset) - returns field_name field content as date and time with applied offset</li> <li>datetime.timezone(field_name, timezone) - returns field_name field content as date and time with timezone info</li> <li>now.timezone(timezone) - returns current date and time with given timezone info</li> <li>lowercase(field_name) - returns lowercased text value of field_name</li> <li>uppercase(field_name) - returns upper-cased text value of field_name</li> <li>datetime.from_timestamp(field_name) - returns date and time created from timestamp content of field field_name</li> </ul>"},{"location":"getting_started/codings/logic_notation/#example-of-function-use","title":"Example of function use","text":"Example<pre><code>datetime.from_timestamp(payload@path.to.data) &gt; datetime.from_timestamp(payload@path.to.time)\n</code></pre> <p>This documentation answers the following questions:</p> <ul> <li>What is logic notation?</li> <li>How to write a condition statement?</li> <li>How is logic notation used in segment configuration and IF plugin actions?</li> <li>What is the syntax for logic expressions?</li> <li>Why is it important to use brackets when expressions have similar operators?</li> <li>What is the correct way to structure a conditional statement to avoid ambiguity?</li> <li>How are conditions resolved in logic notation?</li> <li>What are some examples of operators that can be used in logic expressions?</li> <li>What are some examples of value types that can be used in logic expressions?</li> <li>How can functions be used to manipulate values in logic expressions?</li> </ul>"},{"location":"getting_started/codings/object_template/","title":"Object template","text":"<p>There are places where you may want to create an object that consist of the data from profile, payload, memory. etc. Is such cases you should use an object template. It will allow you to reshape the data into any object you want.</p> <p>Here is an example of object template.</p> <pre><code>{\n  \"some-data\": {\n    \"key\": \"value\",  // This is static value\n    \"value\": \"profile@id\"  // Reads value from profile and saves it in object new.value\n    \"list\": [1, \"payload@data\"] // Reads data value from payload and saves it as 2nd element of list\n    \"event\": \"event@...\"  // Saves in event all data from event.\n  }\n}\n</code></pre> <p>Notice that some parts of this object reference data with dot notation. The data will be replaced be the referenced data.</p> <p>Let's assume that profile has the following data:</p> <pre><code>{\n  \"id\": \"profile-id\",\n  \"data\": {\n    \"name\": \"John\",\n    \"age\": 26\n  }\n}\n</code></pre> <p>And event equals:</p> <pre><code>{\n  \"type\": \"page-view\",\n  \"properties\": {\n    \"url\": \"http://localhost\"\n  }\n}\n</code></pre> <p>then the result of the object template of:</p> <pre><code>{\n  \"some-data\": {\n    \"key\": \"value\",  // This is static value\n    \"value\": \"profile@id\"  // Reads value from profile and saves it in object new.value\n    \"list\": [1, \"payload@data\"] // Reads data value from payload and saves it as 2nf element of list\n    \"event\": \"event@...\"  // Saves in event all data from event.\n  }\n}\n</code></pre> <p>will be:</p> <pre><code>{\n  \"some-data\": {\n    \"key\": \"value\",\n    \"value\": \"profile-id\",\n    \"list\": [\n      1,\n      {\n        \"name\": \"John\",\n        \"age\": 26\n      }\n    ],\n    \"event\": {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"url\": \"http://localhost\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/codings/searching/","title":"Searching","text":"<ul> <li>Before version 0.8.2</li> <li>After version 0.8.2</li> </ul>"},{"location":"getting_started/codings/templates/","title":"Templates","text":"<p>Template is a text file with special mark-up. Within double curly braces you can place dot notation  that reads data from internal state of the workflow. </p> Example<pre><code>Hello {{profile@pii.name}}\n</code></pre> <p>Mark-up  <code>{{profile@pii.name}}</code> will be replaced by the data from profile.</p>"},{"location":"getting_started/codings/search/searching_before_082/","title":"Searching (before 0.8.2)","text":"<p>Filtering is used in Tracardi to limit the number of event, profiles, etc. on the page. It uses a query parser that allows to define the rules of filtering.</p> <p>The query string is parsed into a series of terms and operators. A term can be a single word a phrase, surrounded by double quotes \"quick brown\" which searches for all the words in the phrase, in the same order.</p> <p>Operators allow you to customize the search.</p>"},{"location":"getting_started/codings/search/searching_before_082/#operators","title":"Operators","text":"<p>You can specify fields to search in the query syntax:</p> <ul> <li> <p>Find the records where status field contains active     <pre><code>status:active\n</code></pre></p> </li> <li> <p>where the event.type field contains page-view  or purchase</p> <pre><code>event.type:(page-view OR purchase)\n</code></pre> </li> </ul> <p>Remember the operators like OR, AND must be uppercase.</p> <ul> <li> <p>where the event.properties.product field contains the exact phrase \"Nike sneakers\"</p> <pre><code>event.properties.product:\"Nike sneakers\"\n</code></pre> </li> <li> <p>where the profile first name field contains Alice (note how we need to escape the space with a backslash)</p> <pre><code>profile.data.pii.first\\ name:Alice\n</code></pre> </li> <li> <p>where any of the fields book.title, book.content or book.date contains quick or brown (note how we need to   escape the</p> <ul> <li>with a backslash):</li> </ul> <pre><code>book.\\*:(quick OR brown)\n</code></pre> </li> <li> <p>where the field title has any non-null value:</p> <pre><code>_exists_:title\n</code></pre> </li> <li> <p>where the field title does not exist:</p> <p><pre><code>NOT _exists_:title\n</code></pre>   or <pre><code>!_exists_:title\n</code></pre></p> </li> </ul>"},{"location":"getting_started/codings/search/searching_before_082/#wildcards","title":"Wildcards","text":"<p>Wildcard searches can be run on individual terms, using ? to replace a single character, and * to replace zero or more characters:</p> <pre><code>qu?ck bro*\n</code></pre> <p>Be aware that wildcard queries can use an enormous amount of memory and perform very badly just think how many terms need to be queried to match the query string \"a b c*\".</p> <p>Warning</p> <p>Allowing a wildcard at the beginning of a word (eg \"*ing\") is particularly heavy, because all terms in the index  need to be examined, just in case they match. Leading wildcards are disabled.</p>"},{"location":"getting_started/codings/search/searching_before_082/#regular-expressions","title":"Regular expressions","text":"<p>Regular expression patterns can be embedded in the query string by wrapping them in forward-slashes (\"/\"):</p> <pre><code>name:/joh?n(ath[oa]n)/\n</code></pre>"},{"location":"getting_started/codings/search/searching_before_082/#fuzziness","title":"Fuzziness","text":"<p>You can run fuzzy queries using the ~ operator:</p> <pre><code>quikc~ brwn~ foks~\n</code></pre> <p>The query uses the Damerau-Levenshtein distance to find all terms with a maximum of two changes, where a change is the insertion, deletion or substitution of a single character, or transposition of two adjacent characters.</p> <p>The default edit distance is 2, but an edit distance of 1 should be sufficient to catch 80% of all human misspellings. It can be specified as:</p> <pre><code>quikc~1\n</code></pre> <p>Avoid mixing fuzziness with wildcards</p> <p>Mixing fuzzy and wildcard operators is not supported. When mixed, one of the operators is not applied. For example, you can search for app~1 (fuzzy) or app (wildcard), but searches for app~1 do not apply the fuzzy operator (~1).</p>"},{"location":"getting_started/codings/search/searching_before_082/#ranges","title":"Ranges","text":"<p>Ranges can be specified for date, numeric or string fields. Inclusive ranges are specified with square brackets [min TO max] and exclusive ranges with curly brackets {min TO max}. By default, when you filter by query ranges in filtering box (right to the filter textbox) are disabled. You can define ranges as query.</p>"},{"location":"getting_started/codings/search/searching_before_082/#examples","title":"Examples","text":"<ul> <li> <p>All days in 2012:   <pre><code>date:[2012-01-01 TO 2012-12-31]\n</code></pre></p> </li> <li> <p>Numbers 1..5</p> </li> </ul> <pre><code>count:[1 TO 5]\n</code></pre> <ul> <li>Tags between alpha and omega, excluding alpha and omega:</li> </ul> <pre><code>tag:{alpha TO omega}\n</code></pre> <ul> <li>Numbers from 10 upwards</li> </ul> <pre><code>count:[10 TO *]\n</code></pre> <ul> <li>Dates before 2012</li> </ul> <pre><code>date:{* TO 2012-01-01}\n</code></pre> <ul> <li>Ranges with one side unbounded can use the following syntax:</li> </ul> <pre><code>age:&gt;10\nage:&gt;=10\nage:&lt;10\nage:&lt;=10\n</code></pre>"},{"location":"getting_started/codings/search/searching_before_082/#boolean-operators","title":"Boolean operators","text":"<p>When filtering all terms are optional, as long as one term matches the record is returned. A search for foo bar baz will find any document that contains one or more of foo or bar or baz.</p> <p>There are also boolean operators which can be used in the query string itself to provide more control.</p> <p>The operators are + (this term must be present) and - (this term must not be present). All other terms are optional.</p> <p>For example, this query:</p> <pre><code>quick brown +fox -news\n</code></pre> <p>states that:</p> <ul> <li>fox must be present</li> <li>news must not be present</li> <li>quick and brown are optional their presence increases the relevance</li> </ul>"},{"location":"getting_started/codings/search/searching_before_082/#and-or-not","title":"And, or, not","text":"<p>The boolean operators AND, OR and NOT (also written &amp;&amp;, || and !) are also supported but beware that they do not honor the usual precedence rules, so parentheses should be used whenever multiple operators are used together. For instance the previous query could be rewritten as:</p> <pre><code>((quick AND fox) OR (brown AND fox) OR fox) AND NOT news\n</code></pre>"},{"location":"getting_started/codings/search/searchng_after_082/","title":"Searching (after 0.8.2)","text":"<p>Filtering in version 0.8.2 was simplified and has the following operations.</p> <ol> <li> <p>Comparison Conditions:</p> <ul> <li>Basic comparison between a field and a value:<ul> <li><code>fieldName &gt; \"value\"</code> or <code>product_price &lt;= 100.50</code> or - <code>active = true</code></li> </ul> </li> <li>Text search<ul> <li><code>field.name = \"value\"</code> (text search + exact match, finds sentence with <code>value</code> or fields with <code>value</code>)</li> <li><code>field.name == \"value\"</code> or <code>field.name is \"value\"</code>(exact text search)</li> <li><code>field.name ~ \"value\"</code> or <code>field.name match \"value\"</code> (full text search only)</li> </ul> </li> <li>Text with wildcards<ul> <li><code>field.name = \"value*\"</code> (wildcard search + text search: searches for any string starting with <code>value</code>)</li> <li><code>field.name == \"value?\"</code> (wildcard search in field: searches for any string starting with <code>value</code> + 1 character)</li> <li><code>field.name != \"value\"</code> (all but <code>value</code> search)</li> </ul> </li> <li>Boolean values search:<ul> <li><code>is_active = TRUE</code></li> <li><code>is_deleted = FALSE</code></li> </ul> </li> <li>Checking for NULL values:<ul> <li><code>product_name IS NULL</code></li> </ul> </li> <li>Basic numeric value conditions:<ul> <li><code>quantity &gt; 10</code></li> <li><code>quantity = 10.01</code></li> <li><code>quantity &lt; 10</code></li> <li><code>quantity &gt;= 10</code></li> <li><code>quantity != 10</code></li> <li><code>quantity &lt;= 10</code></li> </ul> </li> <li>Using arrays in conditions:</li> <li><code>categories IN [\"Electronics\", \"Clothing\", \"Books\"]</code></li> <li><code>product_id NOT IN [101, 102, 103]</code> (TO BE IMPLEMENTED)</li> </ul> </li> <li> <p>Logical Operators:</p> <ul> <li>Combining conditions with <code>AND</code> and <code>OR</code>:<ul> <li><code>sales &gt; 1000 AND region = \"North\"</code></li> <li><code>age &gt;= 18 OR (gender = \"Female\" AND has_children = TRUE)</code></li> </ul> </li> </ul> </li> <li> <p>Grouping:</p> <ul> <li>Using parentheses to group conditions:<ul> <li><code>(age &lt; 30 AND income &gt; 50000) OR (region = \"West\" AND product = \"Widget\")</code></li> </ul> </li> </ul> </li> <li> <p>Field Existence:</p> <ul> <li>Checking for the existence or non-existence of a field:<ul> <li><code>customer_email EXISTS</code></li> <li><code>employee_manager NOT EXISTS</code></li> </ul> </li> </ul> </li> <li> <p>Range Conditions:</p> <ul> <li>Comparing a field with a range:<ul> <li><code>temperature BETWEEN 68 AND 72</code></li> <li><code>price BETWEEN 10.99 AND 19.99</code></li> </ul> </li> </ul> </li> <li> <p>Field Equality:</p> <ul> <li>Comparing two fields:<ul> <li><code>order_total_amount = payment_total_amount</code></li> <li><code>start_date &lt; end_date</code></li> </ul> </li> </ul> </li> <li> <p>Field Functions:</p> <ul> <li>Applying functions to fields:</li> <li><code>DATE(order_date) = \"2023-01-15\"</code> (TO BE IMPLEMENTED)</li> <li><code>UPPER(product_name) = \"WIDGET\"</code> (TO BE IMPLEMENTED)</li> </ul> </li> <li> <p>Compound Value and Field Conditions:</p> <ul> <li>Using compound values and fields:</li> <li><code>category(\"Electronics\") = price + tax</code> (TO BE IMPLEMENTED)</li> <li><code>order_status(\"Shipped\") = customer_name</code> (TO BE IMPLEMENTED)</li> </ul> </li> <li> <p>Time Conditions:</p> <ul> <li>Expressing time conditions:</li> <li><code>time_elapsed &gt;= 2d</code> (greater than or equal to 2 days) (TO BE IMPLEMENTED)</li> <li><code>duration &lt; 1h</code> (less than 1 hour) (TO BE IMPLEMENTED)</li> </ul> </li> </ol> <p>This documentation answer the following questions:</p> <ul> <li>How to search for profile, session, and events in Tracardi GUI</li> <li>How to search data in Tracardi?</li> <li>How does Tracardi's query parser work?</li> <li>What is a query condition?</li> <li>What is the syntax for searching, filtering in Tracardi?</li> </ul>"},{"location":"getting_started/components/","title":"Core components","text":""},{"location":"getting_started/components/action/","title":"Action or Action Plugin in Tracardi","text":"<p>An action or action plugin is a modular unit of functionality that performs specific operations within a workflow. Actions are the building blocks of workflows, and they define the tasks to be executed when certain conditions or triggers are met.</p>"},{"location":"getting_started/components/action/#key-features-of-action-plugins","title":"Key Features of Action Plugins","text":"<ol> <li> <p>Modularity:</p> <ul> <li>Action plugins are self-contained modules that can be reused across different workflows. This modularity allows   for easy customization and extension of Tracardi's capabilities.</li> </ul> </li> <li> <p>Flexibility:</p> <ul> <li>They can perform a wide range of tasks, from data transformation and enrichment to external system integrations   and conditional logic.</li> </ul> </li> <li> <p>Configuration:</p> <ul> <li>Action plugins can be configured with various parameters and options to tailor their behavior to specific   requirements. Configuration can include input fields, resource connections, and processing rules.</li> </ul> </li> <li> <p>Integration:</p> <ul> <li>They enable integration with external APIs, databases, messaging systems, and other services, allowing Tracardi to   interact with a wide array of external systems.</li> </ul> </li> </ol>"},{"location":"getting_started/components/action/#common-types-of-action-plugins","title":"Common Types of Action Plugins","text":"<ol> <li> <p>Data Transformation:</p> <ul> <li>Plugins that manipulate or transform data, such as converting data formats, aggregating data, or filtering data   based on specific criteria.</li> </ul> </li> <li> <p>External Integrations:</p> <ul> <li>Plugins that connect to external services and APIs, such as sending emails, making HTTP requests, or writing data   to a database.</li> </ul> </li> <li> <p>Conditional Logic:</p> <ul> <li>Plugins that evaluate conditions and route data accordingly, such as IF/ELSE branches, switch cases, or   comparisons.</li> </ul> </li> <li> <p>Data Enrichment:</p> <ul> <li>Plugins that enhance data by adding additional information, such as looking up data from external sources or   calculating new fields based on existing data.</li> </ul> </li> </ol>"},{"location":"getting_started/components/bridge/","title":"Bridge","text":"<p>A bridge in Tracardi acts as a communication link between separate systems, facilitating data exchange. It collects data from various sources and transfers it to an event source within Tracardi, which then processes the data. Event Source and Bridge</p> <p>Event sources use bridges to collect data, each with its own configuration. When creating an event source, the form includes a section for bridge configuration. By default Open Source Tracardi supports several types of bridges:</p> <ul> <li>REST API Bridge - Standard way of collecting data form external systems or the Javascript placed on the web page. </li> <li>Webhook Bridge - Collects unstructured data</li> <li>Redirect URL Bridge - Captures data when a link is clicked</li> </ul> <p>Each serves a different purpose. A bridge is an extension point of Tracardi, making it easy to code a new bridge. We provide a tutorial to guide you through the process.</p>"},{"location":"getting_started/components/destination/","title":"Destination","text":"<p>Destination refers to a target endpoint or system where processed profiles or events are sent. This can include various types of systems or services such as APIs, databases, messaging queues, and more. The concept of destinations is used to route the profile or events to these external systems for further processing, storage, or analysis. To function, a destination requires a specific resource, such as an API endpoint or queue service, to receive and process the data.</p> <p>Destinations are defined in the system and can be configured to handle asynchronous operations. This setup ensures that data is transmitted to the destination efficiently without blocking other operations within the workflow. The definition and configuration of destinations can be found within the outbound traffic settings, where you can specify the type of destination, connection details, and any required authentication parameters.</p> <p>For instance, a typical destination setup might involve configuring a REST API resource where you would specify the URL, HTTP method (GET, POST, etc.), headers, and any necessary payload formatting in the destination configuration. The system can then route processed data to this endpoint as part of its execution flow.</p>"},{"location":"getting_started/components/destination/#available-destinations","title":"Available destinations","text":"<p>Depending on the system version, the list of available destinations may change. The easiest way to check the available ones is to go to the <code>resources/extensions</code> tab and filter out <code>type/destinations</code>. To use one of them you need to install.</p> <p>Typical destination would be:</p> <ul> <li>Kafka</li> <li>Apache Pulsar</li> <li>Rabbitmq</li> <li>Remote API</li> <li>Mautic</li> </ul> <p>Destinations are an extension point in tracardi meaning you can easily code your own destination and add it to the system core.</p>"},{"location":"getting_started/components/event/","title":"Event","text":"<p>In Tracardi, events are records of actions or occurrences that take place at a specific point in time. They serve as the primary mechanism for tracking and understanding user behavior on a website or application. Here\u2019s a detailed overview of events in Tracardi:</p>"},{"location":"getting_started/components/event/#purpose-of-events","title":"Purpose of Events","text":"<ul> <li>Tracking User Behavior: Events are used to monitor and record various user interactions and activities on a   website or application.</li> <li>Capturing Data: Events can capture a wide range of data points, such as user actions, timestamps, and additional   context-specific information.</li> </ul>"},{"location":"getting_started/components/event/#examples-of-events","title":"Examples of Events","text":"<ul> <li>Click Events: Tracking when a user clicks on a link or button.</li> <li>Login Events: Recording when a user logs into an account.</li> <li>Form Submissions: Capturing data when a user submits a form.</li> <li>Page Views: Logging when a user views a specific page.</li> <li>Purchase Orders: Recording details of a purchase made by the user.</li> </ul>"},{"location":"getting_started/components/event/#event-data","title":"Event Data","text":"<p>Events can carry various types of data depending on the interaction being tracked. This data can include:</p> <ul> <li>User Information: Details such as username or user ID.</li> <li>Interaction Details: Information about the action taken, such as the item purchased or the page viewed.</li> <li>Contextual Data: Additional information such as the device used, browser type, operating system, screen   resolution, and other environmental details.</li> </ul>"},{"location":"getting_started/components/event/#triggering-events","title":"Triggering Events","text":"<p>Events in Tracardi can be triggered in several ways:</p> <ul> <li>JavaScript Execution: Events can be triggered by executing JavaScript code on a webpage.</li> <li>API Calls: Events can be triggered by making API requests to the <code>/track</code> endpoint.</li> </ul>"},{"location":"getting_started/components/event/#configurability","title":"Configurability","text":"<ul> <li>Customizable Event Types: The types of events and the data they capture can be configured to meet specific   tracking requirements.</li> <li>Data Configuration: The data sent with each event can be customized based on the type of event and the information   needed.</li> </ul>"},{"location":"getting_started/components/event/#event-processing","title":"Event Processing","text":"<ul> <li>Storage: Events can be stored within the Tracardi system for later analysis and reporting.</li> <li>Workflow Integration: Events can be passed to workflows for real-time processing and action. This allows for   automated responses and further data manipulation based on the events.</li> </ul>"},{"location":"getting_started/components/event/#types-of-events","title":"Types of Events","text":"<p>Tracardi supports four primary types of events:</p> <ul> <li>Events with Profiles: These events are associated with user profiles, providing a richer context by linking events   to specific users.</li> <li>Events without Profiles: These events are not linked to any user profile, useful for tracking anonymous or   non-user-specific actions.</li> <li>Ephemeral events: Ephemeral events are temporary events that are processed without being permanently stored in the system</li> <li>System Events: System events in Tracardi are automatically generated events that record the internal workings of the system.</li> </ul>"},{"location":"getting_started/components/event/#flexibility-and-usage","title":"Flexibility and Usage","text":"<p>Events provide a flexible and powerful way to track and respond to user interactions. They are fundamental to understanding user behavior, personalizing user experiences, and driving data-driven decision-making within the Tracardi system.</p> <p>By leveraging events, Tracardi enables comprehensive monitoring, analysis, and automation of user interactions, enhancing the ability to tailor experiences and optimize engagement strategies.</p>"},{"location":"getting_started/components/event_source/","title":"Event source","text":"<p>In Tracardi, an event source is a defined entry point for collecting data. It specifies where and how data is captured, and it plays a critical role in the data collection process. Here\u2019s a detailed description of event sources in Tracardi:</p>"},{"location":"getting_started/components/event_source/#what-is-an-event-source","title":"What is an Event Source?","text":"<p>An event source in Tracardi is a configuration that determines the origin and nature of the data being collected. It serves as a gateway through which events, representing various user interactions and actions, enter the Tracardi system. Key Components of an Event Source</p> <ul> <li> <p>Source Bridge: Bridge defines how the data will be collected. This is kind of type of event source that specifies   the nature and protocol of the data collection. Common types include REST API endpoints, webhooks, JavaScript   tracking, and more. Each bridge defines a different method of data ingestion.</p> </li> <li> <p>Source ID: Each event source is assigned a unique identifier (ID) that is used to reference it within the Tracardi   system. This   ID is crucial for configuring integrations and ensuring data is routed correctly.</p> </li> <li> <p>Configuration Details: Name: A descriptive name for the event source to easily identify it; Description:   Description of the source; Channel: Mobile, Web, CRM, Call Center, etc.; Bridge specific configuration: Queue Topic,   etc.</p> </li> </ul>"},{"location":"getting_started/components/event_source/#purpose-of-event-sources","title":"Purpose of Event Sources","text":"<ul> <li> <p>Data Collection: Event sources are fundamental for collecting data from various channels, including websites,   mobile apps, CRM systems, and other platforms. They enable Tracardi to capture user interactions and other relevant   data in real-time.</p> </li> <li> <p>Data Source Identification: They allow identification of the channel that the event came from for further   processing and analysis.</p> </li> <li> <p>Event Routing: For certain event sources, you can specify how incoming events are processed within Tracardi. Some   event sources may only collect data with a defined payload, which will be processed in a strictly defined manner   within Tracardi.</p> </li> </ul>"},{"location":"getting_started/components/event_source/#setting-up-an-event-source","title":"Setting Up an Event Source","text":"<ul> <li> <p>Create an Event Source: In the Tracardi GUI, navigate to the Inbound Traffic section and select Add New Source.   Provide the necessary details,   such as name, type, and channel.</p> </li> <li> <p>Integration with JavaScript Snippet: If using a web-based event source, integrate the JavaScript snippet into your   web pages. This snippet will send events   to the Tracardi event source.</p> </li> <li> <p>Testing and Verification: After setting up the event source, test it to ensure that data is being collected   correctly. This involves triggering   events from the configured source and verifying that they appear in the Tracardi system.</p> </li> </ul>"},{"location":"getting_started/components/event_source/#example-use-cases","title":"Example Use Cases","text":"<ul> <li> <p>Web Tracking: Capturing page views, clicks, and form submissions from a website using the JavaScript tracking   snippet.</p> </li> <li> <p>Call Center Calls: Collect all the interactions with your call center under the profile history.</p> </li> <li> <p>Email Campaigns: Tracking email opens and link clicks using redirect links and tracking parameters.</p> </li> <li> <p>CRM Integration: Collecting customer data from a CRM system through a REST API event source.</p> </li> <li> <p>Webhook Integration with Other Systems: Collect Slack messages, or Github Stars, or Filled forms, etc.</p> </li> </ul> <p>There are endless use cases how the data can be collected</p>"},{"location":"getting_started/components/profile/","title":"Profile","text":"<p>A profile in Tracardi represents an aggregated and comprehensive set of data about a customer, built dynamically as events are processed by the system. Profile is referenced in sessions, and events. It captures all relevant information and interactions pertaining to a user/customer, allowing for personalized and context-aware actions within Tracardi workflows.</p>"},{"location":"getting_started/components/profile/#key-components-of-a-profile","title":"Key Components of a Profile","text":"<ol> <li> <p>Profile ID:</p> <ul> <li>A unique identifier (usually a UUID) that distinguishes the profile from other profiles.</li> </ul> </li> <li> <p>Profile IDS:</p> <ul> <li>A number unique identifier (usually a UUID) that identifies the profile on different devices. Profile can be   identified by many IDS.</li> </ul> </li> <li> <p>Data and Custom Traits:</p> <ul> <li>Key-value pairs that store various attributes of the profile. These include demographic information, preferences,   behavioral data, and more (e.g., name, email, age, location, purchase history).</li> </ul> </li> <li> <p>Metadata:</p> <ul> <li>Additional context about the profile, such as creation and update timestamps, source information, and tags for   categorization.</li> </ul> </li> <li> <p>Consents:</p> <ul> <li>Data capturing the user\u2019s permissions and agreements regarding data usage, ensuring compliance with privacy   regulations.</li> </ul> </li> </ol>"},{"location":"getting_started/components/resource/","title":"Resource Definition","text":"<p>A resource is a configurable object that represents an external service, data source, or API that Tracardi can connect to and interact with. Resources are used to manage credentials, configurations, and connections to these external systems, allowing Tracardi to perform actions such as data retrieval, sending data, and integrating with third-party services.</p>"},{"location":"getting_started/components/resource/#components-of-a-resource","title":"Components of a Resource","text":"<ol> <li>Resource ID: A unique identifier for the resource.</li> <li>Resource Name: A descriptive name for the resource.</li> <li>Resource Configuration: The configuration details needed to connect to the resource. This typically includes    parameters such as URLs, API keys, authentication credentials, and other settings.</li> <li>Resource Type: The type of resource, which determines the kind of connection and interactions that Tracardi will    have with it (e.g., database, API, messaging service).</li> <li>Tags: Keywords or tags associated with the resource to help categorize and filter resources within the system.</li> </ol>"},{"location":"getting_started/components/resource/#creating-and-managing-resources","title":"Creating and Managing Resources","text":"<p>Resources are created and managed within Tracardi's GUI. Here are the steps typically involved:</p> <ol> <li>Define the Resource: Specify the resource details, including its name, type, and configuration settings.</li> <li>Configure the Resource: Input the necessary configuration parameters, such as API URLs, authentication    credentials, and any other required settings.</li> <li>Save the Resource: Save the resource configuration, making it available for use in workflows and other parts of    the system.</li> </ol>"},{"location":"getting_started/components/resource/#using-resources-in-workflows","title":"Using Resources in Workflows","text":"<p>Resources can be utilized in workflows to perform various actions, such as fetching data from an API, sending data to an external service, or integrating with other systems. Here\u2019s how resources are typically used in Tracardi workflows:</p> <ol> <li>Reference the Resource: In a workflow node or plugin, reference the resource by its ID or name.</li> <li>Access the Resource Configuration: Use the resource's configuration details to establish a connection and perform    actions.</li> <li>Execute Actions: Carry out the desired actions using the resource, such as sending a request to an API or    retrieving data from a database.</li> </ol>"},{"location":"getting_started/components/resource/#example-api-resource","title":"Example: API Resource","text":"<p>Here\u2019s an example of how an API resource might be configured and used in Tracardi:</p> <ol> <li> <p>Resource Definition - This is an internal object that is created when using GUI:     <pre><code>{\n  \"id\": \"api-resource\",\n  \"name\": \"Example API\",\n  \"config\": {\n    \"url\": \"https://api.example.com\",\n    \"method\": \"GET\",\n    \"headers\": {\n      \"Authorization\": \"Bearer YOUR_API_KEY\"\n    }\n  },\n  \"type\": \"api\",\n  \"tags\": [\"example\", \"api\"]\n}\n</code></pre></p> </li> <li> <p>Using the Resource in a Plugin:     <pre><code>import requests\nfrom tracardi.service.storage.driver.elastic import resource as resource_db\n\nclass ExampleApiPlugin(ActionRunner):\n    config: dict\n    credentials: dict\n\n    async def set_up(self, config):\n        self.config = config\n        resource = await resource_db.load(config['resource']['id'])\n        self.credentials = resource.credentials\n\n    async def run(self, payload: dict, in_edge=None):\n        response = await self._call_api()\n        return Result(port=\"response\", value=response)\n\n    async def _call_api(self):\n        url = self.credentials['url']\n        headers = self.credentials.get('headers', {})\n        response = requests.get(url, headers=headers)\n        return response.json()\n</code></pre></p> </li> </ol>"},{"location":"getting_started/components/resource/#resource-types","title":"Resource Types","text":"<p>Tracardi supports various types of resources, including but not limited to:</p> <ul> <li>API Resources: For interacting with RESTful APIs.</li> <li>Database Resources: For connecting to databases like PostgreSQL, MySQL, etc.</li> <li>Messaging Services: For connecting to messaging platforms like Kafka, RabbitMQ, etc.</li> <li>Storage Services: For connecting to cloud storage services like AWS S3, Google Cloud Storage, etc.</li> </ul>"},{"location":"getting_started/components/resource/#benefits-of-using-resources","title":"Benefits of Using Resources","text":"<ul> <li>Centralized Configuration: Resources provide a centralized way to manage connection details and credentials for   external services.</li> <li>Reusability: Once defined, resources can be reused across multiple workflows and plugins, reducing duplication and   configuration overhead.</li> <li>Security: Resources allow for secure handling of sensitive information like API keys and authentication   credentials.</li> </ul>"},{"location":"getting_started/components/resource/#credentials","title":"Credentials","text":"<p>Most of the resources need credentials that are used to connect to the resource. Credentials are attached to resource and stored inside Tracardi.</p>"},{"location":"getting_started/components/resource/#credentials-caching","title":"Credentials caching","text":"<p>Credentials are subject to caching. That means that after they are changed you will not see the change immediately but after a certain number of seconds. Usually 60 seconds.</p>"},{"location":"getting_started/components/resource/#extending-resource-types","title":"Extending Resource Types","text":"<p>Resources are an extension point in tracardi meaning you can easily code your own destination and add it to the system core.</p>"},{"location":"getting_started/components/session/","title":"Session","text":"<p>In Tracardi, a session is a type of data that is often associated with a visit to a website or application. It is a period during which a user actively interacts with the system or application.</p>"},{"location":"getting_started/components/session/#how-tracardi-knows-when-the-session-ends","title":"How tracardi knows when the session ends?","text":"<p>Sessions are tracked to understand user behavior and engagement over a period of time. Here's how Tracardi detects and manages session changes:</p> <ol> <li> <p>Session Initialization:</p> <ul> <li>When a user visits a website or application integrated with Tracardi, a unique session ID is assigned to the user.   This session ID is typically stored in a cookie on the user's device or in device memory .</li> </ul> </li> <li> <p>Session Continuity:</p> <ul> <li>As long as the session ID remains the same, Tracardi considers the user to be part of the same session. This means   that all user interactions and events are grouped under this session ID, indicating continuous activity.</li> </ul> </li> <li> <p>Session Expiration:</p> <ul> <li>If the user closes their browser or the session expires due to inactivity, the session ID is deleted. When the   user revisits the site, a new session ID is generated, indicating the start of a new session .</li> </ul> </li> <li> <p>Session ID Changes:</p> <ul> <li>The session ID changes when certain conditions are met, such as the user closing the browser, the session timing   out, or the session being explicitly invalidated. Tracardi detects these changes and increments the visit count in   the user profile to reflect a new session or visit .</li> </ul> </li> <li> <p>Debug Mode Considerations:</p> <ul> <li>In debug mode, the session ID remains constant for every simulated event, which can affect the expected behavior.   This mode is designed to simplify the debugging process by providing consistency and predictability, but it's   important to be aware of its impact on session-dependent logic when transitioning to live deployment .</li> </ul> </li> </ol> <p>Summary</p> <p>As long as the session remains unchanged, the visit is considered ongoing. The session ID is set when data is sent to Tracardi, and it is typically under the control of the client program.</p>"},{"location":"getting_started/components/session/#session-data","title":"Session Data","text":"<p>Session can contain data. Sessions are used to track user interactions over a period of time, and they can store various types of information related to these interactions. Session draws data from the context of event track payload. </p>"},{"location":"getting_started/components/session/#components-of-a-session","title":"Components of a Session","text":"<ol> <li>Session ID: Each session has a unique identifier that distinguishes it from other sessions.</li> <li>User Profile: Sessions are linked to user profiles, which contain detailed information about the user. This    linkage helps in associating session activities with the user\u2019s overall behavior and characteristics.</li> <li>Start Time: Sessions have defined start time, and a sequence of events.</li> <li>Events: Sessions contain events that record user interactions and activities during the session. Events can    include page views, clicks, form submissions, and other user actions.</li> <li>Context Data: Sessions often contain data about the context in which an event was launched, such as the type of    device, operating system, or other characteristics of the user's environment.</li> </ol>"},{"location":"getting_started/components/session/#importance-of-sessions","title":"Importance of Sessions","text":"<ul> <li>User Tracking: Sessions help in tracking user interactions over a period, providing insights into user behavior   and engagement.</li> <li>Behavior Analysis: By analyzing session data, you can understand user behavior patterns, such as how long users   stay on your site, what actions they perform, and what content they engage with.</li> <li>Marketing and Analytics: Sessions provide valuable data for marketing campaigns origin, helping you measure the   effectiveness of your strategies and optimize user engagement.</li> </ul>"},{"location":"getting_started/components/session/#session-management","title":"Session Management","text":"<p>In Tracardi, sessions are automatically created and managed. Here\u2019s how session management typically works:</p> <ol> <li>Session Initiation: A session starts when a user begins interacting with your website or application. This can be    triggered by various events, such as loading a page or performing an action.</li> <li>Event Recording: Throughout the session, events are recorded to capture user interactions. These events are    associated with the session ID.</li> <li>Session Termination: A session ends when the user becomes inactive for a certain period or explicitly logs out.    The session\u2019s end time is recorded, and the session is then closed which is indicated with event <code>Visit Ended</code>.</li> </ol>"},{"location":"getting_started/components/trigger/","title":"Workflow Trigger","text":"<p>A workflow trigger is a condition that initiates the execution of a workflow. Triggers are crucial for defining when and how workflows should start, allowing for automated responses to specific events or changes within the system.</p>"},{"location":"getting_started/components/trigger/#key-aspects-of-workflow-triggers","title":"Key Aspects of Workflow Triggers:","text":"<ol> <li>Triggers are Event-Based:<ul> <li>Workflows are triggered in response to specific events occurring within the system. For example, a   purchase event, a user logging in, or a page view can all serve as event-based triggers.</li> </ul> </li> </ol>"},{"location":"getting_started/components/trigger/#examples-of-workflow-triggers","title":"Examples of Workflow Triggers:","text":"<ol> <li> <p>User Registration Event:</p> <ul> <li>Trigger: A new user registers on the website.</li> <li>Workflow: Sends a welcome email, updates the user profile with registration details, and adds the user to a   new user segment.</li> </ul> </li> <li> <p>Abandoned Cart Event:</p> <ul> <li>Trigger: A user adds items to their cart but does not complete the purchase within a specified timeframe.</li> <li>Workflow: Sends a reminder email to the user, offers a discount, and updates the user profile with the   abandoned cart information.</li> </ul> </li> <li> <p>Profile Update Condition:</p> <ul> <li>Trigger: A user's profile is updated with a new email preference.</li> <li>Workflow: Adjusts the email marketing preferences in the user's profile, ensuring future emails match the   user's new preferences.</li> </ul> </li> <li> <p>Daily Data Processing:</p> <ul> <li>Trigger: Scheduled to run daily at 2 AM.</li> <li>Workflow: Aggregates daily user activity data, updates analytics dashboards, and archives old data.</li> </ul> </li> </ol>"},{"location":"getting_started/components/trigger/#setting-up-workflow-triggers","title":"Setting Up Workflow Triggers","text":"<p>Workflow triggers are configured within the Tracardi Workflow Editor. Here\u2019s how to set them up:</p> <ol> <li> <p>Select Trigger Type:</p> <ul> <li>Choose between event-based, condition-based, or scheduled triggers based on the desired initiation criteria for   the workflow.</li> </ul> </li> <li> <p>Define Trigger Criteria:</p> <ul> <li>Specify the event type (e.g., purchase, login, page view).</li> <li>Specify the event source</li> <li>Define what consents must be granted to run the workflow</li> <li>Specify the workflow</li> </ul> </li> <li> <p>Configure Workflow Actions:</p> <ul> <li>Design the workflow by adding nodes and defining actions that should be performed when the trigger activates the   workflow.</li> </ul> </li> <li> <p>Save and Activate:</p> <ul> <li>Save the workflow configuration and activate it to start listening for the defined triggers.</li> </ul> </li> </ol>"},{"location":"getting_started/components/workflow/","title":"Workflow","text":"<p>A workflow is a sequence of automated processes designed to manage and manipulate data as it flows through the system. Workflows define how events are processed, how data is transformed, and what actions are taken based on specific conditions or triggers.</p>"},{"location":"getting_started/components/workflow/#key-components-of-a-workflow","title":"Key Components of a Workflow:","text":"<ol> <li> <p>Nodes:</p> <ul> <li>Individual units of work within a workflow, each representing a specific action or operation. Nodes can perform   various tasks, such as data transformation, conditional checks, or external API calls.</li> </ul> </li> <li> <p>Edges:</p> <ul> <li>Connections between nodes that define the flow of data from one node to another. Edges determine the path that   data follows through the workflow based on the outcome of each node's operation.</li> </ul> </li> <li> <p>Triggers:</p> <ul> <li>Conditions that initiate the execution of a workflow. Triggers can be based on specific event types,   such as a user action, data change.</li> </ul> </li> <li> <p>Actions:</p> <ul> <li>Operations performed by nodes within the workflow. Actions can include data enrichment, filtering, transformation,   routing, and external system integration.</li> </ul> </li> <li> <p>Conditions:</p> <ul> <li>Logical expressions used to make decisions within the workflow. Conditions evaluate data and determine the path   data should take through the workflow.</li> </ul> </li> </ol>"},{"location":"getting_started/components/workflow/#workflow-management","title":"Workflow Management","text":"<ul> <li> <p>Design:</p> <ul> <li>Workflows are designed using the Tracardi Workflow Editor, a visual interface that allows users to create and   connect nodes, set conditions, and define actions.</li> </ul> </li> <li> <p>Execution:</p> <ul> <li>Once defined, workflows are executed automatically when their triggers are activated. Tracardi ensures that data   flows through the workflow as specified, performing each action and following each edge and condition.</li> </ul> </li> <li> <p>Monitoring:</p> <ul> <li>Tracardi provides tools to monitor and debug workflows, ensuring that they perform as expected and identifying any   issues that need to be addressed.</li> </ul> </li> </ul>"},{"location":"getting_started/components/bridges/api/","title":"REST API Bridge in Tracardi","text":"<p>The REST API Bridge in Tracardi is designed to facilitate data collection via HTTP requests. It is one of the primary bridges used for structured data collection, providing a straightforward method for integrating external systems with Tracardi.</p>"},{"location":"getting_started/components/bridges/api/#how-the-rest-api-bridge-works","title":"How the REST API Bridge Works?","text":"<ul> <li>Endpoint and Method:  The REST API Bridge uses a standard endpoint <code>/track</code> and the HTTP POST method to collect   data. This endpoint is   configured to receive event data from external systems.</li> </ul> Example Endpoint<pre><code>POST http://your-tracardi-url/track\n</code></pre> <ul> <li>Data Structure: Data sent to the REST API Bridge must be structured in JSON format. This JSON payload includes.   metadata plus a list of event for particular profile.</li> </ul> Example Payload<pre><code>{\n  \"events\": [\n    {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"url\": \"https://example.com\",\n        \"title\": \"Homepage\"\n      }\n    }\n  ],\n  \"session\": {\n    \"id\": \"session-id\"\n  },\n  \"profile\": {\n    \"id\": \"profile-id\"\n  }\n}\n</code></pre> <ul> <li> <p>Configuration and Setup: The REST API Bridge does not require additional configuration beyond setting up the event   source in Tracardi. Here\u2019s how   to set it up:</p> </li> <li> <p>Create an Event Source:</p> <ul> <li>Navigate to the Inbound Traffic section in the Tracardi GUI.</li> <li>Click on Add New Source.</li> <li>Provide a name, type, and channel for the event source.</li> <li>Select the REST API Bridge as the method of data collection.</li> </ul> </li> <li> <p>Integration with External Systems:</p> <ul> <li>Configure your external system to send HTTP POST requests to the /track endpoint of your Tracardi instance.</li> <li>Ensure the payload follows the JSON structure required by Tracardi.</li> </ul> </li> <li> <p>Event Processing:  Once the data is received by the /track endpoint, Tracardi processes the event through   several stages: Validation:, Mapping, Identity Resolution, Event Storage, Workflow Execution. Some steps may be   executed in parallel in commercial version of Tracardi.</p> </li> <li> <p>Example Integration:  To illustrate, here\u2019s how you might configure an external application to send data to Tracardi using the REST API Bridge.</p> </li> </ul> Example cURL Command<pre><code>curl -X POST http://your-tracardi-url/track \\\n-H \"Content-Type: application/json\" \\\n-d '{\n   \"events\": [\n      \"type\": \"purchase\",\n      \"properties\": {\n         \"product\": \"Laptop\",\n         \"price\": 1200.00\n      }\n    ],\n    \"source\": {\n      \"id\": \"source-12345\"\n    },\n    \"profile\": {\n      \"id\": \"profile-67890\"\n    }\n}'\n</code></pre>"},{"location":"getting_started/components/bridges/api/#benefits-of-using-rest-api-bridge","title":"Benefits of Using REST API Bridge","text":"<p>Simplicity: Easy to set up and use with minimal configuration. Flexibility: Can be integrated with various systems and platforms that support HTTP POST requests. Real-Time Data Collection: Enables real-time data ingestion and processing. Scalability: Suitable for collecting data from high-traffic applications.</p>"},{"location":"getting_started/components/bridges/redirect/","title":"Redirect Bridge","text":"<p>A redirect bride is a valuable tool for tracking and associating clicks on links with user profiles. It is commonly used when sending emails with community invites, promotions, etc. or monitoring email openings. By creating redirected links, we can track user interactions and gather data. For example, we can create a link that redirects to a tiny 1px image. When that image is displayed, Tracardi receives an event indicating the email was opened. Additionally, the redirect link can include the customer's session ID to identify the specific customer.</p> <p>The Inbound Traffic/Event Redirects feature allows you to redirect traffic from specific links to a designated URL. When a user clicks on one of these predefined links, they will be redirected to the defined URL. Simultaneously, Tracardi will receive an event containing information about the redirect, along with any predefined event properties you have set. This feature helps gather valuable data about user interactions and link activities.</p> <p>The process of setting up Inbound Traffic/Event Redirects involves the following steps:</p> <ul> <li> <p>Define the links that you want to redirect: This could be any link on your website or in an email that you want to   redirect to a specific URL.</p> </li> <li> <p>Set the target URL: This is the URL that the user will be redirected to when they click on one of the defined links.</p> </li> <li> <p>Define the event properties: These are additional pieces of information that you want to send to Tracardi along with   the event. This could include information such as the type of event, the source of the event, or any other relevant   data that you want to track.</p> </li> <li> <p>Set up the event tracking in Tracardi: This involves configuring Tracardi to receive and process the events that will   be sent from your Inbound Traffic/Event Redirects setup.</p> </li> </ul> <p>Once you have completed these steps, your Inbound Traffic/Event Redirects setup will be ready to use. When a user clicks on one of your defined links, they will be redirected to the target URL and an event will be sent to Tracardi, providing information about the redirect and any event properties that you have defined.</p>"},{"location":"getting_started/components/bridges/redirect/#redirect-links","title":"Redirect links","text":"<p>All redirect links are in the form of:</p> <pre><code>http://&lt;tracardi-api-url&gt;/redirect/&lt;redirect-id&gt;\n</code></pre> <ul> <li>tracardi-api-url the url to Tracardi API server</li> <li>redirect-id id of the redirection. Click on any item in __Inbound Traffic/Event redirects___ to see the full url   path.</li> </ul>"},{"location":"getting_started/components/bridges/redirect/#redirect-links-with-session","title":"Redirect links with session","text":"<p>By default, all redirect links do not contain any user profile. However, it is possible to include a session ID in the redirect link when sending a message from Tracardi. To do this, use the following format for the extended link:</p> <pre><code>http://&lt;tracardi-api-url&gt;/redirect/&lt;redirect-id&gt;/&lt;session-id&gt;\n</code></pre> <p>When using this extended link, Tracardi will associate the click with the profile that corresponds to the specified session ID.</p> <p>To obtain the session ID, use session@id. If you wish to send the redirect link via email, you can use the provided template and access the session ID using {{session@id}}.</p>"},{"location":"getting_started/components/bridges/webhook/","title":"Webhook bridge","text":"<p>Webhook bridge is used to collect unstructured data via API call from external system. It should be used to collect data from systems that we do not have control over the data structure that is sent. If you can structure the payload an api call then it is better to use REST API Bridge.</p> <p>Event payload is sent as unstructued data in JSON. Url defines the event and event source id.</p> <p>Event properties should be send in the body of request or as URL parameters and event-type inside URL should be replaced with the event type you would like to emit.</p> <p>Tracking events with webhook</p> <p>A webhook is a way for an application to provide other applications with real-time information. It allows one application to send a message or information to another application when a specific event or trigger occurs.</p>"},{"location":"getting_started/components/bridges/webhook/#overview","title":"Overview","text":""},{"location":"getting_started/components/bridges/webhook/#what-is-a-webhook-bridge","title":"What is a Webhook Bridge?","text":"<p>A Webhook Bridge is a tool designed to collect unstructured data via an API call from external systems. It is particularly useful for retrieving data from systems where the data structure is beyond our control. For structured payloads, a REST API Bridge is recommended.</p>"},{"location":"getting_started/components/bridges/webhook/#key-features","title":"Key Features","text":"<ul> <li>Handles unstructured data in JSON format.</li> <li>Utilizes URLs to define the event and its source ID.</li> <li>Allows sending event properties in the request body or as URL parameters.</li> <li>Collect profile-less events then can be matched to existing profiles.</li> </ul>"},{"location":"getting_started/components/bridges/webhook/#posting-events-with-webhooks","title":"Posting Events with Webhooks","text":"<ul> <li>Use the format: <code>POST /collect/EVENT-TYPE/SOURCE-ID</code></li> <li><code>EVENT-TYPE</code>: Type of the event (e.g., <code>coupon-received</code>).</li> <li><code>SOURCE-ID</code>: ID of the event source.</li> <li>Send a JSON object in the body, which becomes the event's properties.</li> </ul>"},{"location":"getting_started/components/bridges/webhook/#matching-profiles-to-sent-data","title":"Matching Profiles to Sent Data","text":""},{"location":"getting_started/components/bridges/webhook/#process-overview","title":"Process Overview","text":"<ul> <li>Webhook data, while initially profile-less, can be matched against existing profiles.</li> <li>Payload must include a profile ID or an identifier (e.g., email) for matching.</li> <li>Enable profile and session creation settings for the webhook data.</li> </ul>"},{"location":"getting_started/components/bridges/webhook/#matching-methods-in-webhook-bridge","title":"Matching Methods in Webhook Bridge","text":"<p>The Webhook Bridge offers two distinct methods for matching profiles based on the data available in the payload.</p>"},{"location":"getting_started/components/bridges/webhook/#method-1-direct-profile-id-matching","title":"Method 1: Direct Profile ID Matching","text":"<ul> <li>Applicability: When the payload contains a profile ID. Configure the Webhook Bridge to use this ID for loading profiles in Tracardi. </li> <li>Operational Process: If the ID exists in the system, the corresponding profile is matched directly.</li> </ul>"},{"location":"getting_started/components/bridges/webhook/#method-2-matching-via-auto-profile-merging","title":"Method 2: Matching via Auto Profile Merging","text":"<p>This method only works when system is configured to use AUTO PROFILE MERGING.</p> <p>To enable this feature do the following:</p> <ul> <li>Set the environment parameter <code>AUTO_PROFILE_MERGING</code> to a key of at least 20 characters when system starts (add it to docker command when you start tracardi API). It will be used to hash the e-mails and phones.</li> <li>Enabling this parameter automatically activates the feature to generate and store unique IDs for every email sent to the system.</li> <li>Generated IDs are stored in the 'profile IDS' field.</li> <li>Email-based IDs receive prefixes like 'emm-', 'emb-', 'emp-' for main, business, and private emails, respectively.</li> <li> <p>Phone-based IDs use prefixes such as 'pho-', 'phm-', 'phw-', 'phb-' for mobile, main, WhatsApp, and business phones, respectively.</p> </li> <li> <p>Applicability: When a unique matching key (e.g., email or phone) is available.</p> </li> <li>Operational Process:</li> <li>Once the IDs are stored and the Webhook Bridge is set to use email or phone as an identifier, the system computes the respective ID.</li> <li>This computed ID is then used to load profile data when an event is collected.</li> </ul>"},{"location":"getting_started/components/bridges/webhook/#webhook-bridge-configuration","title":"Webhook bridge configuration","text":"<p>To enable profile matching create an Event Source using Webhook bridge and fill the form in the following way:</p> <ol> <li> <p>Create Profile and Session for Collected Data:</p> <ul> <li>Boolean switch to decide whether to generate a profile and session ID for webhook events.</li> <li>Options: On (Yes) or Off (No). Select (Yes)</li> </ul> </li> <li> <p>Identification Method:</p> <ul> <li>Functional only when 'Create profile and session for collected data' is enabled.</li> <li>Choose a method for profile identification: 'e-mail', 'phone', 'Custom ID', or 'none'.</li> <li>Determines how the profile will be identified. Select 'Custom ID' for the 1st method. Select 'e-mail', 'phone' for the 2nd method.</li> </ul> </li> <li> <p>Set Profile ID from Payload:</p> <ul> <li>Functional only when 'Create profile and session for collected data' is enabled and Identification Method is not none.</li> <li>Specify the location of the Profile ID Identifier in the payload.</li> <li>Adjusts based on the chosen identification method. Reference either ID or 'e-mail', or 'phone'. </li> </ul> </li> <li> <p>Set Session ID from Payload:</p> <ul> <li>Functional only when 'Create profile and session for collected data' is enabled.</li> <li>Option to set the Session ID from the payload.</li> <li>Specify the reference to the Session ID in the webhook payload.</li> </ul> </li> </ol>"},{"location":"getting_started/components/events/ephemeral_events/","title":"Ephemeral events","text":"<p>In Tracardi, ephemeral events are temporary events that are processed without being permanently stored in the system. These events are useful for scenarios where real-time processing is required, but long-term storage of the event data is unnecessary. Here\u2019s a detailed overview of ephemeral events in Tracardi:</p>"},{"location":"getting_started/components/events/ephemeral_events/#characteristics-of-ephemeral-events","title":"Characteristics of Ephemeral Events","text":"<ol> <li>Temporary Nature: Ephemeral events are processed in real-time but are not saved to the Tracardi database.</li> <li>Real-Time Processing: These events are typically used for workflows that need immediate action or decision-making    based on the event data.</li> <li>Reduced Storage Load: By not storing these events, Tracardi reduces the load on storage systems, which can be    beneficial for high-frequency event scenarios.</li> </ol>"},{"location":"getting_started/components/events/ephemeral_events/#use-cases-for-ephemeral-events","title":"Use Cases for Ephemeral Events","text":"<ul> <li>Real-Time Personalization: Triggering immediate changes to a webpage based on user interactions without storing   the interaction data.</li> <li>Dynamic Notifications: Sending instant notifications or alerts based on specific user actions.</li> <li>Temporary Data Handling: Handling data that is only relevant for a short period and does not need to be stored for   future analysis.</li> </ul>"},{"location":"getting_started/components/events/ephemeral_events/#implementing-ephemeral-events","title":"Implementing Ephemeral Events","text":"<p>There are two main ways to configure events as ephemeral in Tracardi:</p> <ol> <li> <p>Ephemeral Event Sources:</p> <ul> <li>When defining an event source, you can configure it to handle events ephemerally.</li> <li>This ensures that all events coming from this source are processed without being stored.</li> </ul> </li> <li> <p>Event Payload Configuration:</p> <ul> <li>Within the event payload, you can set the <code>options</code> attribute with <code>saveEvent</code> set to <code>false</code>.</li> <li>This configuration directs Tracardi to process the event without saving it.</li> </ul> </li> </ol>"},{"location":"getting_started/components/events/ephemeral_events/#example-configuration","title":"Example Configuration","text":"<p>Here\u2019s an example of how to configure an event payload to be ephemeral:</p> <pre><code>{\n  \"type\": \"page-view\",\n  \"properties\": {\n    \"url\": \"https://example.com\",\n    \"title\": \"Example Page\"\n  },\n  \"options\": {\n    \"saveEvent\": false\n  }\n}\n</code></pre> <p>In this example, the <code>saveEvent</code> option is set to <code>false</code>, making this a temporary event that will be processed but not stored.</p>"},{"location":"getting_started/components/events/ephemeral_events/#benefits-of-ephemeral-events","title":"Benefits of Ephemeral Events","text":"<ul> <li>Performance: By avoiding the overhead of storing events, the system can process events more quickly.</li> <li>Scalability: Reduces the storage requirements, allowing the system to handle a larger volume of events.</li> <li>Cost Efficiency: Lower storage costs as events are not retained long-term.</li> </ul>"},{"location":"getting_started/components/events/ephemeral_events/#considerations","title":"Considerations","text":"<ul> <li>Data Persistence: Since ephemeral events are not stored, any data or insights derived from these events will not   be available for future analysis.</li> <li>Workflow Design: Workflows using ephemeral events should be designed to handle the event data immediately, as it   will not be available later.</li> </ul>"},{"location":"getting_started/components/events/ephemeral_events/#summary","title":"Summary","text":"<p>Ephemeral events in Tracardi provide a way to handle real-time event processing without the need for long-term storage. They are ideal for scenarios where immediate action is required, and the event data does not need to be preserved. By configuring events or event sources as ephemeral, you can optimize the performance and scalability of your Tracardi system.</p>"},{"location":"getting_started/components/events/internal_events/","title":"Pre-build event types","text":"<p>Tracardi 0.8.1 provides a set of internal events that can be used to track customer journey on your website or application. These events come with default properties that can be used to collect data without the need for manual copying.</p> <p>Using internal events simplifies the use of Tracardi and allows for better analytics. When an internal event is used, the system automatically detects it and fills up the profile and session with appropriate data.</p> <p>However, if the default event does not expect the data that you want to send, don't worry. You can still send the data and copy it manually. Other defined properties will be copied automatically, and the missing ones will be saved in the event and can be moved to the profile manually.</p> <p>The following are some examples of Tracardi internal events:</p> <ul> <li> <p>Page View: This event is triggered when a customer visits a new page on your website or application. It captures the   URL of the page and the time of the visit.</p> </li> <li> <p>Search: This event is triggered when a customer performs a search on your website or application. It captures the   search query and the category of the search.</p> </li> <li> <p>Signup: This event is triggered when a customer signs up for an account on your website or application. It captures   the customer's first name, last name, email address, and login information.</p> </li> <li> <p>Identification: This event is triggered when a customer logs into their account on your website or application. It   captures the customer's login information.</p> </li> <li> <p>Purchase Order: This event is triggered when a customer makes a purchase on your website or application. It captures   the details of the purchase, including the product ID, name, price, and quantity.</p> </li> <li> <p>Cart Update: This event is triggered when a customer adds or removes items from their shopping cart on your website or   application. It captures the details of the update, including the product ID, name, price, and quantity.</p> </li> </ul> <p>Using Tracardi internal events helps you understand your customers' behavior and preferences, allowing you to optimize your website or application for better engagement and conversions.</p>"},{"location":"getting_started/components/events/profile_less_events/","title":"Profile-less events","text":"<p>Profile-less events in Tracardi are events that are not associated with any user profile. These events are useful for tracking interactions and occurrences that do not need to be linked to a specific user, such as anonymous user actions or system-generated events. Here\u2019s a detailed overview of profile-less events in Tracardi:</p>"},{"location":"getting_started/components/events/profile_less_events/#characteristics-of-profile-less-events","title":"Characteristics of Profile-less Events","text":"<ol> <li>No User Association: These events do not contain information that links them to a specific user profile.</li> <li>Anonymity: Useful for tracking actions from users who have not logged in or who are interacting with the system    anonymously.</li> <li>System Events: Can also be used for system-generated events where user context is irrelevant.</li> </ol>"},{"location":"getting_started/components/events/profile_less_events/#use-cases-for-profile-less-events","title":"Use Cases for Profile-less Events","text":"<ul> <li>Anonymous Interactions: Tracking page views, clicks, or other interactions from external systems that do not have   the information about profile id.</li> <li>System Monitoring: Capturing events related to system performance, errors, or other technical occurrences that do   not need to be tied to a user.</li> </ul>"},{"location":"getting_started/components/events/profile_less_events/#implementing-profile-less-events","title":"Implementing Profile-less Events","text":"<p>Profile-less events are usually created when using event source that is based on a webhook bridge. Then usually you can not control schema of sent data:</p>"},{"location":"getting_started/components/events/profile_less_events/#example-configuration","title":"Example Configuration","text":"<p>Here\u2019s an example of a profile-less event payload:</p> Example of profile-less data<pre><code>POST /collect/EVENT-TYPE/SOURCE-ID`\n{\n    \"url\": \"https://example.com\",\n    \"user\": \"John\",\n    \"email\": \"a@a.com\"\n}\n</code></pre> <p>In this example, we use a <code>/collect</code> endpoint and send just the data without any additional metadata.</p>"},{"location":"getting_started/components/events/profile_less_events/#considerations","title":"Considerations","text":"<ul> <li>Limited Personalization: Since these events are not linked to user profiles, they cannot be used for personalized   interactions or targeted actions.</li> <li>Aggregated Insights: While useful for aggregate data analysis, these events do not provide insights at the   individual user level.</li> </ul>"},{"location":"getting_started/components/events/profile_less_events/#summary","title":"Summary","text":"<p>Profile-less events in Tracardi are designed to handle interactions and occurrences that lack user identification. They are often generated in use cases where the user cannot be identified. However, profile-less events can be converted to events with profiles if the event payload contains identifiable information, such as an email address, which can be used to reference the correct profile ID.</p>"},{"location":"getting_started/components/events/system_events/","title":"System Events","text":"<p>System events in Tracardi are automatically generated events that record the internal workings of the system as they relate to the customer journey. These events provide insights into critical milestones and actions within the user experience, such as when a visit starts, when it ends, or when a profile is created. They can be enabled or disabled based on configuration settings. Here\u2019s a detailed overview of system events in Tracardi:</p>"},{"location":"getting_started/components/events/system_events/#characteristics-of-system-events","title":"Characteristics of System Events","text":"<ol> <li>Automatically Generated: Created by Tracardi to document significant actions and states within the customer journey.</li> <li>Customer Journey Focused: These events are tied to the customer journey and provide context about user interactions and system responses.</li> <li>Configurable: System events can be turned on or off during system configuration based on specific needs.</li> </ol>"},{"location":"getting_started/components/events/system_events/#use-cases-for-system-events","title":"Use Cases for System Events","text":"<ul> <li>Tracking Customer Journey: Monitoring key actions within the customer journey, such as visits, profile creations, and session terminations.</li> </ul>"},{"location":"getting_started/components/events/system_events/#examples-of-system-events","title":"Examples of System Events","text":"<ul> <li>Visit Started: Logged when a user visit begins.</li> <li>Visit Ended: Logged when a user visit concludes.</li> <li>Profile Created: Logged when a new user profile is created in the system.</li> <li>Session Initiated: Logged when a new session is initiated for a user.</li> <li>Session Terminated: Logged when a session ends.</li> </ul>"},{"location":"getting_started/components/events/system_events/#implementing-and-handling-system-events","title":"Implementing and Handling System Events","text":"<p>System events are managed internally by Tracardi, but they can be used to trigger workflows or other automated actions. Here\u2019s how system events can be utilized:</p> <ol> <li>Automatic Logging: System events are automatically logged by Tracardi based on predefined actions within the customer journey.</li> <li>Workflow Integration: System events can trigger workflows to automate responses to specific user actions or system states, e.g when customer visit ends.</li> <li>Configuration: Administrators can enable or disable specific system events based on their requirements during system configuration.</li> </ol>"},{"location":"getting_started/components/events/system_events/#benefits-of-system-events","title":"Benefits of System Events","text":"<ul> <li>Enhanced Tracking: Provides detailed tracking of key actions and states within the customer journey.</li> <li>Auditability: Ensures an audit trail for critical events related to user interactions and system responses.</li> <li>Automation: Facilitates the automation of responses to significant events, improving operational efficiency.</li> </ul>"},{"location":"getting_started/components/resources/activecampaign_resource/","title":"Activecampaign resource","text":"<p>ActiveCampaign is a Customer Experience Automation Platform. ActiveCampaign will let you send email campaigns, automate features, and manage contacts.</p>"},{"location":"getting_started/components/resources/activecampaign_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to enable an integration between ActiveCampaign and Tracardi you need an API key. ActiveCampaign API allows you to sync contact information, view contact information, add contacts to automations, create and send campaigns, and much more.</p> <p>To obtain your ActiveCampaign API URL and Key, follow these steps:</p> <ol> <li>Log-in to ActiveCampaign</li> <li>Click \"Settings\" (gear icon) on the left menu.</li> <li>The Account Settings menu will appear. Click the \"Developer\" option.</li> <li>Copy your API URL and Key into the Tracardi resource form</li> </ol> <p>If you do not have account or need more help with getting your API key visit: https://help.activecampaign.com/hc/en-us/articles/207317590-Getting-started-with-the-API#getting-started-with-the-api-0-0</p>"},{"location":"getting_started/components/resources/airtable_resource/","title":"Airtable resource","text":"<p>Airtable is a cloud collaboration service. Airtable is a spreadsheet-database hybrid, with the features of a database but applied to a spreadsheet.</p>"},{"location":"getting_started/components/resources/airtable_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to connect Airtable to Tracardi you need an API key. Airtable API key allows you to use system public API to create, fetch, update, and delete records in the bases you have access to.</p> <p>To find your Airtable API key</p> <ol> <li>navigate to your Airtable account page.</li> <li>Look in the \"API section\",</li> <li>if you already have an API key defined click in the purple text box and the API key will appear.</li> </ol> <p>If you do not have account or need more help with getting your API key visit: https://support.airtable.com/docs/creating-a-read-only-api-key </p>"},{"location":"getting_started/components/resources/amplitude_resource/","title":"Amplitude resource","text":"<p>Amplitude is a cloud based analytical system for better understanding of your customers.</p>"},{"location":"getting_started/components/resources/amplitude_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to connect Amplitude to Tracardi you need an API key. The API key allows you to use Analytics APIs that help you gather and democratize data about how users engage with your apps.</p> <p>To find your Amplitude project's unique API key, follow these steps.</p> <ol> <li>Log-in to the Amplitude system</li> <li>In the Amplitude Analytics web app, click Settings in the lower left navigation.</li> <li>Click Projects, then find your target project.</li> <li>On the General tab, copy your API key and secret key if needed.</li> <li>Paste it into resource API Key</li> </ol> <p>If you do not have account or need more help with getting your API key visit: https://www.docs.developers.amplitude.com/analytics/find-api-credentials/</p>"},{"location":"getting_started/components/resources/apache_pulsar_resource/","title":"Apache pulsar resource","text":"<p>Apache Pulsar is a free, open-source platform for distributed messaging and data streaming. Initially created by Yahoo, it's now under the Apache Software Foundation. Designed for processing and streaming large amounts of messages, Apache Pulsar is known for its reliability, scalability, and flexibility.</p>"},{"location":"getting_started/components/resources/apache_pulsar_resource/#setting-up-resources-and-configuration","title":"Setting Up Resources and Configuration","text":"<p>To establish a connection with Apache Pulsar from Tracardi, you need the Pulsar server's location. The Apache Pulsar client, which is used for all interactions with Apache Pulsar, requires a host and a JWT Token for API request authentication. These details, including the host and token, are specified during the installation of Apache Pulsar. For guidance on how to connect to your queue, you should consult the Apache Pulsar documentation or reach out to your devops team.</p>"},{"location":"getting_started/components/resources/aws_resource/","title":"Aws resource","text":"<p>AWS (Amazon Web Services) is a comprehensive, evolving cloud computing platform provided by Amazon that includes a mixture of infrastructure as a service (IaaS), platform as a service (PaaS) and packaged software as a service (SaaS) offerings. AWS services can offer an organization tools such as compute power, database storage and content delivery services.</p>"},{"location":"getting_started/components/resources/aws_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To get your access key ID and secret access key</p> <ol> <li>Open the IAM console at https://console.aws.amazon.com/iam/</li> <li>On the navigation menu, choose Users. If you do not see user in menu type in search box Users and click IAM.</li> <li>Choose your IAM username (not the checkbox).</li> <li>Open the Security credentials tab, and then choose Create access key.</li> <li>To see the new access key, choose Show. Your credentials resemble the following:</li> </ol> <pre><code>   Access key ID: AKIAI...\n   Secret access key: wJalrXU...\n</code></pre>"},{"location":"getting_started/components/resources/aws_resource/#what-is-iam","title":"What is IAM?","text":"<p>AWS Identity and Access Management (IAM) is a web service that helps you securely control access to AWS resources. You use IAM to control who is authenticated (signed in) and authorized (has permissions) to use resources.</p>"},{"location":"getting_started/components/resources/aws_resource/#plugins","title":"Plugins","text":"<p>Plugins are automatically installed when you connect the AWS to Tracardi. Please search them in Workflow editor by typing \"AWS\" or \"Amazon\"</p>"},{"location":"getting_started/components/resources/chatwoot_resource/","title":"Chatwoot resource","text":"<ol> <li>Log-in to the chatwoot.com</li> <li>Select Chatwoot icon</li> <li>Click new inbox in the left menu</li> <li>Select website</li> <li>Fill the form </li> <li>Select agent</li> <li>You will see the javascript snippet that you should copy and paste to you page.    Do not do it. Copy only the website token. It is marked  below in the example script <pre><code>&lt;script&gt;\n      (function(d,t) {\n        var BASE_URL=\"https://app.chatwoot.com\";\n        var g=d.createElement(t),s=d.getElementsByTagName(t)[0];\n        g.src=BASE_URL+\"/packs/js/sdk.js\";\n        g.defer = true;\n        g.async = true;\n        s.parentNode.insertBefore(g,s);\n        g.onload=function(){\n          window.chatwootSDK.run({\n            websiteToken: '&lt;TOKEN-IS-HERE&gt;',\n            baseUrl: BASE_URL\n          })\n        }\n      })(document,\"script\");\n    &lt;/script&gt;\n</code></pre>"},{"location":"getting_started/components/resources/civi_resource/","title":"Civi resource","text":"<p>CiviCRM is a web-based suite of internationalized open-source software for constituency relationship management. CiviCRM is designed to manage information about an organization's donors, members, event registrants, subscribers, grant-application seekers and funders, and case contacts. Volunteers, activists, and voters - as well as more general sorts of business contacts such as employees, clients, or vendors.</p>"},{"location":"getting_started/components/resources/civi_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To set up this resource, API key, Site key and API URL are needed.</p>"},{"location":"getting_started/components/resources/civi_resource/#api-key","title":"API Key","text":"<p>API keys are unique to CiviCRM contacts. You should add the API key to the contact, and grant appropriate permissions to this contact. You can do it by API explorer, or editing/adding a contact in any other way.</p>"},{"location":"getting_started/components/resources/civi_resource/#site-key","title":"Site key","text":"<p>Site key can be found in civicrm.settings.php file on the server. Its location can vary between CMSs and versions. The file should contain something like:</p> <pre><code>if (!defined('CIVICRM_SITE_KEY')) {\n  define( 'CIVICRM_SITE_KEY', 'qwednKcpN93x0mvv');\n}\n</code></pre> <p>In this case, the Site key is qwednKcpN93x0mvv.</p>"},{"location":"getting_started/components/resources/civi_resource/#api-url","title":"API URL","text":"<p>Here provide the host of your CiviCRM instance, extended by /sites/all/modules/civicrm/extern/rest.php, or the location of rest.php file if it has been moved.</p>"},{"location":"getting_started/components/resources/clicksend_resource/","title":"ClickSend API Configuration","text":"<p>To use the ClickSend Send SMS plugin in Tracardi, you need to configure your ClickSend API credentials, which include your username and API key. This documentation will guide you through the process of obtaining and configuring these credentials.</p>"},{"location":"getting_started/components/resources/clicksend_resource/#step-1-login-to-clicksend","title":"Step 1: Login to ClickSend","text":"<ol> <li>Go to the ClickSend website and log in to your ClickSend account using your account username and password. Typically,    the username is your email address.</li> </ol>"},{"location":"getting_started/components/resources/clicksend_resource/#step-2-access-api-credentials","title":"Step 2: Access API Credentials","text":"<ol> <li> <p>Once you are logged in, navigate to the API Credentials section. You can usually find this in the developer or    settings area of your ClickSend account.</p> </li> <li> <p>In the API Credentials section, you will find your username and API key. These credentials are required to    authenticate with the ClickSend API and send SMS messages through the ClickSend gateway.</p> </li> </ol>"},{"location":"getting_started/components/resources/clicksend_resource/#step-3-copy-username-and-api-key","title":"Step 3: Copy Username and API Key","text":"<ol> <li>Copy your ClickSend username, which is your account username, and your API key. You will need these credentials to    configure the ClickSend Send Resource. The use this resource in the plugin.</li> </ol>"},{"location":"getting_started/components/resources/discord_resource/","title":"Discord","text":"<p>Discord is VoIP and instant messaging social platform. Users have the ability to communicate with voice calls, video calls, text messaging, media and files in private chats or as part of communities called \"servers\".</p>"},{"location":"getting_started/components/resources/discord_resource/#resource-configuration","title":"Resource configuration","text":"<ol> <li>In your application open Server setting and go into the Integrations</li> <li>Click Create Webhook</li> <li>Type Name for your webhook and choose what channel the Webhook posts to</li> <li>Click Copy Webhook URL and paste it into Tracardi resource URL field.</li> </ol>"},{"location":"getting_started/components/resources/elastic_email_resource/","title":"Elastic email resource","text":"<p>To use Elastic mail you will need an API Key from their dashboard.</p> <p>To obtain Email Marketing API KEY: </p> <ol> <li>Log in to Elastic Email</li> <li>Go to Settings</li> <li>Click Manage API Keys</li> <li>Click Create in the upper right corner</li> <li>Fill the name and set the permission</li> <li>Click Create</li> <li>Copy API KEY</li> </ol> <p>To find your Public Account Identifier  1. Log in to Elastic Email 2. Go to Settings 3. Security 4. Copy Public Account Identifier https://app.elasticemail.com/security</p>"},{"location":"getting_started/components/resources/elasticsearch_resource/","title":"Elasticsearch resource","text":"<p>Elasticsearch is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured.</p>"},{"location":"getting_started/components/resources/elasticsearch_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to enable connection to Elasticsearch from Tracardi you need an API URL. The Elasticsearch API provides a programmatic interface for all interactions with Elasticsearch, it uses username and password to authorize API requests. The username and password is set during Elasticsearch installation. The other connection parameters are  set-up during ElasticSearch configuration. Please refer to the ElasticSearch documentation  or contact your devops team for information on how ot connect to your database. </p>"},{"location":"getting_started/components/resources/fullcontact_resource/","title":"Fullcontact resource","text":"<p>Full contact is a cloud based contact identity resolution platform. Full contact provides the data intelligence you need in your platforms to accurately identify people and optimize experiences\u2014while putting privacy and security first.</p>"},{"location":"getting_started/components/resources/fullcontact_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<ol> <li>Create account at http://www.fullcontact.com/</li> <li>Log-in to the account</li> <li>Select API Keys from the left menu</li> <li>Click Generate New Key</li> <li>Copy the token to Tracardi form. It is only showed once. </li> <li>Save the Tracardi form</li> </ol>"},{"location":"getting_started/components/resources/ga4_tracker_resource/","title":"Ga4 tracker resource","text":"<p>Google Analytics is a web analytics service offered by Google that tracks and reports website traffic, currently as a platform inside the Google Marketing Platform brand.</p>"},{"location":"getting_started/components/resources/ga4_tracker_resource/#google-analytics-4-id","title":"Google Analytics 4 ID","text":"<p>To find your Google Analytics 4 Measurement ID:</p> <ol> <li>Open Google Analytics</li> <li>Click the \u2018Admin\u2019 tab, left-hand side menu, at the bottom.</li> <li>In the left-hand column, click Data Streams</li> <li>Select a data stream from the list</li> <li>Your code will appear in the top right-hand corner of the page. For GA4 users, the codes start with \u201cG.\u201d</li> <li>Copy the code and paste to the Tracardi Resource Form into measurement_id.</li> <li>Find on the page Secret API Keys for Measurement Protocol in Events section and click on it.</li> <li>If you do not see the key click create in the upper right corner.</li> <li>Give a key a name</li> <li>Save it.</li> <li>Now you should see the API KEY, copy it into API Key (api_key) field in the Tracardi Resource Form</li> </ol>"},{"location":"getting_started/components/resources/ghost_resource/","title":"Ghost resource","text":"<p>Ghost is an open-source blog and membership application.</p>"},{"location":"getting_started/components/resources/ghost_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To add a Ghost resource, you need to create a custom integration for your Ghost website.</p> <ol> <li>api_url - this is the API URL.</li> <li>api_key - this is the Admin API key.</li> </ol>"},{"location":"getting_started/components/resources/ghost_resource/#adding-a-custom-integration-to-your-ghost-website","title":"Adding a Custom Integration to Your Ghost Website","text":"<ol> <li>Navigate to the admin section of your Ghost website and go to settings.</li> <li>In the advanced section of settings, click on the custom tab under integrations.</li> <li>Create a new custom integration by clicking on the \"Add Custom Integration\" button.</li> <li>Give your custom integration a name.</li> <li>At this stage, your api_url and api_key will be displayed.</li> <li>Finally, click \"Save &amp; Close\" to complete setting up your Ghost custom integration.</li> </ol> <p>For more details, you can refer to the following help articles:</p> <ul> <li>Custom Integrations + Ghost</li> </ul>"},{"location":"getting_started/components/resources/github_resource/","title":"Github resource","text":"<p>GitHub is an internet hosting service for software development and version control using Git.</p>"},{"location":"getting_started/components/resources/github_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To add a GitHub resource, you need to add your PAT (personal access token).</p> <ol> <li>api_url - usually this does not need changing and can be left at the default value of https://api.github.com.</li> <li>personal_access_token - this is a personal access token linked to your GitHub account. Refer to the link below    for how to generate a PAT.</li> </ol>"},{"location":"getting_started/components/resources/github_resource/#getting-the-access-token","title":"Getting the access token","text":"<ol> <li>In the upper-right corner of any page, click your profile photo, then click Settings.</li> <li>In the left sidebar, click Developer settings.</li> <li>In the left sidebar, under Personal access tokens, click Tokens (classic).</li> <li>Select Generate new token, then click Generate new token (classic).</li> <li>In the \"Note\" field, give your token a descriptive name.</li> <li>To give your token an expiration, select Expiration, then choose a default option or click Custom to enter a date.</li> <li>Select the scopes you'd like to grant this token. To use your token to access repositories from the command line,    select repo. A token with no assigned scopes can only access public information. For more information, see \"Scopes    for OAuth apps.\" on Github Documentation.</li> <li>Click Generate token.</li> <li>Optionally, to copy the new token to your clipboard</li> </ol> <p>For more details you can refer to the following help articles:</p> <ul> <li>Github documentation on personal tokens</li> </ul>"},{"location":"getting_started/components/resources/hubspot_resource/","title":"Hubspot resource","text":"<p>HubSpot's integrated CRM platform contains the marketing, sales, service, operations, and website-building software you need to grow your business.</p>"},{"location":"getting_started/components/resources/hubspot_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To use Hubspot you will need an API Key from their dashboard.</p> <p>To obtain AccessToken/API KEY:</p> <ol> <li>Log in to Hubspot as regular user</li> <li>Go to Settings (upper right corner - Gear icon)</li> <li>Find \"Account Setup\" -&gt; \"Integrations\" -&gt; \"Private Apps\" and click it</li> <li>Click \"Create Private App\"</li> <li>Fill the name and description in \"Basic Info\" tab</li> <li>Set the scope/permission for any actions you want to do (crm.objects.contacts, crm.objects.companies, etc) in \"    Scopes\" tab. We suggest to select the following scopes for the Tracardi plugins to work.     <pre><code>crm.objects.companies.write, \ncrm.objects.companies.read, \ncrm.objects.contacts.write, \ncrm.schemas.contacts.read, \ncontent\n</code></pre></li> <li>Click \"Create app\"</li> <li>You should see and alert \"You're about to create a new private app. This will generate an access token that can be    used to view or update your HubSpot account data.\". Click \"Continue creating\".</li> <li>Click show token and Copy token</li> <li>Paste token to Token field in Tracardi form</li> </ol>"},{"location":"getting_started/components/resources/influxdb_resource/","title":"Influxdb resource","text":"<p>InfluxDB is an open-source time series database (TSDB). It includes APIs for storing and querying data, processing it in the background for ETL or monitoring and alerting purposes, user dashboards, and visualizing and exploring the data and more.</p>"},{"location":"getting_started/components/resources/influxdb_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to enable an integration between InfluxDB and Tracardi you need an API. The InfluxDB API provides a programmatic  interface for all interactions with InfluxDB, it uses API tokens to authorize API requests. API tokens ensure secure  interaction between InfluxDB and Tracardi. An API token belongs to a specific user and identifies InfluxDB permissions  within the user\u2019s organization.</p> <p>To manage InfluxDB API Tokens in the InfluxDB UI:</p> <ol> <li>Navigate to the API Tokens management page.</li> <li>In the navigation menu on the left, select Data (Load Data) &gt; Tokens.</li> <li>Click a token name in the list to view the token and a summary of access permissions.</li> </ol> <p>For Creating a token in the InfluxDB UI:</p> <ol> <li>From the API Tokens management page, click Generate and select a token type (Read/Write Token or All Access API    Token).</li> <li>In the window that appears, enter a description for your token in the Description field.</li> <li>If generating a read/write token:</li> <li>Search for and select buckets to read from in the Read pane.</li> <li>Search for and select buckets to write to in the Write pane.</li> <li>Click Save.</li> </ol> <p>If you need more help with getting your API Token visit: https://docs.influxdata.com/influxdb/v2.4/security/tokens/</p>"},{"location":"getting_started/components/resources/mailchimp_resource/","title":"Mailchimp resource","text":"<p>Mailchimp is a marketing automation platform and email marketing service.</p>"},{"location":"getting_started/components/resources/mailchimp_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To connect Tracardi and MailChimp, you need an API key. To obtain an API key follow the steps:</p> <ol> <li>Log-in to your MailChimp account</li> <li>Click on your account icon in the top-right corner</li> <li>Select \"Profile\"</li> <li>Select \"Extras &gt; API keys\" on the top, and click \"Create A Key\" beneath \"Your API keys` section. Or if you would like    to use \"Send Transactional Email\" plugin, that means send one-to-one emails click \"Add a Mandrill API Key\" and follow    the instructions. Note that you will have to verify you domain with mandrill in order to send one-to-one emails.</li> <li>Copy API key to Tracardi Form to Token field</li> </ol>"},{"location":"getting_started/components/resources/mailchimp_resource/#more-information","title":"More information","text":"<p>More information on how to generate, disable, and delete API tokens visit https://mailchimp.com/help/about-api-keys/</p>"},{"location":"getting_started/components/resources/matomo_resource/","title":"Matomo Credentials","text":"<p>In order to connect to matomo you will need to provide an API address and a token</p> <p>The token acts as your password and is used to authenticate in API requests. The token is secret and should be handled very carefully: do not share it with anyone. Each Matomo user has a different token.</p> <p>API address is the URL where the matomo API is installed.</p>"},{"location":"getting_started/components/resources/matomo_resource/#where-to-get-matomo-token","title":"Where to get matomo token","text":"<p>You must be logged in to the Matomo server and do the following procedure.</p>"},{"location":"getting_started/components/resources/matomo_resource/#matomo-4-and-newer","title":"Matomo 4 and newer","text":"<p>To generate a token_auth follow these steps:</p> <ul> <li>Log in to Matomo</li> <li>Go to the Matomo Admin through the top menu (gear icon)</li> <li>Click on Personal -&gt; Security</li> <li>In the bottom of the page click on \"Create new token\"</li> <li>Confirm your account password</li> <li>Enter the purpose for this plugin as a description</li> <li>Click on \"Create new token\"</li> </ul> <p>You will now see the newly created token. Save it somewhere safe as you won\u2019t be able to see it anymore once you leave that screen. For example in a password manager. If you lose it, you will need to generate a new token.</p> <p>We recommend you create a new token for every app or purpose. This way, you can easily delete or regenerate the token for specific purposes and see which ones are still being used etc.</p>"},{"location":"getting_started/components/resources/matomo_resource/#matomo-3-and-older","title":"Matomo 3 and older","text":"<p>You can find the token by logging in Matomo (Piwik), then click on Administration in the top menu, then click the link \u201cAPI\u201d in the left menu.</p> <p>The token_auth value can be re-generated on request by any user under Administration &gt; Personal Settings.</p>"},{"location":"getting_started/components/resources/matomo_resource/#how-do-i-find-the-site-id","title":"How do I find the Site ID","text":"<p>Matomo (Piwik) lets you measure several websites within one Matomo server. Each website added into Matomo has its very own ID Site (or Website ID).</p> <p>To find out the site ID value for a given website, you can follow these steps:</p> <ul> <li>Log into your Matomo.</li> <li>Go to Administration (click on the gear icon in the top right of the screen).</li> <li>Click on the Measurables(or Websites) &gt; Manage page. You will find a list of all websites on this page.</li> <li>The website ID is on the left of the table listing all websites directly below the website name.</li> </ul> <p>If you are using Matomo for WordPress, your Site ID should be 1 and you can double-check this ID in Matomo Analytics &gt; System Report &gt; Matomo Blog idSite.</p>"},{"location":"getting_started/components/resources/mautic_resource/","title":"Mautic resource","text":"<p>Mautic is the open-source marketing automation platform. The software has all the essential features like lead management, campaign management, contacts and emails and responsive email creation</p>"},{"location":"getting_started/components/resources/mautic_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To use this resource, you first need to enable Mautic API. Go to Mautic configuration, then to API Settings and make sure that API enabled? option is set to Yes.</p> <p>To connect to Mautic, three parameters are needed:</p>"},{"location":"getting_started/components/resources/mautic_resource/#public-key-and-private-key","title":"Public key and private key","text":"<p>Go to API Credentials on the right side menu. Select OAuth 2 as a protocol, name the credentials to recognize them later, and fill in Tracardi API URL as Redirect URI. This parameter is to specify all hosts (separated by commas), that are going to connect to Mautic API. Public and private key should now be generated.</p>"},{"location":"getting_started/components/resources/mautic_resource/#api-url","title":"API URL","text":"<p>This is your Mautic API host.</p>"},{"location":"getting_started/components/resources/mautic_resource/#info","title":"Info","text":"<p>This resource can be used as destination</p>"},{"location":"getting_started/components/resources/max_mind_resource/","title":"MaxMind Cloud Services","text":""},{"location":"getting_started/components/resources/max_mind_resource/#api-key","title":"API Key","text":"<p>MaxMind provides API access through their service called \"GeoIP2 Precision Services.\" To get an API key for accessing their services, you can follow these steps:</p> <ol> <li> <p>Visit the MaxMind website: Go to the official MaxMind website at https://www.maxmind.com.</p> </li> <li> <p>Sign up or log in: If you already have an account with MaxMind, log in using your credentials. Otherwise, you will    need to sign up for a new account by providing your email address and creating a password.</p> </li> <li> <p>Access API section: Once logged in, navigate to the API section on their website. It may be under a menu like \"My    Account\", or \"Manage Access Keys\".</p> </li> <li> <p>Select the appropriate plan: MaxMind offers different API plans with varying levels of access and usage limits.    Choose the plan that suits your needs and budget. </p> </li> <li> <p>Generate an API key: After selecting a plan, you will be prompted to generate an API key. Click on the appropriate    button to create a new API key associated with your account.</p> </li> <li> <p>Review terms and conditions: Make sure to read and understand the terms and conditions of using the API before    proceeding.</p> </li> <li> <p>Receive your API key: Once you've completed the process, MaxMind will provide you with an API key that you can use to    access their GeoIP2 Precision Services.</p> </li> </ol>"},{"location":"getting_started/components/resources/max_mind_resource/#account-id","title":"Account ID","text":"<ol> <li>Visit the MaxMind website: Go to the official MaxMind website at https://www.maxmind.com.</li> <li>Sign up or log in: If you already have an account with MaxMind, log in using your credentials. Otherwise, you will    need to sign up for a new account by providing your email address and creating a password.</li> <li>Click \"Account Information\"</li> <li>Account ID should be on the top row of the list.</li> </ol> <p>Please note that the steps and details might have changed since my last update, so it's a good idea to visit the MaxMind website directly and follow their latest instructions to obtain an API key, or Account ID.</p>"},{"location":"getting_started/components/resources/meaningcloud_resource/","title":"Meaningcloud resource","text":"<p>Meaning Cloud provides Machine Learning services, such as sentiment analysis, language detection, text classification and summation, corporate reputation, etc.</p>"},{"location":"getting_started/components/resources/meaningcloud_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to start using Meaning Cloud Plugin please follow the steps:</p> <ol> <li>Visit https://www.meaningcloud.com/ and create free account</li> <li>Your license key should be available at https://www.meaningcloud.com/developer/account/subscriptions or look for    box \"Your subscriptions\"</li> <li>Copy and past the key as Meaning Cloud Token</li> </ol>"},{"location":"getting_started/components/resources/meaningcloud_resource/#plugins","title":"Plugins","text":"<p>Plugins are automatically installed when you connect the Meaning Cloud to Tracardi. Please search them in Workflow editor by typing \"Meaning Cloud\" or \"Machine learning\"</p>"},{"location":"getting_started/components/resources/microservice_resource/","title":"Microservice resource","text":"<p>Tracardi microservice plugin is a new way to extend Tracardi without system upgrade.  Each microservice can deliver a set of new plugins that you can easily plug and use.  The main benefit of using Tracardi microservices is access to continuously growing set of services  and zero maintenance cost.</p>"},{"location":"getting_started/components/resources/microservice_resource/#tracardi-microservice-credentials","title":"Tracardi Microservice Credentials","text":"<p>To use the Tracardi microservice plugin you will need to provide an API KEY.</p>"},{"location":"getting_started/components/resources/microservice_resource/#where-to-get-microservices-api-key","title":"Where to get Microservice's API key","text":"<p>Microservice is usually a new docker that you start on your server. Tracardi microservices require you to set  API_KEY environment variable. It must be at least 32 char long. And must be a random value hard to guess.</p> <p>Please paste this value to API key input and click get secret. Your APIKEY will be replaced by token that will allow you to access the server microservices. </p>"},{"location":"getting_started/components/resources/microservice_resource/#microservice-setup","title":"Microservice setup","text":"<ul> <li>Type the microservice URL to Type microservice URL Input.</li> <li>Type the API KEY and click get secret. If the API KEY is correct you will see the green lock.</li> <li>Select on of the available services that are installed on the microservice server.</li> <li>Depending on the selected service you may see additional form to fill with the credentials that are required for   the service to work. For example a service that integrates with Trello will require the Trello credentials.  </li> <li>If the developer provided the documentation for the microservice you should see the manual with the tips how to    configure the selected service. </li> </ul>"},{"location":"getting_started/components/resources/microservice_resource/#microservice-plugins","title":"Microservice plugins","text":"<p>Each microservice installs plugins that will connect to the microservice and run the configured action. Plugins can be  found in the workflow editor. </p>"},{"location":"getting_started/components/resources/mixpanel_resource/","title":"Mixpanel resource","text":"<p>Mixpanel is a business analytics service company. It tracks user interactions with web and mobile applications and provides tools for targeted communication with them. Data collected is used to build custom reports and measure user engagement and retention.</p>"},{"location":"getting_started/components/resources/mixpanel_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to enable an integration between Mixpanel and Tracardi you need an API. Mixpanel has developed a number of APIs for clients to use that provide a substantial amount of added functionality and give clients the means to customize data analysis. Mixpanel uses Project tokens for API authentication, it is an identification sent along with each piece of data you send to your project.</p> <p>To get a Mixpanel project token for accessing the Mixpanel API, you'll need to follow these steps:</p> <ol> <li> <p>Sign up for a Mixpanel account: If you don't already have a Mixpanel account, go to the Mixpanel    website (https://mixpanel.com/) and sign up for a new account.</p> </li> <li> <p>Log in to your Mixpanel account: After creating an account, log in using your credentials on the Mixpanel website.</p> </li> <li> <p>Access your project: Once you're logged in, you should see your Mixpanel dashboard. If you haven't created a    project yet, you'll need to create one by clicking on the \"Create Project\" or \"Add New Project\" button and following    the instructions.</p> </li> <li> <p>Go to Project Settings: Navigate to the settings or configuration section of your project. This can usually be    found by clicking on your project name or the gear/settings icon in the dashboard.</p> </li> <li> <p>API Access: Look for the \"Project Settings\". Here, you should find options related to Access Keys.</p> </li> <li> <p>Project token: Copy project token.</p> </li> </ol> <p>If you need more help with getting your Project Token visit (this page)[https://help.mixpanel.com/hc/en-us/articles/115004502806-Find-Project-Token-]</p>"},{"location":"getting_started/components/resources/mongo_resource/","title":"Mongo resource","text":"<p>MongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas.</p>"},{"location":"getting_started/components/resources/mongo_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<ul> <li>Type the MongoDB URI - The URI describes the hosts to be used and options. The format of the URI is: mongodb:   //[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database.collection][?options]] mongodb://   is a required prefix to identify that this is a string in the standard connection format.</li> <li>Type connection timeout - Tracardi will disconnect from mongoDB after this time in micro-seconds if there is no   connection.</li> </ul>"},{"location":"getting_started/components/resources/mqtt_resource/","title":"Mqtt resource","text":"<p>MQTT is an OASIS standard messaging protocol for the Internet of Things (IoT). It is designed as an extremely lightweight publish/subscribe messaging transport that is ideal for connecting remote devices with a small code footprint and minimal network bandwidth.</p>"},{"location":"getting_started/components/resources/mqtt_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to connect to MQTT you need the following information:</p> <ul> <li>url: Url of your MQTT Server</li> <li>port: Port of your MQTT Server</li> <li>username: Set-up during MQTT Server installation</li> <li>password: Set-up during MQTT Server installation</li> </ul> <p>All above information is required. None can be left empty.</p>"},{"location":"getting_started/components/resources/mysql_resource/","title":"Mysql resource","text":"<p>MySQL is a relational database management system (RDBMS) developed by Oracle that is based on structured query language (SQL). </p>"},{"location":"getting_started/components/resources/mysql_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>Follow the steps:</p> <ul> <li>Type MySQL HOST - this is the address where the server was installed. Type only IP or the address without http/https, e.g. mysql.server.com</li> <li>Type MySQL PORT - most of the time this field does not require any change. Default port is 3306</li> <li>Type Username - this is set during the installation of MySQL server</li> <li>Type Password - this is set during the installation of MySQL server</li> </ul>"},{"location":"getting_started/components/resources/novu_resource/","title":"Novu resource","text":"<p>Novu is the open-source notification infrastructure for developers. You can register an notification event in Novu  and the system will send to your user via different means of messaging, e.g. e-mail, SMS, push message.</p>"},{"location":"getting_started/components/resources/novu_resource/#novu-credentials","title":"Novu Credentials","text":"<p>To use the novu plugin you will need to provide Apikey and create your notification template.</p>"},{"location":"getting_started/components/resources/novu_resource/#where-to-get-novus-apikey","title":"Where to get Novu's Apikey","text":"<ul> <li>Go to https://novu.co/</li> <li>In right corner click on \"Get started\"</li> <li>After creating your profile go to \"Settings\" tab</li> <li>In the settings navigation menu there is \"Api Keys\" tab</li> <li>With your Apikey go to \"Integrations Store\" tab and set up email provider which you want use to</li> <li>Now with your Apikey and configured provider, you can create templates and edit workflow for notifications in \"Notifications\" tab</li> </ul> <p>In the case of any issue, every email provider has his own guide, just click on chosen provider and look for \"Read our guide on where to get the credentials here.\"</p>"},{"location":"getting_started/components/resources/postgresql_resource/","title":"Postgresql resource","text":"<p>PostgreSQL is a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.</p>"},{"location":"getting_started/components/resources/postgresql_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>Follow the steps:</p> <ul> <li>Type PostgreSQL HOST - this is the address where the server was installed. Type only IP or the address without   http/https, e.g. postgres.server.com</li> <li>Type PostgreSQL PORT - most of the time this field does not require any change. Default port is 5432</li> <li>Type Username - this is set during the installation of PostgreSQL server</li> <li>Type Password - this is set during the installation of PostgreSQL server</li> </ul>"},{"location":"getting_started/components/resources/pushover_resource/","title":"Pushover resource","text":"<p>Pushover makes it easy to get real-time notifications on your Android, iPhone, iPad, and Desktop (Android Wear and Apple Watch, too!) </p>"},{"location":"getting_started/components/resources/pushover_resource/#pushover-credentials","title":"Pushover Credentials","text":"<p>To use the pushover plugin you will need to provide a token and a pushover user key.</p>"},{"location":"getting_started/components/resources/pushover_resource/#where-to-get-pushovers-token-and-user-key","title":"Where to get Pushover's token and user key","text":"<ul> <li>Go to https://pushover.net/</li> <li>Log-in to the system. If you do not have an account register first.</li> <li>In right corner You will see a User key as a string of characters.</li> <li>Scroll down and find \"Your Applications\"</li> <li>Click on \"Create an Application/API Token\"</li> <li>You will see API Token</li> </ul> <p>In order to receive notifications download Pushover's mobile app and login to your account. </p>"},{"location":"getting_started/components/resources/rabbitmq_resource/","title":"Rabbitmq resource","text":"<p>RabbitMQ allows to process compute intensive data outside tracardi server. You may want to run some data processing in the background and distribute the load to multiple servers.</p> <p>For Extensive Information about RabbitMQ visit : https://www.rabbitmq.com/documentation.html</p> <ul> <li> <p>You can create new user for accessing your RabbitMQ broker. Normally port used is 5672 but you can change it in your configuration file.</p> </li> <li> <p>So suppose your IP is 1.1.1.1 and you created user test with password test and you want to access vhost \"dev\" (without quotes) then it will look something like this: amqp://test:test@1.1.1.1:5672/dev</p> </li> <li> <p>A virtual host has a name. When an AMQP 0-9-1 client connects to RabbitMQ, it specifies a vhost name to connect to. If authentication succeeds and the username provided was granted permissions to the vhost, connection is established.</p> </li> </ul>"},{"location":"getting_started/components/resources/rabbitmq_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<ol> <li>Type the RabbitMQ url</li> <li>Type the port Number.</li> <li>Type the Virtual Host Name(if any)</li> <li>Type the Connection Timeout limit.</li> </ol>"},{"location":"getting_started/components/resources/rabbitmq_resource/#info","title":"Info","text":"<p>This resource can be used as destination.</p>"},{"location":"getting_started/components/resources/redis_resource/","title":"Redis resource","text":"<p>Redis is an open source, in-memory data structure store, used as a database, cache, and message broker. Redis' versatile in-memory data structures enable building data infrastructure for real-time applications that require low latency and high-throughput.</p>"},{"location":"getting_started/components/resources/redis_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to connect to Redis you need the following information:</p> <ul> <li>url: Url of your redis database</li> <li>username: Set-up during redis installation</li> <li>password: Set-up during redis installation</li> </ul> <p>All above information is required. None can be left empty.</p>"},{"location":"getting_started/components/resources/s3_aws/","title":"S3 aws","text":"<p>To set up an AWS S3 bucket and obtain the necessary access keys, you'll need to follow several steps. These steps involve creating an S3 bucket and generating an AWS access key and secret access key. Here\u2019s how you can do it:</p>"},{"location":"getting_started/components/resources/s3_aws/#1-sign-in-to-the-aws-management-console","title":"1. Sign In to the AWS Management Console","text":"<ul> <li>First, log in to your AWS Management Console using your AWS account. If you don't have an account, you will need to   sign up for one.</li> </ul>"},{"location":"getting_started/components/resources/s3_aws/#2-create-an-s3-bucket","title":"2. Create an S3 Bucket","text":"<ul> <li>In the AWS Management Console, find and select the S3 service under the Storage category or use the search bar.</li> <li>Click on Create bucket.</li> <li>Provide a bucket name. This name must be unique across all existing bucket names in Amazon S3.</li> <li>Select a Region that is closest to you or your users for the best performance.</li> <li>Leave the settings as they are for the most part, unless you have specific requirements. For a basic setup, you don't   need to modify them.</li> <li>Click on Create bucket at the bottom of the page.</li> </ul>"},{"location":"getting_started/components/resources/s3_aws/#3-obtain-your-aws-access-keys","title":"3. Obtain Your AWS Access Keys","text":"<p>For security reasons, it's recommended to create a new IAM user and grant it the necessary permissions to access only the resources it needs (in this case, your S3 bucket).</p>"},{"location":"getting_started/components/resources/s3_aws/#create-a-new-iam-user","title":"Create a New IAM User:","text":"<ul> <li>In the AWS Management Console, navigate to the IAM service.</li> <li>Go to Users &gt; Add user.</li> <li>Enter a user name and select (if displayed) Programmatic access as the access type. This will enable an access key ID and   secret access key for the AWS API, CLI, SDK, and other development tools.</li> <li>Click on Next: Permissions.</li> </ul>"},{"location":"getting_started/components/resources/s3_aws/#set-permissions","title":"Set Permissions:","text":"<ul> <li>Choose Attach existing policies directly.</li> <li>Search for and select the AmazonS3FullAccess policy. Note: For production environments or more secure setups, it's   better to create a custom policy that grants only the permissions necessary.</li> <li>Click on Next: Tags (optional) and then Next: Review.</li> <li>Review your user details and click on Create user.</li> </ul>"},{"location":"getting_started/components/resources/s3_aws/#obtain-access-keys","title":"Obtain Access Keys:","text":"<ul> <li>After the user is created, you\u2019ll be taken to a screen showing the list of users. </li> <li>Click on the created user</li> <li>Click on Create Access Key</li> <li>You will see Access key best practices &amp; alternatives</li> <li>Select Other and click Next</li> <li>Fill the description tag. This is the name of the keys. It can be any name. Click Create Access Key</li> <li>Retrieve access keys Access key ID and Secret access key. Make   sure to download or copy these keys and store them securely. You will not be able to see the secret access key again   after this step.</li> </ul>"},{"location":"getting_started/components/resources/salesforce_resource/","title":"Salesforce resource","text":"<p>Salesforce is a cloud-based customer relationship management platform and marketing automation system.</p>"},{"location":"getting_started/components/resources/salesforce_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To add a salesforce resource, you need to add you client_id, client_secret and subdomain.</p> <ol> <li> <p><code>client_id</code> - This is the consumer key of the connected app. To access the consumer key from the App Manager, find the connected app. Then select View from dropdown -&gt; Manage Consumer Details. You will be prompted to verify your identity before accessing the page.</p> </li> <li> <p><code>client_secret</code> - This is the consumer secret of the connected app. To access the consumer secret from the App Manager, find the connected app. Then select View from dropdown -&gt; Manage Consumer Details. You will be prompted to verify your identity before accessing the page.</p> </li> <li> <p>Your salesforce subdomain (also called MyDomainName) is the name which you get while setting up the account for your organisation.</p> </li> </ol> <p>For more details you can refer to the following help articles: - https://help.salesforce.com/s/articleView?id=sf.remoteaccess_oauth_client_credentials_flow.htm&amp;type=5 - https://help.salesforce.com/s/articleView?id=sf.faq_domain_name_what.htm&amp;type=5</p>"},{"location":"getting_started/components/resources/scheduler_resource/","title":"Scheduler resource","text":"<p>Schedule handles scheduled events. You can schedule and postpone any event. For example, it will allow you to deliver the messages to customers after they end the visit on your site.</p>"},{"location":"getting_started/components/resources/scheduler_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>The scheduler schedules an event to be sent to Tracardi after a specified period of time. To do this, you must define the Tracardi API URL where you want to send the event. You can send the event back to the same instance you are working on.</p> <p>Type the Tracardi API url in the Schedule settings. </p>"},{"location":"getting_started/components/resources/scheduler_resource/#dependencies","title":"Dependencies","text":"<p>Scheduler uses redis to schedule the events. </p>"},{"location":"getting_started/components/resources/sendgrid_resource/","title":"Sendgrid resource","text":"<p>SendGrid is a Denver, Colorado-based customer communication platform for transactional and marketing email.</p>"},{"location":"getting_started/components/resources/sendgrid_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>In order to connect Sendgrid to Tracardi you need an API key. Sendgrid API key allows you to send emails from Sendgrid platform through Tracardi.</p> <p>To find your API Key:</p> <ol> <li>Go to sendgrid system and log-in. If you do not have account please sing-up first.</li> <li>Navigate to Settings on the left navigation bar, and then select API Keys.</li> <li>Click Create API Key.</li> <li>Give your API key a name.</li> <li>Select Full Access, Restricted Access, or Billing Access. Tracardi needs rights to add contacts and send emails.</li> <li>If you're selecting Restricted Access, or Billing Access, select the specific permissions to give each category. For more information, see API key permissions.</li> <li>Click Create &amp; View.</li> <li>Copy your API key to Tracardi form.</li> </ol> <p>For more information on how to get an API key and get started with Sendgrid visit (Sendgrid documentation)[https://docs.sendgrid.com/for-developers/sending-email/api-getting-started]</p>"},{"location":"getting_started/components/resources/sms77_resource/","title":"Sms77 resource","text":"<p>Sms77 is a professional solutions for your company to send and receive SMS. Online, via API, by email or directly in your app. Easy. Fast. Reliable.</p>"},{"location":"getting_started/components/resources/sms77_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To obtain the API Key follow the steps:</p> <ol> <li>Go to https://www.sms77.io/ and create free account</li> <li>Log-in to the system.</li> <li>From the main menu on the left select Developer link</li> <li>Click \"+\" icon in the API Keys box</li> <li>Fill the form, add name, etc.</li> <li>Click Save button.</li> <li>Copy Key to Tracardi API Key field.</li> </ol>"},{"location":"getting_started/components/resources/telegram_resource/","title":"Telegram Bot Configuration","text":"<p>In order to send messages to telegram you will need a Telegram Bot.</p> <p>To create a Telegram bot and obtain the bot token and chat ID, you'll need to follow these steps:</p> <ol> <li> <p>Create a Telegram Bot:</p> <ul> <li>Open the Telegram app and search for the \"BotFather\" (username: @BotFather).</li> <li>Start a chat with BotFather and use the command \"/newbot\" to create a new bot.</li> <li>Follow the instructions provided by BotFather to choose a name and username for your bot. d. Once the bot is   created, BotFather will provide you with a unique API token. This token is your bot token, and you will need it to   authenticate and interact with the Telegram Bot API.</li> </ul> </li> <li> <p>Obtain your Chat ID:</p> <ul> <li>Add your newly created bot to the desired Telegram chat or group where you want to receive messages.</li> <li>Open a web browser and enter the following URL, replacing [YourBotToken] with the token you received from   BotFather: https://api.telegram.org/bot[YourBotToken]/getUpdates</li> <li>You should see a JSON response that contains information about the most recent messages received by your bot.</li> <li>Look for the \"chat\" object in the response, which contains details about the chat your bot is part of.</li> <li>The \"id\" field within the \"chat\" object corresponds to the chat ID of the group or channel. Make note of this chat   ID; you will need it to send messages to the chat.</li> </ul> </li> </ol> <p>Remember to keep your bot token and chat ID confidential and do not share them publicly or with unauthorized individuals. With this information, you can use the Telegram Bot API to program your bot to send and receive messages in your chat or group.</p>"},{"location":"getting_started/components/resources/twitter_resource/","title":"Twitter","text":"<p>Twitter is a free social networking site where users broadcast short posts known as tweets. These tweets can contain text, videos, photos or links</p>"},{"location":"getting_started/components/resources/twitter_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To create your twitter application please follow these steps.</p> <ol> <li>Go to  https://apps.twitter.com/ sing in your Twitter account and then click on the \"Create new app\" button.</li> <li>Choose App Environment, then type your application name, Click Next</li> <li>Now click \"Go to dashboard\" button in the bottom right corner.</li> </ol>"},{"location":"getting_started/components/resources/twitter_resource/#permissions","title":"Permissions","text":"<p>Now you have to change your access level from Essential to Elevated, to do this you have to go through a few steps.</p> <ol> <li>Go to https://developer.twitter.com/en/portal/products/elevated and change your access to elevated, then click \"    Apply\".</li> <li>Now you will need to provide information why you do you need elevated access.</li> </ol> <p>If you get Elevated access level then you have to change User authentication settings</p> <ol> <li>On the list in left side expand Projects and Apps and click your project name. The same name you set in the    previous steps.</li> <li>Now in the bottom of page you can see \"User authentication settings\" section, click on \"Set up\" button in    this section.</li> <li>Change App permission to \"Read and write\", choose type of your app (most probably Web App, Automated App or    Bot)</li> <li>Fill App info with the following information:<ol> <li>Callback URI - the webhook from the Tracardi source. Create a source that will receive events from Twitter and    copy the source webhook to the form.</li> <li>Website URL - you website URL</li> <li>Organization name - you business name, or website name.</li> </ol> </li> <li>Confirm that you want to change you permissions.</li> <li>Copy Client ID and Client Secret in case you need them.</li> </ol>"},{"location":"getting_started/components/resources/twitter_resource/#generate-api-keys","title":"Generate API keys","text":"<p>If the previous steps have been completed now you can generate your API keys.</p> <ol> <li>Expand Projects and Apps and click your app name.</li> <li>Now select \"Keys and tokens\" in the tabs (right after the app title).</li> <li>Click Generate button in the Consumer Keys section. Button next to API Key and Secret.</li> <li>Copy the API Key and API Key Secret to the Tracardi form</li> <li>Click Generate button in the Authentication Tokens section. Button next to Access Token and Secret.</li> <li>Copy the Access Token and Access Token Secret to the Tracardi form</li> </ol>"},{"location":"getting_started/components/resources/ua3_tracker_resource/","title":"Ua3 tracker resource","text":"<p>Google Analytics is a web analytics service offered by Google that tracks and reports website traffic, currently as a platform inside the Google Marketing Platform brand.</p>"},{"location":"getting_started/components/resources/ua3_tracker_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>Google Analytics has 2 versions. The latest one is Google Analytics 4. Google Universal Analytics will become obsolete in 2023.</p>"},{"location":"getting_started/components/resources/ua3_tracker_resource/#google-universal-analytics-id","title":"Google Universal Analytics ID","text":"<p>If you are a Universal Analytics user:</p> <ol> <li>Open Google Analytics</li> <li>Click the \u2018Admin\u2019 tab</li> <li>In the left-hand column, click Tracking Info</li> <li>Click \u2018Tracking Code\u2019 </li> <li>Your code will be available here. For Universal Analytics users, the codes start with \u201cUA.\u201d</li> <li>Copy the code and paste to the Tracardi Resource Form.</li> </ol>"},{"location":"getting_started/components/resources/zapier_resource/","title":"Zapier resource","text":"<p>Zapier is a product that allows end users to integrate the web applications they use and automate workflows. </p>"},{"location":"getting_started/components/resources/zapier_resource/#resource-configuration-and-set-up","title":"Resource configuration and set-up","text":"<p>To connect Tracardi and Zapier, we need to create a webhook. To create a webhook, use the following steps: 1. Go to zapier.com and after logging in to your account, click on the Create Zap button. 2. Choose the trigger app and look for Webhooks by Zapier option. 3. Choose the event and then select continue. 4. Copy the custom webhook URL generated by Zapier and then you can add it in Tracardi.</p> <p>For more information, you can refer to this article https://zapier.com/blog/what-are-webhooks/</p>"},{"location":"getting_started/components/resources/commercial/twilio_resource/","title":"Twilio resource","text":"<p>To use Twilio's services, you will need an account_sid and an auth_token. Twilio is a cloud communications platform that allows you to send SMS messages, make voice calls, and more using their API. Here's how you can obtain the account_sid and auth_token:</p> <ol> <li> <p>Sign up for a Twilio account: If you don't have a Twilio account, you can sign up for a new account on their    website at https://www.twilio.com/try-twilio.</p> </li> <li> <p>Log in to your Twilio account: After creating an account, log in using your email address and password.</p> </li> <li> <p>Dashboard: Once you're logged in, you will be directed to your Twilio dashboard.</p> </li> <li> <p>Account SID: On the dashboard page, you will find your account_sid displayed prominently. It is a 34-character    string that uniquely identifies your Twilio account. Copy this value; you will need it to authenticate API requests.</p> </li> <li> <p>Auth Token: To get your auth_token, click on your account name or the three vertical dots at the top right    corner of the dashboard, and then click on \"Settings\" or \"Account Settings.\" In the account settings page, you will    find your auth_token under the \"API Credentials\" or \"Live Credentials\" section. This token is used to authenticate    your API requests along with your account_sid.</p> </li> <li> <p>Store and secure your credentials: Both the account_sid and auth_token are sensitive and should be kept    secure. Do not share them publicly or hardcode them in your application's source code. Use environment variables or    configuration files to store them securely.</p> </li> </ol>"},{"location":"getting_started/components/resources/commercial/weaviate_resource/","title":"Weaviate","text":"<p>To connect to Weaviate cloud you will need an API Key. This url will help you find it. https://weaviate.io/developers/weaviate/quickstart</p> <p>A local installation might require a login and password, or it may not require anything if not configured.</p>"},{"location":"getting_started/components/resources/commercial/weaviate_resource/#open-ai-api-key","title":"Open AI API Key","text":"<p>Here are the steps on how to get an OpenAI API Key:</p> <ul> <li>Go to the OpenAI Platform website: https://platform.openai.com/ and sign in to your account. If you don't have an   account, you can create one for free.</li> <li>Once you're logged in, click on your profile icon in the top right corner of the page.</li> <li>From the dropdown menu, select \"View API Keys\".</li> <li>Click on the \"Create New Secret Key\" button.</li> <li>Give your key a name and click on the \"Create\" button.</li> <li>Your new API key will be displayed on the screen. Copy it to a safe place, as you won't be able to see it again.</li> </ul> <p>Your API key is a secret key that gives you access to the OpenAI API. You should keep it safe and secure, and never share it with anyone else.</p> <p>Here are some additional tips for using your OpenAI API Key:</p> <ul> <li>You can create multiple API keys, each with a different name and purpose. This can be useful if you want to use your   API key for different projects or with different third-party tools.</li> <li>You can revoke your API key at any time. This is useful if you think your key has been compromised.</li> <li>You can monitor your API usage in the OpenAI Platform. This can help you to track how much of your API quota you are   using and to identify any potential problems.</li> </ul>"},{"location":"getting_started/components/resources/commercial/weaviate_resource/#hugging-face-api-key","title":"Hugging face api key","text":"<p>Here are the steps on how to get a Hugging Face API Key:</p> <ul> <li>Go to the Hugging Face website: https://huggingface.co/ and sign in to your account. If you don't have an account, you   can create one for free.</li> <li>Once you're logged in, click on your profile icon in the top right corner of the page.</li> <li>From the dropdown menu, select \"Settings\".</li> <li>Click on the \"Access Tokens\" tab.</li> <li>Click on the \"New Token\" button.</li> <li>Give your key a name and click on the \"Create\" button.</li> <li>Your new API key will be displayed on the screen. Copy it to a safe place, as you won't be able to see it again.</li> </ul> <p>Your API key is a secret key that gives you access to the Hugging Face API. You should keep it safe and secure, and never share it with anyone else.</p> <p>Here are some additional tips for using your Hugging Face API Key:</p> <ul> <li>You can create multiple API keys, each with a different name and purpose. This can be useful if you want to use your   API key for different projects or with different third-party tools.</li> <li>You can revoke your API key at any time. This is useful if you think your key has been compromised.</li> <li>You can monitor your API usage in the Hugging Face dashboard. This can help you to track how much of your API quota   you are using and to identify any potential problems.</li> </ul>"},{"location":"getting_started/definitions/","title":"Definitions","text":"<ul> <li>Tracker Payload</li> <li>Traffic</li> <li>Consent</li> <li>Credentials</li> <li>Identification Point</li> <li>Extension Point</li> <li>Metadata</li> </ul>"},{"location":"getting_started/definitions/consent/","title":"Customer Consent","text":"<p>Consent in Tracardi refers to the permissions and agreements given by users regarding the collection, processing, and use of their personal data. Managing user consents is crucial for ensuring compliance with data privacy regulations such as GDPR (General Data Protection Regulation) and CCPA (California Consumer Privacy Act).</p> <p>Consents are stored in profiles as tags.</p>"},{"location":"getting_started/definitions/consent/#usage","title":"Usage","text":"<p>Consents can be used to constrain certain operations or data storage in Tracardi, such as triggering workflows or saving specific data.</p>"},{"location":"getting_started/definitions/credentials/","title":"Credentials","text":"<p>Credentials refer to the authentication details required to connect to external services or APIs. These credentials are crucial for enabling Tracardi to interact with these services securely. Credentials are part of resource configuration. Here are some key points about credentials in Tracardi:</p> <ol> <li> <p>Types of Credentials:</p> <ul> <li>API Keys: Used for services like SendGrid, ClickSend, Airtable, etc. API keys are unique to each service and   are required to authenticate API requests.</li> <li>Usernames and Passwords: Used for services like Elasticsearch and Redis. These credentials authenticate the   connection to the database or service.</li> <li>Tokens: Used for services like Twilio, Telegram Bot API, and Matomo. Tokens act as passwords and are used to   authenticate API requests.</li> <li>Client IDs and Secrets: Used for services like Salesforce and AWS. These credentials are used in OAuth   authentication flows and other secure API connections.</li> </ul> </li> <li> <p>Configuration and Setup:</p> <ul> <li>Credentials are typically configured through the Tracardi interface by filling out resource forms with the   necessary authentication details.</li> <li>Each external service has its own method for generating or retrieving these credentials, usually detailed in the   service's documentation.</li> </ul> </li> <li> <p>Security:</p> <ul> <li>It is important to handle credentials carefully, ensuring they are not shared publicly or with unauthorized   individuals. Tracardi database stores credentials so please make sure you do not expose it to public access.</li> </ul> </li> <li> <p>Examples of Credential Setup:</p> <ul> <li>SendGrid: To connect SendGrid to Tracardi, you need to generate an API key from the SendGrid dashboard and   input it into the Tracardi resource form.</li> <li>ClickSend: You need to log in to ClickSend, navigate to the API credentials section, and copy your username   and API key into Tracardi.</li> <li>Airtable: Find your Airtable API key in the account settings and input it into Tracardi.</li> <li>Twilio: Retrieve your account SID and auth token from the Twilio dashboard and configure them in Tracardi.</li> </ul> </li> <li> <p>Caching:</p> <ul> <li>Credentials are subject to caching, meaning changes may not take effect immediately but after a set duration (   typically 60 seconds).</li> </ul> </li> </ol>"},{"location":"getting_started/definitions/extension_point/","title":"Extension points","text":"<p>Extension points refer to parts of the system that are designed to be easily extended or customized to enhance functionality. These extension points allow users to add new capabilities to Tracardi by integrating custom modules, plugins, or external services written in Python. The main extension points in Tracardi include:</p> <ol> <li> <p>Inbound Traffic Extension Point: This allows for the creation of new event sources using various types    of data    bridges. Users can develop custom data bridges to gather information from different sources or to generate data in    unique ways. Examples include implementing API bridges, such as a RabbitMQ API bridge, and redirect bridges for    collecting data from link clicks.</p> </li> <li> <p>Outbound Traffic Extension Point: This includes destinations that allow orchestrating data to external systems.</p> </li> <li> <p>Resource/Extensions: Tracardi supports a wide range of extensions that can be installed to integrate with various    external services. These extensions enable Tracardi to interact with different APIs, databases, and third-party    platforms, thereby extending its core functionalities. Examples include integrations with services like    ActiveCampaign, Airtable, Amplitude, AWS IAM, and many more.</p> </li> <li> <p>Plugins: That are parts of the automation process and allow processing events and profiles using the graphical    workflows.</p> </li> </ol> <p>By leveraging these extension points, users can tailor Tracardi to meet specific needs, ensuring that it fits seamlessly into their existing workflows and systems. This modular approach enhances the flexibility and scalability of Tracardi, making it a powerful tool for managing customer data and interactions.</p>"},{"location":"getting_started/definitions/identification_point/","title":"Identification point","text":"<p>An identification point in Tracardi is an event within the customer's journey that can be used to uniquely identify the customer and merge their data across multiple interactions and profiles.</p>"},{"location":"getting_started/definitions/identification_point/#key-components-of-identification-points","title":"Key Components of Identification Points","text":"<ul> <li> <p>Event-Based Identification:  Certain events in the customer journey serve as identification points. For example, a   user logging in with their email address or phone number is an event that provides a unique identifier. Identification   Point is triggered by event, contrary to APM which is a background watch dog like process.</p> </li> <li> <p>Unique Identifiers: Identification points rely also on unique identifiers such as email addresses, phone numbers,   usernames, or other personal identifiers that can uniquely distinguish one user from another. Event that is used to   identify and merge customer profile must have a unique identifier.</p> </li> <li> <p>Profile Matching and Merging: When Tracardi processes an event that includes an identification point, it checks if   the identifier matches any existing profiles. If a match is found, the data from the current event is merged with the   existing profile, and the profile is further processed.</p> </li> </ul>"},{"location":"getting_started/definitions/identification_point/#how-identification-points-work-in-tracardi","title":"How Identification Points Work in Tracardi","text":"<ul> <li> <p>Data Collection: As users interact with a website or app, Tracardi collects data and events. Each event may   include identification points, such as an email address provided during registration.</p> </li> <li> <p>Identification Point Settings: If the event is set in Tracardi as an <code>Identification Point</code> and it includes   defined identifier, Tracardi will merge profiles before further processing the event.</p> </li> </ul>"},{"location":"getting_started/definitions/identification_point/#example-of-identification-points-in-action","title":"Example of Identification Points in Action","text":"<ol> <li> <p>Identification Point Settings: System administrator marks two events <code>sign-in</code>, and <code>contact-form-data</code> event as    an identification points. The first has an email as merging key. The second has a telephone number as merging key.</p> </li> <li> <p>Initial Interaction: A user registers on a website with their email address user@example.com and a phone.    Tracardi creates a profile with <code>profile-id-123</code> and stores the email and phone in profile.</p> </li> <li> <p>Subsequent Interaction:  The user logs in from a different device using the same email address. Tracardi    recognizes that the <code>sign-in</code> is the identification point and the email is a merging key. Then it looks up the    database for all the profiles with the delivered e-mail and matches it to <code>profile-id-123</code>, and merges both profiles.</p> </li> <li> <p>Cross-Device Tracking: If the user later provides their phone number within <code>contact-form-data</code> event, Tracardi    again searches the database for the profiles, but this time uses phone as merging key (identifier). If profiles are    found then system merges them.</p> </li> <li> <p>New profile ID: Every time the profiles are merged    the new profile id is returned in the Tracardi response. </p> </li> </ol>"},{"location":"getting_started/definitions/metadata/","title":"Metadata","text":"<p>Metadata provides additional context and information about a profile, session, or event beyond the core data attributes. It helps in managing,and understanding the data by storing supplementary information that is crucial for accurate data processing and analysis, such as creation date, insert date, timezones, etc.</p>"},{"location":"getting_started/definitions/metadata/#metadata-in-context-of-data-storage","title":"Metadata in context of data storage","text":"<p>In the context of data storage, metadata refers to all the information that allows the system to be configured. In this case, event source data is considered auxiliary to the profile and session data, which are the most critical data that the system stores. From version 0.8.2, metadata is stored in MySQL.</p>"},{"location":"getting_started/definitions/track_payload/","title":"Tracker Payload","text":"<p>Tracker payload refers to the comprehensive data structure sent to the Tracardi system to record an event. This payload includes all the necessary information to track and analyze customer interactions. Here's a detailed breakdown of the track payload:</p>"},{"location":"getting_started/definitions/track_payload/#structure-of-the-track-payload","title":"Structure of the Track Payload","text":"<p>The payload typically follows this JSON structure:</p> Example of tracker payload<pre><code>{\n  \"source\": {\n    \"id\": \"source-id\"\n  },\n  \"session\": {\n    \"id\": \"session-id\"\n  },\n  \"profile\": {\n    \"id\": \"profile-id\"\n  },\n  \"context\": {\n    // Context data\n  },\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      },\n      \"options\": {\n        // Event options\n      },\n      \"context\": {\n        // Additional context data\n      }\n    }\n  ],\n  \"options\": {}\n}\n</code></pre>"},{"location":"getting_started/definitions/track_payload/#key-components-of-the-tracktracker-payload","title":"Key Components of the Track/Tracker Payload","text":"<ol> <li> <p>Source:</p> <ul> <li>id: The ID of the source from which the event originates. This must match the event source defined in   Tracardi.</li> </ul> </li> <li> <p>Session:</p> <ul> <li>id: The ID of the session. This ID is typically generated on the client side using UUID4 and should change   with each new user visit.</li> </ul> </li> <li> <p>Profile:</p> <ul> <li>id: The ID of the user's profile. If it's the first visit, this may not be included, and Tracardi will   generate a new profile ID.</li> </ul> </li> <li> <p>Context:</p> <ul> <li>Additional data that provides context about the event, such as device information, browser type, or location. This data is stored in the session.</li> </ul> </li> <li> <p>Events:</p> <ul> <li>type: The type of event, such as \"page-view\" or \"purchase-order\".</li> <li>properties: Data specific to the event type.</li> <li>options: Optional parameters to control event processing, such as immediate firing or beacon mode.</li> <li>context: Additional context data for the event, such as tags or additional metadata.</li> </ul> </li> <li> <p>Options:</p> <ul> <li>Global options for the payload, such as whether to save the session or event, or to enable async storage.</li> </ul> </li> </ol>"},{"location":"getting_started/definitions/track_payload/#example-payload","title":"Example Payload","text":"<p>A minimal payload might look like this:</p> Minimal payload<pre><code>{\n  \"source\": {\n    \"id\": \"source-id\"\n  },\n  \"session\": {\n    \"id\": \"session-id\"\n  },\n  \"events\": [\n    {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"pageTitle\": \"Home Page\"\n      }\n    }\n  ]\n}\n</code></pre> <p>Important</p> <p>Session and Profile IDs: These are crucial for linking events to the correct session and user profile. The session  ID should be unique per visit, while the profile ID remains consistent across all visits. Context and Properties: These fields provide additional metadata and attributes that enrich the event data, allowing for more detailed analysis.</p>"},{"location":"getting_started/definitions/traffic/","title":"Traffic","text":""},{"location":"getting_started/definitions/traffic/#traffic","title":"Traffic","text":"<p>Traffic refers to all the data that is sent to and from the Tracardi system. This encompasses the full spectrum of interactions, including inbound data coming into Tracardi from various sources and outbound data being sent from Tracardi to external systems or services.</p>"},{"location":"getting_started/definitions/traffic/#examples-of-traffic","title":"Examples of Traffic:","text":"<ol> <li> <p>Inbound Traffic:</p> <ul> <li>Event Data: When a user performs actions on a website, such as clicking a button, submitting a form, or   viewing a page, these interactions generate events. These events are sent to Tracardi as part of the inbound   traffic.</li> <li>Webhook Data: Data received from webhooks, such as notifications from third-party services like payment   gateways, email marketing platforms, or CRM systems.</li> </ul> </li> <li> <p>Outbound Traffic:</p> <ul> <li>API Request: Tracardi sending data to external systems through API. This could include   profile updates, events, etc.</li> <li>Integrations: Data sent to integrated services, such as sending customer data to a marketing automation   platform or synchronizing profiles with a CRM system.</li> <li>Notifications: Sending alerts or messages to other systems or services, such as triggering an email or SMS   notification based on specific events or conditions.</li> </ul> </li> </ol>"},{"location":"getting_started/definitions/traffic/#example-scenario","title":"Example Scenario:","text":"<ul> <li> <p>Inbound Traffic:</p> <ul> <li>A user visits an online store and adds items to their cart. Each interaction, such as viewing a product, adding an   item to the cart, and starting the checkout process, generates events that are sent to Tracardi as inbound   traffic.</li> <li>An external payment gateway sends a webhook notification to Tracardi when a payment is successfully processed.</li> </ul> </li> <li> <p>Outbound Traffic:</p> <ul> <li>Tracardi processes the events and updates the user's profile with their browsing and purchase behavior. This   updated profile data is then sent to the e-commerce platform\u2019s CRM system.</li> <li>Based on the purchase event, Tracardi triggers an outbound notification to the email marketing platform to send a   purchase confirmation email to the user.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/","title":"Tracardi Processes","text":"<p>Tracardi is build around 5 major processes.</p>"},{"location":"getting_started/processes/#key-processes","title":"Key Processes","text":"<ul> <li> <p>Integration: Integration is not a process within Tracardi. Instead, it occurs within a company and involves integrating systems       with Tracardi to send data from various systems, websites, and databases to Tracardi.</p> </li> <li> <p>Collection: Collection is the process responsible for gathering and ingesting data. It consists of several subprocesses:</p> <ul> <li>Tracking: The process of maintaining a consistent single Profile ID across all customer interactions on a single device. It is the responsibility of the device/client to keep the Profile ID unchanged.</li> <li>Identity Resolution and Merging: The process of maintaining a consistent single profile across all customer devices. It is Tracardi's responsibility to merge all profiles created on different devices whenever possible.</li> <li>Storing Data: This process involves storing collected data in one profile record and referencing all historical events and sessions.</li> </ul> </li> <li> <p>Automation: This process automates the customer journey, enhances customer profiles, personalizes customer experiences, and triggers messaging.</p> </li> <li> <p>Audiences and Activations: The process of creating audiences/segments and orchestrating them to external systems such as Marketing Automation platforms.</p> </li> <li> <p>Orchestrator/Router: The process responsible for sending customer data to external systems.</p> </li> </ul>"},{"location":"getting_started/processes/apm/","title":"Automatic Profile Merging (APM) Documentation","text":"<p>Automatic Profile Merging (APM) is the process of merging user profiles in Tracardi. This feature ensures that all data related to a user is consolidated into a single profile. APM operates as a background process, merging profiles when specific predefined fields, known as merging keys, contain matching data.</p>"},{"location":"getting_started/processes/apm/#key-steps-in-automatic-profile-merging","title":"Key Steps in Automatic Profile Merging","text":"<ul> <li> <p>Data Collection and Profile Identification:</p> <ul> <li>When a user interacts with a website or app, Tracardi collects data and creates a new profile if one does not   already exist.</li> <li>Each profile has a unique Profile ID.</li> </ul> </li> <li> <p>Profile Matching:</p> <ul> <li>Tracardi continuously monitors changes in the profile fields designated as merging keys.</li> <li>When a change is detected in these fields, the system identifies profiles that need merging.</li> </ul> </li> <li> <p>Merging Profiles:</p> <ul> <li>Upon finding a match, Tracardi automatically merges the new profile data with the existing profile.</li> <li>Combining Attributes and Traits: Profile data is merged according to the defined merging strategy for each   field.</li> <li>Updating the Existing Profile: The existing profile is updated with new data from the incoming profile.</li> <li>Retaining Historical Data: All events and sessions are updated and accurately reflected in the merged profile.</li> <li>Maintaining All Profile IDs: The Profile IDs from the individual profiles are moved to the <code>profile.ids</code> field   in the merged profile. A new primary ID is then selected from the available <code>profile.ids</code>. This new primary ID   will be returned in the Tracardi response.</li> </ul> </li> <li> <p>Handling Conflicts:</p> <ul> <li>During the merge, if there are conflicting data points (e.g., different values for the same attribute), Tracardi   follows predefined rules to resolve these conflicts.</li> <li>Typically, the most recent data or the data deemed most reliable is retained.</li> </ul> </li> <li> <p>Profile Consolidation:</p> <ul> <li>The merged profile now represents a comprehensive view of the user, consolidating data from all matched profiles.</li> <li>This unified profile gets a new Profile ID and is saved in the database.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/apm/#details","title":"Details","text":"<ul> <li> <p>Merging Keys:</p> <ul> <li>Tracardi uses predefined fields as merging keys to identify profiles that should be merged. These fields typically   include:<ul> <li>Email addresses (<code>data.contact.email.main</code>, <code>data.contact.email.business</code>, <code>data.contact.email.private</code>)</li> <li>Phone   numbers (<code>data.contact.phone.main</code>, <code>data.contact.phone.business</code>, <code>data.contact.phone.whatsapp</code>, <code>data.contact.phone.mobile</code>)</li> <li>Identifiers (<code>data.identifier.pk</code>, <code>data.identifier.id</code>)</li> </ul> </li> </ul> </li> <li> <p>Merging Process:</p> <ul> <li>Profiles flagged for merging (it happens when a change in a merging key is noticed) are processed by a background   worker.</li> <li>This worker consolidates the profiles, moving the profile IDs from the individual profiles fields into the <code>profile.ids</code>   field of the merged profile as hashed values.</li> <li>A new client ID is selected from the available <code>profile.ids</code>, and this new ID is returned in the Tracardi   response.</li> </ul> </li> <li> <p>Profile IDs Management:</p> <ul> <li>The generated IDs that are stored in the <code>profile.ids</code> field have specific prefixes to indicate their origin:<ul> <li><code>emm-</code> hash from main email (<code>data.contact.email.main</code>)</li> <li><code>emb-</code> hash from business email (<code>data.contact.email.business</code>)</li> <li><code>emp-</code> hash from private email (<code>data.contact.email.private</code>)</li> <li><code>phm-</code> hash from main phone (<code>data.contact.phone.main</code>)</li> <li><code>phw-</code> hash from WhatsApp phone (<code>data.contact.phone.whatsapp</code>)</li> <li><code>phb-</code> hash from business phone (<code>data.contact.phone.business</code>)</li> <li><code>pho-</code> hash from mobile phone (<code>data.contact.phone.mobile</code>)</li> <li><code>ipk-</code> hash from <code>data.identifier.pk</code></li> <li><code>iid-</code> hash from <code>data.identifier.id</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"getting_started/processes/apm/#enabling-auto-profile-merging","title":"Enabling Auto Profile Merging","text":"<ul> <li> <p>Add Environment Parameter:</p> <ul> <li>Add the <code>AUTO_PROFILE_MERGING</code> environment parameter with a key of at least 20 characters when starting the   Tracardi API (include it in the Docker command).</li> <li>This key is used as salt when hashing emails and phone numbers.</li> </ul> </li> <li> <p>Enable Unique ID Generation:</p> <ul> <li>Enabling the <code>AUTO_PROFILE_MERGING</code> parameter also automatically enables the generation and storage of unique IDs   for every email address processed by the system.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/audience/","title":"Audiences and Activations","text":""},{"location":"getting_started/processes/audience/#audiences","title":"Audiences","text":"<p>The term \"audience\" refers to a select group of users specifically targeted for certain campaigns or business operations. The formation of an audience is dynamic and tailored to the goals of specific projects. It involves applying a set of logical criteria that segments these users from the broader customer pool. These criteria become relevant during an activation event to pinpoint who presently makes up the audience.</p>"},{"location":"getting_started/processes/audience/#activations","title":"Activations","text":"<p>Activation involves engaging with a predetermined audience by integrating them with an external system, such as a marketing automation platform. This process relies on the specific criteria defined for the audience to gather the relevant members and relay their data to the chosen system. As audiences are dynamic\u2014calculated in real-time\u2014their makeup can fluctuate depending on the set conditions at the time of activation. For instance, an audience defined by recent activity, like \"customers who made a purchase in the last 30 days,\" will continuously update as new transactions occur and older ones become outdated.</p>"},{"location":"getting_started/processes/automation/","title":"Automation Types","text":"<p>Automation in Tracardi refers to the capability to perform tasks and processes without manual intervention by leveraging predefined rules, workflows, and integrations. This involves the use of machine learning algorithms and advanced automation features to personalize customer experiences, optimize marketing campaigns, and streamline data management. Automation in Tracardi can handle dynamic content delivery, real-time decision-making, and complex customer journey orchestration, ensuring efficient and effective data processing and engagement strategies.</p>"},{"location":"getting_started/processes/automation/#available-types-of-automations","title":"Available Types of Automations:","text":"<ul> <li> <p>Personalized Messaging:</p> <ul> <li>Automatically send messages to users based on their behavior, preferences, and interactions. This   includes emails, SMS, push notifications, and in-app messages designed to engage users at the right time with the   right content.</li> </ul> </li> <li> <p>Personalized Widgets:</p> <ul> <li>Customize web pages with dynamic widgets that adapt to user profiles and actions. This allows for the collection   of additional data using techniques like progressive profiling, which incrementally gathers more information about   users over time.</li> </ul> </li> <li> <p>Data Orchestration:</p> <ul> <li>Integrate and route data to Customer Relationship Management (CRM) systems, marketing automation   platforms, and other external systems. This ensures that all relevant data is synchronized and available across   your tech stack for a unified customer view.</li> </ul> </li> <li> <p>Data Enhancement:</p> <ul> <li>Enrich existing data by appending additional information from various sources. This can include demographic data,   behavioral insights, and predictive analytics to create a more comprehensive user profile.</li> </ul> </li> <li> <p>Real-Time Decision-Making:</p> <ul> <li>Use real-time data processing to make immediate decisions based on user actions. This includes triggering   workflows that respond to user behavior as it happens, providing timely and relevant responses.</li> </ul> </li> <li> <p>Complex Customer Journey Orchestration:</p> <ul> <li>Automate the management of customer journeys with sophisticated workflows that guide users through personalized   experiences. This can include multi-step campaigns, targeted offers, and customized user pathways based on   individual behavior and preferences.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/collection/","title":"Data collection","text":"<p>Data collection in Tracardi is a comprehensive process responsible for gathering and ingesting data into the system. This process begins with collecting data from various event sources through a defined bridge and involves multiple stages to ensure data is accurately processed and stored.</p>"},{"location":"getting_started/processes/collection/#stages","title":"Stages","text":"Stage Description <code>Browser event collection</code> Tracardi collects events on browser. See the stages of collection. <code>Source validation</code> Tracardi must have event source defined and enabled in the system. <code>Event mapping</code> Tracardi can validate the event data schema, map event and reshape its schema if needed. <code>Identity resolution</code> At this point the profile is identified if it exists in the system or a new anonymous profile is created. Tracardi checks if the profile can be merged with other profiles that seems to be the same <code>Event reshaping</code> Tracardi can change the event schema if needed. <code>Event collection</code> Tracardi saves the event. <code>Event routing</code> Tracardi reads a rule that defines which workflow, or destination should be triggered."},{"location":"getting_started/processes/collection/#details","title":"Details","text":"<ol> <li>Source Validation</li> </ol> <p>Description: Tracardi must have the event source defined and enabled in the system.    Detail: Ensures that the incoming event is from a recognized and active event source. The event source identifier is    checked against the registered event sources in Tracardi.</p> <ol> <li>Event Mapping</li> </ol> <p>Description: Tracardi can validate the event data schema, map the event, and reshape its schema if needed.    Detail: The event's data is validated to ensure it meets the expected schema. If necessary, the event data is mapped    to build events traits, potentially renaming fields or converting data formats for consistency and    usability.</p> <ol> <li>Identity Resolution</li> </ol> <p>Description: Identifies the profile if it exists in the system or creates a new anonymous profile. Tracardi checks if    the profile can be merged with other profiles that seem to be the same.    Detail: Tracardi attempts to resolve the identity of the event's originator. If a matching profile exists, it is    retrieved; otherwise, a new anonymous profile is created. The system also looks for potential merges with existing    profiles based on predefined keys such as email addresses.</p> <ol> <li>Event Reshaping</li> </ol> <p>Description: Tracardi can change the event schema if needed.    Detail: The event data may be further transformed to match specific workflow requirements or to enhance the data    before processing. This could involve adding, removing, or modifying event attributes.</p> <ol> <li>Event Collection</li> </ol> <p>Description: Tracardi saves the event.    Detail: The validated and possibly reshaped event data is stored in Tracardi's database. This ensures that the event    is available for historical analysis and future reference.</p> <ol> <li>Event Routing</li> </ol> <p>Description: Tracardi reads a rule that defines which workflow must be triggered by the event.    Detail: Based on predefined routing rules, Tracardi determines which workflow should handle the event. These rules    consider the event type, source, and possibly other conditions.</p>"},{"location":"getting_started/processes/identification/","title":"Profile Identification","text":"<p>Identification is a process of loading the correct profile from the system database. To do so Tracardi maintains various types of IDs in the profile record. Here are the types of IDs and their purposes:</p> <ul> <li> <p>Client Profile ID (<code>profile.id</code>): This is the main identifier for each profile. This ID is usually originated by   the client (browser). It is the ID that should be saved on the client. It represents a single user within the system.   Note that this ID may change after profile merging because several profiles are merged and one Client Profile ID   should be selected.</p> </li> <li> <p>Primary ID (<code>profile.primary_id</code>): This is the unique Profile ID across the entire system and event sources. It   must be delivered by an external system that serves as an authority to identify the customer. For example, this could   be an Authorization Service that returns a profile ID after the user signs in. The Primary ID could also be computed   based on a global   value that identifies the customer, such as an email, phone number, or another unique identifier.</p> </li> <li> <p>Previous or Other Profile IDs (<code>profile.ids</code>): These are additional IDs that might have been associated with the   same user from different sources or previous instances of the profile saved on different devices. They help in   maintaining continuity and consistency when profiles are   identified. This allows the profile to be identified when the device has an old ID and was never updated after the   profile was merged. When profiles are merged, the individual profile IDs are moved to the <code>profile.ids</code> field of the   merged profile, and a new Client Profile ID is selected from these IDs. Notice that Client Profile ID and Primary ID   are included in the <code>profile.ids</code>.</p> </li> </ul>"},{"location":"getting_started/processes/identification/#how-tracardi-uses-the-ids","title":"How Tracardi Uses the IDs","text":"<p>When a tracker payload is sent to Tracardi, it contains the Client Profile ID. Tracardi first looks up the profile in the database. The system searches for the profile that either has <code>profile.id</code> equal to the profile ID from the tracker payload or has this ID in <code>profile.ids</code>. Once the profile is found, it is loaded, and new data is appended. This way, when the profile is correctly identified, no merging is needed.</p> <p>Note</p> <p>The <code>profile.ids</code> field contains all historical IDs (including the Primary ID), allowing the profile to be identified by any historical ID.</p>"},{"location":"getting_started/processes/identification/#how-the-system-selects-the-primary-id","title":"How the System Selects the Primary ID","text":"<p>The Primary ID feature is available from version 0.9.0. In a distributed system where there is no single Authorization Service, the concept of the Primary ID differs from widely used definitions. In Tracardi, the Primary ID can be empty, which means there was no data that could identify the profile across all sources. There is a system setting that tells Tracardi which field from the profile schema is selected to be the Primary ID. When this field is filled the Primary ID is also filled.</p> <p>Note</p> <p>The environment variable <code>PRIMARY_ID</code> defines which field to use as the Primary ID. This could be data from <code>data.identifier.pk</code> or a business email from <code>data.contact.email.business</code>. Additionally, we can specify whether the Primary ID should be a hash of the field value using the <code>PRIMARY_ID_AS_HASH</code> environment variable.</p>"},{"location":"getting_started/processes/identification/#merging","title":"Merging","text":"<p>When system detects that some of the profile fields which are set to be merging key are changed it marks profile for merging. This process is called Automatic Profile Merging. </p>"},{"location":"getting_started/processes/identity_resolution/","title":"Identity Resolution","text":"<p>Identity resolution is a process that combines Tracking, Identification and Merging Profiles.</p>"},{"location":"getting_started/processes/identity_resolution/#data-collection","title":"Data Collection","text":"<p>Data collection involves gathering events and interactions from various devices. One set of events may be collected on one device, and another on different devices, resulting in different Profile IDs for the same user. Data collection itself is not responsible for merging these profiles.</p>"},{"location":"getting_started/processes/identity_resolution/#identity-resolution-processes","title":"Identity Resolution Processes","text":"<p>Identity resolution includes several key processes:</p> <ul> <li> <p>Tracking: The process of maintaining a consistent single Profile ID across all customer   interactions on a single device. It is the responsibility of the device/client to keep the Profile ID unchanged and   this is a process on the device.</p> </li> <li> <p>Merging Profiles: Tracardi merges the existing profiles collected on different devices or from   different channels into a single unified profile. This is a server process that returns the new Profile ID to the   client.</p> </li> <li> <p>Identification: The resulting unified profile may retain multiple profile IDs to identify the   same profile created on different devices or browsers. This is a server process that ensures that all historical   Profile IDs are stored in the system.</p> </li> </ul> <p>Note</p> <p>The profile ID sent in the tracking payload may be different in the Tracardi response. For more details,  see why my profile ID in the response from Tracardi is different from the one I have sent.</p>"},{"location":"getting_started/processes/merging/","title":"Merging","text":"<p>There are two types of merging processes.</p> <ul> <li>Automatic Profile Merging: Automatic profile merging in Tracardi is a process designed to unify multiple profiles   that represent the same user. Merging is a background process that looks for the profiles wth the same merging key,   e.g. email.</li> <li>Identification Points: This a realtime process that merges profiles when   a defined event was sent e.g. <code>Identification</code> and it contains data that can be used for mering.</li> </ul>"},{"location":"getting_started/processes/merging/#example-of-profile-merging","title":"Example of Profile Merging","text":"<ol> <li> <p>Initial Interaction:</p> <ul> <li>A user visits a website and signs up with the email address <code>user@example.com</code>. Tracardi creates <code>profile-id-123</code>   for this user.</li> </ul> </li> <li> <p>Subsequent Interaction on a Different Device:</p> <ul> <li>The same user visits the website on a different device and signs up again with the same email   address <code>user@example.com</code>. Tracardi creates a new <code>profile-id-456</code>.</li> </ul> </li> <li> <p>Identification Point Match:</p> <ul> <li>If the Identification point is created for a <code>sign up</code> event then   Tracardi detects that both profiles have the same email address. It identifies this as a match and proceeds to   merge <code>profile-id-456</code> into <code>profile-id-123</code>.</li> <li>If there is no identification point for this event, two profiles with the same email will be detected with the   Automatic Profile Merging (APM) and the profile will be merged.</li> </ul> </li> <li> <p>Data Merging:</p> <ul> <li>The system combines the data from both profiles, updating <code>profile-id-123</code> with any new information   from <code>profile-id-456</code> and retaining all historical data.Is updates events and sessions to link to the new merged profile.</li> </ul> </li> <li> <p>Conflict Resolution:</p> <ul> <li>Conflicting data inf profiles is resolved using predefined set of merging strategies. For example there are 3 different lastnames in the profile. </li> </ul> </li> <li> <p>Unified Profile:</p> <ul> <li>The final unified profile under <code>profile-id-123</code> now contains data from both interactions, providing a complete   view of the user's behavior and attributes across both devices.</li> </ul> </li> </ol>"},{"location":"getting_started/processes/merging/#why-my-profile-id-in-the-response-from-tracardi-is-different-from-the-one-i-have-sent","title":"Why my profile ID in the response from Tracardi is different from the one I have sent?","text":"<p>The profile ID you send in the tracker payload might be different in the response from Tracardi due to several reasons related to identity resolution, merging profiles, or system updates. Here are the key reasons why this might happen:</p> <ol> <li> <p>Identity Resolution:</p> <ul> <li>Tracardi performs identity resolution to merge profiles with matching identifiers (like email or phone number). If   the system detects that the profile you sent should be merged with an existing profile, it will return the ID of   the merged profile.</li> </ul> </li> <li> <p>Profile Merging:</p> <ul> <li>When Tracardi background processed identifies that two profile should be combined with an existing one, it creates   a unified profile. As a result, the returned profile ID will reflect the consolidated profile rather than the one   originally sent.</li> </ul> </li> <li> <p>Session-Based Profile Retrieval:</p> <ul> <li>If the session information provided in the payload is linked to a different profile, Tracardi might return the   profile ID associated with that session. This ensures continuity in tracking user activities across sessions. This   usually happens when the Profile ID is corrupted.</li> </ul> </li> <li> <p>New Profile Creation:</p> <ul> <li>In some cases, if the profile information sent in the payload does not match any existing profiles or the system   is configured to automatically create new profile for not existing ones then a new profile will be created, and   the response will include a newly generated profile ID.</li> </ul> </li> <li> <p>Data Consistency and Updates:</p> <ul> <li>Tracardi continuously updates and maintains profiles based on the latest interactions and data. If there have been   changes or updates to the profile since the payload was sent, the response might reflect the most current profile   ID.</li> </ul> </li> </ol>"},{"location":"getting_started/processes/merging/#example-scenarios","title":"Example Scenarios","text":"<ul> <li> <p>Scenario 1: Identity Resolution</p> <ul> <li>You send a payload with <code>profile-id-abc123</code> and an email. Tracardi identifies that this email already exists   under <code>profile-id-def456</code>. The system merges the profiles and returns <code>profile-id-def456</code>.</li> </ul> </li> <li> <p>Scenario 2: Session Linking</p> <ul> <li>You send a payload with a session ID <code>session-id-1</code> that was originally associated with <code>profile-id-xyz789</code>. The   system returns <code>profile-id-xyz789</code> to maintain session continuity.</li> </ul> </li> <li> <p>Scenario 3: New Profile Creation</p> <ul> <li>You send a payload with an unknown profile ID. Tracardi creates a new profile and returns the new profile ID   generated for this interaction.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/merging/#profile-id-maintenance","title":"Profile ID maintenance","text":"<p>The above scenarios show that your client software should always save the newest returned profile ID. If the Profile ID changes it is a sign that the client should update the local Profile ID.</p>"},{"location":"getting_started/processes/merging_strategy/","title":"Profile Merging Strategies","text":""},{"location":"getting_started/processes/merging_strategy/#what-is-a-merging-strategy","title":"What is a Merging Strategy?","text":"<p>The merging strategy in Tracardi is the method or algorithm used for combining different profiles or events to form a single cohesive profile. It is one of the predefined methods that the system will use in case there is conflicting data in the set of profiles that need to be merged into a single profile. An example of a strategy is an algorithm that prioritizes the last update made to a profile, regardless of the channel from which the data was collected.</p>"},{"location":"getting_started/processes/merging_strategy/#example-of-a-merging-strategy","title":"Example of a Merging Strategy","text":"<p>Last Profile Update Wins:</p> <ul> <li>Prioritizes the most recent information when merging profiles.</li> <li>Useful for ensuring the most current data is always reflected in the unified profile.</li> </ul> <p>Example Scenario:</p> <ul> <li>Profile A: Last Updated: 2024-01-01</li> <li>Profile B: Last Updated: 2024-02-01</li> <li>Profile C: Last Updated: 2024-03-01</li> </ul> <p>Using this strategy, In case of a conflicting data in field e.g. last name the value form Profile C's will be used in the unified profile since it is the most recently updated profile.</p>"},{"location":"getting_started/processes/merging_strategy/#what-is-a-set-of-merging-strategies","title":"What is a Set of Merging Strategies?","text":"<p>Merging strategies are defined in sets. It is a sequence in which the system should attempt to resolve conflicts in profile data. An example of a set may look like this.</p> <ol> <li><code>LAST_UPDATE</code>: Selects the most recently updated field.</li> <li><code>LAST_PROFILE_UPDATE_TIME</code>: Selects the value from the most recently updated profile.</li> <li><code>LAST_PROFILE_INSERT_TIME</code>: Selects the value from the most recently inserted profile.</li> </ol> <p>If the primary merge strategy cannot be applied (e.g., missing update times), a fallback (next in sequence) strategy is used. </p>"},{"location":"getting_started/processes/merging_strategy/#how-merging-strategies-are-matched","title":"How Merging Strategies are Matched","text":"<p>In case of a conflict during merging the system selects which merge strategy to use. Merging strategies are matched using either exact or wildcard field matches:</p> <ul> <li>Exact Match: Specific to a field, e.g., <code>profile.ids</code>.</li> <li>Wildcard Match: Applies to multiple fields, e.g., <code>profile.*</code> or <code>*</code>.</li> </ul>"},{"location":"getting_started/processes/merging_strategy/#available-merge-strategies","title":"Available Merge Strategies","text":"Strategy ID Name Description <code>LAST_UPDATE</code> Last updated value Uses the update date to select the most recent value. <code>FIRST_UPDATE</code> First inserted value Uses the update date to select the first inserted value. <code>MIN</code> Minimal value Selects the minimal value. <code>MAX</code> Maximal value Selects the maximal value. <code>SUM</code> Sum of values Sums all values. <code>AVG</code> Average of values Averages all values. <code>LAST_DATETIME</code> Last date Selects the most recent date. <code>FIRST_DATETIME</code> First date Selects the earliest date. <code>ALWAYS_TRUE</code> Always TRUE Always returns TRUE. <code>ALWAYS_FALSE</code> Always FALSE Always returns FALSE. <code>AND</code> AND Operator Uses AND operator on all boolean values. <code>OR</code> OR Operator Uses OR operator on all boolean values. <code>MERGE_LISTS</code> Merge Values From Lists Concatenates all values from lists. <code>MERGE_LISTS_DISTINCT</code> Merge Unique Values Concatenates unique values from lists. <code>MERGE_LISTS_AND_VALUES</code> Merge Values and Lists Concatenates all values and lists. <code>CONCAT_VALUES_TO_LIST</code> Concatenate Values to List Concatenates all values into a list. <code>FIRST_PROFILE_INSERT_TIME</code> First Profile Insert Time Uses the value from the first inserted profile. <code>FIRST_PROFILE_UPDATE_TIME</code> First Profile Update Time Uses the value from the first updated profile. <code>LAST_PROFILE_CREATE_TIME</code> Last Profile Create Time Uses the value from the last created profile. <code>LAST_PROFILE_UPDATE_TIME</code> Last Profile Update Time Uses the value from the last updated profile. <code>LAST_PROFILE_INSERT_TIME</code> Last Profile Insert Time Uses the value from the last inserted profile. <code>FIRST_ITEM</code> No Merging Does not merge anything."},{"location":"getting_started/processes/merging_strategy/#examples","title":"Examples","text":""},{"location":"getting_started/processes/merging_strategy/#last-update-strategy","title":"Last Update Strategy","text":"<ul> <li>Prioritizes the most recent field update.</li> <li>Example: Two profiles with conflicting email fields will use the email that is the most recently updated (oldest field timestamp).</li> </ul>"},{"location":"getting_started/processes/merging_strategy/#last-profile-update-time-strategy","title":"Last Profile Update Time Strategy","text":"<ul> <li>Selects the value from the profile that was last updated.</li> <li>Example: Two profiles with conflicting email fields will use the email from the most recently updated profile (oldest profile timestamp).</li> </ul>"},{"location":"getting_started/processes/merging_strategy/#last-datetime-strategy","title":"Last DateTime Strategy","text":"<ul> <li>Selects the most recent date.</li> <li>Example: Three profiles with different last login dates will use the most recent login date, regardless of the field timestamp.</li> </ul>"},{"location":"getting_started/processes/orchestration/","title":"Orchestration","text":"<p>Orchestration in Tracardi refers to the automated coordination and management of complex destinations and workflows. Both destinations and workflows are mechanisms to send data out of the system, but they operate with different levels of complexity and control.</p> <ul> <li> <p>Workflows:   Workflows offer granular control over the entire process. They allow the definition of complex rules and conditions   for when and how data should be sent to external systems. This flexibility enables intricate data processing,   transformation, and routing based on specific criteria.</p> </li> <li> <p>Destinations:   Destinations provide a straightforward method for sending events and profiles as they arrive in the system. While less   complex than workflows, destinations are easier to configure and use, making them ideal for simple data forwarding   tasks.</p> </li> </ul>"},{"location":"getting_started/processes/tracking/","title":"Tracking","text":"<p>Tracking refers to the method of consistently maintaining a single Profile ID for all customer interactions on a particular device. This Profile ID is crucial for identifying and linking various activities and behaviors of a customer to a unified profile. The device or client is responsible for ensuring that the Profile ID remains unchanged throughout all interactions, thereby providing a continuous and accurate record of customer behavior on that device. Tracking is connected with the device, while Identification is a process on a server.</p>"},{"location":"getting_started/processes/tracking/#tracking-ids-client-side","title":"Tracking IDs (Client Side)","text":"<p>Tracardi use 2 different IDs for maintaining customer identity: the Profile ID and the Session ID. These IDs help in tracking customer interactions and maintaining single customer profile across multiple sessions and devices.</p>"},{"location":"getting_started/processes/tracking/#profile-id","title":"Profile ID","text":"<ul> <li> <p>Creation:</p> <ul> <li>The Profile ID is generated by Tracardi when a customer first interacts with the website or application. This ID   is unique to the customer and remains consistent across all future interactions within the same browser or device.</li> <li>It is stored in the local storage of the browser to ensure persistence across multiple visits. Browser or device   should make sure that once profile ID is send from Tracardi it will maintain the same on one device.</li> </ul> </li> <li> <p>Purpose:</p> <ul> <li>The Profile ID is used to create and maintain a customer profile that aggregates all customer interactions,   preferences, and attributes over time.</li> <li>It enables Tracardi to identify and later merge multiple profiles from different devices, ensuring a unified view   of the customer.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/tracking/#session-id","title":"Session ID","text":"<ul> <li> <p>Creation:</p> <ul> <li>The Session ID is generated on the client side (e.g., web browser) when a customer opens a browser or mobile app.   Each new session (e.g., each new visit or app launch) results in a new Session ID.</li> <li>It is stored in a cookie in the customer's browser and remains the same for the duration of the session. A new   Session ID is created if the browser or app is closed and reopened. This applies to any device capable of storing   the ID, including mobile apps.</li> </ul> </li> <li> <p>Purpose:</p> <ul> <li>The Session ID is used to track a customer's activities within a single session. It helps in understanding the   sequence of customer actions and behaviors during a specific visit.</li> <li>It ensures that interactions are grouped into distinct sessions, providing insights into session-based metrics   like duration, page views, and conversion rates.</li> <li>If the device cannot store the Session ID, a new session will be created for every event. However, it is possible   to embed static session with each event so that all events belong to the same session.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/tracking/#how-they-work-together","title":"How They Work Together","text":"<ul> <li> <p>Profile ID:</p> <ul> <li>When a customer visits the website for the first time, Tracardi generates a Profile ID and stores it in the local   device storage.</li> <li>The Profile ID should be saved on the device and remain constant across multiple visits and sessions, allowing   Tracardi to build a comprehensive profile based on long-term interactions.</li> </ul> </li> <li> <p>Session ID:</p> <ul> <li>Each time the customer starts a new session (opens the browser or app), a new Session ID is generated and stored   in a cookie.</li> <li>Session should also be saved on the device. All events and interactions within this session are tagged with the   Session ID, enabling Tracardi to group them accordingly.</li> <li>A session can be used to retrieve a lost Profile ID. If an existing session is sent, the system will return the   corresponding profile that originated this session, and the event will reference this profile along with the sent   session. This is a very powerful way of maintaining consistency in the use-cases where the profile ID can not be   sent.</li> </ul> </li> <li> <p>Identification and Identity Resolution:</p> <ul> <li>Tracardi uses the Profile ID or Session ID to load profile before consuming the event. When the event is sent,   Tracardi first must identify the profile and load it.</li> <li>Correct identification ensures that all customer data is consolidated under a single profile.</li> <li>Identity resolution is a process that combines Tracing, Identification and Merging.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/tracking/#example","title":"Example","text":"<ul> <li> <p>First Visit:</p> <ul> <li>User visits the website, and Tracardi generates a Profile ID (<code>profile-id-123</code>) and a Session   ID (<code>session-id-abc123</code>).</li> <li>The Profile ID is stored in local storage, and the Session ID is stored in a cookie.</li> </ul> </li> <li> <p>Subsequent Visits:</p> <ul> <li>On the next visit, the browser retrieves the existing Profile ID (<code>profile-id-123</code>) from local storage.</li> <li>A new Session ID (<code>session-id-def456</code>) is generated and stored in a cookie for this new session.</li> <li>Tracardi associates the new session's data with the existing Profile ID, enriching the customer's profile with new   interactions.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/integration/","title":"Integration","text":"<p>Integration in Tracardi refers to the process of connecting external systems, websites, and databases to Tracardi, enabling data exchange and interaction. This process ensures that data from various sources can be collected, and processed.</p>"},{"location":"getting_started/processes/integration/#integration-types","title":"Integration Types","text":""},{"location":"getting_started/processes/integration/#integrations-via-api","title":"Integrations via API","text":"<ol> <li> <p>API Calls:</p> <ul> <li>Track Endpoint - Tracardi supports integration with external systems through APIs. This involves setting up API endpoints to receive data from third-party applications or to send processed data and insights back to these applications.</li> <li>Webhook Endpoint - Tracardi supports integration via webhooks, which is an endpoint that does not require a predefined data schema.</li> </ul> </li> <li> <p>Javascript:</p> <ul> <li>This type of integration allows for the automatic event ingestion from the web page. Javascript snippet uses Track Endpoint.</li> </ul> </li> </ol> <p>Both methods use the Tracardi API.</p>"},{"location":"getting_started/processes/integration/#integrations-via-url","title":"Integrations via URL","text":"<ol> <li> <p>Redirected Links: This method involves creating   special links that, when clicked, send information to Tracardi about the user and then redirect them to a specific page. The information is stored within the link itself.</p> </li> <li> <p>Cross-domain Parameterized Links: The second method involves adding   a parameter <code>__tr_pid</code> to an existing link. This parameter contains user information. When user visits the target   page, the tracking script, that must exist on the target page, sends an event to Tracardi and use the   parameter <code>__tr_pid</code> to identify the customer. </p> </li> </ol> <p>Both methods are similar, but they differ in who sends the event to the system. In Redirected Links, Tracardi handles the event since the link is within the system. In the second method, the script located at the target page is responsible for sending the event.</p> <p>There could be other integration types when different bridges are used.</p>"},{"location":"getting_started/processes/integration/api/","title":"API integration","text":"<p>Integrating Tracardi with a web page or other systems is easy by calling the Tracardi endpoint.</p>"},{"location":"getting_started/processes/integration/api/#track-endpoint","title":"Track Endpoint","text":"<p>Events can be sent via the <code>/track</code> endpoint using the POST method and sending Tracker Payload</p>"},{"location":"getting_started/processes/integration/api/#tracker-payload","title":"Tracker Payload","text":"<p>There are two parts of this Tracker Payload:</p> <ul> <li>Track Payload: Consists of metadata such as <code>source.id</code>, <code>profile.id</code>, <code>session.id</code>, <code>options</code>, and <code>context</code></li> <li>Event Payload: That consists events. This is the data inside the <code>events</code> key. It consists of   event <code>type</code>, <code>properties</code>, etc.</li> </ul> Example of Tracker Payload, Highlighed Event Payload<pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\"\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\"\n  },\n  \"context\": {\n    // Context data\n  },\n  \"properties\": {},\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      },\n      \"options\": {\n        // Event options\n      },\n      \"context\": {\n        // Additional context data\n      }\n    },\n    ...\n  ],\n  \"options\": {}\n}\n</code></pre> <p>The payload has the following data:</p> Attribute Type Description events List of Event List of events source dict Source object (required) session dict Session object (required) profile dict Profile object (required) properties Optional[dict] Properties associated with the event (may be empty) options Optional[dict] Additional options for the event (may be empty) context Optional[dict] Additional context data for the event (may be empty) tags Optional[list] Tags associated with the event (optional) <p>Tracardi can collect several events in one request for one profile. That's why we define a list of objects in the events key. Each event may have different context and can also inherit values from the tracker payload. Here's an example of the tracker payload that could be sent to Tracardi.</p> Full-fledged tracker payload with a lot of data<pre><code>{\n  \"source\": {\n    \"id\": \"3ee63fc6-490a-4fd8-bfb3-bf0c8c8d3387\"\n  },\n  \"session\": {\n    \"id\": \"bfb3-bf0c8c8d3387-3ee63fc6-490a-4fd8\"\n  },\n  \"profile\": {\n    \"id\": \"bf0c8c8d3387-3ee63fc6-490a-4fd8bfb3\"\n  },\n  \"events\": [\n    {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"pageTitle\": \"My Page\"\n      },\n      \"options\": {\n        \"saveEvent\": false,\n        \"saveSession\": false,\n        \"debugger\": false\n      },\n      \"context\": {\n        \"tag\": \"product-details-page\"\n      }\n    },\n    {\n      \"type\": \"consent-granted\",\n      \"properties\": {\n        \"marketing\": false,\n        \"general\": true\n      },\n      \"options\": {\n        \"profile\": true,\n        \"saveSession\": false\n      }\n    },\n    {\n      \"type\": \"product-in-basket\",\n      \"properties\": {\n        \"product\": \"Adidas sneakers\",\n        \"price\": 34.43\n      },\n      \"options\": {\n        \"profile\": false,\n        \"logs\": false\n      }\n    }\n  ]\n}\n</code></pre> <p>Notice</p> <p>Not all the fields are required.</p> <p>The required fields are: <code>source.id</code>, <code>session.id</code>, <code>profile.id</code> if exists, and collection of <code>events</code></p> Minimalistic tracker payload could look like this<pre><code>{\n  \"source\": {\n    \"id\": \"f14dc4b1-8dd8-4fc1-bd14-d6823ba7013e\"\n  },\n  \"session\": {\n    \"id\": \"d6823ba7013e-8dd8-4fc1-bd14-f14dc4b1\"\n  },\n  \"events\": [\n    {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"pageTitle\": \"My Page\"\n      }\n    },\n    {\n      \"type\": \"product-in-basket\",\n      \"properties\": {\n        \"product\": \"Adidas sneakers\",\n        \"price\": 34.43\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#custom-times","title":"Custom times","text":"<p>There can be a need to send historical sessions and profile to Tracardi with the old timestamps. This can be done by setting the profile and session metadata.</p>"},{"location":"getting_started/processes/integration/api/#session-default-times","title":"Session Default Times","text":"<p>To override the session timestamps, you can use the session object. Add additional metadata to define the default values that will be used when the session is created. This is particularly useful if you are importing old data or want to pass the <code>create</code> time from your client. <code>Metadata</code> is optional.</p> <p>Note</p> <p>This feature is available from version 0.9.0.</p> Example of track data payload with session times<pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\",\n    \"metadata\": {\n      \"create\": \"2023-01-01 00:00:00\",\n      \"insert\": \"2023-01-01 00:00:01\",\n      \"update\": \"2024-01-01 00:00:01\"\n    }\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\"\n  },\n  \"properties\": {},\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      }\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#profile-default-times","title":"Profile Default Times","text":"<p>To override the profile timestamps, you can use the profile object. Add additional metadata to define the default values that will be used when the profile is created. This is particularly useful if you are importing old data or want to pass the <code>create</code> time from your client. <code>Metadata</code> is optional.</p> <p>Note</p> <p>This feature is available from version 0.9.0.</p> Example of track data payload with profile times<pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\"\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\",\n    \"metadata\": {\n      \"create\": \"2023-01-01 00:00:00\",\n      \"insert\": \"2023-01-01 00:00:01\",\n      \"update\": \"2024-01-01 00:00:01\"\n    }\n  },\n  \"properties\": {},\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      }\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#profile-ids","title":"Profile IDs","text":"<p>Additional profile IDS can be appended to the profile during event consumption. To do so, add <code>IDs</code> as an array of strings to the profile object. <code>Ids</code> are optional.</p> <p>Note</p> <p>This feature is available from version 0.9.0.</p> Example of track data payload with profile ids<pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\"\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\",\n    \"ids\": [\n      \"id1\",\n      \"id2\",\n      \"id3\"\n    ],\n    \"metadata\": {\n      \"create\": \"2023-01-01 00:00:00\",\n      \"insert\": \"2023-01-01 00:00:01\",\n      \"update\": \"2024-01-01 00:00:01\"\n    }\n  },\n  \"properties\": {},\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      }\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#context","title":"Context","text":"<p>Context encompasses supplementary information or data that offers a wider perspective on an event. It includes pertinent details that contribute to a deeper comprehension of the event's surrounding circumstances. There are two types of context, Track Context and Event Context. Track context is defined on the level of Tacker Payload. Event Context is defined inside the event object.</p> Tracker Context that will be saved in Session<pre><code>{\n  \"source\": {\n    \"id\": \"f14dc4b1-8dd8-4fc1-bd14-d6823ba7013e\"\n  },\n  \"session\": {\n    \"id\": \"d6823ba7013e-8dd8-4fc1-bd14-f14dc4b1\"\n  },\n  \"events\": [\n    {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"pageTitle\": \"My Page\"\n      }\n    }\n  ],\n  \"context\": {\n    \"browser\": {\n      \"local\": {\n        \"browser\": {\n          \"userAgent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\"\n        }\n      }\n    },\n    \"location\": {\n      \"country\": {\n        \"code\": \"PL\",\n        \"name\": \"Poland\"\n      },\n      \"city\": \"Warsaw\",\n      \"longitude\": 15.634,\n      \"latitude\": 48.1962,\n      \"zip\": \"3100\"\n    }\n  }\n}\n</code></pre> Event Context that will be saved in Event<pre><code>{\n  \"source\": {\n    \"id\": \"f14dc4b1-8dd8-4fc1-bd14-d6823ba7013e\"\n  },\n  \"session\": {\n    \"id\": \"d6823ba7013e-8dd8-4fc1-bd14-f14dc4b1\"\n  },\n  \"events\": [\n    {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"pageTitle\": \"My Page\"\n      },\n      \"context\": {\n        \"page\": \"http://tracardi.com\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#options","title":"Options","text":"<p>Event options provide additional instructions or directives related to the processing of an event. They can specify how the event should be handled, what actions to take, or what data to return as a result of processing the event. Here are some examples of what can be included as event options:</p> Options<pre><code>{\n  \"source\": {\n    \"id\": \"f14dc4b1-8dd8-4fc1-bd14-d6823ba7013e\"\n  },\n  \"session\": {\n    \"id\": \"d6823ba7013e-8dd8-4fc1-bd14-f14dc4b1\"\n  },\n  \"events\": [\n    {\n      \"type\": \"page-view\",\n      \"properties\": {\n        \"pageTitle\": \"My Page\"\n      }\n    }\n  ],\n  \"options\": {\n    \"saveEvent\": false,\n    \"saveSession\": false,\n    \"debugger\": false\n  }\n}\n</code></pre> <p>Here is the description of the configuration options in a table format:</p> Option Description saveEvent Determines whether the event should be saved or treated as ephemeral. If set to <code>false</code>, the event is processed but not permanently saved. saveSession Specifies whether the session associated with the event should be saved. If set to <code>false</code>, the session data will not be stored for this particular event. debugger Controls the inclusion of debugger information in the event response. If set to <code>false</code>, debugger information will not be returned."},{"location":"getting_started/processes/integration/api/#tracker-payload-event-payload","title":"Tracker Payload, Event Payload","text":"<p>Event payload is the part of Track Payload that has events data:</p> Highlighed Event Payload<pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\"\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\"\n  },\n  \"context\": {\n    // Context data\n  },\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      },\n      \"options\": {\n        // Event options\n      },\n      \"context\": {\n        // Additional context data\n      }\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#event-type","title":"Event type","text":"<p>An event type refers to the specific kind of interaction or activity that is tracked and recorded within the system. It categorizes events based on their nature, such as page views, clicks, form submissions, purchases, or custom-defined actions.</p> <p>Define event type as slug of its name. For example if the event type is <code>Page View</code> set <code>type</code> to <code>page-view</code>.</p>"},{"location":"getting_started/processes/integration/api/#events-default-times","title":"Events Default Times","text":"<p>To send an event, you can populate the attributes described above according to your specific event data. If you wish to override the current insert time, which represents the time of event collection, and instead use a custom time, you can set the <code>time.insert</code> attribute to the desired date and time.</p> <p>The same principle applies to the <code>create</code> and <code>update</code> attributes. If you want to provide custom timestamps for event creation or update, you can set the corresponding values of <code>time.create</code> and <code>time.update</code> to the appropriate dates and times.</p> <p>By customizing the <code>time</code> attributes, you can have more control over the temporal aspects associated with the event, ensuring accurate representation within your event tracking system.</p> Example of track data payload with event times<pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\"\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\"\n  },\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      },\n      \"time\": {\n        \"create\": \"2023-01-01 00:00:00\",\n        \"insert\": \"2023-01-01 00:00:01\",\n        \"update\": \"2024-01-01 00:00:01\"\n      }\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#properties","title":"Properties","text":"<p>Event properties refer to specific attributes or characteristics that provide relevant details about an event. They contain the actual data associated with the event and can vary depending on the nature of the event and the specific requirements of the system or application. Here are some examples of what can be included as event properties:</p> <ol> <li>User information: Information about the user involved in the event, such as user ID, username, email address, or any    other relevant user identifiers.</li> <li>Event parameters: Parameters or values that capture specific aspects of the event, such as quantity, price, duration,    location, or any other measurable or meaningful attributes.</li> <li>Status indicators: Flags or indicators that reflect the status or outcome of the event, such as success, failure,    pending, or in-progress.</li> <li>Metadata: Additional contextual information or metadata that provides further insights into the event, such as event    source, event category, or any custom-defined metadata specific to the application or system.</li> </ol> <p>Event properties serve to enrich the event data, allowing for a more detailed and meaningful representation of the event within the system or application.</p>"},{"location":"getting_started/processes/integration/api/#tracker-response","title":"Tracker response","text":"<p>This is the example of the response from Tracardi after the events were collected.</p> <pre><code>{\n \"task\": [\n  \"fae054ab-fab4-4eaf-8762-f8b71638b043\"\n ],\n \"ux\": [],\n \"response\": {},\n \"events\": [],\n \"profile\": {\n  \"id\": \"60a05b82-0554-48a6-a53c-b759031a8f0b\"\n },\n \"session\": {\n  \"id\": \"4812b132-1c07-4b68-899b-d18b5c24b6e6\"\n },\n \"errors\": [],\n \"warnings\": []\n}\n</code></pre>"},{"location":"getting_started/processes/integration/api/#response-schema-description","title":"Response Schema Description","text":"Key Description Example Value task List containing the Task ID [\"fae054ab-fab4-4eaf-8762-f8b71638b043\"] ux List of JavaScript widgets to include on the page [{\"tag\":\"script\",\"type\":\"text/javascript\",\"content\":[\"\\n  (function(d,t) \"]}] response Response data from workflow (requires synchronous event) {\"data\": \"value\"} events List of events [] profile Profile information {\"id\": \"60a05b82-0554-48a6-a53c-b759031a8f0b\"} session Session information {\"id\": \"4812b132-1c07-4b68-899b-d18b5c24b6e6\"} errors List of errors [\"error message\"] warnings List of warnings [\"warning message\"] <p>Response key can be considered as the output of workflows, which are executed based on the configurations and logic defined within them. These responses from multiple workflows are consolidated into a single response, which can then be further processed, analyzed, or used to trigger subsequent actions.</p> <p>Responses may also contain additional information, such as the response key, which is a defined field that includes the data returned by a specific workflow. The response key helps organize and structure the data collected from different workflows, making it easier to access and utilize in downstream processes.</p>"},{"location":"getting_started/processes/integration/api/#other-information","title":"Other information","text":""},{"location":"getting_started/processes/integration/api/#obtaining-the-profile-id","title":"Obtaining the Profile ID","text":"<p>To obtain the profile ID, the recommended approach is to send the tracker payload without setting the profile ID, and only generate the session ID. Tracardi will then return the generated profile ID, which needs to be saved on the client side. This is how the Tracardi JavaScript snippet works, by saving the profile ID in the browser's localStorage and the session ID in cookies. Please refer to Tracking to understand how tracking works.</p>"},{"location":"getting_started/processes/integration/api/#changing-session-id-while-keeping-profile","title":"Changing Session ID while Keeping Profile","text":"<p>In some cases, the client may want to keep the profile unchanged but change the session ID. To achieve this, the client can provide the profile ID while generating a new session ID. This will result in a new session being created, while the profile remains unchanged, and the system generates a new visit for the user.</p>"},{"location":"getting_started/processes/integration/api/#sending-same-session-id-with-tracking-payloads","title":"Sending Same Session ID with Tracking Payloads","text":"<p>While it is possible to send the same session ID with all the tracking payloads, allowing the system to keep the session and profile unchanged, this practice is not suggested. This is because if a profile is saved with only one visit, it will not be possible to change the visits associated with the profile. It is recommended to generate a new session ID for each visit to ensure accurate tracking and profiling of user behavior.</p>"},{"location":"getting_started/processes/integration/api/#how-to-integrate-tracardi-with-mobile-apps-or-external-systems","title":"How to integrate Tracardi with mobile apps or external systems","text":"<p>Integrating Tracardi with mobile apps or external systems follows a similar process as integrating with a web page, with the only difference being that Tracardi provides a JavaScript snippet for a web page that simplifies the integration. The JavaScript snippet automates the process of calling the track endpoint and saving the Session ID and Profile ID in the browser.</p> <p>However, when integrating with mobile apps or backend systems, the process needs to be done manually. It is crucial to remember that both the Profile ID and Session ID must be saved on the customer's device or backend system for effective tracking.</p> <p>While it may be evident to save the Profile ID and Session ID when integrating with a mobile app, it may not be as apparent when integrating with a PHP application or other server-side applications. In such cases, it is necessary to set a PHPSESSIONID or other relevant token that can be used to track the customer and store the Tracardi Profile ID and Session ID within the defined user session. This ensures that the data collected by Tracardi can be accurately associated with the correct customer profile and used for further personalization or analysis.</p> <p>It is essential to follow these steps diligently when integrating Tracardi with mobile apps or external systems to ensure error-free tracking.</p>"},{"location":"getting_started/processes/integration/api/#errors","title":"Errors","text":""},{"location":"getting_started/processes/integration/api/#response-422-unprocessed-entity","title":"Response - 422 Unprocessed entity","text":"<p>This error occurs when the tracker payload is missing some data. Usually it will happen when you miss required field.</p>"},{"location":"getting_started/processes/integration/api/#response-unauthorized","title":"Response - Unauthorized","text":"<p>This error occurs when the <code>source.id</code> that is sent with payload does not exist in Tracardi.</p>"},{"location":"getting_started/processes/integration/api/#response-headers","title":"Response - Headers","text":"<p>With response there is a <code>x-process-time</code> header thar returns how much time it took to process the request.</p>"},{"location":"getting_started/processes/integration/js/","title":"Javascript integrations","text":"<p>Tracardi provides a JavaScript snippet that allows seamless integration of any webpage with Tracardi for tracking and personalization purposes. </p> <p>It is crucial to first understand the concept of tracker payload and API integrations because the JavaScript snippet is browser code that relies on API integration and the tracker payload schema to send data. </p>"},{"location":"getting_started/processes/integration/js/#integrating-tracardi-with-web-page","title":"Integrating Tracardi with web page.","text":"<p>Follow the steps below to connect and configure the JavaScript snippet on your web page.</p>"},{"location":"getting_started/processes/integration/js/#step-1-connecting-the-javascript-snippet","title":"Step 1: Connecting the JavaScript Snippet","text":"<p>To use the Tracardi JavaScript snippet, you need to create an event source with bridge Rest API. Then click on the event source and select tab <code>Use &amp; Javascript</code>. Then copy the Javascript code displayed in GUI to the header of your web page. Here's an example of the snippet:</p> Example of a Javascript code<pre><code>&lt;script&gt;\n\n    !function(e){\"object\"==typeof exports&amp;&amp;\"undefine...  // (1)\n\n    const options = {\n        tracker: {\n            url: {\n                script: 'http://192.168.1.103:8686/tracker', \n                api: 'http://192.168.1.103:8686'\n            },\n            source: {\n                id: \"&lt;your-event-source-id-HERE&gt;\" // (2)\n            }\n        }\n    }\n&lt;/script&gt;\n</code></pre> <ol> <li>Compiled javascript code must be the first line in the script.</li> <li>You <code>event source id</code> should be copied here. Event source can be found in Inbound traffic in Tracardi GUI.</li> </ol>"},{"location":"getting_started/processes/integration/js/#step-2-sending-events-via-javascript","title":"Step 2: Sending events via Javascript","text":"<p>Events are defined in a separate script. </p> Example of events<pre><code>window.tracker.track(\"purchase-order\", {\"product\": \"Sun glasses - Badoo\", \"price\": 13.45})\nwindow.tracker.track(\"interest\", {\"Eletronics\": [\"Mobile phones\", \"Accessories\"]})\nwindow.tracker.track(\"page-view\",{});\n</code></pre> <p>Events consist of an event type. Event type is any string that describes what happened. In our example we have 3 events: <code>purchase-order</code>, <code>interest</code>, <code>page-view</code>.</p> <p>Caution</p> <p>The code with events must be placed after the configuration code. Otherwise, it will now work.</p> <p>For a detailed description of event trigger function see this page.</p>"},{"location":"getting_started/processes/integration/js/#step-3-refreshing-the-page-and-verifying-the-response","title":"Step 3: Refreshing the Page and Verifying the Response","text":"<p>After refreshing your web page with the JavaScript code, you may notice a response from Tracardi indicating \"Access denied. Invalid source.\" This is because the event source ID was not defined in the tracker.source.id section of the snippet.</p> <pre><code>Headers:\nStatus: 401 Unauthorized\n\nBody:\n{\"detail\": \"Access denied. Invalid source.\"}\n</code></pre> <p>To resolve this, create an event source in Tracardi and replace the string  with the actual event source ID from Tracardi, as shown below: <pre><code>&lt;script&gt;\n    !function(e){\"object\"==typeof exports&amp;&amp;\"undefined\"!=ty... // (3)\n\n    const options = {\n        tracker: {\n            url: {\n                script: 'http://192.168.1.103:8686/tracker', // (2)\n                api: 'http://192.168.1.103:8686'\n            },\n            source: {\n                id: \"ee2db027-46cf-4034-a759-79f1c930f80d\" // (1)\n            }\n        }\n    }\n\n&lt;/script&gt;\n</code></pre> <ol> <li>Correct <code>event source id</code>.</li> <li>Replace IP with the IP of Tracardi API. Please mind the port and correct it as well</li> <li>The code here is truncated for the purpose of more readable documentation.</li> </ol> <p>Please notice that there is also the URL of Tracardi backend server. Please replace the IP e.g. <code>192.168.1.103</code> with the address of your Tracardi server.</p>"},{"location":"getting_started/processes/integration/js/#additional-configuration","title":"Additional configuration","text":""},{"location":"getting_started/processes/integration/js/#configuration-of-event-context-scope","title":"Configuration of event context scope","text":"<p>Tracardi automatically adds a context to the event. The scope of the context can be configured.  Configuration can be extended with context parameter, where you may define the scope of context data.</p> <p>Caution</p> <p>When working with event's context in Tracardi, it's important to understand that the context data refers to all  tracker events within a session, rather than a single event. The context data is saved in the session when it is  created and remains constant throughout the session, as data such as browser type or system used typically  does not change during a visitor's session on a website.</p> <p>However, it's worth noting that some context data, such as the page URL, may change from event to event within a  session. This dynamic data is sent in the event context. Although It is configured on the tracker level it  will be attached to each event.</p> Example of tracker configuration with scope of event context<pre><code>    const options = {\n      tracker: {\n        url: {\n            script: '//localhost:8686/tracker',\n            api: '//localhost:8686'\n        },\n        source: {\n            id: \"3ee63fc6-490a-4fd8-bfb3-bf0c8c8d3387\"\n        },\n        context: {\n            cookies: false,\n            storage: false,\n            browser: true,\n            page: true,\n            screen: true,\n            performance: false,\n            location: false,\n            utm: true\n        }\n    }\n}\n</code></pre> <p>If you omit the context configuration it will be set to the default value:</p> Default Context Values<pre><code>{\n  \"cookies\": false,\n  \"storage\": false,\n  \"screen\": true,\n  \"page\": true,\n  \"browser\": true,\n  \"performance\": false,\n  \"location\": false,\n   \"utm\": true\n}\n</code></pre> <p>By default, the following session context data will be sent to Tracardi:</p> Example<pre><code>{\n  \"context\": {\n    \"time\": {\n      \"local\": \"12/8/2021, 12:50:55 AM\",\n      \"tz\": \"Europe/Warsaw\"\n    },\n    \"browser\": {\n      \"local\": {\n        \"browser\": {\n          \"name\": \"Netscape\",\n          \"engine\": \"Gecko\",\n          \"appVersion\": \"5.0 (X11)\",\n          \"userAgent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:94.0) Gecko/20100101 Firefox/94.0\",\n          \"language\": \"en-US\",\n          \"onLine\": true,\n          \"javaEnabled\": false,\n          \"cookieEnabled\": true\n        },\n        \"device\": {\n          \"platform\": \"Linux x86_64\"\n        }\n      }\n    },\n    \"screen\": {\n      \"local\": {\n        \"width\": 1835,\n        \"height\": 1032,\n        \"innerWidth\": 1835,\n        \"innerHeight\": 928,\n        \"availWidth\": 1835,\n        \"availHeight\": 1013,\n        \"colorDepth\": 24,\n        \"pixelDepth\": 24\n      }\n    }\n  }\n}\n</code></pre> <p>It consists of browser data, screen data and page data. It can be extended with cookies and local storage data. Storage (localStorage) and session data is by default excluded. You can change it by explicitly flagging storage:true in the context configuration.</p> <p>Caution</p> <p>Sending cookies and localStorage data can lead to data explosion in Tracardi database. Each customer may have different cookies and local data that will lead to the 1000 fields per record limit in elastic. This will stop writing new sessions to the system.</p>"},{"location":"getting_started/processes/integration/js/#customer-geo-location","title":"Customer GEO location","text":"<p>By setting the context.location to true, system will try to catch geo location on client side. </p>"},{"location":"getting_started/processes/integration/js/#event-performance-metrics","title":"Event performance metrics","text":"<p>If you set <code>tracker.context.performance</code> to TRUE in tracker context configuration the result from window.performance.getEntriesByType(\" navigation\") will be sent as event context.</p> Example of event performance context<pre><code>{\n  \"context\": {\n    \"performance\": {\n      \"name\": \"http://localhost:63343/analytics-js-tracardi/index.html\",\n      \"entryType\": \"navigation\",\n      \"startTime\": 0,\n      \"duration\": 0,\n      \"initiatorType\": \"navigation\",\n      \"nextHopProtocol\": \"http/1.1\",\n      \"workerStart\": 0,\n      \"redirectStart\": 0,\n      \"redirectEnd\": 0,\n      \"fetchStart\": 20,\n      \"domainLookupStart\": 101,\n      \"domainLookupEnd\": 101,\n      \"connectStart\": 101,\n      \"connectEnd\": 102,\n      \"secureConnectionStart\": 0,\n      \"requestStart\": 102,\n      \"responseStart\": 102,\n      \"responseEnd\": 102,\n      \"transferSize\": 9394,\n      \"encodedBodySize\": 9089,\n      \"decodedBodySize\": 9089,\n      \"serverTiming\": [],\n      \"unloadEventStart\": 106,\n      \"unloadEventEnd\": 107,\n      \"domInteractive\": 158,\n      \"domContentLoadedEventStart\": 160,\n      \"domContentLoadedEventEnd\": 161,\n      \"domComplete\": 0,\n      \"loadEventStart\": 0,\n      \"loadEventEnd\": 0,\n      \"type\": \"reload\",\n      \"redirectCount\": 0\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/integration/js/#event-utm-collection","title":"Event UTM collection","text":""},{"location":"getting_started/processes/integration/js/#what-is-utm","title":"What is UTM?","text":"<p>UTM (Urchin Tracking Module) parameters are used to track the effectiveness of online marketing campaigns across traffic sources and publishing media. They are appended to URLs and help in identifying the source, medium, and campaign name associated with the marketing efforts. Common UTM parameters include:</p> <ul> <li>utm_source: Identifies the source of the traffic (e.g., Google, newsletter).</li> <li>utm_medium: Identifies the medium (e.g., email, CPC).</li> <li>utm_campaign: Identifies the specific campaign (e.g., spring_sale).</li> <li>utm_term: Identifies the paid keywords (used for paid search).</li> <li>utm_content: Differentiates similar content or links within the same ad (e.g., banner, link).</li> </ul>"},{"location":"getting_started/processes/integration/js/#turn-on-utm-collection","title":"Turn on UTM collection","text":"<p>To turn UTM collection you need to configure it in tracker script.</p> Example of tracker configuration with UTM collection<pre><code>    const options = {\n      tracker: {\n        url: {\n            script: '//localhost:8686/tracker',\n            api: '//localhost:8686'\n        },\n        source: {\n            id: \"3ee63fc6-490a-4fd8-bfb3-bf0c8c8d3387\"\n        },\n        context: {\n            utm: true\n        }\n    }\n}\n</code></pre> <p>UTM data will be saved in event and session UTM fields.</p>"},{"location":"getting_started/processes/integration/js/#append-profile-id-to-external-links-tagging-links","title":"Append profile ID to external links (Tagging links)","text":"<p>The tracking script has the capability to include the current profile ID, session ID, and source ID in the URL parameter, allowing for consistent profile ID persistence across domains that utilize the same Tracardi system. It uses Parametrized Links feature to pass the Profile ID across different web sites.</p> <p>Note</p> <p>Please note that default system behaviour without <code>passing of profile ID in Link</code> enabled would be to create a random profile ID   if customer never visited the page before. And later merge the profile if customer provides data that can be used    for this. </p> <p>To enable this functionality, you can add the following code: <code>trackExternalLinks: ['example.com', 'tracardi.com']</code>.  This will automatically update all <code>A.href</code> links on the page  with the <code>__tr_pid</code>, <code>__tr_src</code> parameter, which will contain the current profile ID, source ID respectively, if the A.href URL end with any of the defined domains in <code>trackExternalLinks</code>. In our example it is 'example.com' and ,  'tracardi.com'.</p> Example<pre><code>    const options = {\n      tracker: {\n        url: {\n            script: '//localhost:8686/tracker',\n            api: '//localhost:8686'\n        },\n        source: {\n            id: \"3ee63fc6-490a-4fd8-bfb3-bf0c8c8d3387\"\n        },\n        settings: {\n          trackExternalLinks: ['example.com', 'tracardi.com']\n        }\n    }\n}\n</code></pre> <p>Tracardi recognize these params and saves them in <code>session.context</code> and replaces profile ID with the profile ID referenced in <code>__tr_pid</code></p> <p>Warning</p> <p>Profile must exist in Tracardi to be passed from domain to domain. If profile does not exist then new profile ID will be generated and a Javascript warning will be logged: <code>Referred Tracardi Profile Id {referred_profile_id} is invalid</code>.</p> <p>Notice</p> <p>This feature is available from version 0.8.1 up.</p> <pre><code>{\n  \"context\": {\n    \"tracardi\": {\n      \"pass\": {\n        \"profile\": \"0adfd4c8-36eb-40cd-9350-5df37706286a\",\n        \"source\": \"d15aaf64-90ff-4c72-9d93-e7851c326127\",\n        \"session\": \"9cb9a69b-e657-47dc-85f6-791ebc4b4822\"\n      }\n    }\n  }\n}\n</code></pre> <p>Where possible system will use this information to merge profiles between devices and browsers. </p> <p>Tip</p> <p>The script utilizes an underlying technique that involves creating a POST payload for the tracker, with  parameters such as <code>__tr_pid</code>, <code>__tr_src</code>. The payload contains data sent in a specific context,  formatted as follows in JSON:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"d15aaf64-90ff-4c72-9d93-e7851c326127\"\n  },\n  \"context\": {\n    \"tracardi\": {\n      \"pass\": {\n        \"profile\": \"0adfd4c8-36eb-40cd-9350-5df37706286a\",\n        \"source\": \"d15aaf64-90ff-4c72-9d93-e7851c326127\"\n      }\n    }\n  },\n  \"profile\": {\n    \"id\": \"0adfd4c8-36eb-40cd-9350-5df37706286a\"\n  },\n  \"session\": {\n    \"id\": \"3a18978e-1d74-4382-8e50-f0b8ae3c2d55\"\n  },\n  \"options\": {},\n  \"events\": [ ... ]\n}\n</code></pre> <p>This technique can be used also to reference profile ID from browser to device.  However you will need a find a way to pass the refered profile ID, session ID, and source ID to your mobile  device when the app is opened, and the first <code>/track</code> payload should include the refered IDs. The same  will also work with other systems. </p> <p>To disable params <code>__tr_pid</code>, <code>__tr_src</code> and turn off session context, set <code>tracardiPass</code> to <code>false</code> in  tracker context:</p> Example<pre><code>    const options = {\n      tracker: {\n        url: {\n            script: '//localhost:8686/tracker',\n            api: '//localhost:8686'\n        },\n        source: {\n            id: \"3ee63fc6-490a-4fd8-bfb3-bf0c8c8d3387\"\n        },\n        context: {\n            tracardiPass: false\n        }\n    }\n}\n</code></pre>"},{"location":"getting_started/processes/integration/js/#respect-do-not-track-dnt-browser-setting","title":"Respect Do Not Track (DNT) browser setting","text":"<p>Do Not Track (DNT) is a web browser setting that adds a signal to the browser, telling websites that the user don\u2019t want to be tracked. By 2011, DNT had been adopted by all the major browsers, but it\u2019s not enforceable. That means its default value is set to track the user.</p> <p>You can respect the browser setting and do not to track the user. If you decide to do this Tracardi will not load the tracking script if the user sets DNT. To respect the DNT set <code>respectDoNotTrack: true</code> in settings section of tracker options.</p> Example<pre><code>    const options = {\n      tracker: {\n        url: {\n            script: '//localhost:8686/tracker',\n            api: '//localhost:8686'\n        },\n        source: {\n            id: \"3ee63fc6-490a-4fd8-bfb3-bf0c8c8d3387\"\n        },\n        settings: {\n          respectDoNotTrack: true\n        }\n    }\n}\n</code></pre> <p>If the <code>respectDoNotTrack</code> is missing in the settings than Tracardi sets default setting and loads tracking script.</p>"},{"location":"getting_started/processes/integration/js/#auto-events","title":"Auto Events","text":"<p>Auto events and triggers provide a simple approach to managing event handling in web pages. This documentation outlines the benefits of using auto events, describes how they are configured, and provides guidance on integrating triggers with HTML elements.</p> <p>At a high level, the primary benefit of using auto events is the centralization of event and trigger definitions. Instead of scattering event handling logic throughout the page, auto events allow for the consolidation of these definitions in one place. This results in improved code organization, readability, and maintainability.</p>"},{"location":"getting_started/processes/integration/js/#key-concepts","title":"Key Concepts","text":"<ol> <li>Auto Events - these events are triggered automatically upon page load.</li> <li>Auto Triggers - these triggers are activated in response to user interactions with the page.</li> </ol>"},{"location":"getting_started/processes/integration/js/#configuration","title":"Configuration","text":"<p>Auto events and triggers are configured using a structured format.</p> <p>Following is an example configuration:</p> Configuration Example<pre><code>const options = {\n    tracker: {\n        url: {\n            script: 'http://192.168.1.103:8686/tracker', \n            api: 'http://192.168.1.103:8686'\n        },\n        source: {\n            id: \"&lt;your-event-source-id-HERE&gt;\"\n        },\n        auto: { // (1)\n                events: [\n                        [\"increase-interest\", {\"interest\": \"laptops\", \"value\": 1}],\n                        [\"increase-interest\", {\"interest\": \"systems\", \"value\": 2}],\n                        [\"page-view\", {\"category\": \"laptops\"}]\n                ],\n                triggers: [\n                        {tag:\"product\", trigger:'onVisible', data: {event: 'image-viewed'}},\n                        {tag:\"title\", trigger:'onTextSelect', data: {event: 'text-selected'}\n                ]\n        }\n\n}\n</code></pre> <p>Note:</p> <ul> <li>(1) - Optional <code>auto</code> configuration extends the track options.</li> </ul>"},{"location":"getting_started/processes/integration/js/#usage-with-triggers-and-html-elements","title":"Usage with Triggers and HTML Elements","text":"<p>In addition to configuring auto events and triggers in your JavaScript code, you can integrate them with HTML elements using the data-tracardi-tag attribute.</p> <p>This allows you to specify which elements on the page should trigger events based on user interactions.</p>"},{"location":"getting_started/processes/integration/js/#steps-to-implement","title":"Steps to Implement:","text":""},{"location":"getting_started/processes/integration/js/#1-define-triggers","title":"1 - Define Triggers:","text":"<p>Configure auto triggers in your JavaScript code as described in the previous section.</p>"},{"location":"getting_started/processes/integration/js/#2-add-data-tracardi-tag-attribute","title":"2 - Add data-tracardi-tag Attribute:","text":"<p>Identify the HTML elements on your page that should trigger events based on user interactions.</p> <p>Add the data-tracardi-tag attribute to these elements and assign a value corresponding to the desired trigger tag defined in your JavaScript configuration.</p> Example<pre><code>&lt;div data-tracardi-tag=\"product\"&gt; &lt;!-- Content of the div --&gt; &lt;/div&gt;\n</code></pre>"},{"location":"getting_started/processes/integration/js/#3-trigger-events","title":"3 - Trigger Events:","text":"<p>When the specified user interaction or condition associated with the trigger occurs on the tagged HTML element, the corresponding event defined in your JavaScript configuration will be triggered.</p>"},{"location":"getting_started/processes/integration/js/#notes","title":"Notes:","text":"<ol> <li>The value assigned to the data-tracardi-tag attribute should match the tag property specified in your auto trigger    configuration.</li> <li>You can customize the data-tracardi-tag value based on your application's specific requirements and naming    conventions.</li> <li>By integrating triggers with HTML elements using the data-tracardi-tag attribute, you can easily specify which    elements should activate events based on user interactions, enabling flexible and targeted event tracking on your web    pages.</li> </ol>"},{"location":"getting_started/processes/integration/js/advanced/","title":"Advanced configurations","text":""},{"location":"getting_started/processes/integration/js/advanced/#forcing-profile-id","title":"Forcing Profile ID","text":"<p>Sometimes, your backend system might need to send a unique Profile ID to Tracardi. This can happen when your backend system is working and needs to use that ID as the profile ID for Tracardi (e.g. PHPSESSID is used to store the profile ID). This is helpful if your backend system already knows the profile ID and you want to share it with Tracardi. To do this, you need to turn on the option for a fixed ID in the data collection settings, and then add the profile ID into the tracking settings.</p> <p>Here's an example:</p> Example<pre><code>&lt;script&gt;\n\n    !function(e){\"object\"==typeof exports&amp;&amp;\"undefine...  \n\n    const options = {\n        tracker: {\n            url: {\n                script: 'http://192.168.1.103:8686/tracker', \n                api: 'http://192.168.1.103:8686'\n            },\n            source: {\n                id: \"&lt;your-event-source-id-HERE&gt;\" \n            },\n            profile: {\n                id: \"&lt;your-static-profile-id-HERE&gt;\" \n            }\n        }\n    }\n&lt;/script&gt;\n</code></pre> <p>Notice</p> <p>It's important to note that this will send the provided profile ID regardless of whether a profile ID is already stored in the browser's local storage. If event source si not configured to allow static profile ID then System will try to load profile with provided ID - it will most probably fail and then it will generate the random ID. Please do not use this feature with events sources that has disabled static profile processing in events source. </p> <p>Warning</p> <p>Please be aware that sending a profile ID that's easy to guess can be a security risk. Attackers can potentially guess the ID and try to corrupt its data. Always use IDs like UUID4 to ensure security.</p> <p>Notice</p> <p>This feature is available from version 0.8.1 up.</p>"},{"location":"getting_started/processes/integration/js/advanced/#capturing-tracker-response","title":"Capturing Tracker Response","text":"<p>Tracardi allows you to capture the response from event collector, which can be useful for customizing page content based on customer segments or utilizing data returned from workflows. In the provided example, the event response is captured using the window.onTracardiReady event and accessed through the context.response object. For example:</p> Example<pre><code> // Change page if has response custom.text\n window.onTracardiReady.bind( ({tracker, helpers, context, config}) =&gt; {\n     if(context?.response?.custom?.text) {\n         const customText = document.getElementById('custom')\n         customText.innerText = context?.response?.custom?.text\n     }\n })\n</code></pre> <p>In the above example, the context.response.custom.text value is accessed from the response and used to update the content of an HTML element with the id attribute of 'custom'. This allows you to dynamically change the page content based on the data returned from Tracardi workflows.</p>"},{"location":"getting_started/processes/integration/js/advanced/#binding-page-elements","title":"Binding Page Elements","text":"<p>You can also bind events to page elements. To do that you will need to be sure that the page loads and every element of the page is accessible.</p> <p>To do that bind the function to <code>window.onTracardiReady</code> property.</p> Example<pre><code>window.onTracardiReady.bind( ({helpers, context, config, tracker}) =&gt; {\n      // Code that binds events.\n    }\n});\n</code></pre> <p>The whole configuration should look like this.</p> Example<pre><code>&lt;script&gt;\n        !function(e){\"object\"==typeof exports&amp;&amp;\"undefined\\...\n\n        window.onTracardiReady.bind( ({helpers, context, config, tracker}) =&gt; {\n              // Code that binds events.\n            }\n        });\n\n        const options = {\n            tracker: {\n                url: {\n                    script: 'http://192.168.1.103:8686/tracker',\n                    api: 'http://192.168.1.103:8686'\n                },\n                source: {\n                    id: \"ee2db027-46cf-4034-a759-79f1c930f80d\"\n                }\n            }\n        }\n\n  &lt;/script&gt;\n</code></pre> <p>The above example will run on every page after the events are triggered. It will not run if TRACARDI did not respond.</p> <p>The function have the following parameters.</p> <ul> <li>helpers - this is a reference to class that will allow you to raise another events</li> <li>context has the response from Tracardi to you initial events. It will have profile data, and if configured debug   information.</li> <li>config - it is the tracker config as defined in options</li> <li>tracker - it is tracker object.</li> </ul>"},{"location":"getting_started/processes/integration/js/advanced/#ontracardiready-triggered-on-selected-page","title":"OnTracardiReady triggered on selected page","text":"<p>You can bind functions to <code>windows.OnTracardiReady</code> on selected pages together with track events. Then it will be executed only on selected pages.</p> <pre><code>window.tracker.track(\"page-view\",{}); // (1)\nwindow.onTracardiReady = ({tracker, helpers, context, config}) =&gt; {\n    // Code\n}\n</code></pre> <ol> <li>Set tracks first. Then bind a function.</li> </ol>"},{"location":"getting_started/processes/integration/js/advanced/#binding-events-to-page-elements","title":"Binding events to page elements","text":"<p>Then you can write a code that binds for example onClick event on a button to tracardi event.</p> <p>This is the example code that you can bind to <code>window.onTracardiReady</code></p> Example<pre><code>({helpers, context}) =&gt; {\n    const btn0 = document.querySelector('#button')\n\n    helpers.onClick(btn0, async ()=&gt; {\n        const response = await helpers.track(\"page-view\", {\"page\": \"hello\"});\n\n        if(response) {\n            const responseToCustomEvent = document.getElementById('response-to-custom-event');\n            responseToCustomEvent.innerText = JSON.stringify(response.data, null, \" \");\n            responseToCustomEvent.style.display = \"block\"\n        }\n    });\n}\n</code></pre> <p>It looks for the element with id=\"button\"</p> Example<pre><code>const btn0 = document.querySelector('#button')\n</code></pre> <p>Then using helpers binds onClick on that element to function:</p> Example<pre><code>async ()=&gt; {\n        // Send event to tracardi\n        const response = await helpers.track(\"page-view\", {\"page\": \"hello\"});\n\n        if(response) {\n            const responseToCustomEvent = document.getElementById('response-to-custom-event');\n            responseToCustomEvent.innerText = JSON.stringify(response.data, null, \" \");\n            responseToCustomEvent.style.display = \"block\"\n        }\n    }\n</code></pre> <p>Inside the function we send the event to Tracardi:</p> Example<pre><code>const response = await helpers.track(\"page-view\", {\"page\": \"hello\"});\n</code></pre> <p>And on response we make a string from JSON response and bind it as innerText of element with id='response-to-custom-event'</p>"},{"location":"getting_started/processes/integration/js/advanced/#wrap-up","title":"Wrap up","text":"<p>The whole configuration looks like this:</p> Whole code<pre><code>&lt;script&gt;\n\n    // Compiled code must be always in the first line\n\n    !function(e){\"object\"==typeof exports&amp;&amp;\"undefined\"!=typeof module?module.exports=e():\"function\"==typeof define&amp;&amp;define.amd?define([],e):(\"undefined\"!=typeo...\n\n    // Configure tracker\n\n    const options = {\n        tracker: {\n            url: {\n                script: 'http://192.168.1.103:8686/tracker',\n                api: 'http://192.168.1.103:8686'\n            },\n            source: {\n                id: \"ee2db027-46cf-4034-a759-79f1c930f80d\"\n            }\n        }\n    }\n\n    // Bind some function when TRACARDI responds\n\n    window.onTracardiReady.bind(({helpers, context}) =&gt; {\n        const btn0 = document.querySelector('#button')\n\n        helpers.onClick(btn0, async ()=&gt; {\n            const response = await helpers.track(\"page-view\", {\"page\": \"hello\"});\n\n            if(response) {\n                const responseToCustomEvent = document.getElementById('response-to-custom-event');\n                responseToCustomEvent.innerText = JSON.stringify(response.data, null, \" \");\n                responseToCustomEvent.style.display = \"block\"\n            }\n        });\n    });\n\n&lt;/script&gt;\n</code></pre>"},{"location":"getting_started/processes/integration/js/advanced/#tracardi-helpers","title":"Tracardi helpers","text":"<p>You probably noticed that we use helpers to bind events. We used onClick method to bind to click event. You might need to bind to other than click event. To do that use addEventListener:</p> Example<pre><code>const btn0 = document.querySelector('#button')                 \nhelpers.addListener(btn0, 'mouseover', async ()=&gt; {\n    // Code\n});\n</code></pre> <p>Helpers also have track method that let you send custom event to Tracardi at any time.</p> <p>This is how you can use it:</p> Example<pre><code>const response = await helpers.track(\"new-page-view\", {\"page\": \"hello\"});\n</code></pre>"},{"location":"getting_started/processes/integration/js/event_trigger/","title":"Event Trigger","text":"<p>The <code>window.tracker.track</code> function in Tracardi is a JavaScript call used to send event data from your web page to the Tracardi server. This function is part of the Tracardi JavaScript integration snippet and allows you to track various user interactions on your website. Here\u2019s a detailed description of the function and its parameters:</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#syntax","title":"Syntax","text":"<pre><code>window.tracker.track(eventType, eventProperties, options);\n</code></pre>"},{"location":"getting_started/processes/integration/js/event_trigger/#parameters","title":"Parameters","text":"<ol> <li><code>eventType</code> (string): The type of event you want to track. This is a mandatory parameter and should be a string    representing the name of the event.</li> </ol> <p>Example: <code>\"page-view\"</code>, <code>\"purchase-order\"</code>, <code>\"button-click\"</code>, etc.</p> <ol> <li><code>eventProperties</code> (object): An object containing key-value pairs that represent the properties of the event. This    parameter is optional but typically used to provide additional context or data about the event.</li> </ol> <p>Example: <pre><code>{\n  \"product\": \"Sun glasses\",\n  \"price\": 13.45,\n  \"category\": \"Accessories\"\n}\n</code></pre></p> <ol> <li><code>options</code> (object): An optional object that can include additional settings or metadata for the event. This can    include properties such as <code>profile</code>, <code>session</code>, or other tracking options.</li> </ol> <p>Example: <pre><code>{\n  \"fire\": true,\n  \"context\": { \"type\": \"purchase\"}\n}\n</code></pre></p>"},{"location":"getting_started/processes/integration/js/event_trigger/#detailed-examples","title":"Detailed Examples","text":"Tracking a simple page view event<pre><code>window.tracker.track(\"page-view\", {\n  \"url\": window.location.href,\n  \"title\": document.title\n});\n</code></pre> <p>In this example:</p> <ul> <li><code>\"page-view\"</code> is the event type.</li> <li>The event properties include the current page URL and the document title.</li> </ul> Tracking a purchase order with additional properties<pre><code>window.tracker.track(\"purchase-order\", {\n  \"product\": \"Sun glasses\",\n  \"price\": 13.45,\n  \"category\": \"Accessories\"\n});\n</code></pre> <p>In this example:</p> <ul> <li><code>\"purchase-order\"</code> is the event type.</li> <li>The event properties include product details such as name, price, and category.</li> </ul> Using Options for Profile and Immediate Event Sending<pre><code>window.tracker.track(\"button-click\", {\n  \"button-id\": \"subscribe-button\",\n  \"button-text\": \"Subscribe Now\"\n}, {\n  \"fire\": true\n});\n</code></pre> <p>In this example:</p> <ul> <li><code>\"button-click\"</code> is the event type.</li> <li>The event properties include the button ID and text.</li> <li>The <code>options</code> object includes a specific profile ID and the <code>fire</code> property set to <code>true</code>, indicating the event should   be sent immediately.</li> </ul>"},{"location":"getting_started/processes/integration/js/event_trigger/#parts-of-events","title":"Parts of Events","text":""},{"location":"getting_started/processes/integration/js/event_trigger/#event-type","title":"Event type","text":"<p>Event type is a crucial aspect of defining events in Tracardi. It refers to the name that distinguishes events from each other. For example, a <code>purchase-order</code> event provides information about an order, while a <code>page-view</code> event signifies a viewed page. There are different event types in Tracardi please refer to event types for more information.</p> <p>Defining an appropriate event type is essential to ensure proper categorization and processing of events within Tracardi. It allows you to effectively organize and analyze event data based on their type.</p> <p>Importance</p> <p>Event type serves as a unique identifier for events and helps differentiate them from one another. It enables you to   effectively manage and process events, as different events may require different handling or processing logic based on   their type.</p> <p>When defining an event in Tracardi, you need to specify an event type that accurately represents the nature of the   event. For instance, if you are tracking purchase orders, you can define the event type as \"purchase-order\". Similarly,   if you are tracking page views, you can define the event type as \"page-view\".</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#events-properties","title":"Events properties","text":"<p>In Tracardi, each event can have additional data that provides detailed information about the event. For example, consider the event \"interest\" which sends data in the format {\"Electronics\": [\"Mobile phones\", \"Accessories\"]}.</p> <p>Tracardi collects all events with their respective data and sends them as a single request to the Tracardi tracker endpoint. This request is made when the web page is fully loaded, ensuring that all events and their associated data are captured accurately.</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#event-options","title":"Event options","text":"<p>Event options in Tracardi allow you to define the behavior of events and add contextual information associated with an event. When events are triggered using the Tracardi JavaScript snippet, they automatically include default context information, such as browser information and metadata, to provide additional details about the event. To understand how the browser events are collected read this.</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#context","title":"Context","text":"<p>To add context add <code>context</code> kay and include it in configuration part (third parameter) of the <code>window.tracker.track</code></p> Example<pre><code>window.tracker.track(\n   \"page-view\",\n   {},\n   {\n    \"context\": {\"tag\": \"search\"}\n   }\n);\n</code></pre>"},{"location":"getting_started/processes/integration/js/event_trigger/#default-event-context-in-javascript-snippet","title":"Default Event Context in JavaScript Snippet","text":"<p>Tracardi Javascript Snippet adds default event context. It includes the following information:</p> Example Context<pre><code>{\n  \"page\": {\n    \"url\": \"&lt;page-url&gt;\",\n    \"path\": \"&lt;page-path&gt;\",\n    \"hash\": \"&lt;page-hash&gt;\",\n    \"title\": \"&lt;page-title&gt;\",\n    \"referer\": {\n      \"host\": null,\n      \"query\": null\n    },\n    \"history\": {\n      \"length\": 10\n    }\n  },\n  \"ip\": \"127.0.0.1\"\n}\n</code></pre> <p>The event context includes details about the current page, such as its URL, path, hash, title, referer information (host and query), and browsing history length. It also includes the IP address of the user.</p> <p>Tip</p> <p>When working with Tracardi, you have the option to configure whether or not to include page data in the context of  each event. This configuration is done at the tracker level and can be customized according to your requirements.  By adjusting the tracker context configuration, you can easily control whether or not page data is sent along with  each event, providing you with flexibility and control over the data captured and processed.</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#customizing-event-context","title":"Customizing Event Context","text":"<p>You can add additional context information to events by including a \"context\" key in the options when triggering events using the Tracardi JavaScript snippet. For example:</p> Example<pre><code>window.tracker.track(\n   \"page-view\",\n   {},\n   {\n    \"context\": {\"tag\": \"search\"}\n   }\n);\n</code></pre> <p>In the example above, a custom context object with a \"tag\" key and value \"search\" is added to the event options. This allows you to include additional information that is relevant to your specific use case.</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#options","title":"Options","text":""},{"location":"getting_started/processes/integration/js/event_trigger/#immediate-triggering-of-event","title":"Immediate triggering of event","text":"<p>By default, tracking events are accumulated in a set of tracks and dispatched once the page loading completes. The timing of event dispatch is crucial and depends on how the event is sent using your JavaScript code. Typically, <code>window.tracker.track</code> is used for sending events, and it's vital to configure these events to fire instantly, particularly if they're collected post page load. To achieve this, you should add the <code>fire: true</code> option in your <code>window.tracker.track</code> call. This specific option commands the event to trigger immediately, without waiting for the entire page to load or after the page has loaded. Incorporating <code>fire: true</code> ensures the event is transmitted to Tracardi as soon as the function executes.</p> Example<pre><code>window.tracker.track(\"purchase-order\", {}, {\n\"fire\": true\n});\n</code></pre>"},{"location":"getting_started/processes/integration/js/event_trigger/#beacon-tracks","title":"Beacon tracks","text":"<p>Beacon events in Tracardi are events that are sent even if the customer leaves the page. These events allow you to track user interactions that may occur after a user has navigated away from a page, providing valuable insights into user behavior.</p> <p>To configure a beacon event in Tracardi, you can add the asBeacon: true option to the track configuration. This indicates that the event should be sent as a beacon event.</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#example-of-beacon-event","title":"# Example of Beacon Event","text":"<p>Here is an example of how to configure a beacon event in Tracardi:</p> Example of Beacon Event<pre><code>window.tracker.track(\"out-link-clicked\", {}, {\n   \"fire\": true, \n   asBeacon: true\n});\n</code></pre> <p>In the above example, the asBeacon option is set to true, indicating that the \"out-link-clicked\" event should be sent as a beacon event, even if the customer leaves the page.</p> <p>Beacon events can be useful in scenarios where you want to track user interactions that may occur when user leaves the webpage, such as form submissions, redirect button clicks, or other events that may happen after the user has navigated away from the page.</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#triggering-on-user-actions","title":"Triggering on user actions","text":""},{"location":"getting_started/processes/integration/js/event_trigger/#sending-event-on-demand","title":"Sending event on demand","text":"<p>Tracardi offers the flexibility to send events immediately when the fire parameter is set to true, enabling real-time event triggering and ensuring that data is captured and processed instantly. By default, events are queued and sent when the web page is fully rendered, which is beneficial for consolidating events and sending them as a single request. However, there are scenarios where sending events immediately upon certain actions, such as button clicks, is necessary. Sending Events in Real-Time</p> <p>To send events in real-time, simply set the <code>fire</code> parameter to <code>true</code> when making API requests or using the Tracardi JavaScript snippet on your web page. This will bypass the event queue and send the events without any delay.</p> <p>This feature is particularly useful in scenarios where real-time data processing is critical, such as tracking user interactions, capturing user behavior, and implementing dynamic marketing strategies.</p>"},{"location":"getting_started/processes/integration/js/event_trigger/#example-breaking-the-event-queue","title":"Example: Breaking the Event Queue","text":"<p>In some cases, you may need to break the event queue and trigger an event immediately upon a certain event type. You can do this by setting the fire parameter to true in your JavaScript code, as shown in the example below:</p> Example where we break the event queue<pre><code>window.tracker.track(\"purchase-order\", {\"product\": \"Sun glasses - Badoo\", \"price\": 13.45})\nwindow.tracker.track(\"interest\", {\"Eletronics\": [\"Mobile phones\", \"Accessories\"]}, {\"fire\": true}) //(1)\nwindow.tracker.track(\"page-view\",{});\n</code></pre>"},{"location":"getting_started/processes/integration/js/event_trigger/#binding-directly-to-page-elements","title":"Binding directly to Page Elements","text":"<p>You can also bind events directly to page elements, such as buttons, using JavaScript code. However, please note that in this case, you may not have access to response data, such as profile ID, etc. The example below shows how you can add an onClick event to a button that sends an event when clicked:</p> <pre><code>&lt;button onClick=\"testClick()\"&gt;Test click&lt;/button&gt;\n</code></pre> <p>Where the testClick function sends an event.</p> Example<pre><code>&lt;script&gt;\n    function testClick() {\n       window.tracker.track(\"page-view\", {\"view\": 1});\n    }\n&lt;/script&gt;\n</code></pre> <p>Please note that in this case, the event is recorded in the console but not sent to Tracardi by default.</p> <pre><code>[Tracker] Event track \nObject { type: \"track\", event: \"page-view\", properties: {\u2026}, options: {}, userId: null, anonymousId: \"642aa4a6-9a48-4c08-8fd5-f0772415c824\", meta: {\u2026} }\n</code></pre> <p>To trigger the event and send it to Tracardi immediately, you can add the <code>fire</code> attribute with a value of <code>true</code> as a parameter to the window.tracker.track function, as shown in the example below:</p> Example<pre><code>&lt;script&gt;\n    function testClick() {\n       window.tracker.track(\"page-view\", {\"view\": 1}, {\"fire\": true}); // (1)\n    }\n&lt;/script&gt;\n</code></pre> <ol> <li>This event will fire immediately.</li> </ol> <p>The event \"interest\" will be sent immediately, because of <code>{\"fire\": true}</code>.</p>"},{"location":"getting_started/processes/integration/js/general/","title":"Processing events from browser","text":"<p>In Tracardi, browser events are processed in two main stages: the browser stage (split into Stage 1 and Stage 2) and server processing. Here\u2019s a breakdown of each stage:</p>"},{"location":"getting_started/processes/integration/js/general/#browser-stage-1-page-load-and-initial-event-collection","title":"Browser Stage 1: Page Load and Initial Event Collection","text":"<ol> <li> <p>Page Rendering: During the first stage, when the page is loading, the browser reads and renders all elements. At    this point, the page is not yet visible to the user.</p> </li> <li> <p>Event Collection: As the browser parses the page, it collects events using the command:    <pre><code>window.tracker.track(&lt;event-type&gt;, &lt;properties&gt;, {})\n</code></pre>    If there are multiple events on the page, they are stored in memory but not yet sent to Tracardi.</p> </li> <li> <p>Batch Sending: Once the page loading is completed, the collected events are sent all at once to Tracardi through    a single API call. This batching helps reduce the number of network requests and enhances performance.</p> </li> <li> <p>JavaScript Snippet: Tracardi uses a JavaScript snippet embedded within the web page to gather these events. This    snippet tracks user interactions and transmits them to the Tracardi server asynchronously.</p> </li> <li> <p>Limitation: The default behavior in this stage means events are not fired in a specific order, and real-time    event transmission (e.g., clicks or mouse hovers) requires a different approach, handled in Stage 2.</p> </li> </ol>"},{"location":"getting_started/processes/integration/js/general/#browser-stage-2-real-time-event-collection","title":"Browser Stage 2: Real-Time Event Collection","text":"<ol> <li> <p>Dynamic Events: After the page has loaded, sending an event using:    <pre><code>window.tracker.track(&lt;event-type&gt;, &lt;properties&gt;, {})\n</code></pre>    no longer automatically triggers an event. The trigger in Stage 1 was the page load itself, so now, events such as    clicks, scrolls, or mouseovers must use the \"fire: true\" option to ensure they are sent immediately:    <pre><code>window.tracker.track(&lt;event-type&gt;, &lt;properties&gt;, {\"fire\": true})\n</code></pre></p> </li> <li> <p>Immediate Firing: Setting <code>\"fire\": true</code> in the track command ensures that events are dispatched immediately    without waiting for the page to reload.</p> </li> </ol>"},{"location":"getting_started/processes/integration/js/general/#server-processing-of-events","title":"Server Processing of Events","text":"<ol> <li> <p>Open Source vs. Commercial: The processing of events on the server differs between the open-source and commercial    versions of Tracardi:</p> <ul> <li>Open Source: Processes all event stages one after another synchronously.</li> <li>Commercial Version: Processes all stages in parallel. The workflow processing is detached from the collection   process, which means no responses are sent back to the browser by default.</li> </ul> </li> <li> <p>Synchronous Processing (Optional): By default, the commercial version processes events asynchronously. However,    if you need a synchronous response (e.g., to return data or a widget to the browser), you can use:    <pre><code>window.tracker.track(&lt;event-type&gt;, &lt;properties&gt;, {\"async\": false})\n</code></pre>    This setting requires the server to complete event processing before responding.</p> </li> </ol> <p>This comprehensive structure allows Tracardi to efficiently collect, process, and respond to browser events, offering flexibility for both initial data collection and real-time user interactions.</p>"},{"location":"getting_started/processes/integration/js/response/","title":"Event response","text":"<p>Event response in Tracardi refers to the data that is sent back from the server after processing an event. This response typically includes information about the current profile ID and may also contain additional data based on the configurations and logic defined within workflows. </p>"},{"location":"getting_started/processes/integration/js/response/#structure-of-event-response","title":"Structure of Event Response","text":"<p>Event responses in Tracardi are structured in JSON format and contain various keys and values. The response typically includes information related to different aspects of the workflow, such as saved events, errors, IDs, and types. For example, in the provided example response:</p> <pre><code>{\n  \"response\": {\n    \"data\": [\"a\", \"b\"]\n  },\n  \"ux\": {},\n  \"profile\": {\n    \"id\": \"0d2d9dc5-0d60-471e-956f-8766dcb8aba2\"\n  }\n}\n</code></pre> <p>The above response includes information about segments, profile ID, etc. </p> <p>Tracardi provides you with the flexibility to configure response data within each event type workflow. This means that you can define what data should be included in the response generated by a specific workflow, which is bound to a defined event type and its properties. The response data can be structured and organized using response keys, such as <code>segments</code>, which are defined fields that contain the data returned by a workflow and can be copied from a profile, for example.</p> <p>By configuring response data in your event type workflows, you can specify the data that should be included in the response generated by that particular workflow. This allows you to return and data captured and processed in Tracardi based on your specific requirements and business needs. You can define the response keys that should be included in the response, which can be used in downstream processes for further analysis, actions, and decision-making  (e.g. content personalisation).</p>"},{"location":"getting_started/processes/integration/param/","title":"Parametrized URL (Cross-domain profile linking)","text":"<p>A parameterized link in Tracardi is a URL that contains specific parameters designed to track and identify user interactions and collect data effectively. These parameters help in associating the link click with a specific user profile, session, or other relevant information.</p>"},{"location":"getting_started/processes/integration/param/#key-concepts-of-parameterized-links","title":"Key Concepts of Parameterized Links","text":"<ol> <li>Profile ID (<code>__tr_pid</code>): This parameter carries the unique identifier of a user profile. When a user clicks the    link, the profile ID is used to associate the interaction with the correct profile in Tracardi.</li> <li>Source ID (<code>__tr_src</code>): This parameter identifies the source of the event. It is used to understand where the    traffic is coming from (e.g., a specific campaign, email, or ad).</li> <li>Session ID (<code>__tr_sid</code>): This parameter can be used to maintain session continuity and link interactions within    the same session.</li> </ol>"},{"location":"getting_started/processes/integration/param/#creating-a-parameterized-link","title":"Creating a Parameterized Link","text":"<p>To create a parameterized link, you need to append the necessary parameters to your URL. Here\u2019s a step-by-step guide:</p>"},{"location":"getting_started/processes/integration/param/#step-1-construct-the-parameterized-link","title":"Step 1: Construct the Parameterized Link","text":"<p>Include the profile ID, source ID, and optionally, the session ID in your URL.</p> <p>Example URL:</p> <pre><code>http://example.com/landing-page?__tr_pid=&lt;profile-id&gt;&amp;__tr_src=&lt;source-id&gt;&amp;__tr_sid=&lt;session-id&gt;\n</code></pre> <ul> <li>Replace <code>&lt;profile-id&gt;</code> with the actual profile ID.</li> <li>Replace <code>&lt;source-id&gt;</code> with the actual source ID.</li> <li>Replace <code>&lt;session-id&gt;</code> with the actual session ID (if necessary).</li> </ul> <p>Example:</p> <pre><code>http://example.com/landing-page?__tr_pid=12345&amp;__tr_src=email_campaign&amp;__tr_sid=67890\n</code></pre> <p>Tip</p> <p>If tracardi javascript snippet is placed on the source and destination page adding parameters can be automated.    See Append profile ID to external links.</p>"},{"location":"getting_started/processes/integration/param/#step-2-use-the-parameterized-link-in-your-campaigns","title":"Step 2: Use the Parameterized Link in Your Campaigns","text":"<p>Embed this URL in your marketing campaigns, such as email newsletters, ads, or social media posts. When users click on these links, Tracardi will track their interactions using the provided parameters.</p>"},{"location":"getting_started/processes/integration/param/#step-3-add-javascript-snippet-on-the-web-page","title":"Step 3: Add JavaScript Snippet on the Web Page","text":"<p>Ensure that Tracardi is configured to recognize and process these parameters:</p> <ol> <li>Include JavaScript Integration on the target web page:<ul> <li>Embed the Tracardi tracking script on your landing page. This script will capture the parameters and associate the   interaction with the correct profile and session.</li> </ul> </li> </ol> <p>Note</p> <p>The destination web site that the params will be sent must have the Tracardi javascript snipped installed and it must be configured to accept incoming parameters.</p> <p>This is the example of such configuration.</p> Example configuration of destination web site, e.g example.com<pre><code>var options = {\n     tracker: {\n         url: {\n             script: '//mydomain.com/tracker',\n             api: '//mydomain.com'\n         },\n         source: {\n             id: \"some-source-id\"\n         },\n         context: {\n             tracardiPass: true\n            }\n     }\n}\n</code></pre>"},{"location":"getting_started/processes/integration/param/#example-use-case","title":"Example Use Case","text":"<p>Let\u2019s say you\u2019re running an email campaign and want to track user interactions:</p> <ol> <li> <p>E-mail Content:</p> <ul> <li>Include a parameterized link in your email:    <pre><code>&lt;a href=\"http://example.com/landing-page?__tr_pid=abc123&amp;__tr_src=email_campaign\"&gt;Click here&lt;/a&gt;\n</code></pre></li> </ul> </li> <li> <p>Landing Page:</p> <ul> <li>Ensure the Tracardi JavaScript snippet is included on the landing page to capture the parameters.</li> </ul> </li> <li> <p>Data Collection:</p> <ul> <li>When users click the link, their profile ID and source ID are captured, and interactions are tracked in Tracardi.</li> </ul> </li> </ol>"},{"location":"getting_started/processes/integration/param/#merging","title":"Merging","text":"<p>If the system already has a profile saved in the browser's local storage, it will try to merge the previous history of events on that page with the new profile ID and its history. If the user is visiting your page for the first time, there shouldn't be any merging.</p> <p>Remember that if a session number is provided, the event will be associated with the corresponding profile. If only a profile ID is given, a new session will be created for that profile.</p>"},{"location":"getting_started/processes/integration/redirect/","title":"Redirect Link","text":"<p>A redirect link in Tracardi is used to track user clicks by redirecting them through a specified URL before they reach their final destination. This mechanism helps in gathering valuable data about user interactions and link activities, providing insights into user behavior and the effectiveness of marketing campaigns.</p>"},{"location":"getting_started/processes/integration/redirect/#key-features-of-redirect-links","title":"Key Features of Redirect Links","text":"<ol> <li>Tracking Clicks: Redirect links track when a user clicks on a link by redirecting them through a URL managed by    Tracardi.</li> <li>Event Data Collection: When the user clicks the link, Tracardi receives an event with information about the    click, including predefined event properties.</li> <li>Session and Profile Association: Redirect links can include session IDs and other identifiers to associate the    click with a specific user profile.</li> </ol>"},{"location":"getting_started/processes/integration/redirect/#setting-up-redirect-links-in-tracardi","title":"Setting Up Redirect Links in Tracardi","text":"<p>To use redirect links for tracking clicks, follow these steps:</p>"},{"location":"getting_started/processes/integration/redirect/#step-1-define-redirect-links","title":"Step 1: Define Redirect Links","text":"<ol> <li> <p>Create Redirect Link:</p> <ul> <li>Go to the Tracardi dashboard and navigate to the \"Inbound Traffic\" section.</li> <li>Select \"Event Source\"</li> <li>Create an Event Source that uses Redirect Link.</li> <li>Select \"Event Redirects\" to create a new redirect link - select created Event source.</li> </ul> </li> <li> <p>Set Target URL:</p> <ul> <li>Define the URL to which users will be redirected after clicking the link. This is the target URL where   you want to send your users.</li> </ul> </li> <li> <p>Define Event Properties:</p> <ul> <li>Specify any additional properties you want to capture with the event, such as the type of event, source, or other   relevant data.</li> </ul> </li> </ol>"},{"location":"getting_started/processes/integration/redirect/#step-2-generate-the-redirect-link","title":"Step 2: Generate the Redirect Link","text":"<p>Tracardi will generate a redirect link in the following format:</p> <pre><code>http://&lt;tracardi-api-url&gt;/redirect/&lt;redirect-id&gt;\n</code></pre> <ul> <li><code>&lt;tracardi-api-url&gt;</code>: The base URL of your Tracardi API server.</li> <li><code>&lt;redirect-id&gt;</code>: A unique identifier for the redirect link generated by Tracardi.</li> </ul>"},{"location":"getting_started/processes/integration/redirect/#step-3-include-redirect-link-in-campaigns","title":"Step 3: Include Redirect Link in Campaigns","text":"<p>Use the generated redirect link in your marketing campaigns, such as emails, ads, or social media posts.</p> <p>Example:</p> <pre><code>&lt;a href=\"http://your-tracardi-url/redirect/12345\"&gt;Click here to learn more&lt;/a&gt;\n</code></pre>"},{"location":"getting_started/processes/integration/redirect/#step-4-track-events-with-session-association-optional","title":"Step 4: Track Events with Session Association (Optional)","text":"<p>To associate the click with a specific user session, you can include the session ID in the redirect link:</p> <p>Extended Link Format:</p> <pre><code>http://&lt;tracardi-api-url&gt;/redirect/&lt;redirect-id&gt;/&lt;session-id&gt;\n</code></pre> <p>To obtain the session ID, use session@id. If you wish to send the redirect link via email, you can use Tracardi template and access the session ID using {{session@id}}.</p> <p>Example:</p> <pre><code>&lt;a href=\"http://your-tracardi-url/redirect/12345/67890\"&gt;Click here to learn more&lt;/a&gt;\n</code></pre> <ul> <li><code>&lt;session-id&gt;</code>: The session ID to associate with the click.</li> </ul>"},{"location":"getting_started/processes/integration/redirect/#example-use-case","title":"Example Use Case","text":""},{"location":"getting_started/processes/integration/redirect/#email-campaign-with-redirect-links","title":"Email Campaign with Redirect Links","text":"<ol> <li> <p>Create Email Content:</p> <ul> <li>Include a redirect link in your email:    <pre><code>&lt;a href=\"http://your-tracardi-url/redirect/12345/&lt;last-user-session&gt;\"&gt;Get your discount&lt;/a&gt;\n</code></pre></li> </ul> </li> <li> <p>User Clicks Link:</p> <ul> <li>When a user clicks the link, they are redirected through the Tracardi URL, and the event is captured. Session is used to identify the user and connect the event with the user profile.</li> </ul> </li> <li> <p>Data Collection:</p> <ul> <li>Tracardi collects data about the click event, including any predefined event properties.</li> </ul> </li> <li> <p>Analyze Click Data:</p> <ul> <li>Use Tracardi\u2019s analytics tools to review the collected data and gain insights into user interactions and campaign   performance.</li> </ul> </li> </ol>"},{"location":"getting_started/processes/integration/webhook/","title":"Webhook Integration","text":""},{"location":"getting_started/processes/integration/webhook/#overview","title":"Overview","text":"<p>Tracardi supports integration via webhooks, which are endpoints that allow external systems to send data to Tracardi without requiring a predefined data schema. This flexibility makes webhooks an excellent choice for integrating various external services with Tracardi.</p>"},{"location":"getting_started/processes/integration/webhook/#webhook-url","title":"Webhook URL","text":"<p>Event properties should be sent in the body of the request or as URL parameters. The event-type inside the URL should be replaced with the event type you would like to emit.</p> <p>Example Webhook URL:</p> Example webhook call<pre><code>/collect/&lt;event_type&gt;/&lt;source_id&gt;\n</code></pre>"},{"location":"getting_started/processes/integration/webhook/#webhook-url-with-session","title":"Webhook URL with Session","text":"<p>If you can add a session ID to your URL, the user profile will be recreated. Use this webhook if you have access to the Tracardi user session. Replace session_id with the user session ID and type your event type instead of event-type. Event properties should be sent in the body of the request or as URL parameters.</p> <p>Example Webhook URL with Session:</p> Example webhook call with session<pre><code>/collect/&lt;event_type&gt;/&lt;source_id&gt;/&lt;session_id&gt;\n</code></pre> <p>Here are the parameters described:</p> <ul> <li> <p>/collect: This is the base endpoint indicating that the URL is intended for data collection via a webhook in   Tracardi.</p> </li> <li> <p>: This placeholder should be replaced with the specific type of event you are collecting. The event   type is a string that describes the nature of the event, such as \"page-view\", \"purchase\", \"click\", etc. <li> <p>: This is the Source ID, a unique identifier for the source of the event. It tells Tracardi which   source configuration to use when processing the incoming data. <li> <p>: Replace this placeholder with the unique session ID associated with the current user session. The   session ID is utilized to retrieve the corresponding user profile. If the session is recognized within the system, the   profile that initiated it will be linked to the webhook event."},{"location":"getting_started/processes/integration/webhook/#available-webhooks","title":"Available Webhooks","text":"<p>Below are the available webhooks in Tracardi:</p> <ul> <li>POST /collect/EVENT-TYPE/SOURCE-ID: Collects data from a POST request with an event type and source ID. It can create profile-less events with the provided properties.</li> <li> <p>GET /collect/EVENT-TYPE/SOURCE-ID: Similar to the POST method, this endpoint collects data from a GET request with an event type and source ID. It can also create profile-less events based on query parameters.</p> </li> <li> <p>POST /collect/EVENT-TYPE/SOURCE-ID/SESSION-ID: Collects data from a POST request with an event type and source ID and session ID.</p> </li> <li>GET /collect/EVENT-TYPE/SOURCE-ID/SESSION-ID: Similar to the POST method, this endpoint collects data from a GET request with an event type and source ID and session ID.</li> </ul>"},{"location":"getting_started/processes/workflow/","title":"Workflow Core Definitions","text":"<p>Flow is a central mechanism of event processing. Workflow is a series of actions connected into graph. The actions are run one after another to fetch, process, store the data. The actions (sometimes called nodes) may do different things, such as fetching the data from external databases, storing data in profile, sending data to external services, etc. The list of action nodes is constantly extended.</p>"},{"location":"getting_started/processes/workflow/#actions","title":"Actions","text":"<p>Tracardi is an extendable system. It is build in a way that anyone with basic knowledge of python can add new action nodes. That's why you can find a lot of plug-ins for Tracardi on the Internet. New actions can be installed on the system simply by adding its module name. Tracardi will then download the plugin code and install it. See more about plugins installation  in plugins section.</p>"},{"location":"getting_started/processes/workflow/#action-configuration","title":"Action configuration","text":"<p>Most of the actions need configuration. It is done by filling the configuration file in JSON format. Most of none-technical user are not familiar with JSON so the action nodes come with plain forms that fill the JSON configuration automatically after the user saves the data in the form. There is no need for the user to manually edit JSON files.</p> <p>There are cases when IT personnel wants to inspect the configuration so the JSON file is also visible in the action configuration in the Graphical User Interface. Information edited in JSON is automatically visible in forms, as well.</p>"},{"location":"getting_started/processes/workflow/#action-documentation","title":"Action documentation","text":"<p>This manual provides a detailed workflow actions documentation. It documents how to use and configure the plugin. The information provided shows how to configure the plugin using the JSON configuration file. Configuration via forms should be self-explanatory so there is no additional documentation for this.</p>"},{"location":"getting_started/processes/workflow/#workflow-staging","title":"Workflow staging","text":"<p>Tracardi automatically saves workflow changes. This means that any change or error in workflow could break the running system. Therefore, workflows are in 2 different stages. One is production stage. This is the copy of a working workflow.  This workflow is running and the data is processed. It can not be changed. The second stage is development stage. This is a copy of a workflow that the user is editing. The change in this workflow is saved every 3 seconds. At some point it will become a production workflow.</p> <p>Changing the state of the workflow as simple as clicking deploy button on workflow editor. Then current workflow is copied  to production. The old production workflow is saved in case we need to revoke the deployed workflow for some reason.</p>"},{"location":"getting_started/processes/workflow/#workflow-internal-state","title":"Workflow internal state","text":"<p>The concept of the \"Workflow Internal State\" is central to understanding how each workflow operates within a given context. Workflow runs in a context of curren event, profile, and session.</p> <ol> <li> <p>Event: Events are the triggers for workflow actions. When an event is sent, it carries essential information,    including either a \"profile_id\" or a \"session_id,\" along with the event type and its associated properties.</p> </li> <li> <p>Event Loading: When an event is received, the system retrieves the current profile using the provided    identifier (profile_id or session_id). This step ensures that the system knows which profile is associated with the    event.</p> </li> <li> <p>Assignment to Nodes: The retrieved profile, along with the session and event data, is then assigned to each    relevant node within the workflow. This means that the workflow maintains an internal state, and this state is    referenced in each action node. As the workflow progresses, this internal state can change.</p> </li> <li> <p>Dynamic State: Throughout the execution of the workflow, the state of the event, profile, and session may undergo    alterations as various actions are performed. These changes reflect the dynamic nature of workflows, where the    information associated with the profile, session, and event can be modified based on the sequence of actions.</p> </li> <li> <p>Persistent Storage: It's important to note that when the workflow ends, any changes made to the    profile, session, and event are saved back to the system. This ensures that the updated information is preserved for    future reference or processing.</p> </li> </ol> <p>In summary, the \"Workflow Internal State\" refers to the dynamic and evolving set of data that includes events, profiles, and sessions within a workflow.  Please read about actions and the state they hold in Action's Core Definitions</p>"},{"location":"getting_started/processes/workflow/actions/","title":"Action's Core Definitions","text":"<p>Action is a single task in the workflow. Actions consist of input and output ports. Input ports are used to receive data. On the other hand, output ports send data via connection to another action. Action is basically a code in the system. Input ports are mapped to input parameters of a function in code when output ports are mapped to the return values. Tracardi can be extended by programmers who write code and map it with action, which later on is visible in the workflow editor as nodes.</p>"},{"location":"getting_started/processes/workflow/actions/#action-ports","title":"Action ports","text":"<p>Action node can have only one input port and many output ports. Port that return no data (Python: None) will not  trigger the next node execution.</p>"},{"location":"getting_started/processes/workflow/actions/#action-internal-state","title":"Action internal state","text":"<p>Each action node has a reference to the following data:</p> <ul> <li>id - node id</li> <li>debug - flag that tells if the node is in the debug mode</li> <li>event - currently processed event</li> <li>profile - currently processed profile. Profile may be empty if the event that is being processed is a profile less </li> <li>event. Search for profile-less events in the documentation.</li> <li>session - current user session</li> <li>flow  - flow diagram</li> <li>execution_graph - information on graph execution, with nodes that have referenced action class instances. </li> <li>node - information on current executing node. With information on the inbound and outbound edges.</li> <li>console - the object where you can log error and warnings.</li> <li>metrics - metrics object</li> </ul>"},{"location":"getting_started/processes/workflow/actions/#accessing-internal-state","title":"Accessing internal state","text":"<p>Actions use dot notation to access the internal state of the node. Some date is not available via dot notations. See dot notation for details.</p>"},{"location":"getting_started/processes/workflow/actions/#action-core-methods","title":"Action core methods","text":"<p>Action node has 3 core methods:</p> <ul> <li>build - asynchronous method for action building</li> <li>init -  synchronous action constructor</li> <li>run - methods that runs the action </li> </ul>"},{"location":"getting_started/processes/workflow/actions/#auxiliary-functions","title":"Auxiliary functions","text":"<p>Action should also have a set of auxiliary functions that help Tracardi with acton registration and data validation.  Those functions are:</p> <ul> <li>register - it should return a Plugin object with information on action specification (where is it located in code,    what class should Tracardi run, where is the documentation etc.), metadata (how to present the action in the workflow,    its icon, configuration form , etc.)</li> <li>validate -  how to validate the configuration data</li> </ul>"},{"location":"getting_started/processes/workflow/actions/#action-documentation","title":"Action Documentation","text":"<p>Below you will find a list of action that are available in Tracardi. Documentation shows how to configure those action using JSON file. GUI user can configure actions by filling the form. </p>"},{"location":"getting_started/processes/workflow/actions/add_active_campaign_contact_action/","title":"Add contact to ActiveCampaign action","text":"<p>This plugin adds new contact to ActiveCampaign, or updates existing one if the  contact already exists.</p>"},{"location":"getting_started/processes/workflow/actions/add_active_campaign_contact_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/add_active_campaign_contact_action/#outputs","title":"Outputs","text":"<p>This plugin returns created contact's info on port success if the action was successful, or some error info on port error if there was an error.</p>"},{"location":"getting_started/processes/workflow/actions/add_active_campaign_contact_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-activecampaign-resource&gt;\",\n    \"name\": \"&lt;name-of-your-activecampaign-resource&gt;\"\n  },\n  \"fields\": {\n    \"email\": \"&lt;path-to-email&gt;\",\n    \"lastName\": \"&lt;path-to-last-name&gt;\",\n    \"...\": \"...\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/add_consents_action/","title":"Add consent plugin","text":"<p>This plugin appends consents to profile. With this plugin you will need to provide the reference to new consent data, for example event@properties.consents.</p>"},{"location":"getting_started/processes/workflow/actions/add_consents_action/#consents-payload","title":"Consents payload","text":"<p>The most possible use-case is when customer grants consents by filling a form. This data is sent to Tracardi as an event with properties set to granted consents. Consents payload should be in form of:</p> <pre><code>{\n  \"example-consent-id-1\": true,\n  \"example-consent-id-1\": false\n}\n</code></pre> <p>Plugin reads a data referenced with config as consents and adds them to profile if they are valid.</p>"},{"location":"getting_started/processes/workflow/actions/add_consents_action/#output","title":"Output","text":"<p>If there is no error plugin returns input payload (without any changes) on port payload.</p>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/","title":"Save Integration Id","text":"<p>This plugin is designed to establish a connection between Tracardi profiles and external systems by saving an external ID to the profile. It's useful for linking profiles with their counterparts in other systems, enhancing data integration and synchronization.</p>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#description","title":"Description","text":"<p>The plugin works by taking an external ID and, optionally, additional data related to the external system, then saving this information to the entity related to profile in Tracardi. The process involves converting the specified system name to a lowercase string with hyphens replacing spaces, ensuring consistency in naming conventions. The additional data can include any information relevant to the external system, and it can be referenced from any part of the event or payload using Tracardi's dot notation system. The plugin has two possible outcomes: successfully saving the integration ID to the profile or returning an error if the process fails.</p>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin accepts input through the \"payload\" port. It expects data that includes the external ID and,   optionally, additional related data.</li> <li>Outputs: There are two possible outputs:<ul> <li>payload: The original payload is returned, indicating successful execution.</li> <li>error: An error message is returned if the plugin encounters an issue during execution.</li> </ul> </li> </ul> <p>This plugin does not initiate workflows but acts within them, processing and returning data based on the provided inputs.</p>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#configuration","title":"Configuration","text":"<ul> <li>External ID: A dot notation path referencing the external ID within the event or payload.</li> <li>External System Name: The name of the external system. This name will be formatted to lowercase with spaces   replaced by hyphens.</li> <li>Additional Data: A JSON object containing additional data related to the external system. This data can be   referenced from any part of the event or payload using dot notation.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"id\": \"event@properties.id\",\n  \"name\": \"example-system\",\n  \"data\": \"{\\\"key\\\": \\\"event@properties.value\\\"}\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#event-prerequisites","title":"Event prerequisites","text":"<p>This plugin works with all types of events and does not require the event to be synchronous. It is not a UIX widget, so it does not wait for the workflow to finish before proceeding.</p>"},{"location":"getting_started/processes/workflow/actions/add_external_id_action/#errors","title":"Errors","text":"<ul> <li>Id can not be empty. Occurs if the External ID field in the configuration is left empty. Ensure this field is   populated with the correct dot notation path to the external ID.</li> <li>Name can not be empty. Happens when the External System Name configuration field is left blank. Fill in this field   with the name of the external system.</li> <li>Generic error message (e.g., \"An unexpected error occurred\"). If the plugin encounters an unexpected issue during   execution, a generic error message will be returned. This could be due to problems with data formatting, network   issues, or other unforeseen errors.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/add_interest/","title":"Add Interest","text":"<p>The Add Interest plugin is used for adding interests to a user profile during a workflow processing.</p>"},{"location":"getting_started/processes/workflow/actions/add_interest/#version","title":"Version","text":"<p>0.8.0</p>"},{"location":"getting_started/processes/workflow/actions/add_interest/#description","title":"Description","text":"<p>The Add Interest plugin works by taking any payload as input and adding specific interests to a user profile. It is primarily used for segmentation and collection purposes in a workflow. </p> <p>The plugin begins by validating if a legitimate profile exists for the event. If the event is \"profile less\" or has no profile linked to it, the plugin outputs an error message and ends the process. If the profile is found, the plugin checks if the specified interest (from the plugin configuration) is already present in the profile's interests. </p> <p>If the interest is not present, the plugin updates the profile with the new interest value. The value of the interest is determined by the plugin configuration. If the specified interest is a list, the plugin makes sure to reshape the interest information by traversing this list. </p> <p>At the end of the process, the modified payload is returned. If an error occurs at any step, an error message indicating the reason is produced.</p>"},{"location":"getting_started/processes/workflow/actions/add_interest/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin accepts a payload at its input. It outputs through two ports: payload and error. </p> <p>The payload port outputs the input payload, while the error port is used to output error messages when exceptions are encountered during the process.</p> <p>This plugin cannot start the workflow by itself; it needs a payload input to start a process.</p>"},{"location":"getting_started/processes/workflow/actions/add_interest/#configuration","title":"Configuration","text":"<p>The Add Interest plugin can be configured with two parameters:</p> <ul> <li>Interest name: This indicates the name of the interest you want to add to the user profile.</li> <li>Interest value: This denotes how much value you attach to the specified interest.</li> </ul> <p>You need to provide values for these two parameters to properly configure the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/add_interest/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"interest\": \"music\",\n  \"value\": \"1.0\"\n}\n</code></pre> <p>In the above configuration example, an interest named music is being added to the profile with a value of 1.0.</p>"},{"location":"getting_started/processes/workflow/actions/add_interest/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/add_interest/#errors","title":"Errors","text":"<ul> <li>\"Can not add interests profile when processing profile less events.\" - This error is thrown when the plugin is run on an event that does not have a profile linked to it.</li> <li>\"Can not add interests to empty profile.\" - This error means that the plugin cannot add interests to a non-existent profile.</li> <li>\"Not acceptable interest type. Allowed type: string or list of strings\" - This error indicates that the specified interest value isn't either of the accepted types. It should be a string or list of strings.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/add_mautic_contact_action/","title":"Add contact to Mautic plugin","text":"<p>This plugin adds new contact to Mautic, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/add_mautic_contact_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/add_mautic_contact_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from Mautic API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/add_mautic_contact_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/add_mautic_contact_action/#form-fields","title":"Form fields","text":"<ul> <li>Mautic resource - please select your Mautic resource. It should contain:<ul> <li>Mautic API URL</li> <li>Mautic Client private key</li> <li>Mautic Client public key</li> </ul> </li> <li>Email address - please type in the path to the email address of your new contact.</li> <li>Additional fields - you can add optional mapping for your contact, for example lastname:   profile@traits.public.surname. Remember to use field aliases from Mautic.</li> <li>Overwrite with blank - you can overwrite the fields that are not mentioned in configuration, with empty values. ON -   overwrite with empty, OFF - do not do so.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/add_mautic_contact_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mautic-resource&gt;\",\n    \"name\": \"&lt;name-of-your-mautic-resource&gt;\"\n  },\n  \"email\": \"&lt;path-to-email-of-new-contact&gt;\",\n  \"additional_mapping\": {\n    \"country\": \"&lt;path-to-country-data&gt;\",\n    \"firstname\": \"&lt;path-to-first-name&gt;\",\n    \"...\": \"...\"\n  },\n  \"overwrite_with_blank\": \"&lt;bool&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/append_remove_trait_action/","title":"Append/Remove data plugin","text":"<p>This plugin adds or removes values in arrays.</p>"},{"location":"getting_started/processes/workflow/actions/append_remove_trait_action/#configuration","title":"Configuration","text":"<p>The following config:</p> <pre><code>{\n  \"append\": {\n    \"profile@traits.orders\": \"event@properties.order\",\n    \"session@properties.list\": \"event@properties.property_list\"\n  },\n  \"remove\": {\n    \"profile@traits.emails\": \"session@properties.email\"\n  }\n}\n</code></pre> <p>Will:</p> <ul> <li>Append value from event@properties.order to profile@traits.private.orders list. If profile@traits.private.orders   is not an array, then new array will be created, with current value as the only element.</li> <li>Append all values from event@properties.property_list to session@properties.list.</li> <li>Remove value of session@properties.email from profile@traits.public.emails list. If session@properties.email was   also an array, then all elements from session@properties.email would be removed from profile@traits.public.emails.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/assign_condition_result_action/","title":"Assign condition results plugin","text":"<p>This plugin resolves a set of conditions and set profile fields.</p>"},{"location":"getting_started/processes/workflow/actions/assign_condition_result_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/assign_condition_result_action/#output","title":"Output","text":"<p>This plugin returns given payload on port payload without any changes.</p>"},{"location":"getting_started/processes/workflow/actions/assign_condition_result_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/assign_condition_result_action/#form-fields","title":"Form fields","text":"<ul> <li>Conditions - key-value pairs, where key is a path to field in profile, and value is a condition to be resolved.    (e.g. profile@consents.marketing-consent: profile@consents.marketing EXISTS). Every key must start with 'profile@'.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/assign_condition_result_action/#json-configuration","title":"JSON configuration","text":"<p>Example</p> <pre><code>{\n  \"conditions\": {\n   \"profile@consents.marketing-consent\": \"profile@consents.marketing EXISTS\",\n   \"profile@interests.computers\": \"session@context.browser.url == \\\"http://computers.com\\\"\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/assign_profile_id_action/","title":"Assign profile id plugin","text":"<p>This plugin assigns given value as current profile's id.</p>"},{"location":"getting_started/processes/workflow/actions/assign_profile_id_action/#input","title":"Input","text":"<p>This plugin takes any payload as input</p>"},{"location":"getting_started/processes/workflow/actions/assign_profile_id_action/#output","title":"Output","text":"<p>This plugin returns given payload on port payload without any changes.</p>"},{"location":"getting_started/processes/workflow/actions/assign_profile_id_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"value\": \"&lt;path-to-new-id&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/base64_decode/","title":"Decode Base64","text":"<p>The purpose of this plugin is to decode a base64-encoded string to its plain text form.</p>"},{"location":"getting_started/processes/workflow/actions/base64_decode/#configuration","title":"Configuration","text":"<p>This node requires configuration.</p> <p>You have to provide a path to string that needs to be transformed and set the encoding of the output string.</p> <pre><code>{\n  \"source\": \"payload@path.to.data\",\n  \"output_encoding\": \"utf-8\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/base64_decode/#input-payload","title":"Input payload","text":"<p>This node reads a property from the input payload.</p>"},{"location":"getting_started/processes/workflow/actions/base64_decode/#output","title":"Output","text":"<p>This plugin returns an object with the input property decoded from a base64 string.</p>"},{"location":"getting_started/processes/workflow/actions/base64_decode/#output_1","title":"Output","text":"<p>Example</p> <pre><code>{\n  \"text\": \"plain text string\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/base64_encode/","title":"Encode Base64","text":"<p>The purpose of this plugin is to encode a plain text string as base64.</p>"},{"location":"getting_started/processes/workflow/actions/base64_encode/#configuration","title":"Configuration","text":"<p>This node requires configuration.</p> <p>You have to provide a path to string that needs to be transformed and set the encoding of the input string.</p> <pre><code>{\n  \"source\": \"payload@path.to.data\",\n  \"source_encoding\": \"utf-8\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/base64_encode/#input-payload","title":"Input payload","text":"<p>This node reads a property from the input payload.</p>"},{"location":"getting_started/processes/workflow/actions/base64_encode/#output","title":"Output","text":"<p>This plugin returns an object with the input property encoded as base64 string.</p>"},{"location":"getting_started/processes/workflow/actions/base64_encode/#output_1","title":"Output","text":"<p>Example</p> <pre><code>{\n  \"base64\": \"aGVsbG8gdHJhY2FyZGkh\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/calculate_time_difference_action/","title":"Calculate Time Difference Plugin","text":"<p>This plugin calculates the time difference between two dates. </p>"},{"location":"getting_started/processes/workflow/actions/calculate_time_difference_action/#config","title":"Config","text":"<p>The plugin takes two dates. </p> <ul> <li>1st date or path to date - this is a reference date, for example, profile@metadata.time.visit.last. </li> <li>2nd date or path to date</li> </ul> <p>Dates can be in the following formats * now - the time of workflow execution * date - correct values are for example 2021-03-14 or Aug 28 1999. For more information about correct formats, check https://dateutil.readthedocs.io/en/stable/parser.html * path - This one takes a path to date, e.g. profile@metadata.time.visit.last</p>"},{"location":"getting_started/processes/workflow/actions/calculate_time_difference_action/#output","title":"Output","text":"<p>This plugin returns time difference information on port <code>time_difference</code>. The returned time difference is always in form of an object with the following information:</p> <p><pre><code>{\n    \"seconds\": &lt;number-of-seconds&gt;,\n    \"minutes\": &lt;number-of-minutes&gt;,\n    \"hours\": &lt;number-of-hours&gt;,\n    \"days\": &lt;number-of-days&gt;,\n    \"weeks\": &lt;number-of-weeks&gt;\n}\n</code></pre> These values can be floats.</p>"},{"location":"getting_started/processes/workflow/actions/calculator_action/","title":"Calculator","text":"<p>This plugin performs simple operations such as add, subtract, divide, and multiply. Arguments of those operations may be values from payload, profile, etc. The result is returned as an object of new values.</p> <p>Each operation must be in separate row. Operations may share variables.</p> <p>Example 1</p> <pre><code>profile@traits.private.interests.sports =  profile@traits.private.interests.sports / payload@time_passed\n</code></pre> <p>This calculation will divide the value from profile that is located in traits.private.interests.sports by the number provided in payload (time_passed). Value of time_passed can be a time that passed from the last visit. The above equation will return the following result.</p> <pre><code>{\n  \"result\": &lt;some-value&gt;,\n  \"variables\": {}\n}\n</code></pre> <p>Example 2 - variables</p> <pre><code>decay_rate = 2\nresult.value = profile@traits.private.interests.sports / decay_rate\n</code></pre> <p>This simple calculation assigns value to variable decay_rate. Then uses this value to compute result.value. This equation will return the following result.</p> <pre><code>{\n  \"result\": &lt;some-value-equal-to-last-operation-result.value&gt;,\n  \"variables\": {\n    \"decay_rate\": 2,\n    \"result\": {\n      \"value\": &lt;some-value-equal-to-last-operation-result.value&gt;\n    }\n  }\n}\n</code></pre> <p>This way you can construct object that have different values that are calculated and assigned to variables. Of course the variable ca be assigned to profile, session, etc. This is the last example with variable result.value assigned to profile@traits.private.interests.sports</p> <pre><code>decay_rate = 2\nresult.value = profile@traits.private.interests.sports / decay_rate\nprofile@traits.private.interests.sports = result.value\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/calculator_action/#compound-calculations","title":"Compound calculations","text":"<p>Calculations may have several operations.</p> <pre><code>a = 1 + 2 / 3\nb = (1 + 2) / 3\nc = a + b\n</code></pre> <p>The result of this calculation is:</p> <pre><code>{\n  \"result\": 2.6666666666666665,\n  \"variables\": {\n    \"a\": 1.6666666666666665,\n    \"b\": 1,\n    \"c\": 2.6666666666666665\n  }\n}\n</code></pre> <p>Each number can be replaced by variable or a field from profile, event, etc.</p>"},{"location":"getting_started/processes/workflow/actions/calculator_action/#negative-values","title":"Negative values","text":"<pre><code>event@counter = 1\n-event@counter\n</code></pre> <p>The result of this operation is:</p> <pre><code>{\n  \"result\": -1,\n  \"variables\": {}\n}\n</code></pre> <p>And the event@counter equals 1.</p>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/","title":"Chatwoot widget","text":"<p>The Chatwoot widget plugin is a user experience (UX) enhancement tool for webpages, integrating Chatwoot's live chat widget. It allows users to interact with customer support or sales teams directly from the webpage it's implemented on.</p>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#version","title":"Version","text":"<p>0.7.3</p>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#description","title":"Description","text":"<p>This plugin integrates a Chatwoot live chat widget into a webpage. The widget is powered by a user-provided Chatwoot token, which is essential for the widget's functionality. Once set up, the plugin injects a script into the webpage that initializes and displays the Chatwoot widget, allowing website visitors to start conversations. The widget enhances user engagement by providing a direct communication channel with the service team.</p>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin takes a payload object, which serves as a container for passing data.</li> <li>Outputs:<ul> <li>response: Outputs the same payload received as input, as this plugin primarily works by adding a UX element to   the webpage.</li> <li>error: Outputs in case of any execution error.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#configuration","title":"Configuration","text":"<ul> <li>Token: Your Chatwoot token. This is a mandatory field. To find your token, log into chatwoot.com, go to   settings/inboxes, and look for the JavaScript configuration section.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"token\": \"your-chatwoot-token-here\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#event-prerequisites","title":"Event prerequisites","text":"<p>Plugins like the Chatwoot widget, which fall under the \"UIX Widgets\" category, require a synchronous event. It will not work if sent event is asynchronous.</p>"},{"location":"getting_started/processes/workflow/actions/chatwoot_widget_action/#errors","title":"Errors","text":"<ul> <li>\"Token can not be empty.\": This error occurs when the Chatwoot token field is left empty during configuration. The   token is essential for the widget to function, and thus it must be provided.</li> <li>Generic errors related to script injection or execution failures might occur. These are less common and usually   pertain to issues with the webpage where the script is being injected or network-related problems.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/","title":"ClickSend Send SMS","text":"<p>The ClickSend Send SMS plugin allows you to send SMS messages using the ClickSend gateway in your Tracardi workflows. This documentation will provide an overview of the plugin, including its functionality, configuration options, and examples of how to use it.</p>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#version","title":"Version","text":"<p>This documentation is created for version 0.8.2 of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#description","title":"Description","text":"<p>The ClickSend Send SMS plugin is used to send SMS messages through the ClickSend gateway. You can customize the content of the SMS message and specify the recipient's phone number. This plugin supports dynamic content generation by allowing you to use data placeholders in your SMS message.</p>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#how-it-works","title":"How it Works","text":"<ol> <li>The plugin takes a payload as input, which is a dictionary containing various data.</li> <li>It retrieves the necessary configuration parameters, including the ClickSend resource, SMS message template, sender, and recipient phone number.</li> <li>The SMS message template can contain placeholders that will be replaced with data from the payload. The placeholders use a dot notation to reference specific data in the payload.</li> <li>The plugin sends the SMS message to the specified recipient using the ClickSend gateway.</li> <li>It captures the response status and content from the ClickSend gateway.</li> </ol> <p>Example Output: <pre><code>{\n  \"status\": 200,\n  \"content\": \"SMS message sent successfully.\"\n}\n</code></pre></p>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The ClickSend Send SMS plugin accepts a payload as input and provides two output ports: \"response\" and \"error.\"</p> <p>Inputs: - payload: This port accepts a payload object, which is a dictionary containing data.</p> <p>Outputs: - response: This port returns the response status and content from the ClickSend gateway if the SMS message is sent successfully. - error: This port returns an error if the SMS message sending process fails.</p> <p>The plugin does not have the capability to start a workflow.</p>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#configuration","title":"Configuration","text":"<p>The ClickSend Send SMS plugin has the following configuration parameters:</p> <ul> <li>Resource: Select your ClickSend resource, which defines the credentials for the ClickSend gateway.</li> <li>Message template: Type the SMS message. This message template can include data placeholders that will be replaced with data from the payload.</li> <li>Sender: Type the sender's name or leave it blank to use the default sender. Custom sender names can be configured in the ClickSend system.</li> <li>Recipient: Type or reference the recipient's phone number for the SMS message.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#json-configuration","title":"JSON Configuration","text":"<p>Here's an example JSON configuration for the ClickSend Send SMS plugin:</p> <pre><code>{\n  \"resource\": {\n    \"id\": \"your_resource_id\",\n    \"name\": \"ClickSend Resource\"\n  },\n  \"message\": \"Hello, {profile@data.pii.firstname}! Your appointment is confirmed for {payload@appointment.date}.\",\n  \"sender\": \"Tracardi\",\n  \"recipient\": \"profile@data.contac.telephone\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#required-resources","title":"Required Resources","text":"<p>This plugin requires the configuration of a ClickSend resource to work. You need to set up the ClickSend resource with your ClickSend credentials to enable the plugin to send SMS messages.</p>"},{"location":"getting_started/processes/workflow/actions/clicksend_sms/#errors","title":"Errors","text":"<p>The ClickSend Send SMS plugin may raise the following errors along with their descriptions:</p> <ul> <li>HTTP Request Error: This error may occur if there is an issue with the HTTP request made to the ClickSend gateway.</li> <li>Invalid Recipient: If the recipient's phone number is invalid or not provided, this error may occur.</li> <li>Missing Message: If the message template is empty or not provided, this error may occur.</li> <li>Profile Event Sequencing Error: This error may occur if the plugin is unable to access profile data. It requires a profile for certain dot notation references.</li> </ul> <p>Please note that these errors may occur based on the specific conditions or configurations of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/","title":"Resolve conditions","text":"<p>This plugin returns results with a resolved condition set, designed to evaluate specific conditions within a workflow and provide outcomes based on these evaluations.</p>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/#description","title":"Description","text":"<p>The Resolve conditions plugin operates by taking a set of user-defined conditions and evaluating them against provided data. Each condition is assessed to determine if it is true or false. For instance, you might want to check if a profile has given marketing consent or if the current weather condition is rain. The plugin processes these conditions and returns an object indicating the outcome of each condition.</p> <p>The plugin achieves this by using the Condition class to evaluate each condition against the provided payload. The payload is accessed using a DotAccessor, allowing the plugin to extract specific data points based on dot notation, like profile@consents.marketing. Each condition is defined in the plugin's configuration and is checked against the payload. The results are then compiled into an object, with each key representing a condition and its evaluated Boolean value.</p>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Input: The plugin accepts any type of payload as input. This input is used to evaluate the specified conditions.</li> <li>Output: The plugin outputs an object where each key corresponds to a condition, and the value is a Boolean   indicating whether the condition was met (true) or not (false).</li> </ul> <p>Example Output:</p> <pre><code>{\n  \"marketing-consent\": true,\n  \"is-it-raining\": false\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/#configuration","title":"Configuration","text":"<ul> <li>Conditions: Key-value pairs where the key is a custom name for a condition and the value is the condition to be   evaluated. For example, checking if marketing consent is not empty in a profile (profile@consents.marketing EMPTY). For the syntax of condition see Tracardi documentation.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/#json-configuration","title":"JSON Configuration","text":"<p>Example Configuration:</p> <pre><code>{\n  \"conditions\": {\n    \"marketing-consent\": \"profile@consents.marketing EXISTS\",\n    \"is-it-raining\": \"lowercase(payload@weather.condition) == 'rain'\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/condition_set_action/#errors","title":"Errors","text":"<ul> <li>\"Could not parse the condition {value}. Got error: {str(e)}\": This error occurs when the plugin encounters an   issue in parsing or evaluating a condition. It might happen if the condition is incorrectly formatted or if the   required data is not present in the payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/contact_popup_action/","title":"Show contact popup plugin","text":"<p>This plugin shows the contact widget to user. This widget allows user to give you some contact data (phone number or email address), which will be sent back in Tracardi event. (event@properties.contact)</p>"},{"location":"getting_started/processes/workflow/actions/contact_popup_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/contact_popup_action/#output","title":"Output","text":"<p>This plugin returns given payload on port payload without any changes.</p>"},{"location":"getting_started/processes/workflow/actions/contact_popup_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/contact_popup_action/#form-fields-description","title":"Form fields description","text":"<ul> <li>UIX source - provide a URL of API where this widget is located. Usually, it's just Tracardi API URL.</li> <li>API URL - provide a URL of API to send event back to.</li> <li>Popup message - provide a template of message for your contact popup. This field supports dot templates.</li> <li>Contact data type - define whether you want the user to provide their email address or phone number.</li> <li>Horizontal position - select a horizontal position for your contact popup.</li> <li>Vertical position - select a vertical position for your contact popup.</li> <li>Event type - type in a type of event that will be sent back from popup.</li> <li>Save event - determine whether sent event should be saved or not. ON - save, OFF - do not save.</li> <li>Dark theme - you can enable dark theme for your popup. ON - dark mode, OFF - bright mode.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/contact_popup_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"uix_source\": \"&lt;url-of-uix-source&gt;\",\n  \"api_url\": \"&lt;url-of-api-for-event-to-be-sent-to&gt;\",\n  \"content\": \"&lt;popup-message&gt;\",\n  \"contact_type\": \"email | phone\",\n  \"horizontal_pos\": \" left | center | right \",\n  \"vertical_pos\": \" top | bottom \",\n  \"event_type\": \"&lt;type-of-event-to-be-sent-back&gt;\",\n  \"save_event\": \"&lt;bool&gt;\",\n  \"dark_theme\": \"&lt;bool&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/contains_pattern_action/","title":"Contains Pattern Plugin","text":"<p>This plugin checks if data field contains selected pattern. It is capable to match single patterns for the whole string or search for all the patterns in given string. Chose ALL to look for patterns in the text regardless if the patterns is inside the text or the whole text contains pattern.</p> <p>When you select the single pattern this plugin will search for the pattern and will return its value only if the whole text contains pattern. E.g. This string: \"My email is email@email.com\" will not be matched if single e-mail pattern is selected as the string contains other information besides e-mail. If you want to search for email in this pattern  select ALL.</p>"},{"location":"getting_started/processes/workflow/actions/contains_pattern_action/#json-configuration","title":"JSON Configuration","text":"<p>Example config:</p> <pre><code>{\n  \"field\": \"payload@field\",\n  \"pattern\": \"all\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/contains_pattern_action/#available-patterns","title":"Available patterns","text":"<ul> <li>url - checks if data field contains exactly URL e.g. https://www.google.com </li> <li>ip - checks if data field contains exactly ip address</li> <li>date - checks if data field contains exactly date in dd-mm-yyyy format</li> <li>email - checks if data field contains exactly email address</li> <li>all - checks if data field contains all the patterns listed above</li> </ul> <p>Output:</p> <p>Plugin returns found patterns on port TRUE or FALSE if no patterns were found.</p>"},{"location":"getting_started/processes/workflow/actions/contains_pattern_action/#output-examples","title":"Output examples","text":"<p>Output for single pattern match</p> <pre><code>{\n  \"email\": [\"test@test.com\"]\n}\n</code></pre> <p>Output for multiple pattern match</p> <pre><code>{\n  \"date\": [\"2022-01-01\"],\n  \"email\": [\"test@test.com\", \"admin@admin.com\"]\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/contains_string_action/","title":"ContainsString Plugin","text":"<p>This plugin checks if data field contains defined substring.</p>"},{"location":"getting_started/processes/workflow/actions/contains_string_action/#json-configuration","title":"JSON Configuration","text":"<p>Example config:</p> <pre><code>{\n  \"field\": \"payload@field\",\n  \"substring\": \"string\"\n}\n</code></pre> <p>Output:</p> <p>Plugin outputs the payload on ports TRUE if field contains prefix or FALSE if otherwise.</p>"},{"location":"getting_started/processes/workflow/actions/copy_data/","title":"Copy data","text":"<p>This plugin copies event properties to a specified destination. It is a module that allows users to define a copying or setting action to perform on data from an event to a profile. It is suitable for use in the data processing, collection, and segmentation stages of workflows.</p>"},{"location":"getting_started/processes/workflow/actions/copy_data/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/copy_data/#description","title":"Description","text":"<p>The Copy data plugin is a Tracardi plugin designed to copy data from event properties to a defined destination. When the plugin is initialised, it validates its configuration settings and sets up the copying action based on these settings.</p> <p>When an event occurs, the Copy data plugin checks the mapping defined in the configuration. It loops through each configured destination, checks the value, and assigns it to the specified destination.</p> <p>Notably, the plugin is not capable of copying data to an event directly, as events are immutable and cannot be modified. When a destination is an event, the plugin will skip that property and proceed with the rest.</p> <p>If the event metadata contains a profile (i.e., the event is not profile-less) the plugin then checks for the presence of a \"traits\" field in the profile. If it is not present or the \"traits\" field is not a dictionary, an error is returned.</p> <p>The plugin continues by comparing the initial and final state of the profile's \"traits\" field to check if any fields were removed during the operation, which indicates a potential misconfiguration. It raises an error if such inconsistencies are found.</p> <p>Lastly, the plugin will replace the current session with the new session details. In the end, the modified payload is returned.</p>"},{"location":"getting_started/processes/workflow/actions/copy_data/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The \"Copy data\" plugin has one input:</p> <ul> <li>payload. This port accepts any JSON-like object.</li> </ul> <p>The plugin has two outputs:</p> <ul> <li>payload - Returns the given payload modified according to configuration.</li> <li>error - Returns an error message if the copying operation could not be carried out.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/copy_data/#configuration","title":"Configuration","text":"<p>The Copy data plugin's configuration contains a single property:</p> <ul> <li>traits.set - Represents a dictionary of source and target data parameters for the copying or setting actions the   plugin will carry out.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/copy_data/#json-configuration","title":"JSON Configuration","text":"<p>Below is an example of a configuration setup:</p> <pre><code>{\n  \"traits\": {\n    \"set\": {\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/copy_data/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/copy_data/#errors","title":"Errors","text":"<p>The following errors could be returned by the plugin.</p> <ul> <li>\"Missing traits in profile\" - This error occurs when the \"traits\" field is absent in the profile of the event.</li> <li>\"Some values were not added to profile. Profile schema seems not to have path: {}. This node is probably   misconfigured\" - This error is raised if there are inconsistencies between the initial and final state of the   profile's \"traits\" field. This is an indicator of a possible misconfiguration.</li> <li>Error when setting profile@traits to value {}. Traits must have key:value pair. E.g. name: {} - This error   occurs when the \"traits\" field is not a dictionary in the event's profile.</li> <li>\"Profile changes were discarded in node 'Copy data'. This event is profile-less so there is no profile\" - This warning   is returned when the event does not have a profile (is profile-less), thus it is not capable of having profile   changes.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/corporate_reputation_action/","title":"Corporate reputation plugin","text":"<p>This plugin sends given text to MeaningCloud's Corporate reputation API to analyze it for included opinions about companies.</p>"},{"location":"getting_started/processes/workflow/actions/corporate_reputation_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/corporate_reputation_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from API on port response, or optional error info on error port if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/corporate_reputation_action/#plugin-configuration","title":"Plugin configuration","text":"<ul> <li>MeaningCloud resource - select your MeaningCloud resource, containing your MeaningCloud API token.</li> <li>Path to text - type in the path to the text that you want to analyze.</li> <li>Path to language - type in the path to the language of the text (es, en)   you can type the language itself as well. This option can be left as auto for automatic language detection.</li> <li>Focus on company - you can optionally provide a name of company for API to focus on when analyzing your text.</li> <li>Filter by company type - you can filter your results by company type. It should be provided according   to MeaningCloud's ontology.</li> <li>Relaxed typography - You can enable this option to make the API less strict in terms of spelling and mistakes.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/corporate_reputation_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"&lt;name-of-your-meaningcloud-resource&gt;\",\n    \"id\": \"&lt;id-of-your-meaningcloud-resource&gt;\"\n  },\n  \"text\": \"&lt;path-to-text-to-analyze&gt;\",\n  \"lang\": \"&lt;path-to-language-or-language-itself&gt;\",\n  \"focus\": \"&lt;name-of-company-to-focus-on&gt;\",\n  \"company_type\": \"&lt;type-of-company-to-filter-with&gt;\",\n  \"relaxed_typography\": \"&lt;bool&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/count_by_query_string_action/","title":"Count records by query string plugin","text":"<p>This plugin counts records is given index, that match given query and are within given time range.</p>"},{"location":"getting_started/processes/workflow/actions/count_by_query_string_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/count_by_query_string_action/#output","title":"Output","text":"<p>This plugin returns number of records on port result, or optional error information on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/count_by_query_string_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/count_by_query_string_action/#with-form","title":"With form","text":"<ul> <li>Index - please select index that you want to count records in.</li> <li>Time range - please provide some time offset expression like -14d or -15 minutes.   Negative values are not allowed.</li> <li>Query string - here provide regular Elasticsearch query string. It can be provided in form   of dot template, so for example profile.id:{{profile@id}} AND type:page-view</li> </ul>"},{"location":"getting_started/processes/workflow/actions/count_by_query_string_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"index\": \"event | session | profile\",\n  \"time_range\": \"&lt;valid-negative-time-expression&gt;\",\n  \"query\": \"&lt;valid-elasticsearch-query-string&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/","title":"Cut out data","text":"<p>This plugin is designed to extract a part of referenced data and return it as the payload. </p>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/#version","title":"Version","text":"<p>This documentation was created for the plugin version 0.8.0.</p>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/#description","title":"Description","text":"<p>The Cut Out Data plugin enables the user to specify a path to a property within the workflow's internal data. This could be in the event, profile, memory, or other data. The plugin then extracts this data and returns it as the payload. </p> <p>It is also possible for the returned data to be wrapped within an object with a specified key. If a key is provided in the configuration, the data at the specified path will be returned as an object where the key is the provided key and the value is the extracted data.</p> <p>For example, if the key is \"myKey\" and the extracted data is \"myData\", then the returned object would be:</p> <pre><code>{\n  \"myKey\": \"myData\"\n}\n</code></pre> <p>If no key is provided, the plugin just returns the extracted data, whatever it may be.</p>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This placeholder accepts any JSON-like object as its input. </p> <p>The output is given below:</p> <p><pre><code>{\n  \"&lt;optional key&gt;\": \"&lt;output&gt;\"\n}\n</code></pre> Where the optional key is the value provided in the configuration (if any), and output is the piece of data that was specified by the path in the configuration. </p> <p>Also, note that this plugin cannot start a workflow. It needs to have an input passed onto it.</p>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/#configuration","title":"Configuration","text":"<p>The plugin has two configuration parameters:</p> <ul> <li> <p>Path to data: This field allows you to specify the path to the internal data you are interested in. Generally, it should be in the form of @. E.g. \"event@session.context.browser.browser.userAgent\". <li> <p>Return as: This is an optional field that, when filled, would wrap the extracted data in an object with the provided key.</p> </li>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/#json-configuration","title":"JSON Configuration","text":"<p>Here's an example of the configuration:</p> <pre><code>{\"trait\": \"event@session.context.browser.browser.userAgent\", \"key\": \"userAgent\"}\n</code></pre> <p>This configuration would result in an output where the user agent of the browser is returned as an object with the key userAgent.</p>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/cut_out_data/#errors","title":"Errors","text":"<ul> <li> <p>If the \"Path to data\" configuration is left empty, you will receive a Trait should not be empty error. This error occurs when the configuration does not contain a path to any data in the workflow's internal state.</p> </li> <li> <p>If the \"Return as\" configuration is left empty or is filled with whitespace, you will receive a Key is empty error.</p> </li> </ul> <p>These errors can halt the processing of the plugin, so it is important to rectify them for the workflow to proceed.</p>"},{"location":"getting_started/processes/workflow/actions/data_exists_action/","title":"Data check action","text":"<p>This plugin check if data exists and is not null or empty.</p> <p>Type the path to property to be checked.</p> <p>Example: <pre><code>{\n  \"property\": \"event@context.page.url\"\n}\n</code></pre></p> <p>This will check if <code>context.page.url</code> exists in event.</p>"},{"location":"getting_started/processes/workflow/actions/data_exists_action/#input-payload","title":"Input payload","text":"<p>This node does not input payload.</p>"},{"location":"getting_started/processes/workflow/actions/data_exists_action/#output","title":"Output","text":"<ul> <li>True - This port is triggered if the data exists.</li> <li>False - This port is triggered if the data does not exist.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/data_to_json/","title":"Data to JSON","text":"<p>This plugin allows conversion of data objects into a JSON string.</p>"},{"location":"getting_started/processes/workflow/actions/data_to_json/#version","title":"Version","text":"<p>0.6.0.1</p>"},{"location":"getting_started/processes/workflow/actions/data_to_json/#description","title":"Description","text":"<p>The Data to JSON plugin takes the data from the payload's input port (which is in dictionary format), then using a provided reference path, it serializes the data into a JSON string. The processing takes place in the run method of the plugin.</p> <p>First, the payload is passed to the run method. Here, the plugin uses the get_dot_accessor method to access the data referenced by the path provided in the configuration. This path enables the plugin to reach into the payload's nested structure and find the needed values.</p> <p>Afterward, the found data is serialized into a JSON string. This process converts dictionary data into a string format that is easily readable and transferable.</p> <p>The JSON string is then returned, ready to be passed to the next plugin in the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/data_to_json/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has a single input port - \"payload\", and a single output port - \"payload\".</p> <p>The input port accepts a payload object that contains the data to be passed to the plugin.</p> <p>The output of the plugin is a JSON string of the data referenced by the given path in the payload.</p>"},{"location":"getting_started/processes/workflow/actions/data_to_json/#configuration","title":"Configuration","text":"<p>The configuration for this plugin has one parameter:</p> <ul> <li>\"to_json\": It's the reference path to data that will be processed by this plugin. This path should be a string in   dot notation, which represents the location of the desired data in the workflow's internal state. The plugin then   follows this path to find the data to be serialized into JSON. For example, if we   have to_json = \"profile@stats.counters.boughtProducts\", the plugin will access the boughtProducts properties under   the counters object in the stats object of the profile.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/data_to_json/#json-configuration","title":"JSON Configuration","text":"<p>Below is an example of a configuration for the Data to JSON plugin:</p> <pre><code>{\n  \"to_json\": \"event@some.path.to.value\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/data_to_json/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/data_to_json/#errors","title":"Errors","text":"<p>No predefined errors are emitted by this plugin. If an error occurs, it will be due to issues with loading the payload, accessing the data on the given path, or converting the data into a JSON string.</p>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/","title":"Day/Night","text":"<p>This plugin, named \"Day/Night,\" is designed to determine whether a given moment is during the day or night based on specific geographic coordinates. It routes the workflow differently based on this determination.</p>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#description","title":"Description","text":"<p>The Day/Night plugin uses latitude and longitude data to assess whether it is currently day or night at a specific location. It then routes the workflow through one of three possible outputs: day, night, or error. If the given coordinates are valid and it's day time at that location, the workflow will proceed through the \"day\" output. If it's night, the workflow will use the \"night\" output. If the plugin cannot determine the latitude and longitude, it will route through the \"error\" output.</p>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Inputs:</p> <ul> <li>Payload: The plugin reads a payload object from which it extracts latitude and longitude data.</li> </ul> <p>Outputs:</p> <ul> <li>Day: Returns the input payload if it is currently day time at the specified location.</li> <li>Night: Returns the input payload if it is currently night time.</li> <li>Error: Triggers if the latitude and longitude cannot be determined.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#configuration","title":"Configuration","text":"<ul> <li>Latitude: Set the path to latitude data or directly input the latitude value.</li> <li>Longitude: Set the path to longitude data or directly input the longitude value.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"latitude\": \"profile@data.devices.last.geo.latitude\",\n  \"longitude\": \"profile@data.devices.last.geo.longitude\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#event-prerequisites","title":"Event prerequisites","text":"<p>The Day/Night plugin works for all types of events. It does not require synchronous events.</p>"},{"location":"getting_started/processes/workflow/actions/day_night_split_action/#errors","title":"Errors","text":"<ul> <li>\"Returns error if longitude and latitude and not be found in profile\": This error occurs if the plugin cannot find or   access the latitude and longitude data in the provided payload. The workflow will proceed through the \"error\" output   port in this case.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/","title":"Decrease Interest","text":"<p>Decrease Interest is a Tracardi plugin that reduces a specific interest within a user's profile, based on a configurable interest name and decrease value.</p>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/#description","title":"Description","text":"<p>The Decrease Interest plugin works by identifying a particular interest within a user's profile and decreasing it by a specified amount. The decrease in interest is determined through an administrator-defined configuration that outlines the name of the interest and the degree of decrease. Dot notation can be used to dynamically set the interest name. Though there are some restrictions. The interest name must be an alpha-numerical string without spaces. Hyphen and dashes are allowed.</p> <p>If a user profile does not exist or the plugin receives a profile-less event, an error message will be generated and returned through the 'error' port. After successfully decreasing the specified interest, the plugin passes the payload it received to the 'payload' port.</p>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Input: The plugin receives an input via the port named 'payload' in a JSON-like object format. Output: The plugin returns an output through two ports, 'payload' and 'error'. The 'payload' port returns the received payload object if the plugin successfully executed while the 'error' port returns an error message if the plugin encountered issues, such as a missing profile or a profile-less event.</p> <p>E.g., Input (JSON):</p> <pre><code>{\n  \"profile\": {\n    ..\n  },\n  \"event\": {\n    ..\n  }\n}\n</code></pre> <p>Output (JSON):</p> <pre><code>{\n  \"message\": \"Can not decrease profile interest in profile-less events.\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/#configuration","title":"Configuration","text":"<ul> <li>Interest name: Specify the name of the interest that should be decreased.</li> <li>Interest value: Specify the degree by which the interest should be decreased.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"interest\": \"sports\",\n  \"value\": \"1.0\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/decrease_interest/#errors","title":"Errors","text":"<ul> <li>\"Can not decrease profile interest in profile-less events.\" - This error occurs when a profile-less event is   processed.</li> <li>\"Can not decrease interests to empty profile.\" - This error occurs when there is no profile to decrease interests   from.</li> <li>\"Invalid interest name.\" - This error occurs when the name of the interest (key used to save it in the database) is   not an alpha-numerical string. Interest name must be an alpha-numerical string without spaces. Hyphen and dashes are   allowed.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/decrement_action/","title":"Decrement action","text":""},{"location":"getting_started/processes/workflow/actions/deep_categorization_action/","title":"Categorize text plugin","text":"<p>This plugin sends given text to MeaningCloud's Deep categorization API to analyze it.</p>"},{"location":"getting_started/processes/workflow/actions/deep_categorization_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/deep_categorization_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from API on port response, or optional error info on error port if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/deep_categorization_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/deep_categorization_action/#with-form","title":"With form","text":"<ul> <li>MeaningCloud resource - select your MeaningCloud resource, containing your MeaningCloud   API token.</li> <li>Path to text - type in the path to the text that you want to analyze.</li> <li>Model - this API analyzes text using different models. Valid models are:</li> <li>IAB_2.0_language</li> <li>IAB_2.0-tier3_language</li> <li>IAB_2.0-tier4_language</li> <li>You can also use these models without _language suffix for automatic language detection. </li> </ul>"},{"location":"getting_started/processes/workflow/actions/deep_categorization_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"&lt;name-of-your-meaningcloud-resource&gt;\",\n    \"id\": \"&lt;id-of-your-meaningcloud-resource&gt;\"\n  },\n  \"text\": \"&lt;path-to-text-to-analyze&gt;\",\n  \"model\": \"&lt;model-name&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/delete_data/","title":"Delete data","text":"<p>This plugin is designed to remove specified data from the internal state of a workflow.</p>"},{"location":"getting_started/processes/workflow/actions/delete_data/#version","title":"Version","text":"<p>0.1</p>"},{"location":"getting_started/processes/workflow/actions/delete_data/#description","title":"Description","text":"<p>The Delete data plugin sequentially examines the list of fields provided by the user. If the field starts with \"event@\", the plugin issues a warning because event properties cannot be changed in the workflow and skips this value. For other provided values, the plugin attempts to delete this field from the internal state of the workflow. If the field is missing, a warning is issued. </p> <p>If the event is not a profile-less event, the profile is updated with any changes. If a session ID exists, the session is updated as well and the profile is saved in the profile cache. Finally, the payload, updated with the specified fields removed, is returned.</p>"},{"location":"getting_started/processes/workflow/actions/delete_data/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin accepts any JSON-like object as input through the \"payload\" port. After processing the payload and removing the chosen fields, the modified payload is then returned through the \"payload\" output port. The Delete data plugin can not initiate the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/delete_data/#configuration","title":"Configuration","text":"<p>The configuration for the Delete data plugin consists of: - delete - A list of fields to be removed from the payload. These fields should be provided as dot notation referencing the internal state of the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/delete_data/#json-configuration","title":"JSON Configuration","text":"<p>Here is a JSON example of the plugin configuration: <pre><code>{\n  \"delete\": [\"session@id\", \"profile@traits.private.email\"]\n}\n</code></pre></p>"},{"location":"getting_started/processes/workflow/actions/delete_data/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/delete_data/#errors","title":"Errors","text":"<ul> <li>\"List to delete must not be empty.\" - This error is returned when the delete list, as provided in the configuration, is empty.</li> <li>\"Could not delete value {value}, it is an event property and events can not be changed in workflow.\" - If a value that starts with \"event@\" is provided in the delete list, this warning is issued, as event properties cannot be deleted or changed during the workflow.</li> <li>\"Could not delete value {value}, it is missing, details: {KeyError details}\" - This is a warning message that is returned when a value in the delete list does not exist in the payload. The details of the KeyError exception are also reported in this warning.</li> </ul> <p>It is important to note that even if warning messages are reported, the plugin execution will continue, and the remaining elements of the delete list will be processed. However, providing an empty delete list will result in a ValueError and halt the execution of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/","title":"Detect client agent action","text":"<p>This action will parse any user agent and detect the browser, operating system, device used (desktop,  tablet, mobile, tv, cars, console, etc.), brand and model. It detects thousands  of user agent strings, even from rare and obscure browsers and devices. </p> <p>It returns an object containing all the information.</p>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#output-example","title":"Output example","text":"<pre><code>{\n  \"status\": {\n    \"code\": 200,\n    \"message\": \"OK\"\n  },\n  \"device\": {\n    \"model\": {\n      \"name\": \"\",\n      \"brand\": {\n        \"name\": \"UNK\"\n      },\n      \"type\": \"desktop\"\n    },\n    \"os\": {\n      \"name\": \"GNU/Linux\",\n      \"version\": \"\"\n    },\n    \"client\": {\n      \"type\": \"browser\",\n      \"name\": \"Chrome\",\n      \"version\": \"\",\n      \"engine\": {\n        \"default\": \"WebKit\",\n        \"versions\": {\n          \"28\": \"Blink\"\n        }\n      }\n    },\n    \"type\": {\n      \"mobile\": false,\n      \"desktop\": true,\n      \"bot\": false,\n      \"tv\": false\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#detected-operating-systems","title":"Detected operating systems","text":"<ul> <li>AIX</li> <li>Android</li> <li>AmigaOS</li> <li>Apple TV</li> <li>Arch Linux</li> <li>BackTrack</li> <li>Bada</li> <li>BeOS</li> <li>BlackBerry OS</li> <li>BlackBerry Tablet OS</li> <li>Brew</li> <li>CentOS</li> <li>Chrome OS</li> <li>CyanogenMod</li> <li>Debian</li> <li>DragonFly</li> <li>Fedora</li> <li>Firefox OS</li> <li>Fire OS</li> <li>FreeBSD</li> <li>Gentoo</li> <li>Google TV</li> <li>HP-UX</li> <li>Haiku OS</li> <li>IRIX</li> <li>Inferno</li> <li>KaiOS</li> <li>Knoppix</li> <li>Kubuntu</li> <li>GNU/Linux</li> <li>Lubuntu</li> <li>VectorLinux</li> <li>Mac</li> <li>Maemo</li> <li>Mandriva</li> <li>MeeGo</li> <li>MocorDroid</li> <li>Mint</li> <li>MildWild</li> <li>MorphOS</li> <li>NetBSD</li> <li>MTK / Nucleus</li> <li>Nintendo</li> <li>Nintendo Mobile</li> <li>OS/2</li> <li>OSF1</li> <li>OpenBSD</li> <li>Ordissimo</li> <li>PlayStation Portable</li> <li>PlayStation</li> <li>Red Hat</li> <li>RISC OS</li> <li>Remix OS</li> <li>RazoDroiD</li> <li>Sabayon</li> <li>SUSE</li> <li>Sailfish OS</li> <li>Slackware</li> <li>Solaris</li> <li>Syllable</li> <li>Symbian</li> <li>Symbian OS</li> <li>Symbian OS Series 40</li> <li>Symbian OS Series 60</li> <li>Symbian^3</li> <li>ThreadX</li> <li>Tizen</li> <li>Ubuntu</li> <li>WebTV</li> <li>Windows</li> <li>Windows CE</li> <li>Windows IoT</li> <li>Windows Mobile</li> <li>Windows Phone</li> <li>Windows RT</li> <li>Xbox</li> <li>Xubuntu</li> <li>YunOs</li> <li>iOS</li> <li>palmOS</li> <li>webOS</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-browsers","title":"List of detected browsers","text":"<ul> <li>2345 Browser</li> <li>360 Phone Browser</li> <li>360 Browser</li> <li>Avant Browser</li> <li>ABrowse</li> <li>ANT Fresco</li> <li>ANTGalio</li> <li>Aloha Browser</li> <li>Aloha Browser Lite</li> <li>Amaya</li> <li>Amigo</li> <li>Android Browser</li> <li>AOL Shield</li> <li>Arora</li> <li>Amiga Voyager</li> <li>Amiga Aweb</li> <li>Atomic Web Browser</li> <li>Avast Secure Browser</li> <li>AVG Secure Browser</li> <li>Beaker Browser</li> <li>Beamrise</li> <li>BlackBerry Browser</li> <li>Baidu Browser</li> <li>Baidu Spark</li> <li>Basilisk</li> <li>Beonex</li> <li>BlackHawk</li> <li>Bunjalloo</li> <li>B-Line</li> <li>Brave</li> <li>BriskBard</li> <li>BrowseX</li> <li>Camino</li> <li>CCleaner</li> <li>Coc Coc</li> <li>Comodo Dragon</li> <li>Coast</li> <li>Charon</li> <li>CM Browser</li> <li>Chrome Frame</li> <li>Headless Chrome</li> <li>Chrome</li> <li>Chrome Mobile iOS</li> <li>Conkeror</li> <li>Chrome Mobile</li> <li>CoolNovo</li> <li>CometBird</li> <li>COS Browser</li> <li>ChromePlus</li> <li>Chromium</li> <li>Cyberfox</li> <li>Cheshire</li> <li>Crusta</li> <li>Cunaguaro</li> <li>Chrome Webview</li> <li>dbrowser</li> <li>Deepnet Explorer</li> <li>Delta Browser</li> <li>Dolphin</li> <li>Dorado</li> <li>Dooble</li> <li>Dillo</li> <li>DuckDuckGo Privacy Browser</li> <li>Ecosia</li> <li>Epic</li> <li>Elinks</li> <li>Element Browser</li> <li>eZ Browser</li> <li>EUI Browser</li> <li>GNOME Web</li> <li>Espial TV Browser</li> <li>Falkon</li> <li>Faux Browser</li> <li>Firefox Mobile iOS</li> <li>Firebird</li> <li>Fluid</li> <li>Fennec</li> <li>Firefox</li> <li>Firefox Focus</li> <li>Firefox Reality</li> <li>Firefox Rocket</li> <li>Flock</li> <li>Firefox Mobile</li> <li>Fireweb</li> <li>Fireweb Navigator</li> <li>FreeU</li> <li>Galeon</li> <li>Google Earth</li> <li>Hawk Turbo Browser</li> <li>hola! Browser</li> <li>HotJava</li> <li>Huawei Browser</li> <li>IBrowse</li> <li>iCab</li> <li>iCab Mobile</li> <li>Iridium</li> <li>Iron Mobile</li> <li>IceCat</li> <li>IceDragon</li> <li>Isivioo</li> <li>Iceweasel</li> <li>Internet Explorer</li> <li>IE Mobile</li> <li>Iron</li> <li>Jasmine</li> <li>Jig Browser</li> <li>Jio Browser</li> <li>K.Browser</li> <li>Kindle Browser</li> <li>K-meleon</li> <li>Konqueror</li> <li>Kapiko</li> <li>Kinza</li> <li>Kiwi</li> <li>Kylo</li> <li>Kazehakase</li> <li>Cheetah Browser</li> <li>LieBaoFast</li> <li>LG Browser</li> <li>Links</li> <li>Lovense Browser</li> <li>LuaKit</li> <li>Lunascape</li> <li>Lynx</li> <li>mCent</li> <li>MicroB</li> <li>NCSA Mosaic</li> <li>Meizu Browser</li> <li>Mercury</li> <li>Mobile Safari</li> <li>Midori</li> <li>Mobicip</li> <li>MIUI Browser</li> <li>Mobile Silk</li> <li>Minimo</li> <li>Mint Browser</li> <li>Maxthon</li> <li>Nokia Browser</li> <li>Nokia OSS Browser</li> <li>Nokia Ovi Browser</li> <li>Nox Browser</li> <li>NetSurf</li> <li>NetFront</li> <li>NetFront Life</li> <li>NetPositive</li> <li>Netscape</li> <li>NTENT Browser</li> <li>Oculus Browser</li> <li>Opera Mini iOS</li> <li>Obigo</li> <li>Odyssey Web Browser</li> <li>Off By One</li> <li>ONE Browser</li> <li>Opera GX</li> <li>Opera Neon</li> <li>Opera Devices</li> <li>Opera Mini</li> <li>Opera Mobile</li> <li>Opera</li> <li>Opera Next</li> <li>Opera Touch</li> <li>Ordissimo</li> <li>Oregano</li> <li>Origyn Web Browser</li> <li>Openwave Mobile Browser</li> <li>OmniWeb</li> <li>Otter Browser</li> <li>Palm Blazer</li> <li>Pale Moon</li> <li>Oppo Browser</li> <li>Palm Pre</li> <li>Puffin</li> <li>Palm WebPro</li> <li>Palmscape</li> <li>Phoenix</li> <li>Polaris</li> <li>Polarity</li> <li>Microsoft Edge</li> <li>QQ Browser Mini</li> <li>QQ Browser</li> <li>Qutebrowser</li> <li>QupZilla</li> <li>Qwant Mobile</li> <li>QtWebEngine</li> <li>Realme Browser</li> <li>Rekonq</li> <li>RockMelt</li> <li>Samsung Browser</li> <li>Sailfish Browser</li> <li>SEMC-Browser</li> <li>Sogou Explorer</li> <li>Safari</li> <li>SalamWeb</li> <li>Shiira</li> <li>SimpleBrowser</li> <li>Skyfire</li> <li>Seraphic Sraf</li> <li>Sleipnir</li> <li>Snowshoe</li> <li>Sogou Mobile Browser</li> <li>Splash</li> <li>Sputnik Browser</li> <li>Sunrise</li> <li>SuperBird</li> <li>Super Fast Browser</li> <li>START Internet Browser</li> <li>Streamy</li> <li>Swiftfox</li> <li>Seznam Browser</li> <li>t-online.de Browser</li> <li>Tao Browser</li> <li>TenFourFox</li> <li>Tenta Browser</li> <li>Tizen Browser</li> <li>TweakStyle</li> <li>TV Bro</li> <li>UBrowser</li> <li>UC Browser</li> <li>UC Browser Mini</li> <li>UC Browser Turbo</li> <li>Uzbl</li> <li>Vivaldi</li> <li>vivo Browser</li> <li>Vision Mobile Browser</li> <li>Wear Internet Browser</li> <li>Web Explorer</li> <li>WebPositive</li> <li>Waterfox</li> <li>Whale Browser</li> <li>wOSBrowser</li> <li>WeTab Browser</li> <li>Yandex Browser</li> <li>Yandex Browser Lite</li> <li>Xiino</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-browser-engines","title":"List of detected browser engines","text":"<p>WebKit * Blink * Trident * Text-based * Dillo * iCab * Elektra * Presto * Gecko * KHTML * NetFront * Edge * NetSurf * Servo</p>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-libraries","title":"List of detected libraries","text":"<ul> <li>aiohttp</li> <li>curl</li> <li>Faraday</li> <li>Go-http-client</li> <li>Google HTTP Java Client</li> <li>Guzzle (PHP HTTP Client)</li> <li>HTTPie</li> <li>HTTP_Request2</li> <li>Java</li> <li>libdnf</li> <li>Mechanize</li> <li>Node Fetch</li> <li>OkHttp</li> <li>Perl</li> <li>Perl REST::Client</li> <li>Python Requests</li> <li>Python urllib</li> <li>REST Client for Ruby</li> <li>RestSharp</li> <li>ScalaJ HTTP</li> <li>urlgrabber (yum)</li> <li>Wget</li> <li>WWW-Mechanize</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-media-players","title":"List of detected media players","text":"<ul> <li>Audacious</li> <li>Banshee</li> <li>Boxee</li> <li>Clementine</li> <li>Deezer</li> <li>FlyCast</li> <li>Foobar2000</li> <li>Google Podcasts</li> <li>iTunes</li> <li>Kodi</li> <li>MediaMonkey</li> <li>Miro</li> <li>mpv</li> <li>Music Player Daemon</li> <li>NexPlayer</li> <li>Nightingale</li> <li>QuickTime</li> <li>Songbird</li> <li>Stagefright</li> <li>SubStream</li> <li>VLC</li> <li>Winamp</li> <li>Windows Media Player</li> <li>XBMC</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-mobile-apps","title":"List of detected mobile apps","text":"<ul> <li>AndroidDownloadManager</li> <li>AntennaPod</li> <li>Apple News</li> <li>Baidu Box App</li> <li>BeyondPod</li> <li>BingWebApp</li> <li>bPod</li> <li>CastBox</li> <li>Castro</li> <li>Castro 2</li> <li>CrosswalkApp</li> <li>DoggCatcher</li> <li>douban App</li> <li>Facebook</li> <li>Facebook Messenger</li> <li>FeedR</li> <li>Flipboard App</li> <li>Google Go</li> <li>Google Play Newsstand</li> <li>Google Plus</li> <li>Google Search App</li> <li>iCatcher</li> <li>Instacast</li> <li>Instagram App</li> <li>Line</li> <li>NewsArticle App</li> <li>Overcast</li> <li>Pinterest</li> <li>Player FM</li> <li>Pocket Casts</li> <li>Podcast &amp; Radio Addict</li> <li>Podcast Republic</li> <li>Podcasts</li> <li>Podcat</li> <li>Podcatcher Deluxe</li> <li>Podkicker</li> <li>RSSRadio</li> <li>Sina Weibo</li> <li>SogouSearch App</li> <li>tieba</li> <li>WeChat</li> <li>WhatsApp</li> <li>Yahoo! Japan</li> <li>Yelp Mobile</li> <li>YouTube and mobile apps using AFNetworking</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-pims-personal-information-manager","title":"List of detected PIMs (personal information manager)","text":"<ul> <li>Airmail</li> <li>Barca</li> <li>DAVdroid</li> <li>Lotus Notes</li> <li>MailBar</li> <li>Microsoft Outlook</li> <li>Outlook Express</li> <li>Postbox</li> <li>SeaMonkey</li> <li>The Bat!</li> <li>Thunderbird</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-feed-readers","title":"List of detected feed readers","text":"<ul> <li>Akregator</li> <li>Apple PubSub</li> <li>BashPodder</li> <li>Breaker</li> <li>Downcast</li> <li>FeedDemon</li> <li>Feeddler RSS Reader</li> <li>gPodder</li> <li>JetBrains Omea Reader</li> <li>Liferea</li> <li>NetNewsWire</li> <li>Newsbeuter</li> <li>NewsBlur</li> <li>NewsBlur Mobile App</li> <li>PritTorrent</li> <li>Pulp</li> <li>ReadKit</li> <li>Reeder</li> <li>RSS Bandit</li> <li>RSS Junkie</li> <li>RSSOwl</li> <li>Stringer</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-brands-with-detected-devices","title":"List of brands with detected devices","text":"<ul> <li>3Q</li> <li>4Good</li> <li>Ace</li> <li>Acer</li> <li>Advan</li> <li>Advance</li> <li>AGM</li> <li>Ainol</li> <li>Airness</li> <li>Airties</li> <li>AIS</li> <li>Aiwa</li> <li>Akai</li> <li>Alba</li> <li>Alcatel</li> <li>Aligator</li> <li>AllCall</li> <li>AllDocube</li> <li>Allview</li> <li>Allwinner</li> <li>Altech UEC</li> <li>altron</li> <li>Amazon</li> <li>AMGOO</li> <li>Amoi</li> <li>ANS</li> <li>Apple</li> <li>Archos</li> <li>Arian Space</li> <li>Ark</li> <li>Arnova</li> <li>ARRIS</li> <li>Ask</li> <li>Assistant</li> <li>Asus</li> <li>Atom</li> <li>Audiovox</li> <li>AVH</li> <li>Avvio</li> <li>Axxion</li> <li>Azumi Mobile</li> <li>BangOlufsen</li> <li>Barnes &amp; Noble</li> <li>BBK</li> <li>BDF</li> <li>Becker</li> <li>Beeline</li> <li>Beetel</li> <li>BenQ</li> <li>BenQ-Siemens</li> <li>Bezkam</li> <li>BGH</li> <li>Bird</li> <li>Bitel</li> <li>Black Fox</li> <li>Blackview</li> <li>Blaupunkt</li> <li>Blu</li> <li>Bluboo</li> <li>Bluegood</li> <li>Bmobile</li> <li>bogo</li> <li>Boway</li> <li>bq</li> <li>Bravis</li> <li>Brondi</li> <li>Bush</li> <li>CAGI</li> <li>Capitel</li> <li>Captiva</li> <li>Carrefour</li> <li>Casio</li> <li>Casper</li> <li>Cat</li> <li>Celkon</li> <li>Changhong</li> <li>Cherry Mobile</li> <li>China Mobile</li> <li>Chuwi</li> <li>Clarmin</li> <li>CnM</li> <li>Coby Kyros</li> <li>Comio</li> <li>Compal</li> <li>Compaq</li> <li>ComTrade Tesla</li> <li>Concord</li> <li>ConCorde</li> <li>Condor</li> <li>Coolpad</li> <li>Cowon</li> <li>CreNova</li> <li>Crescent</li> <li>Cricket</li> <li>Crius Mea</li> <li>Crosscall</li> <li>Cube</li> <li>CUBOT</li> <li>CVTE</li> <li>Cyrus</li> <li>Daewoo</li> <li>Danew</li> <li>Datang</li> <li>Datsun</li> <li>Dbtel</li> <li>Dell</li> <li>Denver</li> <li>Desay</li> <li>DeWalt</li> <li>DEXP</li> <li>Dialog</li> <li>Dicam</li> <li>Digi</li> <li>Digicel</li> <li>Digiland</li> <li>Digma</li> <li>Divisat</li> <li>DMM</li> <li>DNS</li> <li>DoCoMo</li> <li>Doogee</li> <li>Doov</li> <li>Dopod</li> <li>Doro</li> <li>Dune HD</li> <li>E-Boda</li> <li>E-tel</li> <li>Easypix</li> <li>EBEST</li> <li>Echo Mobiles</li> <li>ECS</li> <li>EE</li> <li>EKO</li> <li>Eks Mobility</li> <li>Element</li> <li>Elenberg</li> <li>Elephone</li> <li>Energizer</li> <li>Energy Sistem</li> <li>Ergo</li> <li>Ericsson</li> <li>Ericy</li> <li>Essential</li> <li>Essentielb</li> <li>Eton</li> <li>eTouch</li> <li>Etuline</li> <li>Eurostar</li> <li>Evercoss</li> <li>Evertek</li> <li>Evolio</li> <li>Evolveo</li> <li>EvroMedia</li> <li>Explay</li> <li>Extrem</li> <li>Ezio</li> <li>Ezze</li> <li>Fairphone</li> <li>Famoco</li> <li>Fengxiang</li> <li>FiGO</li> <li>FinePower</li> <li>Fly</li> <li>FNB</li> <li>Fondi</li> <li>FORME</li> <li>Forstar</li> <li>Foxconn</li> <li>Freetel</li> <li>Fujitsu</li> <li>G-TiDE</li> <li>Garmin-Asus</li> <li>Gateway</li> <li>Gemini</li> <li>General Mobile</li> <li>Geotel</li> <li>Ghia</li> <li>Ghong</li> <li>Gigabyte</li> <li>Gigaset</li> <li>Ginzzu</li> <li>Gionee</li> <li>Globex</li> <li>GOCLEVER</li> <li>Goly</li> <li>GoMobile</li> <li>Google</li> <li>Gradiente</li> <li>Grape</li> <li>Grundig</li> <li>Hafury</li> <li>Haier</li> <li>HannSpree</li> <li>Hasee</li> <li>Hi-Level</li> <li>Highscreen</li> <li>Hisense</li> <li>Hoffmann</li> <li>Homtom</li> <li>Hoozo</li> <li>Hosin</li> <li>HP</li> <li>HTC</li> <li>Huawei</li> <li>Humax</li> <li>Hyrican</li> <li>Hyundai</li> <li>i-Joy</li> <li>i-mate</li> <li>i-mobile</li> <li>iBall</li> <li>iBerry</li> <li>IconBIT</li> <li>iHunt</li> <li>Ikea</li> <li>iKoMo</li> <li>iLA</li> <li>IMO Mobile</li> <li>Impression</li> <li>iNew</li> <li>Infinix</li> <li>InFocus</li> <li>Inkti</li> <li>InnJoo</li> <li>Innostream</li> <li>Inoi</li> <li>INQ</li> <li>Insignia</li> <li>Intek</li> <li>Intex</li> <li>Inverto</li> <li>iOcean</li> <li>iPro</li> <li>Irbis</li> <li>iRola</li> <li>iRulu</li> <li>iTel</li> <li>iView</li> <li>iZotron</li> <li>JAY-Tech</li> <li>Jiayu</li> <li>Jolla</li> <li>Just5</li> <li>K-Touch</li> <li>Kaan</li> <li>Kaiomy</li> <li>Kalley</li> <li>Kanji</li> <li>Karbonn</li> <li>KATV1</li> <li>Kazam</li> <li>KDDI</li> <li>Kempler &amp; Strauss</li> <li>Keneksi</li> <li>Kiano</li> <li>Kingsun</li> <li>Kivi</li> <li>Kocaso</li> <li>Kodak</li> <li>Kogan</li> <li>Komu</li> <li>Konka</li> <li>Konrow</li> <li>Koobee</li> <li>KOPO</li> <li>Koridy</li> <li>KRONO</li> <li>Kr\u00fcger&amp;Matz</li> <li>KT-Tech</li> <li>Kumai</li> <li>Kyocera</li> <li>LAIQ</li> <li>Land Rover</li> <li>Landvo</li> <li>Lanix</li> <li>Lark</li> <li>Lava</li> <li>LCT</li> <li>Leagoo</li> <li>Ledstar</li> <li>LeEco</li> <li>Lemhoov</li> <li>Lenco</li> <li>Lenovo</li> <li>Leotec</li> <li>Le Pan</li> <li>Lephone</li> <li>Lexand</li> <li>Lexibook</li> <li>LG</li> <li>Lingwin</li> <li>Loewe</li> <li>Logicom</li> <li>Lumus</li> <li>Luna</li> <li>LYF</li> <li>M.T.T.</li> <li>M4tel</li> <li>Majestic</li> <li>Mann</li> <li>Manta Multimedia</li> <li>Masstel</li> <li>Maxcom</li> <li>Maxwest</li> <li>Maze</li> <li>Mecer</li> <li>Mecool</li> <li>Mediacom</li> <li>MediaTek</li> <li>Medion</li> <li>MEEG</li> <li>MegaFon</li> <li>Meitu</li> <li>Meizu</li> <li>Memup</li> <li>Metz</li> <li>MEU</li> <li>MicroMax</li> <li>Microsoft</li> <li>Mio</li> <li>Miray</li> <li>Mitsubishi</li> <li>MIXC</li> <li>MLLED</li> <li>Mobicel</li> <li>Mobiistar</li> <li>Mobiola</li> <li>Mobistel</li> <li>Modecom</li> <li>Mofut</li> <li>Motorola</li> <li>Movic</li> <li>Mpman</li> <li>MSI</li> <li>MTC</li> <li>MTN</li> <li>MYFON</li> <li>MyPhone</li> <li>Myria</li> <li>Mystery</li> <li>MyWigo</li> <li>National</li> <li>Navon</li> <li>NEC</li> <li>Neffos</li> <li>Netgear</li> <li>NeuImage</li> <li>Newgen</li> <li>NewsMy</li> <li>NEXBOX</li> <li>Nexian</li> <li>Nextbit</li> <li>NextBook</li> <li>NGM</li> <li>NG Optics</li> <li>Nikon</li> <li>Nintendo</li> <li>NOA</li> <li>Noain</li> <li>Nobby</li> <li>Noblex</li> <li>Nokia</li> <li>Nomi</li> <li>Nous</li> <li>NUU Mobile</li> <li>Nuvo</li> <li>Nvidia</li> <li>NYX Mobile</li> <li>O+</li> <li>O2</li> <li>Obi</li> <li>Odys</li> <li>Onda</li> <li>OnePlus</li> <li>OPPO</li> <li>Opsson</li> <li>Orange</li> <li>Ordissimo</li> <li>Ouki</li> <li>Oukitel</li> <li>OUYA</li> <li>Overmax</li> <li>Oysters</li> <li>Palm</li> <li>Panacom</li> <li>Panasonic</li> <li>Pantech</li> <li>PCBOX</li> <li>PCD</li> <li>PCD Argentina</li> <li>PEAQ</li> <li>Pentagram</li> <li>Philips</li> <li>phoneOne</li> <li>Pioneer</li> <li>Pixus</li> <li>Ployer</li> <li>Plum</li> <li>Point of View</li> <li>Polaroid</li> <li>PolyPad</li> <li>Polytron</li> <li>Pomp</li> <li>Positivo</li> <li>PPTV</li> <li>Prestigio</li> <li>Primepad</li> <li>Proline</li> <li>ProScan</li> <li>PULID</li> <li>Q-Touch</li> <li>Qilive</li> <li>QMobile</li> <li>Qtek</li> <li>Quantum</li> <li>Quechua</li> <li>Qumo</li> <li>R-TV</li> <li>Ramos</li> <li>RCA Tablets</li> <li>Readboy</li> <li>Rikomagic</li> <li>RIM</li> <li>Rinno</li> <li>Ritmix</li> <li>Ritzviva</li> <li>Riviera</li> <li>Roadrover</li> <li>Rokit</li> <li>Roku</li> <li>Rombica</li> <li>Ross&amp;Moor</li> <li>Rover</li> <li>RoverPad</li> <li>RT Project</li> <li>RugGear</li> <li>Runbo</li> <li>Safaricom</li> <li>Sagem</li> <li>Samsung</li> <li>Sanei</li> <li>Santin</li> <li>Sanyo</li> <li>Savio</li> <li>Sega</li> <li>Selevision</li> <li>Selfix</li> <li>Sencor</li> <li>Sendo</li> <li>Senseit</li> <li>Senwa</li> <li>SFR</li> <li>Sharp</li> <li>Shift Phones</li> <li>Shuttle</li> <li>Siemens</li> <li>Sigma</li> <li>Silent Circle</li> <li>Simbans</li> <li>Sky</li> <li>Skyworth</li> <li>Smart</li> <li>Smartfren</li> <li>Smartisan</li> <li>Softbank</li> <li>Sonim</li> <li>Sony</li> <li>Sony Ericsson</li> <li>Spectrum</li> <li>Spice</li> <li>Star</li> <li>Starway</li> <li>STF Mobile</li> <li>STK</li> <li>Stonex</li> <li>Storex</li> <li>Sumvision</li> <li>SunVan</li> <li>Sunvell</li> <li>SuperSonic</li> <li>Supra</li> <li>SWISSMOBILITY</li> <li>Symphony</li> <li>Syrox</li> <li>T-Mobile</li> <li>TB Touch</li> <li>TCL</li> <li>TechniSat</li> <li>TechnoTrend</li> <li>TechPad</li> <li>Teclast</li> <li>Tecno Mobile</li> <li>Telefunken</li> <li>Telego</li> <li>Telenor</li> <li>Telit</li> <li>Tesco</li> <li>Tesla</li> <li>teXet</li> <li>ThL</li> <li>Thomson</li> <li>TIANYU</li> <li>Timovi</li> <li>TiPhone</li> <li>Tolino</li> <li>Tooky</li> <li>Top House</li> <li>Toplux</li> <li>Toshiba</li> <li>Touchmate</li> <li>TrekStor</li> <li>Trevi</li> <li>True</li> <li>Tunisie Telecom</li> <li>Turbo</li> <li>Turbo-X</li> <li>TVC</li> <li>U.S. Cellular</li> <li>Ugoos</li> <li>Uhappy</li> <li>Ulefone</li> <li>Umax</li> <li>UMIDIGI</li> <li>Unihertz</li> <li>Unimax</li> <li>Uniscope</li> <li>Unknown</li> <li>Unnecto</li> <li>Unonu</li> <li>Unowhy</li> <li>UTOK</li> <li>UTStarcom</li> <li>Vastking</li> <li>Venso</li> <li>Verizon</li> <li>Vernee</li> <li>Vertex</li> <li>Vertu</li> <li>Verykool</li> <li>Vesta</li> <li>Vestel</li> <li>VGO TEL</li> <li>Videocon</li> <li>Videoweb</li> <li>ViewSonic</li> <li>Vinga</li> <li>Vinsoc</li> <li>Vitelcom</li> <li>Vivax</li> <li>Vivo</li> <li>Vizio</li> <li>VK Mobile</li> <li>Vodafone</li> <li>Vonino</li> <li>Vorago</li> <li>Voto</li> <li>Voxtel</li> <li>Vsun</li> <li>Vulcan</li> <li>Walton</li> <li>Web TV</li> <li>Weimei</li> <li>WellcoM</li> <li>Wexler</li> <li>Wieppo</li> <li>Wiko</li> <li>Wileyfox</li> <li>Wink</li> <li>Wolder</li> <li>Wolfgang</li> <li>Wonu</li> <li>Woo</li> <li>Woxter</li> <li>X-TIGI</li> <li>X-View</li> <li>Xiaolajiao</li> <li>Xiaomi</li> <li>Xion</li> <li>Xolo</li> <li>Xoro</li> <li>Yandex</li> <li>Yarvik</li> <li>Yes</li> <li>Yezz</li> <li>Yota</li> <li>Ytone</li> <li>Yu</li> <li>Yuandao</li> <li>Yusun</li> <li>Yxtel</li> <li>Zeemi</li> <li>Zen</li> <li>Zenek</li> <li>Zonda</li> <li>Zopo</li> <li>ZTE</li> <li>Zuum</li> <li>Zync</li> <li>ZYQ</li> <li>\u00f6wn</li> </ul>"},{"location":"getting_started/processes/workflow/actions/detect_client_agent_action/#list-of-detected-bots","title":"List of detected bots","text":"<ul> <li>360Spider</li> <li>Aboundexbot</li> <li>Acoon</li> <li>AddThis.com</li> <li>ADMantX</li> <li>aHrefs Bot</li> <li>Alexa Crawler</li> <li>Alexa Site Audit</li> <li>Amazon Route53 Health Check</li> <li>Amorank Spider</li> <li>Analytics SEO Crawler</li> <li>ApacheBench</li> <li>Applebot</li> <li>Arachni</li> <li>archive.org bot</li> <li>Ask Jeeves</li> <li>Awario</li> <li>Awario</li> <li>Backlink-Check.de</li> <li>BacklinkCrawler</li> <li>Baidu Spider</li> <li>BazQux Reader</li> <li>BingBot</li> <li>BitlyBot</li> <li>Blekkobot</li> <li>BLEXBot Crawler</li> <li>Bloglovin</li> <li>Blogtrottr</li> <li>BoardReader</li> <li>BoardReader Blog Indexer</li> <li>Bountii Bot</li> <li>BrandVerity</li> <li>Browsershots</li> <li>BUbiNG</li> <li>Buck</li> <li>Butterfly Robot</li> <li>Bytespider</li> <li>CareerBot</li> <li>Castro 2</li> <li>Catchpoint</li> <li>CATExplorador</li> <li>ccBot crawler</li> <li>Charlotte</li> <li>Cliqzbot</li> <li>CloudFlare Always Online</li> <li>CloudFlare AMP Fetcher</li> <li>Collectd</li> <li>CommaFeed</li> <li>CSS Certificate Spider</li> <li>C\u1ed1c C\u1ed1c Bot</li> <li>Datadog Agent</li> <li>Datanyze</li> <li>Dataprovider</li> <li>Daum</li> <li>Dazoobot</li> <li>Discobot</li> <li>Domain Re-Animator Bot</li> <li>DotBot</li> <li>DuckDuckGo Bot</li> <li>Easou Spider</li> <li>eCairn-Grabber</li> <li>EMail Exractor</li> <li>EmailWolf</li> <li>Embedly</li> <li>evc-batch</li> <li>ExaBot</li> <li>ExactSeek Crawler</li> <li>Ezooms</li> <li>eZ Publish Link Validator</li> <li>Facebook External Hit</li> <li>Feedbin</li> <li>FeedBurner</li> <li>Feedly</li> <li>Feedspot</li> <li>Feed Wrangler</li> <li>Fever</li> <li>Findxbot</li> <li>Flipboard</li> <li>FreshRSS</li> <li>Generic Bot</li> <li>Generic Bot</li> <li>Genieo Web filter</li> <li>Gigablast</li> <li>Gigabot</li> <li>Gluten Free Crawler</li> <li>Gmail Image Proxy</li> <li>Goo</li> <li>Googlebot</li> <li>Google Cloud Scheduler</li> <li>Google Favicon</li> <li>Google PageSpeed Insights</li> <li>Google Partner Monitoring</li> <li>Google Search Console</li> <li>Google Stackdriver Monitoring</li> <li>Google Structured Data Testing Tool</li> <li>Grapeshot</li> <li>Heritrix</li> <li>Heureka Feed</li> <li>HTTPMon</li> <li>HubPages</li> <li>HubSpot</li> <li>ICC-Crawler</li> <li>ichiro</li> <li>IDG/IT</li> <li>IIS Site Analysis</li> <li>Inktomi Slurp</li> <li>inoreader</li> <li>IP-Guide Crawler</li> <li>IPS Agent</li> <li>Kaspersky</li> <li>Kouio</li> <li>Larbin web crawler</li> <li>LCC</li> <li>Let's Encrypt Validation</li> <li>Lighthouse</li> <li>Linkdex Bot</li> <li>LinkedIn Bot</li> <li>LTX71</li> <li>Lycos</li> <li>Magpie-Crawler</li> <li>MagpieRSS</li> <li>Mail.Ru Bot</li> <li>masscan</li> <li>Mastodon Bot</li> <li>Meanpath Bot</li> <li>MetaInspector</li> <li>MetaJobBot</li> <li>Mixrank Bot</li> <li>MJ12 Bot</li> <li>Mnogosearch</li> <li>MojeekBot</li> <li>Monitor.Us</li> <li>Munin</li> <li>Nagios check_http</li> <li>NalezenCzBot</li> <li>nbertaupete95</li> <li>Netcraft Survey Bot</li> <li>netEstate</li> <li>NetLyzer FastProbe</li> <li>NetResearchServer</li> <li>Netvibes</li> <li>NewsBlur</li> <li>NewsGator</li> <li>NLCrawler</li> <li>Nmap</li> <li>Nutch-based Bot</li> <li>Nuzzel</li> <li>oBot</li> <li>Octopus</li> <li>Omgili bot</li> <li>Openindex Spider</li> <li>OpenLinkProfiler</li> <li>OpenWebSpider</li> <li>Orange Bot</li> <li>Outbrain</li> <li>PagePeeker</li> <li>PaperLiBot</li> <li>Phantomas</li> <li>PHP Server Monitor</li> <li>Picsearch bot</li> <li>Pingdom Bot</li> <li>Pinterest</li> <li>PocketParser</li> <li>Pompos</li> <li>PritTorrent</li> <li>QuerySeekerSpider</li> <li>Quora Link Preview</li> <li>Qwantify</li> <li>Rainmeter</li> <li>RamblerMail Image Proxy</li> <li>Reddit Bot</li> <li>Riddler</li> <li>Rogerbot</li> <li>ROI Hunter</li> <li>RSSRadio Bot</li> <li>SafeDNSBot</li> <li>Scooter</li> <li>ScoutJet</li> <li>Scrapy</li> <li>Screaming Frog SEO Spider</li> <li>ScreenerBot</li> <li>Semrush Bot</li> <li>Sensika Bot</li> <li>Sentry Bot</li> <li>SEOENGBot</li> <li>SEOkicks-Robot</li> <li>Seoscanners.net</li> <li>Server Density</li> <li>Seznam Bot</li> <li>Seznam Email Proxy</li> <li>Seznam Zbozi.cz</li> <li>ShopAlike</li> <li>Shopify Partner</li> <li>ShopWiki</li> <li>SilverReader</li> <li>SimplePie</li> <li>SISTRIX Crawler</li> <li>SISTRIX Optimizer</li> <li>Site24x7 Website Monitoring</li> <li>Siteimprove</li> <li>SiteSucker</li> <li>Sixy.ch</li> <li>Skype URI Preview</li> <li>Slackbot</li> <li>SMTBot</li> <li>Snapchat Proxy</li> <li>Sogou Spider</li> <li>Soso Spider</li> <li>Sparkler</li> <li>Speedy</li> <li>Spinn3r</li> <li>Spotify</li> <li>Sputnik Bot</li> <li>sqlmap</li> <li>SSL Labs</li> <li>Startpagina Linkchecker</li> <li>StatusCake</li> <li>Superfeedr Bot</li> <li>Survey Bot</li> <li>Tarmot Gezgin</li> <li>TelegramBot</li> <li>The Knowledge AI</li> <li>theoldreader</li> <li>TinEye Crawler</li> <li>Tiny Tiny RSS</li> <li>TLSProbe</li> <li>TraceMyFile</li> <li>Trendiction Bot</li> <li>TurnitinBot</li> <li>TweetedTimes Bot</li> <li>Tweetmeme Bot</li> <li>Twingly Recon</li> <li>Twitterbot</li> <li>UkrNet Mail Proxy</li> <li>UniversalFeedParser</li> <li>Uptimebot</li> <li>Uptime Robot</li> <li>URLAppendBot</li> <li>Vagabondo</li> <li>Visual Site Mapper Crawler</li> <li>VK Share Button</li> <li>W3C CSS Validator</li> <li>W3C I18N Checker</li> <li>W3C Link Checker</li> <li>W3C Markup Validation Service</li> <li>W3C MobileOK Checker</li> <li>W3C Unified Validator</li> <li>Wappalyzer</li> <li>WebbCrawler</li> <li>Weborama</li> <li>WebPageTest</li> <li>WebSitePulse</li> <li>WebThumbnail</li> <li>WeSEE:Search</li> <li>WikiDo</li> <li>Willow Internet Crawler</li> <li>WooRank</li> <li>WordPress</li> <li>Wotbox</li> <li>YaCy</li> <li>Yahoo! Cache System</li> <li>Yahoo! Japan BRW</li> <li>Yahoo! Link Preview</li> <li>Yahoo! Slurp</li> <li>Yahoo Gemini</li> <li>Yandex Bot</li> <li>Yeti/Naverbot</li> <li>Yottaa Site Monitor</li> <li>Youdao Bot</li> <li>Yourls</li> <li>Yunyun Bot</li> <li>Zao</li> <li>Ze List</li> <li>zgrab</li> <li>Zookabot</li> <li>ZumBot</li> </ul>"},{"location":"getting_started/processes/workflow/actions/discord_webhook_action/","title":"Discord webhook plugin","text":"<p>This plugin sends discord messages.</p>"},{"location":"getting_started/processes/workflow/actions/discord_webhook_action/#configuration","title":"Configuration","text":"<p>Configuration needs a discord webhook url. Webhooks can be created in discord application. Click settings in the channel  that you would like to send message to.  Then click integrations and webhooks.  Expand webhook list and click  new webhook. Give it a name and copy url. This url should be copied to URL in the configuration JSON.</p> <pre><code>{\n  \"url\": \"https://discord.com/api/webhooks/879132030/kXYSPpId...\",\n  \"timeout\": 10,\n  \"message\": \"Hello {{profile@traits.private.name}}\",\n  \"username\": \"&lt;username&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/discord_webhook_action/#input","title":"Input","text":"<p>This plugin does not process input payload. </p>"},{"location":"getting_started/processes/workflow/actions/discord_webhook_action/#output","title":"Output","text":"<p>This plugin returns either the input payload on response port or and error on error port.</p>"},{"location":"getting_started/processes/workflow/actions/edit_points_in_mautic_action/","title":"Edit points in Mautic plugin","text":"<p>This plugin adds or subtracts points from given contact, based on provided contact ID.</p>"},{"location":"getting_started/processes/workflow/actions/edit_points_in_mautic_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/edit_points_in_mautic_action/#outputs","title":"Outputs","text":"<p>This plugin returns payload on port success if the action was successful, or additional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/edit_points_in_mautic_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/edit_points_in_mautic_action/#form-fields","title":"Form fields","text":"<ul> <li>Mautic resource - select you Mautic resource, containing private and public key with API URL.</li> <li>Action - here define whether you want to add or remove given amount of points.</li> <li>Contact ID - type in the path to the field containing contact's ID.</li> <li>Number of points - type in the number of points that you want to add to or subtract from given contact.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/edit_points_in_mautic_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mautic-resource&gt;\",\n    \"name\": \"&lt;name-of-your-mautic-resource&gt;\"\n  },\n  \"action\": \"add | subtract\",\n  \"contact_id\": \"&lt;path-to-id-of-the-contact&gt;\",\n  \"points\": \"&lt;number-of-points-as-string&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/edit_segment_in_mautic_action/","title":"Edit segment in Mautic plugin","text":"<p>This plugin removes or adds given contact to defined segment in Mautic.</p>"},{"location":"getting_started/processes/workflow/actions/edit_segment_in_mautic_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/edit_segment_in_mautic_action/#outputs","title":"Outputs","text":"<p>This plugin returns given payload on port success if everything went OK, or some additional error info on port error if an error occurs.</p>"},{"location":"getting_started/processes/workflow/actions/edit_segment_in_mautic_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/edit_segment_in_mautic_action/#form-fields","title":"Form fields","text":"<ul> <li>Mautic resource - select your Mautic resource, containing private and public key.</li> <li>Action - define if you want to add or remove given contact from the given segment.</li> <li>Contact ID - type in the path to the field containing ID of the Mautic contact.</li> <li>Segment - type in the ID of the segment that you want to add or remove given contact from.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/edit_segment_in_mautic_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mautic-resource&gt;\",\n    \"name\": \"&lt;name-of-your-mautic-resource&gt;\"\n  },\n  \"action\": \"add | remove\",\n  \"contact_id\": \"&lt;path-to-id-of-the-contact&gt;\",\n  \"segment\": \"&lt;id-of-the-segment&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/","title":"Send bulk e-mail plugin","text":"<p>This plugin sends bulk email via ElasticEmail API.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#requirements","title":"Requirements","text":"<p>You'll need a ElasticEmail account to use this plugin. Then you'll need to generate API key </p> <p>ElasticEmail requires a domain configuration to send e-mails, you'll need to add and configure your domain in ElasticEmail settings. Please refer to ElasticEmail documentation for details.</p> <p>The last thing is your ElasticEmail plan - if you're on the trial version, you are able to send emails only within your own domain, so if your email is examplemail@example.com, then your domain is simply example.com and you can send messages only to emails ending with example.com.</p> <p>To get rid of this restriction, you need a paid plan on ElasticEmail.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#input","title":"Input","text":"<p>This plugin takes any payload.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#output","title":"Output","text":"<p>This plugin returns a response from ElasticEmail API. Depending on the response result it will trigger ether payload  port (if the response is successful) or error for if the response indicates that the e-mail was not sent.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#config","title":"Config","text":"<p>Plugin's configuration requires information about API key, sender email,  message recipient's email(s), message subject and message content.</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-elastic-email-resource&gt;\",\n    \"name\": \"&lt;name-of-your-elastic-email-resource&gt;\"\n  },\n  \"sender_email\": \"sender@tracardi.com\",\n  \"message\": {\n    \"recipient\": \"payload@email\",\n    \"content\": {\n      \"type\": \"text/html\",\n      \"content\": \"Message body\"\n    },\n    \"subject\": \"subject\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#elasticemail-resource","title":"ElasticEmail resource","text":"<p>ElasticEmail token must be stored in Tracardis resources. Please remember to provide both test and production API key  (token) in resource configuration.</p> <p>ElasticEmail API Tokens can be found in settings -&gt; SMTP &amp; API Info on  It is a string with random characters.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#senders-e-mail","title":"Sender's e-mail","text":"<p>That's the email that you want to send emails from. It has to end with one of your domains registered in ElasticEmail. For instance, if your shop is exampleshop.com,  then you may want to send emails from an address like office@exampleshop.com, and then that's the value that you want to insert into plugin configuration. Please notice that this address does not have to exist.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#message-recipients-email","title":"Message recipient's email","text":"<p>This is the destination email or emails. It can be in form of dot path to email address (for example profile@data.contact.email.main).  You can also insert the address itself. Please notice that merged profiles can have multiple values in one field -  if John Doe has two or more email addresses in his profile, then plugin will send the message to all of them.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#message-subject","title":"Message subject","text":"<p>That's message subject, if you type in payment, then recipient of the message will see  payment as the subject of received message.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#message-content","title":"Message content","text":"<p>You can select if your content should be HTML or just plain text.  You can also use templates for your emails - both in HTML and text format. </p> <p>Examples:</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#example-1-plain-text","title":"Example 1 - plain text","text":"<pre><code>Hello {{profile@pii.name}}, your order will be dispatched in next two days.\n</code></pre> <p>This message will have the {{profile@pii.name}} changed to the current profile's name, so John Doe will see 'Hello John, your order will be dispatched in next two days.' in his message.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#example-2-html","title":"Example 2 - HTML","text":"<p><pre><code>&lt;h1&gt;Hello {{profile@pii.name}}!&lt;/h1&gt;\n&lt;p&gt;Thanks for visiting our website on {{profile@metadata.time.visit.last}}!&lt;/p&gt;\n&lt;p style=\"color:red\"&gt;To thank you, we send you a photo of cute dog. Enjoy:&lt;/p&gt;\n&lt;img src=\"&lt;url-to-photo-of-cute-dog&gt;\"/&gt;\n</code></pre> Like before, recipient will see his name in the header, and the text with date of his last visit, together with the red text about a photo of a dog, and a photo itself.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_bulk_action/#tip","title":"Tip","text":"<p>On ElasticEmail site, you can turn on the test mode after clicking on you username in up-right corner. In the test mode, you can generate test API key. You can use it in Tracardi for test purposes -  messages won't be sent, but ElasticEmail will act like they are, so you can test your configuration without being charged a single cent.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_change_contact_status_action/","title":"Add contact to Elastic Email plugin","text":"<p>This plugin adds new contact to Elastic Email, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_change_contact_status_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_change_contact_status_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from Elastic Email API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_change_contact_status_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/elastic_email_change_contact_status_action/#form-fields","title":"Form fields","text":"<ul> <li>Elastic Email resource - please select your Elastic Email resource. It should contain:</li> <li>Elastic Email Client api key</li> <li>Email address - please type in the path to the email address you want the status changed.</li> <li>Status - Please put the NUMBER for the status you want. 2=Unsubscribe  https://elasticemail.com/developers/api-documentation/web-api-v2#classes_ContactStatus</li> </ul>"},{"location":"getting_started/processes/workflow/actions/elastic_email_change_contact_status_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-elastic-email-resource&gt;\",\n    \"name\": \"&lt;name-of-your-elastic-email-resource&gt;\"\n  },\n  \"email\": \"&lt;path-to-email-of-new-contact&gt;\",\n  \"status\": 2\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/elastic_email_contact_action/","title":"Elastic email contact action","text":"<p>Documentation not provided by the author. </p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_contact_add_action/","title":"Add contact to Elastic Email plugin","text":"<p>This plugin adds new contact to Elastic Email, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_contact_add_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_contact_add_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from Elastic Email API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_contact_add_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/elastic_email_contact_add_action/#form-fields","title":"Form fields","text":"<ul> <li>Elastic Email resource - please select your Elastic Email resource. It should contain:</li> <li>Elastic Email Client Public Account ID</li> <li>Email address - please type in the path to the email address of your new contact.</li> <li>Additional fields - you can add optional mapping for your contact, for example lastname:   profile@traits.public.surname. Remember to use field aliases from Elastic Email. https://elasticemail.com/developers/api-documentation/web-api-v2#Contact_Add</li> </ul>"},{"location":"getting_started/processes/workflow/actions/elastic_email_contact_add_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-elastic-email-resource&gt;\",\n    \"name\": \"&lt;name-of-your-elastic-email-resource&gt;\"\n  },\n  \"email\": \"&lt;path-to-email-of-new-contact&gt;\",\n  \"additional_mapping\": {\n    \"field_country\": \"&lt;path-to-country-data&gt;\",\n    \"firstName\": \"&lt;path-to-first-name&gt;\",\n    \"lastName\": \"&lt;path-to-last-name&gt;\",\n    \"...\": \"...\"\n  },\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/","title":"Send transactional e-mail plugin","text":"<p>This plugin sends transactional email via ElasticEmail API.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#requirements","title":"Requirements","text":"<p>You'll need a ElasticEmail account to use this plugin. Then you'll need to generate API key </p> <p>ElasticEmail requires a domain configuration to send e-mails, you'll need to add and configure your domain in ElasticEmail settings. Please refer to ElasticEmail documentation for details.</p> <p>The last thing is your ElasticEmail plan - if you're on the trial version, you are able to send emails only within your own domain, so if your email is examplemail@example.com, then your domain is simply example.com and you can send messages only to emails ending with example.com.</p> <p>To get rid of this restriction, you need a paid plan on ElasticEmail.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#input","title":"Input","text":"<p>This plugin takes any payload.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#output","title":"Output","text":"<p>This plugin returns a response from ElasticEmail API. Depending on the response result it will trigger ether payload  port (if the response is successful) or error for if the response indicates that the e-mail was not sent.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#config","title":"Config","text":"<p>Plugin's configuration requires information about API key, sender email,  message recipient's email(s), message subject and message content.</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-elastic-email-resource&gt;\",\n    \"name\": \"&lt;name-of-your-elastic-email-resource&gt;\"\n  },\n  \"sender_email\": \"sender@tracardi.com\",\n  \"message\": {\n    \"recipient\": \"payload@email\",\n    \"content\": {\n      \"type\": \"text/html\",\n      \"content\": \"Message body\"\n    },\n    \"subject\": \"subject\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#elasticemail-resource","title":"ElasticEmail resource","text":"<p>ElasticEmail token must be stored in Tracardi's resources. Please remember to provide both test and production API key  (token) in resource configuration.</p> <p>ElasticEmail API Tokens can be found in settings -&gt; SMTP &amp; API Info on  It is a string with random characters.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#senders-e-mail","title":"Sender's e-mail","text":"<p>That's the email that you want to send emails from. It has to end with one of your domains registered in ElasticEmail. For instance, if your shop is exampleshop.com,  then you may want to send emails from an address like office@exampleshop.com, and then that's the value that you want to insert into plugin configuration. Please notice that this address does not have to exist.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#message-recipients-email","title":"Message recipient's email","text":"<p>This is the destination email or emails. It can be in form of dot path to email address (for example profile@data.contact.email.main).  You can also insert the address itself. Please notice that merged profiles can have multiple values in one field -  if John Doe has two or more email addresses in his profile, then plugin will send the message to all of them.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#message-subject","title":"Message subject","text":"<p>That's message subject, if you type in payment, then recipient of the message will see  payment as the subject of received message.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#message-content","title":"Message content","text":"<p>You can select if your content should be HTML or just plain text.  You can also use templates for your emails - both in HTML and text format. </p> <p>Examples:</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#example-1-plain-text","title":"Example 1 - plain text","text":"<pre><code>Hello {{profile@pii.name}}, your order will be dispatched in next two days.\n</code></pre> <p>This message will have the {{profile@pii.name}} changed to the current profile's name, so John Doe will see 'Hello John, your order will be dispatched in next two days.' in his message.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#example-2-html","title":"Example 2 - HTML","text":"<p><pre><code>&lt;h1&gt;Hello {{profile@pii.name}}!&lt;/h1&gt;\n&lt;p&gt;Thanks for visiting our website on {{profile@metadata.time.visit.last}}!&lt;/p&gt;\n&lt;p style=\"color:red\"&gt;To thank you, we send you a photo of cute dog. Enjoy:&lt;/p&gt;\n&lt;img src=\"&lt;url-to-photo-of-cute-dog&gt;\"/&gt;\n</code></pre> Like before, recipient will see his name in the header, and the text with date of his last visit, together with the red text about a photo of a dog, and a photo itself.</p>"},{"location":"getting_started/processes/workflow/actions/elastic_email_transactional_action/#tip","title":"Tip","text":"<p>On ElasticEmail site, you can turn on the test mode after clicking on you username in up-right corner. In the test mode, you can generate test API key. You can use it in Tracardi for test purposes -  messages won't be sent, but ElasticEmail will act like they are, so you can test your configuration without being charged a single cent.</p>"},{"location":"getting_started/processes/workflow/actions/elasticsearch_query_action/","title":"Elasticsearch query plugin","text":"<p>This plugin fetches data from Elasticsearch.</p>"},{"location":"getting_started/processes/workflow/actions/elasticsearch_query_action/#requirements","title":"Requirements","text":"<p>It requires a configured Elasticsearch resource in Tracardi. You will have to provide the following information to connect to elastic:</p> <pre><code>{\n  \"url\": \"&lt;url&gt;\",\n  \"port\": 9200,\n  \"scheme\": \"http\",\n  \"username\": \"&lt;username&gt;\",\n  \"password\": \"&lt;password&gt;\",\n  \"verify_certs\": true\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/elasticsearch_query_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/elasticsearch_query_action/#output","title":"Output","text":"<p>This plugin returns search result on port result if search was successful, or empty payload on port error if error occurs.  </p>"},{"location":"getting_started/processes/workflow/actions/elasticsearch_query_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/elasticsearch_query_action/#form-fields","title":"Form fields","text":"<ul> <li>Elasticsearch resource - your Elasticsearch resource.</li> <li>Elasticsearch index - name of the index you wish to search.</li> <li>Query - DSL query to search with configured index.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/elasticsearch_query_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"&lt;name-of-your-elasticsearch-resource&gt;\",\n    \"id\": \"&lt;your-elasticsearch-resource-id&gt;\"\n  },\n  \"index\": \"&lt;name-of-your-index&gt;\",\n  \"query\": &lt;your-dsl-query&gt;\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/end/","title":"End","text":"<p>The End plugin can be used to terminate the workflow. It is designed to wrap the entire process of a workflow and provide the last action.</p>"},{"location":"getting_started/processes/workflow/actions/end/#version","title":"Version","text":"<p>The current plugin version is 0.1.</p>"},{"location":"getting_started/processes/workflow/actions/end/#description","title":"Description","text":"<p>End plugin functions as a termination point for the workflow, halting the flow of data. The operation inside the 'run' method of this plugin is simple: it accepts a payload as an input and does not return anything, signifying the end of the workflow. The plugin does not modify the execution graph which means there's no update to the internal state of the workflow (event, profile, session).</p>"},{"location":"getting_started/processes/workflow/actions/end/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The End plugin has one input port:</p> <ul> <li>payload: This port accepts a payload object. An example of a payload object can be a dictionary that holds data   passed in the workflow.</li> </ul> <p>This plugin does not generate any output, hence no output ports.</p>"},{"location":"getting_started/processes/workflow/actions/end/#configuration","title":"Configuration","text":"<p>The End plugin does not require any configuration. Its functionality is predefined.</p>"},{"location":"getting_started/processes/workflow/actions/end/#json-configuration","title":"JSON Configuration","text":"<p>No configuration is required for this plugin, thus no JSON example is provided.</p>"},{"location":"getting_started/processes/workflow/actions/end/#required-resources","title":"Required resources","text":"<p>The End plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/end/#errors","title":"Errors","text":"<p>The End plugin does not throw any specific exceptions.</p>"},{"location":"getting_started/processes/workflow/actions/ends_with_action/","title":"EndsWith Plugin","text":"<p>This plugin checks if data field ends with defined prefix.</p>"},{"location":"getting_started/processes/workflow/actions/ends_with_action/#json-configuration","title":"JSON Configuration","text":"<p>Example input:</p> <pre><code>{\n  \"field\": \"payload@field\",\n  \"prefix\": \"string\"\n}\n</code></pre> <p>Output:</p> <p>Plugin outputs the payload on ports TRUE if field contains prefix or FALSE if otherwise.</p>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/","title":"Event counter","text":"<p>This plugin reads how many events of a defined type were triggered within a defined time.</p>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/#description","title":"Description","text":"<p>The Event counter plugin is designed to count the number of events of a specific type that occurred within a specified time frame. It retrieves the event count based on the provided configuration and returns the result.</p> <p>This documentation is based on version 0.8.1 of the Event counter plugin.</p>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/event_counter_action/#inputs","title":"Inputs","text":"<p>The Event counter plugin accepts the following input:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/#outputs","title":"Outputs","text":"<p>The Event counter plugin provides the following outputs:</p> <ul> <li>payload: Returns the number of events of the defined type.</li> </ul> <p>Example output:</p> <pre><code>{\n  \"events\": 39\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/#configuration","title":"Configuration","text":"<p>The Event counter plugin supports the following configuration parameters:</p> <ul> <li>Event type: Select the event type you would like to count.</li> <li>Time span: Specify the time span to search for events. Use the format \"-15minutes\" to indicate a time span of 15   minutes in the past.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example JSON configuration for the Event counter plugin:</p> <pre><code>{\n  \"event_type\": \"page-view\",\n  \"time_span\": \"-15m\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/event_counter_action/#errors","title":"Errors","text":"<p>The Event counter plugin may encounter the following errors:</p> <ul> <li>ValueError: Invalid time span: This error occurs when the specified time span is invalid or cannot be parsed.   Ensure that the time span is formatted correctly, such as \"-15m\".</li> <li>Event type not specified: This error occurs when the event type is not provided in the configuration. Make sure to   select an event type from the available options.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/event_scheduler_action/","title":"Event scheduler","text":"<p>This action will schedule an event to be triggered after given time.</p>"},{"location":"getting_started/processes/workflow/actions/event_scheduler_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"event_type\": \"&lt;event-type&gt;\",\n  \"properties\": {},\n  \"postpone\": \"+1m\"\n}\n</code></pre> <ul> <li>event_type - type name of event type. e.g. 'page-view', 'purchase-order'.</li> <li>properties - event properties. This is a regular object with key value pairs. </li> <li>postpone - for how long would you like the event to be postponed. For example 1m means trigger event one minute after the action was executed.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/event_scheduler_action/#input","title":"Input","text":"<p>This node does not process input data</p>"},{"location":"getting_started/processes/workflow/actions/event_scheduler_action/#output","title":"Output","text":"<p>Postponed task details. It will include the event itself with, context,profile, etc.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_ac_contact_by_email_action/","title":"Fetch contact from ActiveCampaign plugin","text":"<p>This plugin fetches ActiveCampaign contact based on given email address.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_ac_contact_by_email_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_ac_contact_by_email_action/#outputs","title":"Outputs","text":"<p>This plugin returns contact data on port result if the contact was found, or error info on port error if an error occurred or the contact was not found.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_ac_contact_by_email_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-activecampaign-resource&gt;\",\n    \"name\": \"&lt;name-of-your-activecampaign-resource&gt;\"\n  },\n  \"email\": \"&lt;path-to-email-address&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/fetch_from_airtable_action/","title":"Fetch data from Airtable plugin","text":"<p>This plugin fetches data from given Airtable table, according to provided query.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_from_airtable_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_from_airtable_action/#output","title":"Output","text":"<p>This plugin returns records on port response if everything is OK, or some error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_from_airtable_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/fetch_from_airtable_action/#form-fields","title":"Form fields","text":"<ul> <li>Airtable resource - here select your Airtable resource, containing your API key.</li> <li>Base ID - here paste in the ID of the Airtable base. You can check it while inspecting your base in Airtable. It looks   like https://airtable.com//... <li>Table name - here simply type in the name of your table in given base.</li> <li>Formula - you can add some query. It's optional and supports dot templates, example:   {profileID} = {{profile@id}} will match every record, where value of profileID field is equal to current **   profile@id** value.</li>"},{"location":"getting_started/processes/workflow/actions/fetch_from_airtable_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-airtable-resource&gt;\",\n    \"name\": \"&lt;name-of-your-airtable-resource&gt;\"\n  },\n  \"base_id\": \"&lt;id-of-your-airtable-base&gt;\",\n  \"table_name\": \"&lt;name-of-your-airtable-table&gt;\",\n  \"formula\": \"&lt;optional-query-formula&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/fetch_from_influxdb_action/","title":"Fetch from InfluxDB plugin","text":"<p>This plugin fetches data from InfluxDB resource.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_from_influxdb_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_from_influxdb_action/#output","title":"Output","text":"<p>Plugin returns fetched records on port success, or object with some error info on error port if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_from_influxdb_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/fetch_from_influxdb_action/#form-fields","title":"Form fields","text":"<ul> <li>InfluxDB resource - InfluxDB resource, containing your token and database URL to the database instance.</li> <li>Organization - The name of your organization, it is the equivalent of database instance.</li> <li>Bucket - The name of the bucket that you want to write to.</li> <li>Filters - Insert key-value pairs. Key is the name of your field in InfluxDB, and value is its value. If values match,   then the record will be returned from InfluxDB.</li> <li>Lower time bound - That's the lower time bound of your search. It can be either relative (so for example -1d), or   fixed (2022-01-12). Path notation is fully supported.</li> <li>Upper time bound - That is the upper time bound of your search. It can be relative or fixed, path is supported as   well.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/fetch_from_influxdb_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-influxdb-resource&gt;\",\n    \"name\": \"&lt;name-of-your-trello-resource&gt;\"\n  },\n  \"organization\": \"&lt;name-of-your-influxdb-organization&gt;\",\n  \"bucket\": \"&lt;name-of-your-influxdb-bucket&gt;\",\n  \"filters\": {\n    \"&lt;field-name-1&gt;\": \"payload@example.value\",\n    \"&lt;field-name-2&gt;\": \"1\"\n  },\n  \"start\": \"&lt;lower-time-bound-for-searching&gt;\",\n  \"stop\": \"&lt;upper-time-bound-for-searching&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_email_action/","title":"Fetch Mautic contact by email plugin","text":"<p>This plugin fetches a contact from Mautic, based on provided contact email.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_email_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_email_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from Mautic API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_email_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_email_action/#form-fields","title":"Form fields","text":"<ul> <li>Mautic resource - please select your Mautic resource. It should contain:<ul> <li>Mautic API URL</li> <li>Mautic Client private key</li> <li>Mautic Client public key</li> </ul> </li> <li>Contact email address - please type in the path to the email address of the contact that you want to fetch.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_email_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mautic-resource&gt;\",\n    \"name\": \"&lt;name-of-your-mautic-resource&gt;\"\n  },\n  \"contact_email\": \"&lt;path-to-contact-email-address&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_id_action/","title":"Fetch Mautic contact by ID plugin","text":"<p>This plugin fetches a contact from Mautic, based on provided contact ID.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_id_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_id_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from Mautic API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_id_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_id_action/#form-fields","title":"Form fields","text":"<ul> <li>Mautic resource - please select your Mautic resource. It should contain:<ul> <li>Mautic API URL</li> <li>Mautic Client private key</li> <li>Mautic Client public key</li> </ul> </li> <li>Contact ID - please type in the path to ID of the contact that you want to fetch.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/fetch_mautic_contact_by_id_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mautic-resource&gt;\",\n    \"name\": \"&lt;name-of-your-mautic-resource&gt;\"\n  },\n  \"contact_id\": \"&lt;path-to-contact-id&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/fetch_mixpanel_funnel_action/","title":"Fetch funnel from MixPanel plugin","text":"<p>This plugin fetches funnel created in MixPanel, for current profile. </p>"},{"location":"getting_started/processes/workflow/actions/fetch_mixpanel_funnel_action/#requirements","title":"Requirements","text":"<p>This plugin requires MixPanel account with created project, and a service account created for this project. Credentials for the service account must be included in  resource, as well as server prefix (either EU or US).</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mixpanel_funnel_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mixpanel_funnel_action/#outputs","title":"Outputs","text":"<p>This plugin outputs fetched funnel on port success, or an error message (if it's known one) on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/fetch_mixpanel_funnel_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/fetch_mixpanel_funnel_action/#form-fields","title":"Form fields","text":"<ul> <li>MixPanel resource - Select your MixPanel resource, containing service account username, password   and server prefix.</li> <li>Project ID - Here paste your MixPanel project ID. You can find it under Settings &gt; Project settings &gt;    .  <li>Funnel ID - Paste in your MixPanel funnel ID. You can find it in URL when    inspecting your funnel (...app/funnels#view//...). <li>Lower time bound - Here type in the path to the date (or the date itself). That will   the lower time bound for your funnel. It can be a timestamp, a datetime, or a string in form of YYYY-MM-DD.   Other formats are not supported.</li> <li>Upper time bound - That's the upper bound for your funnel. It's optional. It works according to same rules   as Lower time bound.</li>"},{"location":"getting_started/processes/workflow/actions/fetch_mixpanel_funnel_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mixpanel-resource&gt;\",\n    \"name\": \"&lt;name-of-your-mixpanel-resource&gt;\"\n  },\n  \"project_id\": \"&lt;id-of-your-mixpanel-project&gt;\",\n  \"funnel_id\": \"&lt;id-of-your-mixpanel-funnel&gt;\",\n  \"from_date\": \"&lt;path-to-lower-time-bound&gt;\",\n  \"to_date\": \"&lt;optional-path-to-upper-time-bound&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/field_type_action/","title":"Get field type plugin","text":"<p>This plugin returns type and length (if it exists) of the given field.</p>"},{"location":"getting_started/processes/workflow/actions/field_type_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"field\": \"event@reference.path.here\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/field_type_action/#example-of-returned-value","title":"Example of returned value","text":"<pre><code>{\n  \"type\": \"string\",\n  \"length\": 14\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/fullcontact_webhook_action/","title":"Full contact webhook","text":"<p>FullContact.com is an Identity Resolution Platform. It allows you to resolve and enrich people by submitting any identifiers you already have, such as a personal email address, work email address, phone number, name and home address, social ID, social URL and social username (except Facebook and Instagram).</p> <p>In order to use FullContact you wil have to obtain an API_KEY that will allow you to access FullContact API. To do that go to fullcontact.com, register and follow the steps on the page.</p>"},{"location":"getting_started/processes/workflow/actions/fullcontact_webhook_action/#configuration","title":"Configuration","text":"<p>Example of configuration.</p> <pre><code>{\n  \"source\": {\n    \"id\": \"resource-id\"\n  },\n  \"pii\": {\n    \"email\": \"email@email.com\",\n    \"emails\": [\n      \"email1@email.com\",\n      \"email2@email.com\"\n    ],\n    \"phone\": \"+1838747734\",\n    \"phones\": [\n      \"+1838747734\",\n      \"+1838747735\"\n    ],\n    \"location\": null,\n    \"name\": \"Adam\"\n  }\n}\n</code></pre> <p>Configuration schema description</p> <ul> <li><code>resource-id</code> must be valid id from resource list that points to FullContact api key. Please see below the schema of   the credentials.</li> <li><code>pii</code> does not need all the data from example. It is ok to provide only <code>e-mail</code> or <code>phone</code>.</li> </ul> <p>Example of FullContact resource credentials</p> <p>Use <code>api-token</code> type of resource to configure fullcontact credentials.</p> <pre><code>{\n  \"token\": \"&lt;API_KEY&gt;\"\n}\n</code></pre> <p><code>&lt;API_KEY&gt;</code> must be replaced by API_KEY provided by FullContact service.</p> <p>Example of <code>pii</code> data</p> <p>This configuration is valid too:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;resource-id&gt;\"\n  },\n  \"pii\": {\n    \"email\": \"email@email.com\"\n  }\n}\n</code></pre> <p>The more data you provide th better as FullContact will be able to match the person more precisely.</p> <p>You can use dotted notation to access data from profile or event. This can be done like this.</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;resource-id&gt;\"\n  },\n  \"pii\": {\n    \"email\": \"profile@traits.private.email\"\n  }\n}\n</code></pre> <p>String <code>profile@traits.private.email</code> will be replaced with the value (path to value <code>traits.private.email</code>) from profile.</p>"},{"location":"getting_started/processes/workflow/actions/fullcontact_webhook_action/#input","title":"Input","text":"<p>This action does not need payload.</p>"},{"location":"getting_started/processes/workflow/actions/fullcontact_webhook_action/#output","title":"Output","text":"<p>If the connection to FullContact was successful the port payload will return the response data.  Otherwise, the payload port will be inactive and the error message will be returned on error port. </p> <p>Example of successful response on port payload</p> <pre><code>{\n  \"status\": 200,\n  \"body\": {\n    \"fullName\": \"Kazi Amki\",\n    \"ageRange\": null,\n    \"gender\": \"Male\",\n    \"location\": \"Sao Paulo\",\n    \"title\": \"Film Writer\",\n    \"organization\": \"Freelance\",\n    \"linkedin\": null,\n    \"facebook\": null,\n    \"bio\": null,\n    \"website\": null,\n    \"details\": {\n      \"name\": {\n        \"given\": \"Kazi\",\n        \"family\": \"Amki\",\n        \"full\": \"Kazi Amki\"\n      },\n      \"age\": null,\n      \"gender\": \"Male\",\n      \"demographics\": {\n        \"gender\": \"Male\"\n      },\n      \"emails\": [],\n      \"phones\": [],\n      \"locations\": [\n        {\n          \"region\": \"Sao Paulo\",\n          \"country\": \"Brazil\",\n          \"countryCode\": \"BR\",\n          \"formatted\": \"Sao Paulo\"\n        }\n      ],\n      \"employment\": [\n        {\n          \"name\": \"Freelance\",\n          \"current\": true,\n          \"title\": \"Film Writer\"\n        }\n      ],\n      \"photos\": [],\n      \"education\": [\n        {\n          \"name\": \"ECA - USP\",\n          \"degree\": \"Publishing\"\n        }\n      ],\n      \"urls\": [],\n      \"interests\": []\n    },\n    \"updated\": \"2021-06-16\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/geo_distance/","title":"Geo distance","text":"<p>This plugin is used to calculate the geographical distance between two points: the start point and the end point. Those points are represented by their geographical coordinates (latitude and longitude). </p>"},{"location":"getting_started/processes/workflow/actions/geo_distance/#version","title":"Version","text":"<p>The documentation is valid for the plugin version 0.6.1. </p>"},{"location":"getting_started/processes/workflow/actions/geo_distance/#description","title":"Description","text":"<p>The Geo distance plugin is designed to calculate the distance between two geographical points which are specified using their latitude and longitude coordinates. The starting coordinates are predefined in the plugin\u2019s configuration, while the ending coordinates can be specified in each run of the plugin, which allows for processing different locations within a single configuration of the plugin.</p> <p>The result of the plugin's execution is a measurement of the distance in kilometers between the starts and end points. This distance is returned via the \"payload\" port. </p>"},{"location":"getting_started/processes/workflow/actions/geo_distance/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Geo distance plugin has one input port and one output port: - The input port is named \"payload\". It accepts a dictionary with keys that correspond to the latitude and longitude of the end point. - The output port is named \"payload\". It returns a dictionary containing a single key \"distance\" with the calculated distance in kilometers as its value.</p> <p>The plugin cannot start the workflow, so it needs some data provided by the previous action in the workflow via the \"payload\" port.</p>"},{"location":"getting_started/processes/workflow/actions/geo_distance/#configuration","title":"Configuration","text":"<p>The configuration of Geo distance comprises two parts, which are the geographical coordinates for the start point:</p> <ul> <li>The start_coordinate.lat: the latitude of the start point.</li> <li>The start_coordinate.lng: the longitude of the start point.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/geo_distance/#json-configuration","title":"JSON Configuration","text":"<p><pre><code>{\n    \"start_coordinate\": {\n        \"lat\": \"52.228847\",\n        \"lng\": \"21.003748\"\n    }\n}\n</code></pre> In the above JSON configuration example, the start point is set to the coordinates of Warsaw, Poland.</p>"},{"location":"getting_started/processes/workflow/actions/geo_distance/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/geo_distance/#errors","title":"Errors","text":"<p>Currently, this plugin does not generate errors. However, given the nature of geographical coordinates, it's essential to ensure the input values fall within the valid range. That is, latitude should be a value between -90 and 90 and longitude should be a value between -180 and 180. If the plugin receives invalid coordinates, the calculated distance may be incorrect.</p>"},{"location":"getting_started/processes/workflow/actions/geo_ip_locator/","title":"GeoLite2 Plugin","text":"<p>The \"GeoLite2\" plugin in Tracardi connects to GeoIP servers and provides location information based on the provided IP address. This plugin is useful for retrieving geographical data about customers or users.</p>"},{"location":"getting_started/processes/workflow/actions/geo_ip_locator/#json-configuration","title":"JSON Configuration","text":"<p>The configuration for the \"GeoLite2\" plugin is specified in JSON format. Here is an example configuration:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"5600c92a-835d-4fbe-a11d-7076fd983434\"\n  },\n  \"ip\": \"payload@ip\"\n}\n</code></pre> <p>In the configuration, you need to provide the ID of the source that has the configured GeoLite2 server credentials. The <code>ip</code> field specifies the path to the IP value in the profile, payload, or event, or it can be an IP address itself.</p>"},{"location":"getting_started/processes/workflow/actions/geo_ip_locator/#resource-configuration","title":"Resource Configuration","text":"<p>To run the \"GeoLite2\" plugin, you must provide a source configuration that contains the credentials for the GeoLite2 API. The source configuration for the GeoLite2 API should include the following information:</p> <pre><code>{\n  \"host\": \"geolite.info\",\n  \"license\": \"&lt;license-key&gt;\",\n  \"accountId\": \"&lt;account-id&gt;\"\n}\n</code></pre> <p>You need to replace <code>&lt;license-key&gt;</code> and <code>&lt;account-id&gt;</code> with the actual values provided by MaxMind for your GeoLite2 API access.</p>"},{"location":"getting_started/processes/workflow/actions/geo_ip_locator/#output","title":"Output","text":"<p>The output of the \"GeoLite2\" plugin is a JSON object that provides the following location information:</p> <pre><code>{\n  \"city\": \"&lt;city&gt;\",\n  \"country\": {\n    \"name\": \"&lt;country&gt;\",\n    \"code\": \"&lt;country-code&gt;\"\n  },\n  \"county\": \"&lt;county&gt;\",\n  \"postal\": \"&lt;code&gt;\",\n  \"latitude\": 52.0979,\n  \"longitude\": 18.2016\n}\n</code></pre> <p>The <code>city</code> field represents the city name, the <code>country</code> field provides the country name and country code, the <code>county</code> field specifies the county name, the <code>postal</code> field contains the postal code, and the <code>latitude</code> and <code>longitude</code> fields represent the geographical coordinates of the location.</p> <p>Please refer to the Tracardi documentation for more information on how to configure and use the \"GeoLite2\" plugin.</p>"},{"location":"getting_started/processes/workflow/actions/geo_ip_locator/#plugin-configuration","title":"Plugin Configuration","text":"<p>The \"GeoIP Action\" plugin has the following configuration options:</p> <ul> <li> <p>Maxmind Geolite2 connection resource: This option allows you to select a Maxmind Geolite2 server resource. The   credentials from the selected resource will be used to connect to the GeoIP service.</p> </li> <li> <p>Path to IP: In this field, you can specify the path to the IP data in the payload or directly provide the IP   address itself. The plugin will use this IP address to fetch the location information.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/geo_ip_locator/#plugin-outputs","title":"Plugin Outputs","text":"<p>The \"GeoIP Action\" plugin has two output ports:</p> <ul> <li> <p>location: This port returns the location information as a result of converting the IP address. The location   information includes the city, country name, country code, county, postal code, latitude, and longitude.</p> </li> <li> <p>error: If an error occurs during the execution of the plugin, this port will be triggered. The payload and the   error message will be provided in the output.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/geo_ip_locator/#example-usage","title":"Example Usage","text":"<p>Here's an example of how the \"GeoIP Action\" plugin can be used:</p> <pre><code>- geoip_action:\n    source:\n      id: \"5600c92a-835d-4fbe-a11d-7076fd983434\"\n    ip: \"event@request.ip\"\n</code></pre> <p>In this example, the plugin is configured to use a Maxmind Geolite2 server resource with the specified ID. It retrieves the IP address from the \"event@request.ip\" field and converts it to location information. The location data is returned on the \"location\" port.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/","title":"Get Event Source Plugin","text":"<p>The Get Event Source Plugin is part of the Input/Output group and is primarily used for tasks related to data collection or segmentation. Its function is to read the source that the event came from.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/#version","title":"Version","text":"<p>The current version of this plugin is 0.6.0.1.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/#description","title":"Description","text":"<p>The Get Event Source Plugin is designed to read and return the source from which the event originated. It does this by loading the id of the source associated with the event.</p> <p>In the event where the source does not exist, the plugin returns an error message indicating that the source does not exist. If the source is found, the plugin proceeds to return a dump of the loaded source model.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin only accepts one input port, named \"payload\". As for the output ports, the plugin offers two; 'source' and ' error'.</p> <ul> <li>The Input, \"payload\", reads a payload object.</li> <li>The Output, \"source\", gives back the data of the source in case it is found and loaded successfully.</li> <li>The Output, \"error\", returns an error message in case the source is not found or another error occurs during the   process of loading the source.</li> </ul> <p>This plugin does not initiate the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/#configuration","title":"Configuration","text":"<p>This plugin does not require any configuration.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/#json-configuration","title":"JSON Configuration","text":"<p>Since this plugin does not require any configuration, no configuration example is provided.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/#required-resources","title":"Required resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/get_event_source/#errors","title":"Errors","text":"<p>Error that might be encountered during the operation of this Plugin is:</p> <ul> <li>\"Source {} does not exist.\": This indicates that the source associated with the event's id does not exist in the   system. This error occurs when one tries to load a non-existing source.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/","title":"Load Integration Id","text":"<p>This plugin helps in synchronizing profile IDs between Tracardi and external systems. If your profiles have identifiers in external systems, this plugin allows you to retrieve the connection between these systems and update the Tracardi profile with the external ID.</p>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#description","title":"Description","text":"<p>When executed, this plugin attempts to retrieve the integration ID(s) for the current profile based on the specified external system name. The system name is processed by lowercasing and replacing spaces with hyphens to match the naming conventions. The plugin can be configured to return either a list of IDs only or the full details of the integration IDs. It has three possible outcomes: returning the found integration IDs, indicating a missing ID, or reporting an error if the retrieval process fails.</p>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin accepts input through the \"payload\" port, which should contain the profile data.</li> <li>Outputs: There are three possible outputs:<ul> <li>payload: Returns the integration ID(s) for the profile if found.</li> <li>missing: Indicates that no integration ID was found for the profile.</li> <li>error: Returns an error message if the plugin encounters an issue during execution.</li> </ul> </li> </ul> <p>This plugin does not initiate workflows but acts within them, processing and returning data based on the profile's integration IDs.</p>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#configuration","title":"Configuration","text":"<ul> <li>External System Name: The name of the external system for which the integration ID should be retrieved. The plugin   converts this name to lowercase and replaces spaces with hyphens.</li> <li>Get only IDs: A boolean option. When true, the plugin returns only the IDs of the integrations. When false, it   returns the full details of the integrations.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"name\": \"example-system\",\n  \"get_ids_only\": true\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#event-prerequisites","title":"Event prerequisites","text":"<p>This plugin works with all types of events and does not require the event to be synchronous. It is not a UIX widget, so it does not wait for the workflow to finish before proceeding.</p>"},{"location":"getting_started/processes/workflow/actions/get_external_id_action/#errors","title":"Errors","text":"<ul> <li>Name can not be empty. This error occurs if the External System Name configuration is left blank. Ensure this   field is filled out with the name of the external system you're trying to integrate with.</li> <li>Generic error message (e.g., \"An unexpected error occurred\"). If the plugin encounters an unexpected issue during   execution, a generic error message will be returned. This could be due to network issues, database access problems, or   other unforeseen errors.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/get_issue/","title":"Get Issue","text":"<p>This plugin is used for getting GitHub issue details.</p>"},{"location":"getting_started/processes/workflow/actions/get_issue/#version","title":"Version","text":"<p>0.7.4</p>"},{"location":"getting_started/processes/workflow/actions/get_issue/#description","title":"Description","text":"<p>The Get Issue action plugin is designed to fetch the details of a specific Github issue. It interacts with the Github API, using the provided credentials to authenticate.</p> <p>The plugin operates based on an initially provided configuration which includes references to the Github repository, owner, desired issue ID and credentials.</p> <p>The plugin works by calling the GitHub API using HTTP. It employs the GET method to retrieve issue details using the issue_id that is acquired from the configuration.</p> <p>Upon successful request, it returns the response, which is the details of the issue from Github. However, if the request fails, the action will return the error from the API call.</p>"},{"location":"getting_started/processes/workflow/actions/get_issue/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin takes a payload object as its input.</p> <p>For outputs, it provides 2 ports:</p> <ul> <li>payload - This output port is triggered when the API call is successful. It returns the details of the issue from   Github.</li> <li>error - This port is triggered when the API call is unsuccessful and returns the error response from the API call.</li> </ul> <p>The Get Issue action cannot commence a workflow. It depends on the input data received from another plugin to execute.</p>"},{"location":"getting_started/processes/workflow/actions/get_issue/#configuration","title":"Configuration","text":"<p>The Get Issue action requires the following configuration:</p> <ul> <li>resource: This field should contain the credentials for the GitHub account.</li> <li>owner: This is the GitHub username. The GitHub username is used to establish a connection to the correct GitHub   account.</li> <li>repo: This is the name of the GitHub repository.</li> <li>issue_id: ID of the GitHub issue. This is the ID number of the specific issue to be fetched from Github.</li> <li>timeout: This field allows you to set a timeout value for the call to the GitHub API. The value should be a positive   integer indicating the maximum allowed time (in seconds) to fetch data from the API.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/get_issue/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration in JSON format:</p> <pre><code>{\n  \"resource\": \"your-resource\",\n  \"owner\": \"your-github-username\",\n  \"repo\": \"your-repo-name\",\n  \"issue_id\": \"number-of-the-issue\",\n  \"timeout\": 30\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/get_issue/#required-resources","title":"Required resources","text":"<p>The Get Issue action requires the following resources:</p> <ul> <li>A valid GitHub account with the required access to make API calls.</li> <li>GitHub credentials added to Tracardi in the Resources section.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/get_issue/#errors","title":"Errors","text":"<p>If an error occurred during the run of the plugin, there will be an error output with the response from Github, including the status and an error message. This error may occur if the GitHub API call was unsuccessful. This could be due to invalid credentials, an issue with the connection, a non-existent or inaccessible repository or issue, or other reasons that would lead to an unsuccessful HTTP request to the GitHub API.</p>"},{"location":"getting_started/processes/workflow/actions/get_prev_event_action/","title":"Get previous event plugin","text":"<p>This plugin injects into payload one of the previous events from the current profile, according to given offset and event type.</p>"},{"location":"getting_started/processes/workflow/actions/get_prev_event_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/get_prev_event_action/#outputs","title":"Outputs","text":"<p>This plugin returns event data on port found if the event was found, or input payload on port not_found if the event was not found.</p>"},{"location":"getting_started/processes/workflow/actions/get_prev_event_action/#configuration","title":"Configuration","text":"<ul> <li>Event type - an event type to be loaded into payload.</li> <li>Offset - an offset from current event. 0 will return current event, -1 will return previous one, etc.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/get_prev_event_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"event_type\": \"&lt;type-of-event-to-be-loaded&gt;\",\n  \"offset\": \"&lt;offset-from-current-event&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/get_prev_session_action/","title":"Get Previous Session","text":"<p>The \"Get Previous Session\" plugin in Tracardi is used to load the n-th last session of the current profile and inject it into the payload. This plugin is useful for retrieving information from previous sessions for segmentation and analysis purposes.</p>"},{"location":"getting_started/processes/workflow/actions/get_prev_session_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li> <p>Input: This plugin takes any payload as input.</p> </li> <li> <p>Output Ports:</p> </li> <li>found: This port returns the session information if the session was found.</li> <li>not_found: This port returns the given payload if the session was not found.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/get_prev_session_action/#configuration","title":"Configuration","text":"<p>The \"Get Previous Session\" plugin has the following configuration option:</p> <ul> <li>Offset: This parameter determines the session offset, which is an integer value between -10 and 0 (inclusive). The offset specifies the number of sessions to go back from the current session. For example, an offset of -1 will return the last session, and an offset of -2 will return the second-to-last session.</li> </ul> <p>To configure the plugin, you can use the following JSON format:</p> <pre><code>{\n  \"offset\": \"&lt;number-of-wanted-session-counting-from-current-one&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/get_prev_session_action/#example-usage","title":"Example Usage","text":"<p>Here's an example of how the \"Get Previous Session\" plugin can be used:</p> <pre><code>- get_previous_session:\n    offset: -1\n</code></pre> <p>In this example, the plugin is configured to retrieve the last session of the current profile and inject it into the payload. The session information will be available on the \"found\" port.</p>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/","title":"Ghost","text":"<p>This plugin adds labels to a Ghost member by matching their UUID (a unique identifier) with the corresponding profile in Ghost's database.</p>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#version","title":"Version","text":"<p>This documentation is for version 0.9.0 of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#description","title":"Description","text":"<p>The Ghost plugin connects to your Ghost site to update a member's labels based on their UUID. Here's a step-by-step description of how it works:</p> <ol> <li>It first checks the configuration to ensure it has the necessary API key and member UUID.</li> <li>The plugin generates a token to authenticate with the Ghost API.</li> <li>It retrieves the member's details from Ghost using the provided UUID.</li> <li>The plugin compares the member's current labels with the segments assigned to the profile in Tracardi.</li> <li>If the labels and segments match, no update is needed, and it simply returns the current labels.</li> <li>If there is a mismatch, the plugin updates the member's labels in Ghost to match the profile's segments in Tracardi.</li> <li>The plugin then returns the updated labels and a response from the Ghost service.</li> </ol>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin takes a payload object, which should include the member's UUID and potentially other data from   Tracardi's internal state.</li> <li>Outputs: There are two possible outputs:<ul> <li>Result: Returns the member's labels after checking or updating them.</li> <li>Error: Outputs an error message if the plugin encounters any issues during its execution.</li> </ul> </li> </ul> <p>This plugin does not initiate the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#configuration","title":"Configuration","text":"<p>To configure the plugin, you need to provide:</p> <ul> <li>Ghost Resource: The resource ID and name where the Ghost API key is stored.</li> <li>UUID: The dot notation path to the member's UUID in the payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"resource\": {\n    \"id\": \"resource-id\",\n    \"name\": \"Ghost Resource\"\n  },\n  \"uuid\": \"payload@member.uuid\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#required-resources","title":"Required resources","text":"<p>This plugin requires a configured resource in Tracardi that stores the Ghost API key.</p>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#event-prerequisites","title":"Event prerequisites","text":"<p>The plugin works with all event types and does not have specific requirements for the event to be synchronous.</p>"},{"location":"getting_started/processes/workflow/actions/ghost_labeler/#errors","title":"Errors","text":"<ul> <li>Could not split API key into id and secret: This error occurs if the provided API key does not contain a colon (:)   character, which is required to separate the ID and secret parts of the key.</li> <li>Connection errors or response issues with Ghost API: These are general errors that can occur if there is a problem   with the network connection, the Ghost API is down, or the API responds with an unexpected result.</li> <li>JWT token issues: Errors related to generating the JWT token for authentication with Ghost, which could be due to   incorrect API key parts or other token generation issues.</li> </ul> <p>These errors are logged in Tracardi's console and returned in the error output port, indicating issues that need to be addressed in the plugin's configuration or the network environment.</p>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/","title":"Google Analytics Event Tracker","text":"<p>The Google Analytics Event Tracker is a plugin designed to send custom events to Google Analytics for tracking user interactions with your website. This documentation will provide an overview of this plugin, including its functionality, configuration, input/output, and potential errors.</p>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/#version","title":"Version","text":"<p>This documentation is created for plugin version 0.7.3.</p>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/#description","title":"Description","text":"<p>The Google Analytics Event Tracker plugin allows you to send custom event tracking data to Google Analytics. It can be useful for tracking specific user interactions on your website, such as button clicks, form submissions, or other custom events. By configuring this plugin, you can define the category, action, label, and value associated with the event you want to track.</p>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li> <p>Input: This plugin accepts a payload object, typically containing data related to the event you want to track.</p> </li> <li> <p>Outputs:</p> <ul> <li>response: This port returns the response status and content if the tracking request was successful.</li> <li>error: If the tracking request fails, this port returns an error message.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/#configuration","title":"Configuration","text":"<p>The Google Analytics Event Tracker plugin requires the following configuration parameters:</p> <ul> <li> <p>Google Universal Analytics Tracking ID (source): Select the Google Universal Analytics resource that you want to   use for tracking. The credentials from the selected resource will be used to authorize your account.</p> </li> <li> <p>Event Category (category): Define the category of the event you're tracking. The category helps organize events   into groups. For example, you might use \"Buttons\" as a category.</p> </li> <li> <p>Event Action (action): Specify the action of the event you're tracking. The action describes what a visitor did.   For example, \"Click\" could be an action.</p> </li> <li> <p>Event Label (label): Enter the name of the event you're tracking. The label provides additional information about   the event. For instance, \"Sign up (a CTA on your button)\" might be used as a label.</p> </li> <li> <p>Event Value (value): Assign a numeric value to the event you're tracking. The value parameter is optional. Use it   if the event has a monetary value. For example, if a \"Sign up\" action is worth 5 USD, you can assign a value of 5.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of the JSON configuration for this plugin:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"your-source-id\",\n    \"name\": \"your-source-name\"\n  },\n  \"category\": \"category\",\n  \"action\": \"action\",\n  \"label\": \"label\",\n  \"value\": 0\n}\n</code></pre> <ul> <li>source: Replace \"your-source-id\" and \"your-source-name\" with your actual Google Universal Analytics resource   ID and name.</li> <li>category: Replace \"category\" with the category of the event you want to track.</li> <li>action: Replace \"action\" with the action of the event.</li> <li>label: Replace \"label\" with the label for the event.</li> <li>value: Replace 0 with the numeric value for the event (optional).</li> </ul>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/#required-resources","title":"Required Resources","text":"<p>This plugin requires access to a Google Universal Analytics resource. You need to configure the resource, including its credentials, in the Tracardi admin panel.</p>"},{"location":"getting_started/processes/workflow/actions/google_event_tracker_action/#errors","title":"Errors","text":"<p>Possible errors that may occur while using the Google Analytics Event Tracker plugin include:</p> <ul> <li> <p>If the \"Category\" field is left empty, an error will occur, indicating that the category cannot be empty.</p> </li> <li> <p>If the \"Action\" field is left empty, an error will occur, indicating that the action cannot be empty.</p> </li> <li> <p>If the tracking request fails for any reason, an error message will be returned on the \"error\" output port.</p> </li> </ul> <p>Please ensure that the required configuration parameters are correctly set to avoid errors during plugin execution.</p>"},{"location":"getting_started/processes/workflow/actions/google_spreadsheet/","title":"Google Spreadsheet","text":"<p>The Google Spreadsheet plugin allows Tracardi workflows to connect to Google Sheets and perform read/write operations.</p>"},{"location":"getting_started/processes/workflow/actions/google_spreadsheet/#version","title":"Version","text":"<p>0.6.1</p>"},{"location":"getting_started/processes/workflow/actions/google_spreadsheet/#description","title":"Description","text":"<p>The Google Spreadsheet plugin function allows reading or writing of data from a designated Google Spreadsheet document. The plugin uses a specified Google Cloud Service Account Resource for authentication purposes. However, note that simultaneous reading and writing are not permitted.</p> <p>For reading data, the values (range of data) from the plugin's configuration settings are accessed. The plugin then fetches data from these defined range locations. If no data is found, it issues a warning but continues.</p> <p>Additionally, it's possible to write data on the spreadsheet. For this, the plugin takes a list of values from the plugin's configuration settings and writes it to the specified cells range. If no data values are provided for writing, an error is triggered, and the operation ends.</p>"},{"location":"getting_started/processes/workflow/actions/google_spreadsheet/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The input for this plugin is a payload and the outputs can be successful payload or an error.</p> <p>Here is an example of successful payload and error output in JSON format:</p> <p>Success:</p> <pre><code>{\n  \"port\": \"payload\",\n  \"value\": {\n    # Google Spreadsheet API response...\n  }\n}\n</code></pre> <p>Error:</p> <pre><code>{\n  \"port\": \"error\",\n  \"value\": \"Error Description\"\n}\n</code></pre> <p>Please note that this plugin is unable to trigger new Tracardi workflows.</p>"},{"location":"getting_started/processes/workflow/actions/google_spreadsheet/#configuration","title":"Configuration","text":"<p>The Google Spreadsheet plugin requires the following configuration parameters:</p> <ul> <li>Google Cloud Service Account Resource: The resource used to connect to Google Spreadsheets.</li> <li>Spreadsheet Id: The Id of the Spreadsheet to connect to. The Spreadsheet Id is found in the Spreadsheet URL.</li> <li>Sheet Name: The name of the sheet within the spreadsheet to connect to.</li> <li>Data Range: The range of cells (like \"A1:F4\") where operations are performed.</li> <li>Read data: A Boolean value determining whether data is to be read from the Spreadsheet.</li> <li>Write data: A boolean value determining whether data is written on the Spreadsheet.</li> <li>Values: When writing data, the user provides a list of values (column-value pairs) for the operations.</li> </ul> <p>Such configuration parameters can be represented in JSON format as follows:</p> <pre><code>   {\n  \"source\": {\n    \"id\": \"resource-id\",\n    \"name\": \"resource-name\"\n  },\n  \"spreadsheet_id\": \"spreadsheet id\",\n  \"sheet_name\": \"sheet name\",\n  \"range\": \"A1:F4\",\n  \"read\": true,\n  \"write\": false,\n  \"values\": \"[[\\\"Name\\\", \\\"John\\\"]]\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/google_spreadsheet/#required-resources","title":"Required resources","text":"<p>This plugin requires a Google Cloud Service Account Resource to function.</p>"},{"location":"getting_started/processes/workflow/actions/google_spreadsheet/#errors","title":"Errors","text":"<ul> <li>\"You can't read and write data at the same time.\": This error will be returned if both read and write fields in   the configuration settings are set as TRUE. Only one operation can be performed at a time.</li> <li>\"If you want to parse data, set values to parse\": This error occurs if no data values are provided for writing on   the spreadsheet.</li> <li>\"You do not have permissions to access this spreadsheet. Please go to Google SpreadSheets and click Share in the   upper right corner and add the following address {}.\": This error is returned if the plugin does not have   permissions to access the Google spreadsheet. You may need to share the spreadsheet with the email mentioned in the   error message to rectify this. Any perturbations or interruptions in the network connectivity while trying to access   the Google spreadsheet services can trigger a generic error, returned in the form of a string.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/google_translate_action/","title":"Google translate plugin","text":"<p>This plugin translate the delivered text to English .</p> <p>CAUTION: This plugin is experimental. It is based on the library googletrans which may stop working because it uses the public JSON API which is not intended for this kind of use.</p>"},{"location":"getting_started/processes/workflow/actions/google_translate_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"text_to_translate\": \"veritas lux mea\",\n  \"source_language\": \"la\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/google_translate_action/#output","title":"Output","text":"<p>Returns result on the output port in the following schema:</p> <pre><code>{\n  \"translation\": \"translated text\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/google_v4_event_tracker_action/","title":"Google analytics 4 event tracker","text":"<p>This plugin sends event to google analytics 4</p>"},{"location":"getting_started/processes/workflow/actions/google_v4_event_tracker_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"name\": \"name\",\n  \"params\": \"{params_name: params_value}\"\n}\n</code></pre> <ul> <li>Name (required): The name of your event, event name describe the action taken on your website. Example: Refund</li> <li>Params (required): The parameters of your event which including all details about defined event. Example:   Currency-USD, you can define many parameters for one event.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/google_v4_event_tracker_action/#output","title":"Output","text":"<p>Returns result on the output port in the following schema:</p> <pre><code>{\n  \"status\": 204,\n  \"content\": \"response content\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/","title":"Group and Rank Interests","text":"<p>This plugin gets profile interests and computes new segments based on the defined schema. </p>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#version","title":"Version","text":"<p>This documentation is for version 0.9.0 of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#description","title":"Description","text":"<p>The Group and Rank Interests plugin works by taking a profile's interests, mapping them into segments, and then applying the most relevant segments to the profile. Here's how it does this step by step:</p> <ol> <li>The plugin first loads the profile's interests and the segment mapping. Segment mapping defines how different    interests are grouped into segments.</li> <li>It calculates the total count of interests for each segment. For example, if a profile has interests in \"iphone\", \"    ipad\", and \"imac\", and these are grouped into an \"apple-fan-boy\" segment, it sums up the counts of these interests.</li> <li>The plugin then ranks these segments based on their total interest counts.</li> <li>Depending on the configured threshold (segments to apply), it selects the top-ranked segments and applies them to the    profile.</li> </ol> <p>For instance, if a profile has interests in various gadgets, and the threshold is set to 3, only the top 3 segments with the highest interest counts will be applied to the profile.</p>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: This plugin takes a payload object as its input.</li> <li>Outputs: It has two outputs:<ul> <li>Result: Outputs the segments applied to the profile.</li> <li>Error: Outputs an error message if the plugin encounters any issues during execution.</li> </ul> </li> </ul> <p>This plugin does not start the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#configuration","title":"Configuration","text":"<ul> <li>Interests: Location within the profile where interests are stored, usually referenced as profile@interests.</li> <li>Segment Mapping: Defines how segments are constructed based on profile interests. It maps each segment name to a   list of interests that contribute to that segment.</li> <li>Segments To Apply: This setting decides how many of the top-ranked segments, based on their total interest counts,   should be applied to the profile. For example, if set to 5, only segments whose total interest count is among the top   5 will be applied.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"interests\": \"profile@interests\",\n  \"segment_mapping\": \"{\\\"segment_name\\\": [\\\"interest1\\\", \\\"interest2\\\"]}\",\n  \"segments_to_apply\": \"5\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#event-prerequisites","title":"Event prerequisites","text":"<p>This plugin works for all types of events and does not require the event to be synchronous.</p>"},{"location":"getting_started/processes/workflow/actions/group_and_rank_interests/#errors","title":"Errors","text":"<ul> <li>Interests must not be empty: This error occurs if the interests field is left empty or only contains whitespace.</li> <li>Segment Mapping must not be empty: This error is raised if the segment mapping is not provided.</li> <li>Segments to Apply must not be empty and must be a number: Occurs if the segments to apply field is either empty,   contains only whitespace, or is not a valid number.</li> <li>Segments To Apply must be a number: This message is returned if the segments to apply configuration is not a valid   number, indicating a configuration error.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/has_segment/","title":"Has Segment","text":"<p>The 'Has Segment' plugin is used to check if a given profile is part of a defined segment.</p>"},{"location":"getting_started/processes/workflow/actions/has_segment/#version","title":"Version","text":"<p>The version of this plugin is 0.7.3.</p>"},{"location":"getting_started/processes/workflow/actions/has_segment/#description","title":"Description","text":"<p>The 'Has Segment' plugin operates by checking whether a given profile (from incoming user event data) is included in a specific segment. A segment, in this context, is a subgroup of profiles defined by specific characteristics or behavior.</p> <p>The operation of the plugin is configured using a specific segment name. During the plugin operation, it checks whether the defined segment is listed under the 'segments' attribute of the provided profile.</p> <p>If the profile is found under the specified segment, the plugin returns the payload to the 'True' output port. Otherwise, if the profile is not under the defined segment, or there is no profile data (profile-less event), the payload is returned through the 'False' output port.</p> <p>The plugin also generates console warnings or errors if the event does not have an associated profile (as in a profile-less event) or if the profile value is empty. In either case, the payload will be returned through the 'False' output port.</p>"},{"location":"getting_started/processes/workflow/actions/has_segment/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin accepts a payload of any type through its only input port, named 'payload'. The returned result, which also contains the input payload, is sent through either of two output ports: 'True' or 'False'.</p>"},{"location":"getting_started/processes/workflow/actions/has_segment/#inputs","title":"Inputs","text":"<ul> <li>payload: This port takes any payload. It represents the input data that the plugin will process.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/has_segment/#outputs","title":"Outputs","text":"<ul> <li>True: This port returns the input payload if the provided profile is found in the defined segment.</li> <li>False: This port returns the input payload if the provided profile is not found in the defined segment, or there   is no profile data available.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/has_segment/#configuration","title":"Configuration","text":"<p>The plugin has the following configuration parameter:</p> <ul> <li>Segment: This parameter represents the name of the segment that the plugin will check the profile against. It   should be provided as a string and cannot be empty.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/has_segment/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example configuration for the plugin:</p> <pre><code>{\n  \"segment\": \"Example Segment\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/has_segment/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/has_segment/#errors","title":"Errors","text":"<p>The following are potential errors that can occur during the operation of the plugin:</p> <ul> <li>Segment cannot be empty: This error occurs when the 'Segment' configuration parameter is provided as an empty   string. Ensure that a valid segment name is specified in the configuration.</li> <li>Can not check segment of profile when there is no profile (profileless event): This warning occurs when the plugin   is trying to process a profile-less event. In such a case, the plugin will return the payload on the 'False' port.</li> <li>Can not check segment profile. Profile is empty: This error occurs when the profile data provided to the plugin is   empty. In such a case, the plugin will return the payload on the 'False' port.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/hash_data/","title":"Hash data","text":"<p>The Hash data plugin enables you to hash specified data such as profile traits. This action can be useful in workflows that require data processing tasks such as data security or unique identifiers.</p>"},{"location":"getting_started/processes/workflow/actions/hash_data/#version","title":"Version","text":"<p>The version of the plugin this documentation was created for is 0.7.0.</p>"},{"location":"getting_started/processes/workflow/actions/hash_data/#description","title":"Description","text":"<p>The Hash data plugin takes a payload and hashes specified traits in the payload. The plugin configuration specifies the traits to be hashed and the hashing function to be used (md5, sha1, sha256, sha512). If the designated trait is not a string value, it is serialized to JSON before hashing. </p> <p>The plugin iterates over the configured traits, validates each trait, performs the hashing operation if the trait value is valid and updates the trait value in the payload with the hash result. The plugin supports updating traits within the event, profile, and session of the workflow's state. </p> <p>Finally, the plugin returns a Result object with the updated payload and specifies the output port as 'payload'. </p>"},{"location":"getting_started/processes/workflow/actions/hash_data/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Hash data plugin accepts a single input port 'payload' that takes in a payload object which should include the traits specified in the plugin's configuration. </p> <p>Upon completion, the plugin returns the updated payload on the same 'payload' port (the Hash data Plugin has only one output port 'payload').</p>"},{"location":"getting_started/processes/workflow/actions/hash_data/#configuration","title":"Configuration","text":"<p>The Hash data plugin requires the following configuration parameters: </p> <ul> <li>Traits - Array of dot notation paths referencing the traits to be hashed. If a value is not a string, it is serialized to JSON before hashing. </li> <li>Hashing function - Determines the function used for hashing. The plugin supports md5, sha1, sha256, and sha512.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/hash_data/#json-configuration","title":"JSON Configuration","text":"<p>Here's an example of how to configure the Hash data plugin in JSON format:</p> <pre><code>{\n    \"traits\": [\"profile@traits.email\", \"session@traits.username\"],\n    \"func\": \"sha256\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/hash_data/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/hash_data/#errors","title":"Errors","text":"<p>The plugin raises warnings in two cases: </p> <ul> <li>If a trait path references the 'flow' source. The plugin does not support hashing 'flow' values -- 'Flow values cannot be hashed.'</li> <li>If the trait path is invalid or does not exist in the payload - 'Given trait {trait path} is invalid or does not exist.'</li> </ul> <p>It's important to note that these are warning messages and do not halt the execution of the plugin. However, they do indicate potential issues with the plugin's configuration.</p>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/","title":"HTML fetcher","text":"<p>HTML fetcher is a Tracardi plugin used for fetching an HTML webpage. It can be used to make an HTTP or HTTPS request to a given URL and return the response as a result. This plugin allows the configuration of request method, headers, cookies, SSL check and timeout. The fetched webpage's details such as content, status and cookies are returned upon success operation, while upon any error such as \"time-out\" error, connection error or response status other than [200, 201, 202, 203], corresponding error details are informed.</p>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/#version","title":"Version","text":"<p>This documentation is for the HTML fetcher plugin version 0.6.1.</p>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/#description","title":"Description","text":"<p>The HTML fetcher plugin works as follows:</p> <p>Initially, the plugin's configuration is set up, based on received parameters. The plugin verifies the dictionaries of cookies and headers, ensuring that all keys &amp; values are string types. Any non-string values will result in plugin throwing an error with appropriate message.</p> <p>Upon successful verification, an HTTP client is initiated within the configured timeout limit. Then, it sends a request to selected URL using specified method (like GET, POST, etc.). In the request, headers and cookies provided in configuration are included. If \"ssl_check\" setting is enabled, the request also validates SSL certificate of the page it is trying to reach.</p> <p>When the response is received from the server, it's processed and a \"result\" dictionary is composed, containing status code of response, content of the fetched page and received cookies.</p> <p>If the response's status code is one of the successful HTTP codes (200, 201, 202, 203), the fetching operation is considered successful and \"result\" is returned. However, if the status code is different, the operation is deemed unsuccessful and \"error\" value with description of the error is returned.</p>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The HTML fetcher plugin receives a dictionary with payload in its input.</p> <p>Upon successful operation, it outputs to \"response\" port the following structure:</p> <pre><code>{\n  \"status\": &lt;status-code&gt;,\n  \"content\": &lt;fetched-page-content&gt;,\n  \"cookies\": &lt;received-cookies&gt;\n}\n</code></pre> <p>Upon encountering an error, it outputs to \"error\" port a simple string with description of occurred error.</p>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/#configuration","title":"Configuration","text":"<p>The HTML fetcher plugin requires the following configuration:</p> <ul> <li>\"method\": Request method, can be GET, POST, PUT, or DELETE.</li> <li>\"url\": The URL of the webpage to be fetched.</li> <li>\"body\": Content to be sent in request. Accepts double curly braces for replacing part of content with data, e.g.,   {{profile@id}}.</li> <li>\"timeout\": The maximum time (in seconds) to wait for a response.</li> <li>\"headers\": A dictionary for request headers.</li> <li>\"cookies\": A dictionary for cookies.</li> <li>\"ssl_check\": A boolean value to determine if the SSL certificate should be checked and validated.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of plugin's configuration:</p> <pre><code>{\n  \"method\": \"get\",\n  \"url\": \"https://example.com\",\n  \"timeout\": 30,\n  \"headers\": {\n    \"Content-Type\": \"application/json\"\n  },\n  \"cookies\": {\n    \"sessionid\": \"123456\"\n  },\n  \"ssl_check\": true,\n  \"body\": \"\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/html_fetcher/#errors","title":"Errors","text":"<p>The plugin returns several exceptions:</p> <ul> <li>\"Header values must be strings,  given for header \": May occur when given headers contain   non-string values. <li>\"Cookies values must be strings,  given for cookies \": Occurs when given cookies contain   non-string values. <li>\"Remote call timed out\": Occurs when program does not receive response within the configured time limit from requested   URL.</li> <li>Any other error messages returned from aiohttp library, for example capturing ClientConnectorError which is raised   for connection issues like DNS resolution, refused connection, etc. The detailed error message for such exceptions   will be directly from the aiohttp library.</li> <p>Please note that if there aren't any errors, but response's status is not within [200, 201, 202, 203], the plugin returns a dictionary similar to successful operation, but routes it to \"error\" port instead.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/","title":"Get company from HubSpot plugin","text":"<p>This plugin gets a company from HubSpot, based on provided company ID.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from HubSpot API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/#hubspot-app","title":"HubSpot app","text":"<p>Firstly, you need to create an app in  a HubSpot developer account.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/#initiating-oauth-20-connection","title":"Initiating OAuth 2.0 connection","text":"<p>This plugin uses OAuth 2.0, so you need to initiate an OAuth connection between your app and HubSpot.</p> <p>To do that, you have to go to app auth in the HubSpot website. Below there is a path from main page to  this:</p> <p>hubspot.com -&gt; login -&gt; choose your account -&gt; app menu -&gt; choose app -&gt; auth </p> <p>There are your client ID and client secret and here you need to define your redirect url and scopes:</p> <ul> <li> <p>redirect URL is a URL visitors will be redirected to after granting access to your app. Please note: For    security reasons, this URL must use https in production. When testing using localhost, http can be used.    Also, you must use a domain, as IP addresses are not supported.</p> </li> <li> <p>scopes: for getting company, you need to choose crm.objects.companies.read scope, but this match only with this    and Get Company from HubSpot plugin. For other plugins connecting to HubSpot, you should choose other scopes.   We recommend choose all the following scopes: </p> <pre><code>crm.objects.companies.write, crm.objects.companies.read, crm.objects.contacts.write, crm.schemas.contacts.read, content\n</code></pre> </li> </ul> <p>After filling the fields, copy link and open this. After that, choose the account that match the app you want to connect with HubSpot and press the button. You'll be asked for granting access to your app, then be redirected to  site which URL is based on the redirect URL you've defined. </p> <p>In the last site URL, there is a code you can use later.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/#with-form","title":"With form","text":"<ul> <li>HubSpot resource - please select your HubSpot resource. It should contain: <ul> <li>client id - the client ID of your app. You can find this in your app auth (on the HubSpot    website, after authentication - app menu -&gt; choose app -&gt; auth)</li> <li>client secret - the client secret of your app. This also is in your app auth.</li> </ul> </li> </ul> <p>Optionally:     * if you have got access token:       * refresh token - the refresh token obtained when initially authenticating your OAuth integration.     * if you haven't got token:       * redirect url - the redirect URL that was used when the user authorized your app. This must exactly match          the redirect_url used when initiating the OAuth 2.0 connection.       * code - the code parameter returned to your redirect URL when the user authorized your app. * is token got - please select true if you've got access token. If you select false and then make any operation    to HubSpot with Tracardi, you should select true - in this case, you don't need to remember tokens - Tracardi   will do it for you. * company id - id of a company you want to get.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_company_action/#json-configuration-example","title":"JSON configuration - example","text":"<pre><code>{\n  \"source\": {\n    \"access_token\": \"&lt;your-access-token-optionally&gt;\",\n  },\n  \"company_id\": \"&lt;your-company-id&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/","title":"Get contact from HubSpot plugin","text":"<p>This plugin gets a contact from HubSpot, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from HubSpot API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/#hubspot-app","title":"HubSpot app","text":"<p>Firstly, you need to create an app in  a HubSpot account.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/#initiating-connection","title":"Initiating  connection","text":"<p>You need your apikey/accesstoken  Below there is a path from main page to this:</p> <p>hubspot.com -&gt; login -&gt; choose your account -&gt; settings -&gt; account setup -&gt; integrations -&gt; private app</p> <ul> <li>scopes: for getting contact, you need to choose crm.schemas.contacts.read scope, but this match only with this    and Add Contact to HubSpot plugin. For other plugins connecting to HubSpot, you should choose other scopes.    We recommend choose all the following scopes: <pre><code>crm.objects.companies.write, crm.objects.companies.read, crm.objects.contacts.write, crm.schemas.contacts.read, content\n</code></pre> </li> </ul> <p>You can now access the access token for this app</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/#with-form","title":"With form","text":"<ul> <li> <p>HubSpot resource - please select your HubSpot resource. It should contain: </p> <ul> <li>access token - how you access the site. Like any api token</li> </ul> </li> <li> <p>contact id - id of a contact you want to get.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/hubspot_get_contact_action/#json-configuration-example","title":"JSON configuration - example","text":"<pre><code>{\n  \"source\": {\n    \"access_token\": \"&lt;your-access-token-optionally&gt;\",\n  },\n  \"contact_id\": \"&lt;your-contact-id&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/","title":"Update company from HubSpot plugin","text":"<p>This plugin updates a company from HubSpot, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from HubSpot API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/#hubspot-app","title":"HubSpot app","text":"<p>Firstly, you need to create an app in  a HubSpot account.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/#initiating-connection","title":"Initiating  connection","text":"<p>You need your apikey/accesstoken  Below there is a path from main page to this:</p> <p>hubspot.com -&gt; login -&gt; choose your account -&gt; settings -&gt; account setup -&gt; integrations -&gt; private app</p> <ul> <li>scopes: for getting contact, you need to choose crm.schemas.contacts.read scope, but this match only with this    and Add Contact to HubSpot plugin. For other plugins connecting to HubSpot, you should choose other scopes.    We recommend choose all the following scopes: <pre><code>crm.objects.companies.write, crm.objects.companies.read, crm.objects.contacts.write, crm.schemas.contacts.read, content\n</code></pre> </li> </ul> <p>You can now access the access token for this app</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/#with-form","title":"With form","text":"<ul> <li>HubSpot resource - please select your HubSpot resource. It should contain: <ul> <li>access token - how you access the site. Like any api token</li> </ul> </li> <li>company id - id of a company you want to update.</li> <li>properties - you can add properties for your contact. Remember to use field aliases from HubSpot.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_company_action/#json-configuration-example","title":"JSON configuration - example","text":"<pre><code>{\n  \"source\": {\n    \"access_token\": \"&lt;your-access-token-optionally&gt;\",\n  },\n  \"company_id\": \"&lt;your-company-id&gt;\",\n  \"properties\":\n    {\n      \"name\": \"&lt;a-company-name&gt;\",\n      \"description\": \"&lt;a-company-description&gt;\"\n    }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/","title":"Update contact from HubSpot plugin","text":"<p>This plugin updates a contact from HubSpot, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from HubSpot API on port response, or optional error info on port error if one occurs.</p> <p>Warning: although the plugin updates a contact, HubSpotAPI sometimes returns an unknown error.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/#hubspot-app","title":"HubSpot app","text":"<p>Firstly, you need to create an app in  a HubSpot account.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/#initiating-connection","title":"Initiating  connection","text":"<p>You need your apikey/accesstoken  Below there is a path from main page to this:</p> <p>hubspot.com -&gt; login -&gt; choose your account -&gt; settings -&gt; account setup -&gt; integrations -&gt; private app</p> <ul> <li>scopes: for getting contact, you need to choose crm.schemas.contacts.read scope, but this match only with this    and Add Contact to HubSpot plugin. For other plugins connecting to HubSpot, you should choose other scopes.    We recommend choose all the following scopes: <pre><code>crm.objects.companies.write, crm.objects.companies.read, crm.objects.contacts.write, crm.schemas.contacts.read, content\n</code></pre> </li> </ul> <p>You can now access the access token for this app</p>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/#with-form","title":"With form","text":"<ul> <li>HubSpot resource - please select your HubSpot resource. It should contain: <ul> <li>access token - how you access the site. Like any api token</li> </ul> </li> <li>contact id - id of a contact you want to update.</li> <li>properties - you can add properties for your contact. Remember to use field aliases from HubSpot.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/hubspot_update_contact_action/#json-configuration-example","title":"JSON configuration - example","text":"<pre><code>{\n  \"source\": {\n    \"access_token\": \"&lt;your-access-token-optionally&gt;\",\n  },\n  \"contact_id\": \"&lt;your-contact-id&gt;\",\n  \"properties\":\n    {\n      \"email\": \"&lt;a-contact-email&gt;\",\n      \"firstname\": \"&lt;a-contact-firstname&gt;\",\n      \"lastname\": \"&lt;a-contact-lastname&gt;\"\n    }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/if_action/","title":"IF Action","text":"<p>The \"If\" plugin in Tracardi is a conditional action that allows you to selectively run a branch of the workflow based on a specified condition. This plugin evaluates the provided condition and returns the payload on the \"true\" port if the condition is met, or on the \"false\" port if the condition is not met.</p>"},{"location":"getting_started/processes/workflow/actions/if_action/#plugin-configuration","title":"Plugin Configuration","text":"<p>The behavior of the \"If\" plugin is determined by the following configuration options:</p> <ul> <li> <p>Condition statement: This configuration option allows you to provide a condition for the IF statement. If the condition is met, the payload will be returned on the \"true\" port; otherwise, the \"false\" port will be triggered.</p> </li> <li> <p>Return value only once per condition change: By enabling this option, the relevant port will be triggered only once per condition change. If the option is disabled, the flow will be stopped.</p> </li> <li> <p>Expire trigger again after: If the value is set to 0, the event will occur only once and will not be triggered again unless the conditions change. However, if a value greater than 0 is set, the event will be triggered again after the specified number of seconds, regardless of whether the conditions have changed or not.</p> </li> <li> <p>Return input payload instead of True/False: Enabling this option will return the input payload on the output ports if it is enabled; otherwise, True/False will be returned.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/if_action/#plugin-outputs","title":"Plugin Outputs","text":"<p>The \"If\" plugin has two output ports:</p> <ul> <li> <p>true: If the defined condition is met, the payload will be returned on this port.</p> </li> <li> <p>false: If the defined condition is not met, the payload will be returned on this port.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/if_action/#condition-syntax","title":"Condition syntax","text":"<p>This node uses a language very similar to SQL conditionals. It also uses dotted path notation to access the data. All fields must contain a source and a path to value e.g:</p> <pre><code>profile@data.pii.name\n</code></pre> <p>This means the value traits.public.pii.name from profile will be used in the conditional statement.</p>"},{"location":"getting_started/processes/workflow/actions/if_action/#language-grammar","title":"Language grammar","text":"<p>The following grammar rules define expression syntax in [If node].</p> <pre><code>expr:\n  | expr OR (expr AND expr)\n  | expr AND (expr OR expr)\n</code></pre> <p>that means that expressions with similar operators e.g. OR must be in brackets. The following conditional statement is forbidden:</p> <pre><code>field1=1 AND field2=2 OR field3=3\n</code></pre> <p>correct statement is either:</p> <pre><code>field1=1 AND (field2=2 OR field3=3)\n</code></pre> <p>or</p> <pre><code>(field1=1 AND field2=2) OR field3=3\n</code></pre> <p>There is no auto resolution of priority operations</p>"},{"location":"getting_started/processes/workflow/actions/if_action/#condition-resolution","title":"Condition resolution","text":"<p>Each condition consist of a field, operator, and value. An operator is used to manipulate individual data items and return a result. Operators are represented by special characters or by keywords. List of operators is available below.</p> <p>Example</p> <pre><code>payload@numberOfPurchases == 1\n</code></pre> <p>This example will trigger True port on the [IF node] if numberOfPurchases in payload equals 1</p> <p>Operations can be joined by AND/OR. </p> <p>Example</p> <pre><code>payload@numberOfPurchases == 1 and payload@title == \"Title\"\n</code></pre> <p>This example will trigger True port on the [IF node] if numberOfPurchases in payload equals 1and title in payload  equals \"Title\".</p> <p>There are other operators possible like:</p> <ul> <li>less then (&lt;)</li> <li>greater then (&gt;)</li> <li>less or equal then (&lt;=)</li> <li>greater or equal then (&gt;=)</li> <li>not equal (!=)</li> <li>exists (fieldname EXISTS)</li> <li>not exists (fieldname NOT EXISTS)</li> </ul>"},{"location":"getting_started/processes/workflow/actions/if_action/#value-types","title":"Value types","text":"<p>In the example:</p> <pre><code>payload@numberOfPurchases == 1 and payload@title == \"Title\"\n</code></pre> <p>Field payload@numberOfPurchases is considered an integer number while payload@title is considered a string.</p>"},{"location":"getting_started/processes/workflow/actions/if_action/#examples","title":"Examples","text":"<ol> <li> <p>Simple Comparison:    <pre><code>payload@age &gt; 18\nevent@event_type == \"click\"\nprofile@is_verified == True\nmemory@score &gt;= 90\n</code></pre></p> </li> <li> <p>AND/OR Conditions:    <pre><code>(payload@category == \"electronics\" AND payload@price &lt;= 1000)\n(event@action == \"purchase\" OR event@properties.action == \"add_to_cart\")\n(profile@data.pii.age &gt; 25 AND (event@action == \"purchase\" OR event@properties.action == \"add_to_cart\"))\n</code></pre></p> </li> <li> <p>BETWEEN Condition:    <pre><code>payload@quantity BETWEEN 10 AND 50\npayload@timestamp BETWEEN 1631233200 AND 1631319600\n</code></pre></p> </li> <li> <p>IS NULL/IS NOT NULL Conditions:    <pre><code>payload@description IS NULL\nevent@user_id IS NOT NULL\n</code></pre></p> </li> <li> <p>EXISTS/NOT EXISTS Conditions:    <pre><code>event@location EXISTS\nprofile@address NOT EXISTS\n</code></pre></p> </li> <li> <p>EMPTY/NOT EMPTY Conditions:    <pre><code>memory@notes EMPTY\npayload@items NOT EMPTY\n</code></pre></p> </li> <li> <p>CONTAINS Condition (contains string):    <pre><code>payload@keywords CONTAINS \"technology\"\nevent@tags CONTAINS \"important\"\n</code></pre></p> </li> <li> <p>STARTS WITH/ENDS WITH String Conditions:    <pre><code>payload@name STARTS WITH \"John\"\nevent@description ENDS WITH \"exciting event\"\n</code></pre></p> </li> <li> <p>Array Conditions:    <pre><code>event@participants[0] == \"Alice\"\nevent@ratings[2] &gt;= 4.5\n</code></pre></p> </li> </ol> <p>Warning</p> <p>Please note that the examples provided above are just illustrations of how the conditions might look like within the given syntax. The actual conditions used will depend on the specific context and data structure being used.</p>"},{"location":"getting_started/processes/workflow/actions/if_action/#troubleshooting","title":"Troubleshooting","text":"<p>When you compare date you must pay attention to dates types. There are dates that are time zone aware (offset-aware) and dates that are not aware of time zone. You can not compare them.</p> <pre><code>can't compare offset-naive and offset-aware datetimes\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/if_action/#time-functions","title":"Time functions","text":"<p>The following time functions are available:</p> <ul> <li>now()</li> <li>utcnow()</li> <li>datetime(\"\"), e.g datetime(\"2021-01-01 00:00:00\") <li>datetime(), e.g datetime(profile@metadata.time.insert) <li>now(\"\"), e.g. now(\"europe/warsaw\") <li>now.offset(\"europe/warsaw\", \"+700 days\")</li> <li>now.offset(payload@time, \"+700 days\")</li>"},{"location":"getting_started/processes/workflow/actions/increase_interest/","title":"Increase Interest","text":"<p>The Increase Interest plugin is a tool in the Tracardi suite that is used to increment a specified interest value of a user profile.</p>"},{"location":"getting_started/processes/workflow/actions/increase_interest/#version","title":"Version","text":"<p>The current version of the Increase Interest plugin is 0.8.2.</p>"},{"location":"getting_started/processes/workflow/actions/increase_interest/#description","title":"Description","text":"<p>The Increase Interest plugin operates by raising the interest value associated with a specified profile by a predetermined amount. The plugin receives a payload (in JSON format), and uses this to find the profile to be altered. It then increases the interest of that profile according to the plugin's configuration. Dot notation can be used to dynamically set the interest name. Though there are some restrictions. The interest name must be an alpha-numerical string without spaces. Hyphen and dashes are allowed.</p> <p>The success or failure of each operation is tracked and logged, with error messages being produced for profile-less events and empty profiles. Finally, the plugin returns the same payload it received, allowing it to be passed on to the next plugin in the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/increase_interest/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The input for the Increase Interest plugin is a JSON object, the \"payload\". This object is passed into the plugin and used to find the profile to be processed.</p> <p>There are two outputs from the Increase Interest plugin: the payload and an error. The payload output port returns the object originally received by the plugin, while the error output port returns error messages encountered during the execution of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/increase_interest/#configuration","title":"Configuration","text":"<p>The configuration options for the Increase Interest plugin are:</p> <ul> <li>Interest: This is the name of the interest that you want to increment.</li> <li>Value: This is the amount by which the selected interest should be increased.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/increase_interest/#json-configuration","title":"JSON Configuration","text":"<p>Here's an example of how the JSON configuration for the Increase Interest plugin might look:</p> <pre><code>{\n  \"interest\": \"travel\",\n  \"value\": \"5.0\"\n}\n</code></pre> <p>In this example, the value of the travel interest would be increased by 5.0 for the selected profile.</p> <p>If the interest key is an array of values or a comma separated values like:</p> <pre><code>{\n  \"interest\": \"travel,sports,tennis\",\n  \"value\": \"5.0\"\n}\n</code></pre> <p>Several interests would be increased by the defined value.</p>"},{"location":"getting_started/processes/workflow/actions/increase_interest/#required-resources","title":"Required Resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/increase_interest/#errors","title":"Errors","text":"<p>The Increase Interest plugin may return the following error messages under certain conditions:</p> <ul> <li>\"Can not increase profile interest in profile less events.\": This error occurs when an attempt is made to increase   the interest of a profile-less event.</li> <li>\"Can not increase interests to empty profile.\": This error is encountered when the plugin tries to increase the   interest of an empty profile.</li> <li>\"Invalid interest name.\" - This error occurs when the name of the interest (key used to save it in the database)   is   not an alpha-numerical string. Interest name must be an alpha-numerical string without spaces. Hyphen and dashes are   allowed.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/increment_action/","title":"Increment action","text":""},{"location":"getting_started/processes/workflow/actions/inject_action/","title":"Inject values","text":"<p>The Inject node in a workflow serves as a tool to debug workflows. This node can be used as the starting point of a flow that has a defined payload value. The Inject node is responsible for injecting values into the internal state of the workflow. The data that is injected can be of various types, including strings, integers, or objects.</p> <p>By default, the Inject node will trigger the workflow when the \"debug\" button is clicked. This means that the injected data will be available for subsequent nodes in the workflow to process. The Inject node can be used to simulate specific conditions or scenarios that can be used for testing purposes or for troubleshooting issues that may occur during the workflow execution.</p> <p>To use the Inject node, you will need to define the payload that you want to inject. This can be done by configuring the node properties to specify the payload data. Once the payload is defined, you can click the \"debug\" button to execute the workflow with the injected data.</p> <p>Overall, the Inject node is a useful tool for debugging workflows by allowing you to simulate specific conditions and inject data into the workflow's internal state.</p>"},{"location":"getting_started/processes/workflow/actions/inject_action/#configuration","title":"Configuration","text":"<p>Type into configuration what you want to inject.</p> <p>Example:</p> <pre><code>{\n  \"any_value\": {\n    \"key\": \"value\"\n  }\n}\n</code></pre> <p>Select where the data should be injected. It can take te following values:</p> <ul> <li>\"Event Properties\",</li> <li>\"Payload\",</li> <li>\"Profile PII\",</li> <li>\"Profile Traits\",</li> <li>\"Profile Interests\",</li> <li>\"Profile Counters\",</li> <li>\"Profile Consents\",</li> <li>\"Session Context\"</li> </ul>"},{"location":"getting_started/processes/workflow/actions/inject_action/#side-effects","title":"Side effects","text":"<p>This action will not run in deployed workflow. It is debug node. </p>"},{"location":"getting_started/processes/workflow/actions/inject_event/","title":"Inject Event","text":"<p>Inject Event is a Plugin that allows you to add an event to the payload by providing the event id. The event is directly loaded into the payload, augmenting the data as it passes through the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/inject_event/#version","title":"Version","text":"<p>The version of the plugin used for this documentation is 0.6.0.1.</p>"},{"location":"getting_started/processes/workflow/actions/inject_event/#description","title":"Description","text":"<p>The Inject Event plugin enables you to add an event into the payload (the data structure that carries content for the workflow). When the plugin is run, it loads the event associated with the provided event id into the current payload. If the event is not found, a warning is logged. The modified payload, containing the newly added event, is then returned.</p> <p>Please note that Inject Event can start the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/inject_event/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin accepts one input - a payload:</p> <p>Example:</p> <pre><code>{\n  \"payload\": {\n    \"data\": \"Any data you need to pass to the plugin\"\n  }\n}\n</code></pre> <p>The plugin also outputs the modified payload:</p> <p>Example:</p> <pre><code>{\n  \"payload\": {\n    \"data\": \"Any data you need to pass to the next plugin\",\n    \"event\": \"Loaded event data\"\n  }\n}\n</code></pre> <p>The payload output is the input payload enriched with the event data related to the provided id.</p>"},{"location":"getting_started/processes/workflow/actions/inject_event/#configuration","title":"Configuration","text":"<p>The plugin has one configuration parameter:</p> <ul> <li>event_id: This required parameter specifies the id of the event you want to add to the payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/inject_event/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of the JSON configuration:</p> <pre><code>{\n  \"event_id\": \"123456\"\n}\n</code></pre> <p>Please replace \"123456\" with the actual id of the event you want to inject into your workflow.</p>"},{"location":"getting_started/processes/workflow/actions/inject_event/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/inject_event/#errors","title":"Errors","text":"<p>If the specified \"event_id\" does not exist in the event database, the following warning will be logged: \"Event id XXX does not exist.\". In this case the plugin continues executing and returns the input payload unchanged.</p>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/","title":"Intercom widget","text":"<p>The Intercom widget plugin is designed to integrate the Intercom chat system into a webpage, enhancing user interaction and support.</p>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#version","title":"Version","text":"<p>0.7.3</p>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#description","title":"Description","text":"<p>This plugin adds the Intercom messaging widget to a webpage, allowing for real-time chat and support interactions. It requires an Intercom application ID to function. Once configured, the plugin injects a JavaScript snippet that initializes the Intercom widget on the webpage. This widget can significantly improve user engagement, providing a convenient way for visitors to communicate with the website's support or sales teams.</p>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin takes a payload object as input. This payload is typically used for passing data within the   workflow but isn't directly modified by this plugin.</li> <li>Outputs:<ul> <li>response: Outputs the original payload after processing, as the primary function of this plugin is to append   the   Intercom widget to the webpage.</li> <li>error: Outputs in case of any execution error.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#configuration","title":"Configuration","text":"<ul> <li>Application ID: The unique identifier for your Intercom application. This ID is crucial for linking the widget to   your specific Intercom account.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#how-to-obtain-application-id","title":"How to obtain Application ID","text":"<p>To use this application on your webpage, first, create an account at www.intercom.com.</p> <ol> <li>Once you've signed up and set up your initial application in the Intercom dashboard, locate your app_id. You can find    this in the URL, which looks like this: <code>https://app.intercom.com/a/apps/{app_id here}</code>.</li> <li>Then, take this app_id and input it into the plugin's configuration to set it up.</li> </ol>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"app_id\": \"your-intercom-application-id\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#event-prerequisites","title":"Event prerequisites","text":"<p>Plugins like the Intercom widget, which fall under the \"UIX Widgets\" category, require a synchronous event. It will not work if sent event is asynchronous.</p>"},{"location":"getting_started/processes/workflow/actions/intercom_widget_action/#errors","title":"Errors","text":"<ul> <li>\"Application ID can not be empty.\": This error occurs when the application ID for the Intercom widget is not provided.   The application ID is essential for the widget's operation.</li> <li>General script-related errors might occur, typically related to the execution of the appended JavaScript in the   webpage environment. These could be due to conflicts with other scripts or issues in the webpage's structure.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/","title":"Interest scoring","text":"<p>This plugin calculates a normalized value of interests using the exponential decay over time. It applies a decay function to decrease the magnitude of each interest over time and then normalizes these values using a softmax function to emphasize the most significant interests.</p>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#version","title":"Version","text":"<p>0.9.0</p>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#description","title":"Description","text":"<p>The Interest Scoring Action plugin evaluates the decay of interests over time. This decay is based on a mathematical model where the interest magnitude decreases exponentially based on a defined decay rate and the elapsed time since the interest was last updated. The plugin retrieves timestamps for each interest from a user's profile, computes the decayed interest scores, and then applies a softmax function to normalize these scores. The result highlights the most prominent interests relative to others. The top interest along with its probability score is also identified and returned.</p>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#details","title":"Details","text":"<p>Interest scores are calculated using a decay function, specifically an exponential function that reduces the interest magnitude over time. This reduction is based on the formula: magnitude \u00d7 e^(-decay \u00d7 time_passed), where \"e\" represents the exponential function. The scores are subsequently normalized with a softmax function, which emphasizes the most significant interest by giving it the highest value.</p> <p>For instance, if the initial interest magnitude is 1 with a decay factor of 0.1, the interest will nearly disappear ( approach a value of 0) after 14 time units - these units could be seconds, minutes, etc.</p> <p>In another scenario, if the interest starts with value 10, then after 14 days, it would reduce to approximately 2.46. Additionally, there is always a baseline interest labeled \"unknown\" with a fixed magnitude of 0.5. If any interest's magnitude falls below 0.25, its calculated score will then be set to zero.</p> <p>This plugin is particularly useful when you want to quantify the decline in customer interest over time and identify the most current prominent interest. If multiple interests are equally significant, the probability is evenly distributed among them. The total probability across all interests will always sum up to 1.</p>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: This plugin requires a payload object as input which includes user profile details necessary for   calculating interest decay.</li> <li>Outputs: The plugin outputs the scoring results for each interest, including the list of all interests with their   respective decayed values and the top interest with its probability score.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#examples","title":"Examples","text":""},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#output-example","title":"Output Example","text":"<pre><code>{\n  \"scoring\": {\n    \"unknown\": 0.1,\n    \"reading\": 0.6,\n    \"sports\": 0.3\n  },\n  \"interests\": {\n    #\n  Current\n  interest\n  values\n  \"unknown\": 0.5,\n  \"reading\": 7,\n  \"sports\": 5\n},\n\"top\": \"reading\",\n\"probability\": 0.6\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#configuration","title":"Configuration","text":"<ul> <li>Decay factor: This is the rate at which the interest should decrease over time.</li> <li>Time unit: What is the smallest unit of time that should reduce the interest value? Options include seconds,   minutes, hours, days, or months.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"decay\": 0.1,\n  \"base\": \"60\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#prerequisites","title":"Prerequisites","text":"<p>This plugin works with build-in event types (Increase Interest, Decrease Interest, Reset Interest) and does not specifically require synchronous events.</p>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#side-effects","title":"Side effects","text":"<p>This plugin will update profile (field: metadata.fields) if the last timestamp if any of the interests is missing. The timestamp will be set to current date and time.</p>"},{"location":"getting_started/processes/workflow/actions/interests_scoring_action/#errors","title":"Errors","text":"<ul> <li>Profile event sequencing can not be performed without profile. Is this a profile less event? - This error occurs   if the plugin attempts to access the profile's interests or metadata but the profile data is missing in the payload.   Ensure that the payload includes profile information before running this plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/","title":"Join","text":"<p>Joins payload from incoming data, merging different input connections into a single, unified payload.</p>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#version","title":"Version","text":"<p>0.7.1</p>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#description","title":"Description","text":"<p>The Join plugin focuses on combining data from various input connections into a single payload. This is particularly useful when data from multiple sources needs to be gathered and analyzed as a unified set. If input connections have specific names, the plugin organizes the merged data under these connection names. For unnamed connections, it uses the connection IDs as keys in the resulting object.</p> <p>Additionally, the plugin offers a feature for reshaping the joint data. This allows for transforming the data structure according to a predefined JSON template. The template can include static values, dynamically fetched data using dot notation (such as \"profile@id\"), or combinations thereof. This capability enables tailored data structuring to fit specific analytical or operational needs.</p>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#inputs","title":"Inputs:","text":"<ul> <li>Payload: Accepts a payload object containing the data to be joined.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#outputs","title":"Outputs:","text":"<ul> <li>Payload: Returns the joined payload, Optionally it may be reshaped according to the configured template.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#configuration","title":"Configuration","text":"<ul> <li>Reshape output payload: A JSON template to reshape the output payload, allowing transformations of the joint data.</li> <li>Type of join: Choose between a list or a dictionary for the collection type. Dictionary type uses connection names   as keys.</li> <li>Missing values equal null: If enabled, any missing values in the data will be replaced with null.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"reshape\": \"{\\\"some-data\\\": {\\\"key\\\": \\\"value\\\", \\\"value\\\": \\\"profile@id\\\", \\\"list\\\": [1, \\\"payload@data\\\"], \\\"event\\\": \\\"event@...\\\"}}\",\n  \"default\": true,\n  \"type\": \"dict\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#errors","title":"Errors","text":"<ul> <li>\"Invalid Configuration\": Occurs when the provided plugin configuration is not valid. This can happen if the JSON   reshaping template is incorrectly formatted or if essential configuration parameters are missing or invalid.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/join_output_payloads/#operation","title":"Operation","text":"<p>Upon execution, the plugin processes incoming data from different sources, joining them based on the defined configuration. The reshaping feature applies the specified template to the joint data, allowing for customized data structuring. The output is a single payload that consolidates all input data, optionally reshaped and organized according to the plugin's configuration.</p>"},{"location":"getting_started/processes/workflow/actions/json_to_data/","title":"JSON to data","text":"<p>The JSON to data plugin is designed to convert a JSON string to data objects. It serves as a converter, simplifying the process of dealing with JSON strings in your workflow.</p>"},{"location":"getting_started/processes/workflow/actions/json_to_data/#version","title":"Version","text":"<p>The documentation was created for version 0.6.2 of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/json_to_data/#description","title":"Description","text":"<p>The JSON to data plugin works by accepting a JSON string, specified by a reference path, and converting it into data objects. This process is executed within the \"run\" method of the plugin. The reference path to the JSON string is extracted from the plugin's configuration. Once the JSON string is obtained, it attempts to convert it into a data object.</p> <p>If the JSON string is valid and was correctly converted into a data object, the plugin returns this data on the \" payload\" output port. If the conversion fails, likely due to an issue with the JSON string (\u00e9.g., malformed syntax), then an error message is returned on the \"error\" output port.</p>"},{"location":"getting_started/processes/workflow/actions/json_to_data/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin processes and accepts inputs on the \"payload\" input port which receives the workflow payload.</p> <p>It has two output ports, 'payload', and 'error'. If the JSON string was correctly converted into data objects, the new data is returned on the \"payload\" port. This output consists of a dictionary, with the key \"value\" and the value being the converted data object. Example of successful operation:</p> <pre><code>{\n  \"value\": {\n    \"converted\": \"data objects here...\"\n  }\n}\n</code></pre> <p>If the conversion fails, an error message is returned on the \"error\" output port. This returned error contains the original payload. Example:</p> <pre><code>{\n  \"value\": {\n    \"original\": \"payload here...\"\n  }\n}\n</code></pre> <p>The plugin cannot initiate the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/json_to_data/#configuration","title":"Configuration","text":"<p>The configuration for this plugin is straightforward. It consists of one parameter:</p> <ul> <li>to_data: This is a reference path to a JSON string that needs to be converted. The reference path uses the   Tracardi dot notation for accessing data in the workflow's internal state.</li> </ul> <p>Example: profile@stats.counters.boughtProducts would be a valid reference path in some workflows.</p>"},{"location":"getting_started/processes/workflow/actions/json_to_data/#json-configuration","title":"JSON Configuration","text":"<p>Below is an example of the required JSON configuration for this plugin:</p> <pre><code>{\n  \"to_data\": \"profile@stats.counters.boughtProducts\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/json_to_data/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/json_to_data/#errors","title":"Errors","text":"<p>An error might occur when the plugin is incapable of parsing the specified JSON string. This usually happens if the JSON string is malformed or not a valid JSON. In such a case, the following error will be returned:</p> <p>\"JSONDecodeError - Expecting property name enclosed in double quotes\"</p> <p>In the event of such error, the plugin will return the original payload on the \"error\" port rather than the converted data.</p>"},{"location":"getting_started/processes/workflow/actions/key_counter_action/","title":"Key counter","text":"<p>This plugin counts key strings. Key string provided in configuration will be treated as an information to increase the value of a key in profile. This plugin can be used for simple statistics e.g. count how many user visited us on mobile device vs other devices like desktop or tablet.</p>"},{"location":"getting_started/processes/workflow/actions/key_counter_action/#examples","title":"Examples","text":"<p>For example Lets assume the following configuration:</p> <pre><code>{\n  \"key\": \"payload@value\",\n  \"save_in\": \"payload@traits.counts\"\n}\n</code></pre> <p>if over time the value in payload (defined in config as payload@value) is equals to:</p> <pre><code>{\"value\": \"a\"}\n{\"value\": \"b\"}\n{\"value\": \"a\"}\n</code></pre> <p>or value in payload is a list of </p> <pre><code>[\n  \"a\",\n  \"b\",\n  \"a\"\n]\n</code></pre> <p>then the key count equals to</p> <pre><code>{\n  \"a\": 2,\n  \"b\": 1\n}\n</code></pre> <p>and will be saved in payload@traits.public.counts</p> <p>If the payload values are:</p> <pre><code>[\n  {\"key1\": 1},\n  {\"key2\": 2},\n  {\"key1\": 2}\n]\n</code></pre> <p>then the key will be increased by the provided value. Then key1 + 1, key2 + 2, and key1 + 2. And the result will be:</p> <pre><code>{\n  \"key1\": 3,\n  \"key2\": 2\n}\n</code></pre> <p>You may also want to pass data the following way:</p> <pre><code>  {\n    \"key1\": 1,\n    \"key2\": 2\n  }\n</code></pre> <p>This will also work and the result will be:</p> <pre><code>  {\n    \"key1\": 1,\n    \"key2\": 2\n  }\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/key_counter_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"key\": \"desktop\",\n  \"save_in\": \"profile@stats.counters.MobileVisits\"\n}\n</code></pre> <p>Example of configuration with dot notation in key and save_in</p> <pre><code>{\n  \"key\": \"event@session.context.browser.agent\",\n  \"save_in\": \"profile@stats.counters.visits_origins\"\n}\n</code></pre> <p>Or with multiple key fields.</p> <pre><code>{\n  \"key\": [\n    \"event@session.context.browser.agent\",\n    \"event@session.context.browser.agent.string\"\n  ],\n  \"save_in\": \"profile@stats.counters.visits_origins\"\n}\n</code></pre> <ul> <li>key may be a string or a list of strings. Also, a dot notation can be used to access data.</li> <li>save_in point to data in profile that will hold the information on key counts. It should be empty object {} or a   key-value object. save_in holds the original data that will be incremented.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/lang_detection_action/","title":"Language detection Plugin","text":"<p>The purpose of this plugin is to detect language from given string with meaningcloud API</p>"},{"location":"getting_started/processes/workflow/actions/lang_detection_action/#configuration","title":"Configuration","text":"<p>This node requires configuration. You need have an account in meaningcloud to get access to API.</p> <p>Example</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;source-id&gt;\"\n  },\n  \"message\": \"Hello world!\",\n  \"timeout\": 10\n}\n</code></pre> <ul> <li>source.id - enter your resource id with access token, See below for resource schema.</li> <li>message - enter your message.</li> <li>timeout - response time-out.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/lang_detection_action/#resource-configuration","title":"Resource configuration","text":"<p>Example</p> <pre><code>{\n  \"token\": \"&lt;token&gt;\"\n}\n</code></pre> <p>Please register to https://www.meaningcloud.com/developer/account/subscriptions to obtain token.</p> <p>Use Api-Token resource template in GUI to create this kind of resource.</p>"},{"location":"getting_started/processes/workflow/actions/lang_detection_action/#input","title":"Input","text":"<p>This node does not process input payload.</p>"},{"location":"getting_started/processes/workflow/actions/lang_detection_action/#output","title":"Output","text":"<p>This node returns json with API response at response port if API call was successful.</p> <p>Example of successful call</p> <pre><code>{\n  \"status\": 200,\n  \"body\": {\n    \"deepTime\": 0.04363226890563965,\n    \"language_list\": [\n      {\n        \"iso-639-1\": \"en\",\n        \"iso-639-2\": \"eng\",\n        \"iso-639-3\": \"eng\",\n        \"language\": \"en\",\n        \"name\": \"English\",\n        \"relevance\": 100\n      }\n    ],\n    \"status\": {\n      \"code\": 0,\n      \"msg\": \"OK\",\n      \"credits\": 1,\n      \"remainig_credits\": 19964\n    },\n    \"time\": 0.04784107208251953\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/","title":"Last Profile Visit Time","text":"<p>The Last Profile Visit Time plugin provides the time difference between the current time and the last visit time of a user profile.</p>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/#version","title":"Version","text":"<p>This documentation is for the plugin version 0.7.3.</p>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/#description","title":"Description","text":"<p>The Last Profile Visit Time plugin is used to evaluate the last visit time of a user profile. It works by assessing the visit field in the profile metadata. If a recent visit is recorded, the plugin determines the amount of time passed since the last visit. However, if no recent visit is recorded, the plugin considers the profile insertion time as the last visit.</p> <p>It calculates the time differences in various units, such as seconds, minutes, hours, days, and weeks. If the timestamp recorded for the last visit is not a datetime object, an error message is generated.</p> <p>Note: This plugin is unable to fetch visit times if no profile data is present.</p>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin accepts a payload of any JSON-like object as an input.</p> <p>Here's an example of a typical input:</p> <pre><code>{\n  \"key1\": \"value1\",\n  \"key2\": \"value2\",\n  ...\n}\n</code></pre> <p>The output from the plugin is a JSON object containing the timestamp of the last visit (last) and the time difference (difference) in various units.</p> <p>Here's an example of a typical output:</p> <pre><code>{\n  \"last\": \"2022-03-23T05:58:43.826Z\",\n  // timestamp of the last visit\n  \"difference\": {\n    \"seconds\": 60,\n    \"minutes\": 1,\n    \"hours\": 0.016666667,\n    \"days\": 0.000694444,\n    \"weeks\": 0.000099206\n  }\n}\n</code></pre> <p>Please note that this plugin cannot start a workflow.</p>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/#configuration","title":"Configuration","text":"<p>This plugin does not require any configuration.</p>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/#json-configuration","title":"JSON Configuration","text":"<p>This plugin does not require any configuration thus there's no JSON configuration.</p>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/last_profile_visit_time/#errors","title":"Errors","text":"<p>The following error can occur during the operation of the Last Profile Visit Time plugin:</p> <ul> <li>\"Can not get last profile visit for without a profile.\" - This error occurs when there is no profile data available   for fetching the visit times.</li> <li>\"Last visit is not a date. Expected datetime object got type.\" - This error occurs when the last visit time is not   recorded as an expected datetime object. Here, type is the unexpected data type of the last visit time.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/limiter_action/","title":"Limiter plugin","text":"<p>The plugin limits the number of launches to a certain number in a given period of time. It is particularly useful when we would like to protect valuable resources from overloading or limit the triggering of some plugins. You have to remember that some events maybe triggered very fast and process time of a event may be longer then the time between the event triggers. That may cause the workflow to run server times. Is such case a throttle (limiter) may be used to limit the number of executions. It works ina a way that stops execution of a workflow branch if some threshold is passed, for example, 10 starts within one minute. The workflow will work until 10 executions are completed and then will throttle the rest of the executions until one minute end (or other defined time range).</p>"},{"location":"getting_started/processes/workflow/actions/limiter_action/#configuration","title":"Configuration","text":"<p>In order to properly configure the plugin, we need to know what resource we are protecting and how we identify it. Let's assume that we want to send emails to the specified email address. However, we don't want the system to send more than one email per day. Regardless of the email's message. In this case, the protected resource is email. Therefore, the key that will identify our limiter (throttle) will be the email address. You can define a pair of keys. e.g. if we do not want the customer to accidentally receive an email with the same content twice, we can set the key for the email and the e-mail message. The order of throttle keys is important, because this is the way the limiter identifies the protected resource.</p>"},{"location":"getting_started/processes/workflow/actions/limiter_action/#side-effects","title":"Side effects","text":"<p>The limiters placed in different workflows share the same information if they have he same key. That means if we send emails in many workflow and throttle/limit the number executions based on email - execution in one workflow will add up to the limit on the other workflow as well. This is a very powerful feature that can protect resources across all workflows if set properly. If you want the limiter to work only for one workflow and not across all workflows add workflow id (or custom key) to a limiter key, e.g. workflow.id + email.</p>"},{"location":"getting_started/processes/workflow/actions/limiter_action/#advanced-json-configuration","title":"Advanced JSON configuration","text":"<p>Example</p> <pre><code>{\n  \"keys\": [\"workflow@id\", \"profile@data.contact.email.main\", \"custom-key\"],\n  \"limit\": 10\n  \"ttl\": 60\n}\n</code></pre> <ul> <li>keys - keys that identify the throttle. It may reference data from workflow or be a custome keys</li> <li>limit - the number of allowed passes within defined time</li> <li>ttl - time to live for a throttle. The time period that must pass for the limit to be reset to 0.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/limiter_action/#outputs","title":"Outputs","text":"<ul> <li>pass - Triggers this port if not limited. Returns input payload.</li> <li>block - Triggers this port if executions are limited. Returns input payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/list_issues/","title":"List Issues","text":"<p>This is a Tracardi plugin which allows for the listing of GitHub issues.</p>"},{"location":"getting_started/processes/workflow/actions/list_issues/#version","title":"Version","text":"<p>This documentation was created for the \"List Issues\" plugin version 0.7.4.</p>"},{"location":"getting_started/processes/workflow/actions/list_issues/#description","title":"Description","text":"<p>The \"List Issues\" plugin is designed to retrieve issues from a specified GitHub repository. It begins with pre-defined configuration parameters, including a GitHub repository, which are stored in a dictionary form.</p> <p>Next, a resource is loaded and the credentials from the configuration dictionary are used to initialise a GitHub client. </p> <p>The final step is the execution of the list_issues() function. This retrieves the list of issues from GitHub and returns the result based on the response's 'status' parameter.</p> <p>If the status is either 200, 201, 202, 203, or 204, the result is returned at the payload port. On the other hand, if the status is different than the aforementioned, the result is returned at the error port.</p> <p>For example, if an error arises during the execution, you will receive a return with an error port.</p> <p>Please note that the returned result is dependent on the status of the response.</p>"},{"location":"getting_started/processes/workflow/actions/list_issues/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin takes one input:</p> <ul> <li>\"payload\": This port takes the payload object as an argument.</li> </ul> <p>It gives two outputs:</p> <ul> <li>\"payload\": This port returns the issues data from the GitHub repository.</li> <li>\"error\": This port returns an error message if the list_issues()function returns a status other than 200, 201, 202, 203, or 204.</li> </ul> <p>Note that this plugin cannot start a workflow.</p>"},{"location":"getting_started/processes/workflow/actions/list_issues/#configuration","title":"Configuration","text":"<p>The following are all configuration parameters for the plugin:</p> <ul> <li>\"resource\": This specifies the GitHub API resource and should be provided as a string. </li> <li>\"owner\": This is the username of the GitHub account owner. </li> <li>\"repo\": This specifies the GitHub repository from which you want to list issues. </li> <li>\"timeout\": This allows you to set a timeout limit for the GitHub client to fetch the resource.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/list_issues/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example configuration:</p> <pre><code>{\n\"resource\": \"ExampleResource\",\n\"owner\": \"John Doe\",\n\"repo\": \"example-repo\",\n\"timeout\": 120\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/list_issues/#required-resources","title":"Required resources","text":"<p>The plugin requires access to the GitHub API, therefore you will need to configure it with your own GitHub repository credentials.</p>"},{"location":"getting_started/processes/workflow/actions/list_issues/#errors","title":"Errors","text":"<p>If the list_issues() function returns a status other than 200, 201, 202, 203, or 204, the response will be returned through the error port.</p>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/","title":"LiveChat widget","text":"<p>The LiveChat widget plugin integrates the LiveChat messaging feature into webpages. This widget facilitates real-time chat between the website visitors and the support or sales teams.</p>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#version","title":"Version","text":"<p>0.7.3</p>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#description","title":"Description","text":"<p>This plugin is used to inject the LiveChat widget, a popular customer support chat tool, into a webpage. The widget allows website visitors to communicate directly with customer support or sales teams. It requires a LiveChat license number for activation. Once configured, the plugin appends a JavaScript snippet to the webpage, activating the LiveChat widget. This enhancement can significantly improve user engagement and customer support efficiency.</p>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin accepts a payload, typically containing the data necessary for the widget's operation.</li> <li>Outputs:<ul> <li>response: Outputs the payload back after processing. The main function of this plugin is to append the LiveChat   widget to the page, not to alter the payload.</li> <li>error: Outputs in case of any execution error.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#configuration","title":"Configuration","text":"<ul> <li>License: Your LiveChat license number, a crucial element for enabling the widget on your webpage.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#how-to-obtain-license-number","title":"How to obtain license number","text":"<p>In order to integrate this application with your webpage you will need to open an account at www.livechat.com. During sign-up, you will be presented with the following code:</p> <pre><code>&lt;!-- Start of LiveChat (www.livechat.com) code --&gt;\n&lt;script&gt;\n    window.__lc = window.__lc || {};\n    window.__lc.license = &lt;LICENSE&gt;;\n    ;(function(n,t,c){function i(n){return e._h?e._h.apply(null,n):e._q.push(n)}var e={_q:[],_h:null,_v:\"2.0\",on:function(){i([\"on\",c.call(arguments)])},once:function(){i([\"once\",c.call(arguments)])},off:function(){i([\"off\",c.call(arguments)])},get:function(){if(!e._h)throw new Error(\"[LiveChatWidget] You can't use getters before load.\");return i([\"get\",c.call(arguments)])},call:function(){i([\"call\",c.call(arguments)])},init:function(){var n=t.createElement(\"script\");n.async=!0,n.type=\"text/javascript\",n.src=\"https://cdn.livechatinc.com/tracking.js\",t.head.appendChild(n)}};!n.__lc.asyncInit&amp;&amp;e.init(),n.LiveChatWidget=n.LiveChatWidget||e}(window,document,[].slice))\n\n&lt;/script&gt;\n&lt;noscript&gt;&lt;a href=\"https://www.livechat.com/chat-with/&lt;LICENSE&gt;/\" rel=\"nofollow\"&gt;Chat with us&lt;/a&gt;, powered by &lt;a\n        href=\"https://www.livechat.com/?welcome\" rel=\"noopener nofollow\" target=\"_blank\"&gt;LiveChat&lt;/a&gt;&lt;/noscript&gt;\n&lt;!-- End of LiveChat code --&gt;\n</code></pre> <p>Please copy the sting that is at the LICENSE position to the plugin form.</p> <p>If you already have an account log-in to the system and go to Settings. Select Channel/WebSite. You should see the same code.</p>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"license\": \"your-livechat-license-number\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#event-prerequisites","title":"Event prerequisites","text":"<p>Plugins like the Livechat widget, which fall under the \"UIX Widgets\" category, require a synchronous event. It will not work if sent event is asynchronous.</p>"},{"location":"getting_started/processes/workflow/actions/livechat_widget_action/#errors","title":"Errors","text":"<ul> <li>\"License can not be empty.\": This error occurs when the LiveChat license number is not provided in the plugin   configuration. The license number is essential for the widget's operation.</li> <li>General script-related errors might occur, usually related to the execution of the appended JavaScript in the webpage   environment. These errors could arise from conflicts with other scripts or issues in the webpage's structure.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/local_time_span_action/","title":"Local time span action","text":"<p>The purpose of this plugin is to check if the local time is within  defined time span.</p> <p>This action minds the time zone of the event. Therefore, you must provide  time zone. By default, time zone is included in browser event context. </p>"},{"location":"getting_started/processes/workflow/actions/local_time_span_action/#configuration","title":"Configuration","text":"<p>This node requires configuration. In order to read timezone  you must define path to it. Use dot notation to do that.</p> <p>Moreover, you need to set start and end of the time span. The time slots  have no default values. </p> <p>Example of the configuration:</p> <pre><code>{\n  \"timezone\": \"session@context.time.tz\",\n  \"start\": \"12:00:00\",\n  \"end\": \"14:00:00\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/local_time_span_action/#input","title":"Input","text":"<p>This node does not process input payload.</p>"},{"location":"getting_started/processes/workflow/actions/local_time_span_action/#output","title":"Output","text":"<p>Return input payload on IN port or OUT port. Returns data on IN port if local time is in defined time span.</p>"},{"location":"getting_started/processes/workflow/actions/log_message_action/","title":"Log message plugin","text":"<p>This plugin logs message to flow logs.</p>"},{"location":"getting_started/processes/workflow/actions/log_message_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/log_message_action/#output","title":"Output","text":"<p>This plugin returns given payload on port payload without any changes.</p>"},{"location":"getting_started/processes/workflow/actions/log_message_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"type\": \"warning | info | error\",\n  \"message\": \"&lt;your-message&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/","title":"Add to MailChimp audience plugin","text":"<p>This plugin adds contact to your MailChimp audience based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/#requirements","title":"Requirements","text":"<p>Before using this plugin, you need to create MailChimp account, generate marketing API key and add MailChimp to resources.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/#input","title":"Input","text":"<p>This plugin takes payload - any JSON-like object.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/#outputs","title":"Outputs","text":"<p>Plugin returns MailChimp API response on response port if action was successful, or an error from MailChimp API on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/#config","title":"Config","text":""},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/#form-fields","title":"Form fields","text":"<ul> <li>MailChimp resource - here select your MailChimp marketing resource with API key.</li> <li>ID of your list (audience) - it's your audience's ID, that you can easily check on MailChimp website (see below for instructions).</li> <li>Contact's email address - that's path to email address of your contact. Notice that field can contain multiple values,   so if profile after merging has two email addresses, then plugin will add two contacts to your audience.</li> <li>MailChimp merge fields - here you can determine relation between your audience's merge fields and fields in Tracardi   data. If you associate merge field FNAME (which is default merge field for first name) with dot path **   profile@pii.name**, then your contact's first name will be taken from this Tracardi field.</li> <li>Subscribed - this parameter determines whether contact is ready for sending emails or should receive confirmation   email from MailChimp. According to MailChimp's policy, you must have contact's explicit consent in order to mark them   as subscribed.</li> <li>Update existing data - here you can determine whether plugin is allowed to edit existing contacts according to email   address compatibility.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/#where-do-i-find-mailchimp-audience-id","title":"Where do I find Mailchimp audience ID?","text":"<p>To find your audience ID do the following steps:</p> <ul> <li>Click Audience.</li> <li>Click All contacts.</li> <li>If you have more than one audience, click the Current audience drop-down and choose the one you want to work with.</li> <li>In the tabs find Settings and click the Setting's drop-down</li> <li>Choose \"Audience name and defaults\".</li> <li>In the Audience ID section, you'll see a string of letters and numbers.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/mailchimp_add_to_audience_action/#config-with-json","title":"Config with JSON:","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-resource&gt;\",\n    \"name\": \"&lt;name-of-your-resource&gt;\"\n  },\n  \"list_id\": \"&lt;id-of-your-mailchimp-audience&gt;\",\n  \"email\": \"&lt;dot-path-to-field-containing-email-address&gt;\",\n  \"merge_fields\": {\n    \"&lt;merge_field_name&gt;\": \"&lt;tracardi-field-name&gt;\" \n  },\n  \"subscribed\": &lt;bool&gt;,\n  \"update\": &lt;bool&gt;\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/","title":"Remove from MailChimp audience plugin","text":"<p>This plugin removes contact from your MailChimp audience based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/#requirements","title":"Requirements","text":"<p>Before using this plugin, you need to create MailChimp account, generate marketing API key and add MailChimp to resources.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/#input","title":"Input","text":"<p>This plugin takes payload - any JSON-like object.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/#outputs","title":"Outputs","text":"<p>Plugin returns MailChimp API response on response port if action was successful, or an error from MailChimp API on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/#config","title":"Config","text":""},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/#config-with-form","title":"Config with form","text":"<ul> <li>MailChimp resource - here select your MailChimp marketing resource with API key.</li> <li>ID of your list (audience) - it's your audience's ID, that you can easily check on MailChimp website (see below for instructions).</li> <li>Contact's email address - that's path to email address of your contact. Notice that field can contain multiple values,   therefore if profile after merging has two email addresses, then plugin will add two contacts to your audience.</li> <li>Permanently delete contact - Here you can determine whether given contact should be archived (such that you can re-add   them)   or permanently deleted, with no way of recreating and no data left (at least without their consent).</li> </ul> <p>Possible lose of data</p> <p>Removing an email from the recipient list with the delete option has serious ramifications.  Once deleted, an e-mail cannot be added without the consent of its owner again. Use the delete  option with caution. In most cases, delete: false is the correct configuration</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/#where-do-i-find-mailchimp-audience-id","title":"Where do I find Mailchimp audience ID?","text":"<p>To find your audience ID do the following steps:</p> <ul> <li>Click Audience.</li> <li>Click All contacts.</li> <li>If you have more than one audience, click the Current audience drop-down and choose the one you want to work with.</li> <li>In the tabs find Settings and click the Setting's drop-down</li> <li>Choose \"Audience name and defaults\".</li> <li>In the Audience ID section, you'll see a string of letters and numbers.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/mailchimp_remove_from_audience_action/#config-with-json","title":"Config with JSON","text":"<p>Example</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mailchimp-source&gt;\",\n    \"name\": \"&lt;name-of-your-mailchimp-source&gt;\"\n  },\n  \"list_id\": \"&lt;id-of-your-audience&gt;\",\n  \"email\": \"&lt;path-to-field-containing-emails&gt;\",\n  \"delete\": &lt;bool&gt;\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/","title":"Send transactional e-mail plugin","text":"<p>This plugin sends transactional email via MailChimp (Mandrill) API.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#requirements","title":"Requirements","text":"<p>You'll need a Mandrill account to use this plugin. Then you'll need to generate API key in settings -&gt; SMTP &amp; API Info  on mandrillapp.com.</p> <p>MailChimp requires a domain configuration to send e-mails, you'll need to add and configure your domain in MailChimp settings. Please refer to MailChimp documentation for details.</p> <p>The last thing is your MailChimp plan - if you're on the trial version, you are able to send emails only within your own domain, so if your email is examplemail@example.com, then your domain is simply example.com and you can send messages only to emails ending with example.com.</p> <p>To get rid of this restriction, you need a paid plan on MailChimp.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#input","title":"Input","text":"<p>This plugin takes any payload.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#output","title":"Output","text":"<p>This plugin returns a response from MailChimp API. Depending on the response result it will trigger ether payload  port (if the response is successful) or error for if the response indicates that the e-mail was not sent.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#config","title":"Config","text":"<p>Plugin's configuration requires information about API key, sender email,  message recipient's email(s), message subject and message content.</p> <pre><code>{\n  \"source\": {\n    \"name\": \"MailChimp Token\",\n    \"id\": \"4529f2a4-62a2-44b0-9a0b-e8dae1f5f6b0\"\n  },\n  \"sender_email\": \"sender@tracardi.com\",\n  \"message\": {\n    \"recipient\": \"payload@email\",\n    \"content\": {\n      \"type\": \"text/html\",\n      \"content\": \"Message body\"\n    },\n    \"subject\": \"subject\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#mailchimp-resource","title":"Mailchimp resource","text":"<p>MailChimp token must be stored in Tracardi's resources. Please remember to provide both test and production API key  (token) in resource configuration.</p> <p>MailChimp API Tokens can be found in settings -&gt; SMTP &amp; API Info on mandrillapp.com. It is a string with random characters.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#senders-e-mail","title":"Sender's e-mail","text":"<p>That's the email that you want to send emails from. It has to end with one of your domains registered in Mandrill. For instance, if your shop is exampleshop.com,  then you may want to send emails from an address like office@exampleshop.com, and then that's the value that you want to insert into plugin configuration. Please notice that this address does not have to exist.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#message-recipients-email","title":"Message recipient's email","text":"<p>This is the destination email or emails. It can be in form of dot path to email address (for example profile@data.contact.email.main).  You can also insert the address itself. Please notice that merged profiles can have multiple values in one field -  if John Doe has two or more email addresses in his profile, then plugin will send the message to all of them.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#message-subject","title":"Message subject","text":"<p>That's message subject, if you type in payment, then recipient of the message will see  payment as the subject of received message.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#message-content","title":"Message content","text":"<p>You can select if your content should be HTML or just plain text.  You can also use templates for your emails - both in HTML and text format. </p> <p>Examples:</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#example-1-plain-text","title":"Example 1 - plain text","text":"<pre><code>Hello {{profile@pii.name}}, your order will be dispatched in next two days.\n</code></pre> <p>This message will have the {{profile@pii.name}} changed to the current profile's name, so John Doe will see 'Hello John, your order will be dispatched in next two days.' in his message.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#example-2-html","title":"Example 2 - HTML","text":"<p><pre><code>&lt;h1&gt;Hello {{profile@pii.name}}!&lt;/h1&gt;\n&lt;p&gt;Thanks for visiting our website on {{profile@metadata.time.visit.last}}!&lt;/p&gt;\n&lt;p style=\"color:red\"&gt;To thank you, we send you a photo of cute dog. Enjoy:&lt;/p&gt;\n&lt;img src=\"&lt;url-to-photo-of-cute-dog&gt;\"/&gt;\n</code></pre> Like before, recipient will see his name in the header, and the text with date of his last visit, together with the red text about a photo of a dog, and a photo itself.</p>"},{"location":"getting_started/processes/workflow/actions/mailchimp_transactional_action/#tip","title":"Tip","text":"<p>On MailChimp site, you can turn on the test mode after clicking on you username in up-right corner. In the test mode, you can generate test API key. You can use it in Tracardi for test purposes -  messages won't be sent, but MailChimp will act like they are, so you can test your configuration without being charged a single cent.</p>"},{"location":"getting_started/processes/workflow/actions/mapping_action/","title":"Value mapping plugin","text":"<p>This plugin works like a value switch. Unlike if-then and if-then-else statements, the switch statement can have a number of possible execution paths. The statement value is compared to all the defined key values. If it matches the value the corresponding value is returned.</p>"},{"location":"getting_started/processes/workflow/actions/mapping_action/#input","title":"Input","text":"<p>This plugin takes any payload object as input.</p>"},{"location":"getting_started/processes/workflow/actions/mapping_action/#output","title":"Output","text":"<p>This plugin outputs one of values defined in config if it matches its key in the provided set of key-value pairs. If none of the values are equal to statement value null is returned. </p>"},{"location":"getting_started/processes/workflow/actions/mapping_action/#configuration-example","title":"Configuration example","text":"<p>Configuration takes a value and a set of data defined in switch property.</p> Example<pre><code>{\n  \"value\": \"&lt;statement-value&gt;\",\n  \"switch\": {\n    \"payload@xyz\": \"value1\",\n    \"key1\": \"profile@abc\",\n    \"key2\": \"value2\"\n  }\n}\n</code></pre> <p>Value contains a statement value. It will be compared with all the key values defined in a \"switch\". In this example: value referenced by \"payload@xyz\", key1, key2. If statement value is also a reference to value for example profile@id then it will be evaluated first and the referenced value will be used as a statement value. </p> <p>In the above case, when the field specified in value has the same value as value referenced by payload@xyz, then value1 will be returned. If value is equal to key1, then value from field ** profile@abc** will be returned, etc.</p>"},{"location":"getting_started/processes/workflow/actions/mapping_action/#result-example","title":"Result example","text":"<pre><code>{\n  \"value\": \"value2\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/marge_data_action/","title":"Merge data","text":"<p>The plugin can combine data from two data schemas. This is especially useful in situations where we want to add a new set of data to the existing one. For example, a new set of features for an existing entity. Or when we want to combine profile and event data.</p> <p>The plugin works in such a way that we indicate the source data and the data that we want to combine. The source data is in the form of reference and the data that we want to add is passed in the form of an object. The object can be a schema with references to workflow data. For this purpose, we use an object template - more about the object template can be found in the documentation.</p> <p>The output of this plugin is the combined output of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/marge_data_action/#configuration","title":"Configuration","text":"<p>The plugin requires:</p> <ul> <li>source - a reference to input data, e.g. profile@traits.public</li> <li>data - data to be merged. An object with data: {\"name\": \"Bill\"}</li> <li>connection - a method how to combine the data. The available methods are:</li> <li>override - overwrite data in case of data conflict</li> <li>merge - combine data in case of conflict in array of all data</li> </ul>"},{"location":"getting_started/processes/workflow/actions/marge_data_action/#example","title":"Example","text":"<p>Lets assume that our profile has the following traits:</p> <pre><code>{\n   \"public\": {\n       \"name\":\"William\",\n       \"surname\": \"Gates\",\n       \"age\": 70\n    }\n}\n</code></pre> <p>We reference it in configuration as a source: profile@traits</p> <p>Then we define our data to merge: </p> <pre><code>{\n  \"public\": {\n     \"name\": \"Bill\"\n  },\n  \"private\": {\n     \"location\": \"LA, USA\"\n  }\n}\n</code></pre> <p>After merging we get the follwin result.</p> <p>For override method:</p> <pre><code>{\n  \"public\": {\n     \"name\": \"Bill\",\n     \"surname\": \"Gates\",\n     \"age\": 70\n  },\n  \"private\": {\n     \"location\": \"LA, USA\"\n  }\n}\n</code></pre> <p>For merge method:</p> <pre><code>{\n  \"public\": {\n     \"name\": [\"Bill\", \"William\"],\n     \"surname\": \"Gates\",\n     \"age\": 70\n  },\n  \"private\": {\n     \"location\": \"LA, USA\"\n  }\n}\n</code></pre> <p>Notice that if there are different values for the same field, e.g. for the name field, one is \"Bill\", the second time it is \"William\", then the data will be combined and we will get a value name = [\"Bill\", \"William\"] if merge method is selected.</p>"},{"location":"getting_started/processes/workflow/actions/mask_data/","title":"Mask data","text":"<p>This plugin masks the contents of specified profile traits, replacing them with a \"###\" character sequence. This allows for data obfuscation or masking whenever necessary.</p>"},{"location":"getting_started/processes/workflow/actions/mask_data/#version","title":"Version","text":"<p>The version of this plugin is 0.7.0.</p>"},{"location":"getting_started/processes/workflow/actions/mask_data/#description","title":"Description","text":"<p>The Mask data plugin takes a payload and masks the contents of traits specified in the configuration. Instead of their original content, these traits have their values replaced with a \"###\" character sequence.</p> <p>When running, the plugin first accesses the payload's dot notation through the <code>_get_dot_accessor</code> method. Then for each trait specified in the configuration, it checks the data source. If the data source is either 'flow' or 'event', the trait data cannot be modified and a warning message is logged to the console. Another warning is logged if a specified trait is either invalid or doesn't exist.</p> <p>If none of the above issues occur, the trait's value is replaced with \"###\". If there is profile or session data in the payload, the original profile or session is replaced with an updated version that includes the masked traits.</p> <p>The plugin then returns the payload with the masked trait data back into the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/mask_data/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Mask data plugin has only one input and one output port:</p> <p>Inputs: - payload: This port accepts a payload object. Depending on the payload content and the plugin configuration, some traits of the payload might get masked.</p> <p>Outputs: - payload: This port returns the same payload object that was passed as input, but with some traits masked, depending on the configuration.</p> <p>Note: This plugin cannot be used as a starting node in a workflow.</p>"},{"location":"getting_started/processes/workflow/actions/mask_data/#configuration","title":"Configuration","text":"<ul> <li>traits: A list of strings representing the traits to be masked. These traits should be specified in a dot notation format and will be replaced with \"###\".</li> </ul>"},{"location":"getting_started/processes/workflow/actions/mask_data/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of JSON configuration for the Mask data plugin: <pre><code>{\n    \"traits\": [\"profile@trait1\", \"session@trait2\"]\n}\n</code></pre></p>"},{"location":"getting_started/processes/workflow/actions/mask_data/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/mask_data/#errors","title":"Errors","text":"<ul> <li> <p>If the source of a trait to be masked is either 'event' or 'flow', the trait values cannot be modified in the workflow. In such a case, a warning \"Event/Flow values cannot be hashed.\" will be logged.</p> </li> <li> <p>If a specified trait is either invalid or does not exist, a warning \"Given trait {trait} is invalid or does not exist.\" will be logged. Note that the \"{trait}\" placeholder will be replaced with the actual trait in the log.</p> </li> </ul> <p>Remember to validate your configuration before running a workflow with this plugin. Inaccurately defined traits will lead to warnings and may cause the plugin to not properly mask the desired data.</p>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/","title":"Merge event properties","text":"<p>Automatically merges all event properties to profile traits.</p>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#version","title":"Version","text":"<p>0.8.1</p>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#description","title":"Description","text":"<p>This plugin is designed to merge event properties with the available profile traits. It does not take any decisions, but instead systematically merges all properties with existing traits. It is important to note that if there are existing traits that are the same as the properties, these traits will be updated with the new properties' values. </p> <p>The plugin operates by determining first if there is a profile available. Then, it locates where the properties should be merged within the profile traits using the user-defined path. The merging process may occur at the root of your profile traits if no sub-path is provided. Otherwise, a new sub-path can be created or an existing one can be updated if one is entered by the user.</p> <p>The outcome of this merging process is refleted in the updated profile traits. </p>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Input: This plugin inputs a payload object.</li> <li>Output: This plugin outputs merged traits if the operation is successful. If no profile is available, an error will be generated.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#configuration","title":"Configuration","text":"<p>The configuration of this plugin is quite simple, you only have one configuration parameter: - Sub traits path : If you want to merge data to the root of your profile traits, leave this field empty. But if you intend to create or merge a specific part of the profile traits, type the sub-path in here. This path will be appended to the main traits path, e.g: profile@traits[sub.path]. </p>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#json-configuration","title":"JSON Configuration","text":"<p>Example:</p> <pre><code>{\n  \"sub_traits\": \"sub.path\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#errors","title":"Errors","text":"<ul> <li>error : This error occurs when there is no available profile.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/merge_event_properties/#note","title":"Note","text":"<p>The merging process may replace existing values with new ones from the properties that are being merged, especially if they have the same keys. This is important to bear in mind when deciding which event properties to merge with the profile traits.</p>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/","title":"Merge profiles","text":"<p>This plugin combines customer profiles in Tracardi when new information about a customer is added. It helps to make one complete profile from many separate ones.</p>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#description","title":"Description","text":"<p>The Merge Profiles Action in Tracardi is for joining different customer profiles into one. This is useful when new personal information is added to a customer's profile. The action marks the profile to be joined together at the end of the process. The joining is done using specific keys like email or phone number, which are unique to a user. When it finds profiles with the same key, it puts them together, and all their information and activities become part of one profile. The old profiles are removed but their IDs stay connected to the new combined profile.</p>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#additional-information","title":"Additional Information","text":"<p>The merge key is a special part of the system that helps to put different customer profiles together into one. This key is something unique to each customer, like their email, phone number, or ID. The system searches for other profiles with the same key and combines them into one.</p> <p>When the profiles are put together, all their details and actions become part of one big profile. The profiles that are not needed anymore are removed, but their ID stays linked to the new big profile. So, if you look for an old profile, the system will show you the new, combined one.</p> <p>If you want to join profiles using more than one key, like both email and name, the system will look for profiles that match both these details. You should list these merge keys in a JSON array. To find and use these merge keys, you use a special format called dotted notation. You can learn more about this in the documentation's Notations/Dot notation section.</p>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin takes any kind of data in a JSON format and gives back the same data.</p> <p>Input: <code>{\"payload\": {}}</code> Output: <code>{\"payload\": {}}</code></p> <p>The plugin does not start the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#configuration","title":"Configuration","text":"<ul> <li>Merge by fields: This is a list of fields used to identify a user, such as <code>profile@data.contact.email.main</code>.   These fields are like keys for joining profiles. Profiles with the same key values are put together.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"mergeBy\": [\n    \"profile@data.contact.email.main\"\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#required-resources","title":"Required resources","text":"<p>This plugin does not need external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#errors","title":"Errors","text":"<ul> <li>\"Field mergeBy is empty and has no effect on merging. Add merging key or remove this action from flow.\" This error   happens when the merge key list is empty.</li> <li>\"Field <code>{key}</code> does not start with profile@... Only profile fields are used during merging.\" This error occurs when   the provided merge key does not start with 'profile@'. The plugin only uses profile fields for merging.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/merge_profiles_action/#a-simpler-way-to-combine-profiles-in-commercial-tracardi","title":"A Simpler Way to Combine Profiles in Commercial Tracardi","text":"<p>In the commercial version of Tracardi, there's a feature called an identification point that helps recognize customers during their use of the system. This feature works by watching for certain activities. These activities help the system figure out who the customer is, even if they were unknown before.</p> <p>Here's an easy way to understand it: It's like when you go through a check at an airport or during a police stop. You're just another person until you have to show your ID. That moment, when you show your ID, is like an identification point. Once you're identified in Tracardi, all your past activities are linked to your known profile. This means if you're identified in various ways over time, like with an email or a phone number, all your previously unknown activities get linked to your known profile.</p> <p>For instance, if there's already a profile in the system with an email address, and the same email shows up in a new activity, Tracardi will realize that this anonymous data actually belongs to the existing profile. Then, it combines all the past activities with this profile.</p> <p>In simple terms, this feature in the commercial Tracardi is a way to keep track of customers and ensure their information stays connected and current throughout their interactions with the system.</p>"},{"location":"getting_started/processes/workflow/actions/microservice/","title":"Microservice","text":"<p>This plugin allows you to execute a plugin that resides on a remote microservice. The Microservice plugin sends a payload to a remote server where the actual plugin code is run, and then captures the results of the execution.</p>"},{"location":"getting_started/processes/workflow/actions/microservice/#version","title":"Version","text":"<p>0.7.2</p>"},{"location":"getting_started/processes/workflow/actions/microservice/#description","title":"Description","text":"<p>The Microservice plugin forwards the payload and some other information (called \"context\") about the environment in which the plugin is running to a remote server. The specific plugin that will process the payload is identified by the service_id and action_id. All the information sent to the remote server is packed into a dictionary and encoded as a JSON string.</p> <p>This JSON string is then sent to the specified URL using a POST HTTP request. When the response arrives from the remote server, it is returned as the plugin's result.</p> <p>The plugin returns two types of ports, either \"response\" or \"error\". The value of the port is determined at runtime depending on the outcome of the remote server's execution. The \"response\" port is returned if the remote server successfully processed the payload, and \"error\" is returned if it failed to process the payload.</p> <p>The remote server is responsible for updating the workflow's internal state with new information from the request's context.</p>"},{"location":"getting_started/processes/workflow/actions/microservice/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Microservice plugin only manages one input port named \"payload\". This is the input data that the plugin will forward to the remote server for processing.</p> <p>Here is an example of an input JSON:</p> <pre><code>{\n  \"payload\": {\n    \"data-key\": \"data-value\"\n  }\n}\n</code></pre> <p>This plugin has two output ports: \"response\" and \"error\". The response port is triggered when the communication with the remote server is successful, and returns the data returned by the remote server, and the error port is triggered when the communication failed, it returns the error information.</p> <p>The returned values can be like this (example in JSON format):</p> <pre><code>{\n  \"response\": {\n    \"result\": {\n      \"key1\": \"value1\",\n      \"key2\": \"value2\"\n    },\n    \"context\": {\n      \"session\": {\n        \"id\": \"abc123\",\n        \"startTime\": \"1641326491\"\n      },\n      \"profile\": {\n        \"id\": \"def456\",\n        \"timestamp\": \"1641326491\"\n      }\n    },\n    \"console\": {\n      \"logs\": [\n        \"log1\",\n        \"log2\",\n        \"log3\"\n      ]\n    }\n  },\n  \"error\": {\n    \"message\": \"An error occurred while processing the request.\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/microservice/#configuration","title":"Configuration","text":"<p>This plugin does not require any special configuration.</p>"},{"location":"getting_started/processes/workflow/actions/microservice/#json-configuration","title":"JSON Configuration","text":"<p>This plugin does not have any configuration inputs, thus there is no JSON Configuration required.</p>"},{"location":"getting_started/processes/workflow/actions/microservice/#required-resources","title":"Required resources","text":"<p>The Microservice plugin requires an external resource, a remote server with the specified url and token.</p>"},{"location":"getting_started/processes/workflow/actions/microservice/#errors","title":"Errors","text":"<ul> <li> <p>\"Plugin {node.microservice.plugin.name} not implemented correctly. It must return result either on port response or   error, returned data on port {result.port}. This error occurs when the remote server returns result on a port other   than \"response\" or \"error\".</p> </li> <li> <p>If the remote server returns a HTTP Status different from 200, the error port is triggered and the response from the   server is returned as the error. For example, when a 404 status is returned, it means that the requested resource   could not be found on the remote server. Other status codes represent other types of HTTP errors.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/mongo_query_action/","title":"Mongo connector","text":"<p>This plugin connects to mongo and queries this database.</p>"},{"location":"getting_started/processes/workflow/actions/mongo_query_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"MongoDB\",\n    \"id\": \"fbabb00e-a724-40bf-b889-bd8d6a7f25e2\"\n  },\n  \"database\": \"my_database\",\n  \"collection\": \"my_collection\",\n  \"query\": \"{}\"\n}\n</code></pre> <ul> <li>database - database name.</li> <li>collection - mongodb collection.</li> <li>query - mongodb query.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/mongo_query_action/#input","title":"Input","text":"<p>This node does not process input payload.</p>"},{"location":"getting_started/processes/workflow/actions/mongo_query_action/#output","title":"Output","text":"<p>Query result.</p>"},{"location":"getting_started/processes/workflow/actions/mysql_connector_action/","title":"Mysql Connector","text":"<p>This plugin connects to Mysql and executes a SQL query.</p>"},{"location":"getting_started/processes/workflow/actions/mysql_connector_action/#configuration","title":"Configuration","text":"<p>Example</p> <pre><code>{\n  \"source\": {\n    \"name\": \"mysql\",\n    \"id\": \"a8430a5c-43de-44eb-9c25-2b1426aed3a0\"\n  },\n  \"type\": \"select\",\n  \"query\": \"SELECT * FROM user WHERE User=%s;\",\n  \"data\": [\n    \"root\"\n  ],\n  \"timeout\": 10\n}\n</code></pre> <ul> <li>source this a resource with MySQL credentials. See below for credentials schema.</li> <li>type - type of query, possible values are ['select', 'insert', 'delete', 'update']</li> <li>query - this is the SQL prepared statement. It will replace %s with data provided in data key. This is a   sequential order so order of %s and data matters.</li> <li>data - data to replace in SQL prepared statement template.</li> <li>timeout - query timeout.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/mysql_connector_action/#resource-schema","title":"Resource schema","text":"<p>Example</p> <pre><code>{\n  \"host\": \"192.168.1.103\",\n  \"port\": 3306,\n  \"user\": \"root\",\n  \"password\": \"root\",\n  \"database\": \"mysql\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/mysql_connector_action/#output","title":"Output","text":"<p>It returns the data in JSON.</p> <p>Example</p> <pre><code>{\n  \"result\": [\n    {\n      \"Host\": \"%\",\n      \"User\": \"root\",\n      \"Select_priv\": \"Y\",\n      \"Insert_priv\": \"Y\",\n      \"Update_priv\": \"Y\",\n      \"Delete_priv\": \"Y\",\n      \"Create_priv\": \"Y\",\n      \"Drop_priv\": \"Y\"\n    },\n    {\n      \"Host\": \"localhost\",\n      \"User\": \"root\",\n      \"Select_priv\": \"Y\",\n      \"Insert_priv\": \"Y\",\n      \"Update_priv\": \"Y\",\n      \"Delete_priv\": \"Y\",\n      \"Create_priv\": \"Y\",\n      \"Drop_priv\": \"Y\"\n    }\n  ]\n}\n</code></pre> <p>If the query is of insert type then the output result will have last inserted record id.</p> <p>If the query is of type \"delete\",\"update\", or \"create\" then the output result will have input payload.</p>"},{"location":"getting_started/processes/workflow/actions/mysql_connector_action/#errors","title":"Errors","text":"<pre><code>Not all arguments converted during string formatting\n</code></pre> <p>This error is raised when the number of %s placeholders and data do not match. That means the number of placeholders is not equal to the number of data.</p>"},{"location":"getting_started/processes/workflow/actions/new_event_action/","title":"New Event Action","text":"<p>Raise event action triggers defined event type as if it was triggered for web-site or any other device. This event can be intercepted by TRACARDI to run defined flow. Event can also send defined event properties.</p>"},{"location":"getting_started/processes/workflow/actions/new_event_action/#configuration","title":"Configuration","text":"<p>You need to configure the action for it  to run. Below is an example of RAISE EVENT action configuration file.</p> <p>You must profile event type and event properties that will be attached to event and then send again to TRACARDI.</p> <pre><code>{\n  \"event\": {\n    \"type\": \"purchase-order\",\n    \"properties\": {\"name\":  \"iPhone 128 GB white\", \"delivery\":  \"next day\"}\n  }\n}\n</code></pre> <p>You may want to set properties from payload. To do that start with @ and give a path (in dot notation) to json data. See the example below.</p> <p>PAYLOAD example</p> <pre><code>{\n  \"properties\": {\n    \"private\": {\n      \"email\": \"...\",\n      \"name\": \"...\"\n    }\n  }\n}\n</code></pre> <p>RAISE EVENT configuration <pre><code>{\n  \"event\": {\n    \"type\": \"merge-profile\",\n    \"properties\": \"@traits.private\"\n  }\n}\n</code></pre></p> <p>Above configuration will copy data from payload starting from properties.private. This will give you a slice of data equal to:</p> <pre><code>{\n  \"email\": \"...\",\n  \"name\": \"...\"\n}\n</code></pre> <p>This is an equivalent of the following configuration. Of course it is more dynamic as it will  take any data that comes in payload. </p> <pre><code>{\n  \"event\": {\n    \"type\": \"merge-profile\",\n    \"properties\": {\n      \"email\": \"...\",\n      \"name\": \"...\"\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/new_event_action/#debugging","title":"Debugging","text":"<p>Debugging of flows with raised event can be pretty tricky as you will only see data from one flow. You will not see data from other triggered flows by RAISE EVENT.</p>"},{"location":"getting_started/processes/workflow/actions/new_event_action/#cyclic-flows","title":"Cyclic flows","text":"<p>Raised event can form a never ending cycles. For example flow-1 raises event X which triggers flow-2. And flow-2 raises event Y which triggers flow-1, and flow-2 again triggers event X ... This execution can never end.</p> <p>To prevent this type of cyclic execution TRACARDI will stop sending new events when it detects a possible cyclic execution.</p>"},{"location":"getting_started/processes/workflow/actions/new_profile_action/","title":"New profile","text":"<p>This plugin will return payload on TRUE port if the event created new profile. This usually happens when the customer  visits site for the very first time.</p>"},{"location":"getting_started/processes/workflow/actions/new_profile_action/#output","title":"Output","text":"<p>Payload on TRUE or FALSE port depending on if the profile was just created.</p>"},{"location":"getting_started/processes/workflow/actions/new_visit_action/","title":"New visit","text":"<p>This plugin will return payload on TRUE port if the event indicates that this is a new visit. This usually happens when the customer  visits site for the first, second, third time, etc. Visit is considered finished whe the user leaves the page and closes the browser. This plugin will trigger only on the first page view of the visit when a new session is created. Second click within the visit will  not trigger this action.</p>"},{"location":"getting_started/processes/workflow/actions/new_visit_action/#output","title":"Output","text":"<p>Payload on TRUE or FALSE port depending on if this is a new visit.</p>"},{"location":"getting_started/processes/workflow/actions/novu_plugin_action/","title":"Novu trigger plugin","text":"<p>Novu is an open-source notification infrastructure built for the engineering teams to help them build rich product notification experiences from single platform.</p>"},{"location":"getting_started/processes/workflow/actions/novu_plugin_action/#json-configuration","title":"JSON Configuration","text":"<p>Example:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"0ad150a3-5faa-4161-82b6-5ecfda7eaf6f\",\n    \"name\": \"api_key\"\n  },\n  \"template_name\": \"template_name\",\n  \"subscriber_id\": \"profile@id\",\n  \"recipient_email\": \"profile@data.contact.email.main\",\n  \"payload\": \"{}\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/novu_plugin_action/#resource-configuration","title":"Resource configuration","text":"<p>To run this plugin you must provide APIKEY from your Novu profile configuration.</p> <p>Example of source configuration for Novu trigger:</p> <pre><code>{\n  \"token\": \"token\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/oauth2_token_action/","title":"Get OAuth2 token plugin","text":""},{"location":"getting_started/processes/workflow/actions/oauth2_token_action/#inputs","title":"Inputs","text":"<p>This plugin takes any payload object.</p>"},{"location":"getting_started/processes/workflow/actions/oauth2_token_action/#outputs","title":"Outputs","text":"<p>This plugin outputs given payload object modified according to configuration.</p>"},{"location":"getting_started/processes/workflow/actions/oauth2_token_action/#config","title":"Config","text":""},{"location":"getting_started/processes/workflow/actions/oauth2_token_action/#with-form","title":"With form","text":"<ul> <li>API endpoint resource - here select your API-endpoint-type resource that you want to get a token from.</li> <li>Token destination - here type in path to a field (starting with 'payload@'), where you want to store an object returned by endpoint.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/oauth2_token_action/#advanced-config","title":"Advanced config","text":"<p><pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-api-endpoint-resource&gt;\",\n    \"name\": \"&lt;name-of-your-api-endpoint-resource&gt;\"\n  },\n  \"destination\": \"&lt;dot-path-to-destination-field&gt;\"\n}\n</code></pre> Where destination field is the field where you want to store received object. This path has to start with 'payload@'.</p>"},{"location":"getting_started/processes/workflow/actions/password_generator_action/","title":"Password generator","text":"<p>This plugin returns password according to user input. User can set up password specification by five properties: maximum length, minimum length, uppercase letters, lowercase letters and special characters.</p>"},{"location":"getting_started/processes/workflow/actions/password_generator_action/#example-of-configuration","title":"Example of configuration","text":"<pre><code>{\n  \"min_length\": 8,\n  \"max_length\": 16,\n  \"uppercase\": 6,\n  \"lowercase\": 4,\n  \"special_characters\": 2\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/pause_and_resume/","title":"Pause and resume","text":"<p>The Pause and Resume functionality allows you to temporarily stop the execution of a workflow and then resume its operation after a specified period of time. This feature is useful when you need to introduce a delay or schedule actions to be performed at a later time. The workflow can be resumed with the original event properties or with modified properties if desired.</p>"},{"location":"getting_started/processes/workflow/actions/pause_and_resume/#pausing-the-workflow","title":"Pausing the Workflow","text":"<p>To initiate a pause in the workflow, you need to provide the appropriate configuration parameters. The following parameters are available:</p> <ul> <li> <p>wait: This parameter specifies the duration (in seconds) for which the workflow should be paused before resuming. The   workflow execution halts for this duration.</p> </li> <li> <p>event_type: This parameter allows you to specify an optional event type that can be registered when the workflow   resumes. If no event type is specified, no event will be registered upon resumption.</p> </li> <li> <p>properties: If you wish to provide modified properties to the resumed workflow, you can specify them using this   parameter. The properties should be provided in JSON format within the curly braces {}. If you want the workflow to   resume with the original event properties, leave this field empty.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/pause_and_resume/#resuming-the-workflow","title":"Resuming the Workflow","text":"<p>After the specified pause duration has elapsed, the workflow automatically resumes its operation. Depending on the configuration parameters, the workflow can be resumed with either the original event properties or the modified properties.</p> <p>If an event type was specified, a corresponding event will be registered in the system. If no event type was provided, the resumption occurs as an internal system event without a separate registration. Example of JSON configuration.</p> <pre><code>{\n  \"wait\": 60,\n  \"event_type\": {\n    \"id\": \"workflow-resumed\",\n    \"name\": \"Workflow Resumed\"\n  },\n  \"properties\": \"{\\\"status\\\": \\\"pending\\\", \\\"retry_count\\\": 2}\"\n}\n</code></pre> <p>In this example, the workflow is paused for 60 seconds. After the pause, the workflow automatically resumes. The event type \"workflow_resumed\" with the ID \"123456\" is registered. Additionally, the workflow is resumed with modified properties, setting the status as \"pending\" and the retry count as 2.</p>"},{"location":"getting_started/processes/workflow/actions/pause_and_resume/#does-the-pause-event-impact-performance-when-the-workflow-runs-for-several-days","title":"Does the Pause Event Impact Performance When the Workflow Runs for Several Days?","text":"<p>The pause event does not directly impact the performance of the current event process. When you pause an event, it is sent to a background scheduled task and placed in a queue for completion. This means that the current event process continues without being affected by the pause.</p> <p>Once the pause time is finished, the event either resumes as a separate event if it has been configured as such, or it resumes as an internal system event that is not recorded but processed. In either case, the response to the current event is returned immediately, allowing the process to continue uninterrupted.</p> <p>Overall, the pause event has minimal impact on the performance of the current event process, as it is handled separately in the background without interrupting the ongoing operations.</p>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/","title":"Load profile by ...","text":"<p>This plugin is designed to load and replace the current profile in a Tracardi workflow. It also assigns the loaded profile to the current event, effectively replacing the current profile with the newly loaded one.</p>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/#description","title":"Description","text":"<p>The \"Load profile by ...\" plugin operates by identifying a profile based on a specified field and its value. This field is a piece of personally identifiable information (PII) unique to each profile, such as an email address or phone number. Once the field and its corresponding value are provided, the plugin searches for the profile in the database. If found, it updates the workflow's current profile and assigns it to the current event.</p> <p>The plugin handles different scenarios:</p> <ol> <li>If the specified field is 'id', it loads the profile directly based on the provided ID.</li> <li>For other fields, it searches for an active profile that matches the provided field and value. If exactly one    matching profile is found, it is loaded; otherwise, an error is generated.</li> </ol> <p>The plugin's primary function is to update the workflow's execution graph with the loaded profile, making it available as part of the workflow's internal state.</p>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin takes a payload object as its input. This payload is used to obtain the field value for profile   identification.</li> <li>Outputs:<ul> <li>Profile: Outputs the loaded profile object if a profile is successfully found and loaded.</li> <li>Error: Outputs an error message if the profile cannot be found or if multiple profiles match the search   criteria.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/#configuration","title":"Configuration","text":"<ul> <li>Profile field: The PII profile field used to identify the profile. Options include fields like main email,   business email, private email, main phone, mobile phone, etc.</li> <li>Value: The specific value of the field, which can be a static value or a reference from the event or any object   within the workflow.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"field\": \"data.contact.email.main\",\n  \"value\": \"event@properties.email\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/profile_inject_action/#errors","title":"Errors","text":"<ul> <li>\"Could not find profile.\": This error occurs when no profile is found matching the provided field and value.</li> <li>\"Found [number] records for [field] = [value].\": This error is triggered when multiple profiles match the   specified field and value, indicating an ambiguous search result.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/","title":"Profile live time","text":"<p>This plugin returns the duration for which a profile has existed in the system.</p>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/#version","title":"Version","text":"<p>0.8.0</p>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/#description","title":"Description","text":"<p>The plugin works by finding the date and time when the profile was created. It then calculates the difference between the current time and the creation time in various units such as seconds, minutes, hours, days, and weeks, and returns this information. However, if the profile is not present or the creation time is not a Date-Time object, it returns an error along with the payload.</p>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs:<ul> <li>The plugin takes any JSON-like object as an input through the payload input port.</li> </ul> </li> <li>Outputs:<ul> <li>If the process is successful, the plugin returns the duration for which the profile has existed in the various   time units mentioned above. This duration is returned through the \"live-time\" output port.</li> <li>If there is an error (for example, if the profile is not present or the creation time is not a Date-Time object),   the plugin returns the error message along with the payload through the \"error\" output port.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/#configuration","title":"Configuration","text":"<p>The plugin does not have any configuration parameters.</p>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/#json-configuration","title":"JSON Configuration","text":"<p>Since the plugin does not have any configuration parameters, it does not require a JSON configuration.</p>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/#required-resources","title":"Required resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/profile_live_time/#errors","title":"Errors","text":"<ul> <li>\"Can not get profile live time without a profile.\": This error occurs when there is no profile present.</li> <li>\"Profile time.insert is not a date. Expected datetime object got {type(created)}.\": This error occurs when the   creation time of the profile is not a Date-Time object. The placeholder {type(created)} is replaced with the actual   type of the creation time.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/query_data/","title":"Query Local Database","text":"<p>This plugin provides the capability to execute queries on databases that reside within the local Elasticsearch instance. It fetches data from specified indexes and can return queried data in the form of a result object.</p>"},{"location":"getting_started/processes/workflow/actions/query_data/#version","title":"Version","text":"<p>This documentation was created for the plugin version 0.8.0.</p>"},{"location":"getting_started/processes/workflow/actions/query_data/#description","title":"Description","text":"<p>The Query Local Database Plugin accepts an Elasticsearch data storage language (DSL) query and executes it on the local Elasticsearch database. The plugin preprocesses the query to ensure there is a size specification and limits the returned results to a maximum of 50 records per query. If there is no size specification, it defaults to 20 records per query.</p> <p>In addition to executing the query, this plugin can also log the query and its results. However, fetching more than 50 records might impact GUI performance and it is recommended to disable logging once tests are finished.</p>"},{"location":"getting_started/processes/workflow/actions/query_data/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin takes one input:</p> <ul> <li>The payload object, which contains data that is sent to the plugin.</li> </ul> <p>The plugin generates two types of outputs:</p> <ul> <li>result: This port returns the result from querying the ElasticSearch instance.</li> <li>error: This port returns an error message if one occurs during query execution, or if the returned result contains   more than 20 records.</li> </ul> <p>This plugin cannot act as a start point in the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/query_data/#configuration","title":"Configuration","text":"<p>The configuration parameters of this plugin are:</p> <ul> <li>index: This specifies the Elasticsearch index to be searched. This can be one of three types of indexes: Profile,   Event, or Session.</li> <li>query: It takes in an Elasticsearch DSL query that needs to be executed on the database.</li> <li>log: This boolean variable determines whether or not the query execution is logged.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/query_data/#json-configuration","title":"JSON Configuration","text":"<p>Example of a JSON configuration object:</p> <pre><code>{\n    \"index\": \"Profile\",\n    \"query\": \"{\\\"query\\\":{\\\"match_all\\\":{}}}\",\n    \"log\": False\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/query_data/#required-resources","title":"Required resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/query_data/#errors","title":"Errors","text":"<p>The errors that may be returned by this plugin and the conditions that might cause them are:</p> <ul> <li>Invalid Elasticsearch DSL queries: Syntax or structural errors in the DSL query may result in a JSONDecodeError. The   JSONDecodeError message would provide further details about the error.</li> <li>Query execution issues: Errors that occur during the execution of a query would result in the error output port   being activated. The value property of the Result object would contain an error message detailing the specific   problem.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/question_popup_action/","title":"Show question popup plugin","text":"<p>This plugin shows a question to user, with two possible answers. The answer click by user will be sent back to tracardi  as a new event type. User can define the type in Event type field in the configuration form.  </p>"},{"location":"getting_started/processes/workflow/actions/question_popup_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/question_popup_action/#output","title":"Output","text":"<p>This plugin returns given payload on port payload without any changes.</p>"},{"location":"getting_started/processes/workflow/actions/question_popup_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/question_popup_action/#form-fields","title":"Form fields","text":"<ul> <li>UIX Source - provide a URL, where UIX elements are located. Usually it's   http://localhost:8686 (Tracardi API).</li> <li>API URL - question popup sends an event after user has answered given question.   That's the URL of API that event will be sent to.</li> <li>Popup title - provide a title for your popup. This field does not support dotted notation.</li> <li>Popup content - provide a content for your popup. This field supports dot template.</li> <li>Left button text - provide a text to be displayed on the left button. This field does not support   dotted notation.</li> <li>Right button text - provide a text to be displayed on the right button. This field does not support   dotted notation.</li> <li>Horizontal position - select a horizontal position for your popup to be displayed.</li> <li>Vertical position - select a vertical position for your popup to be displayed.</li> <li>Event type - type in the type of event to be sent back to given API URL. This field does not support   dotted notation.</li> <li>Save event - you can save the event that is sent back from popup. ON - save, OFF - do not save.</li> <li>Popup lifetime - provide a number of seconds for the popup to be displayed. After this amount of   seconds, the popup will disappear without any user interaction.</li> <li>Dark theme - you can switch your popup into dark mode. ON - dark theme, OFF - bright theme.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/question_popup_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"api_url\": \"&lt;url-of-api-for-event-to-be-sent-to&gt;\",\n  \"uix_source\": \"&lt;location-of-uix-components-source&gt;\",\n  \"popup_title\": \"&lt;popup-title&gt;\",\n  \"content\": \"&lt;message-template&gt;\",\n  \"left_button_text\": \"&lt;left-button-text&gt;\",\n  \"right_button_text\": \"&lt;right-button-text&gt;\",\n  \"horizontal_pos\": \" left | center | right \",\n  \"vertical_pos\": \" top | bottom \",\n  \"event_type\": \"&lt;type-of-event-to-be-sent-back&gt;\",\n  \"save_event\": \"&lt;bool&gt;\",\n  \"popup_lifetime\": \"&lt;integer-as-string&gt;\",\n  \"dark_theme\": \"&lt;bool&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/rabbit_publisher_action/","title":"RabbitMQ publisher","text":"<p>The purpose of this plugin is to publish payload to RabbitMQ.</p> <p>It reads payload and sends it to defined RabbitMQ. RabbitMq must be defined as resource in Tracardi.</p>"},{"location":"getting_started/processes/workflow/actions/rabbit_publisher_action/#configuration","title":"Configuration","text":"<p>This node requires configuration.</p> <p>Example configuration</p> <pre><code>{\n  \"source\": {\n    \"name\": \"RabbitMQ\",\n    \"id\": \"79c315aa-2780-4742-bc70-6444bf8ea444\"\n  },\n  \"queue\": {\n    \"name\": \"test-test\",\n    \"routing_key\": \"test\",\n    \"queue_type\": \"direct\",\n    \"compression\": null,\n    \"auto_declare\": true,\n    \"serializer\": \"json\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/rabbit_publisher_action/#input-payload","title":"Input payload","text":"<p>This node reads input payload and sends it to the queue.</p>"},{"location":"getting_started/processes/workflow/actions/rabbit_publisher_action/#output","title":"Output","text":"<p>This node has no output. </p>"},{"location":"getting_started/processes/workflow/actions/rabbitmq_action/","title":"RabbitMQ publisher","text":"<p>The purpose of this plugin is to publish payload to RabbitMQ.</p> <p>It reads payload and sends it to defined RabbitMQ. RabbitMq must be defined as resource in Tracardi.</p>"},{"location":"getting_started/processes/workflow/actions/rabbitmq_action/#configuration","title":"Configuration","text":"<p>This node requires configuration.</p> <p>Example configuration</p> <pre><code>{\n  \"resource\": {\n    \"id\": \"58df3b5c-3109-4750-bb5b-81f5386950b1\"\n  },\n  \"queue\": {\n    \"name\": \"tracardi\",\n    \"routingKey\": \"trk\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/rabbitmq_action/#input-payload","title":"Input payload","text":"<p>This node reads input payload.</p>"},{"location":"getting_started/processes/workflow/actions/rabbitmq_action/#output","title":"Output","text":"<p>This node has no output. </p>"},{"location":"getting_started/processes/workflow/actions/random_element_action/","title":"Return random item","text":"<p>This plugin takes a list of values or references to field values, e.g. profile@traits.public.value. It will choose an item randomly from the list and return it. If the value is a path to field it will be evaluated and the  referenced value will be returned.</p>"},{"location":"getting_started/processes/workflow/actions/random_element_action/#input","title":"Input","text":"<p>This plugin takes any payload object as input.</p>"},{"location":"getting_started/processes/workflow/actions/random_element_action/#output","title":"Output","text":"<p>This plugin outputs a random value from provided list.</p>"},{"location":"getting_started/processes/workflow/actions/random_element_action/#configuration","title":"Configuration","text":"Example<pre><code>{\n  \"list_of_items\": [\n    \"value-1\",\n    \"payload@value\",\n    \"profile@traits.value\"\n  ]\n}\n</code></pre> <p>Result example</p> <pre><code>\"value-1\"\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/","title":"Rating Popup Plugin","text":"<p>This plugin shows the rating widget to user. Rating widget allows user to rate something at scale from 1 to 5. Widget sends back an event with property event@properties.rating  containing an integer from 1 to 5, according to user rating.</p>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#description","title":"Description","text":"<p>The Rating Popup Plugin displays a customizable rating widget as a popup. The plugin allows you to configure the title, message, lifetime, positioning, styling, and reporting of the rating event. You can define the API URL to send the event with the rating, specify the event type, and choose whether to save the event or not.</p> <p>When the plugin is executed, it renders the rating widget with the configured settings. The payload object is passed through the plugin unchanged.</p> <p>Version: 0.8.1</p>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#inputs","title":"Inputs","text":"<ul> <li>payload (dict): This input port accepts a payload object.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#outputs","title":"Outputs","text":"<ul> <li>payload (dict): This output port returns the given payload without any changes.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#configuration","title":"Configuration","text":"<p>The Rating Popup Plugin supports the following configuration parameters:</p> <ul> <li>Widget configuration</li> <li>Title: This text will become the title of your rating popup.</li> <li>Popup message: This is the message to be displayed in the rating popup. You can use a template here.</li> <li> <p>Popup lifetime: Please provide the number of seconds for the rating popup to be displayed.</p> </li> <li> <p>Positioning</p> </li> <li>Horizontal position: This is the horizontal position of your popup. Choose from \"Left\", \"Center\", or \"Right\".</li> <li> <p>Vertical position: This is the vertical position of your popup. Choose from \"Top\" or \"Bottom\".</p> </li> <li> <p>Styling</p> </li> <li>Pop-up styling: This field allows you to customize the appearance of the rating popup.</li> <li> <p>Title size: This field allows you to set the size of the title.</p> </li> <li> <p>Reporting rating</p> </li> <li>API URL: Provide the URL of the Tracardi instance to send the event with the rating.</li> <li>Event type: Please provide the type of event to be sent back after selecting the rating.</li> <li>Save event: Determine whether the sent event should be saved or not.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of the JSON configuration for the Rating Popup Plugin:</p> <pre><code>{\n    \"api_url\": \"http://localhost:8686\",\n    \"title\": \"My Rating\",\n    \"message\": \"Please rate your experience.\",\n    \"lifetime\": \"10\",\n    \"horizontal_position\": \"center\",\n    \"vertical_position\": \"bottom\",\n    \"event_type\": \"rating\",\n    \"save_event\": true,\n    \"styling\": {\n        \"margin\": {\n            \"left\": 0,\n            \"top\": 0,\n            \"right\": 0,\n            \"bottom\": 0\n        },\n        \"padding\": {\n            \"left\": 20,\n            \"top\": 20,\n            \"right\": 20,\n            \"bottom\": 20\n        },\n        \"color\": {\n            \"background\": \"rgba(255,255,255,0.95)\",\n            \"text\": \"rgba(0,0,0,1)\"\n        },\n        \"border\": {\n            \"size\": 0,\n            \"radius\": 0,\n            \"color\": \"black\"\n        }\n    },\n    \"title_size\": \"20\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/rating_popup_action/#errors","title":"Errors","text":"<p>This plugin does not generate any errors.</p>"},{"location":"getting_started/processes/workflow/actions/read_from_memory_action/","title":"Read from memory plugin","text":"<p>This plugin allows you to read from cross-instance Tracardi user memory, using given key.</p>"},{"location":"getting_started/processes/workflow/actions/read_from_memory_action/#requirements","title":"Requirements","text":"<p>Redis database has to be installed and running in order for this plugin to work.</p>"},{"location":"getting_started/processes/workflow/actions/read_from_memory_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/read_from_memory_action/#outputs","title":"Outputs","text":"<p>This plugin returns value on port success if the value was successfully read from the memory, or error detail on port error if an error occurred.</p> <p>Example of value on success port</p> <pre><code>{\n  \"value\": {\n    \"data-1\": 1,\n    \"data-2\": 2\n  }\n}\n</code></pre> <p>Example of value on error port</p> <pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/read_from_memory_action/#configuration","title":"Configuration","text":"<ul> <li>Key - A name of the variable that holds saved data. Please refer to write plugin to find out the correct key.   Missing key will return null value on success port. </li> </ul>"},{"location":"getting_started/processes/workflow/actions/read_from_memory_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"key\": \"&lt;key-to-value-in-memory&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/reduce_array_action/","title":"Reduce array plugin","text":"<p>This plugin reduces given array.</p>"},{"location":"getting_started/processes/workflow/actions/reduce_array_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/reduce_array_action/#output","title":"Output","text":"<p>This plugin returns reduced array on port result, or some error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/reduce_array_action/#example-input","title":"Example input:","text":"<pre><code>{\n  \"list\": [\n    \"a\",\n    \"a\",\n    \"a\",\n    \"b\",\n    \"b\",\n    \"c\"\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/reduce_array_action/#output-for-this-input","title":"Output for this input:","text":"<pre><code>{\n  \"counts\": {\n    \"a\": 3,\n    \"b\": 2,\n    \"c\": 1\n  },\n  \"max\": \"a\",\n  \"min\": \"c\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/reduce_array_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/reduce_array_action/#form-fields","title":"Form fields","text":"<ul> <li>Path to array - a valid dot path to array that you want to reduce.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/reduce_array_action/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"array\": \"&lt;path-to-array&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/remote_call_action/","title":"Remote call plugin","text":"<p>This plugin calls remote API.</p>"},{"location":"getting_started/processes/workflow/actions/remote_call_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"method\": \"post\",\n  \"source\": {\n    \"id\": \"&lt;id-of-API-resource&gt;\",\n    \"name\": \"&lt;name-of-API-resource&gt;\"\n  },\n  \"endpoint\": \"/some/endpoint/{event@with.template}/here\",\n  \"timeout\": 30,\n  \"headers\": {\n    \"X-Customer-Header\": \"Header value\"\n  },\n  \"cookies\": {\n    \"Cookie-Key\": \"Cookie value\"\n  },\n  \"sslCheck\": true,\n  \"body\": {\n    \"content\": \"{\\\"json\\\":1}\",\n    \"type\": \"application/json\"\n  }\n}\n</code></pre> <p>This configuration makes POST request to API URL from selected resource with body <code>{\"json\":1}</code>.</p> <p>If user requires the body to be sent with GET method than body will be squashed to represent keys and values.</p> <p>For example this JSON:</p> <pre><code>{\n  \"payload\": {\n    \"mobile\": \"android\"\n  },\n  \"version\": [\n    10,\n    11\n  ]\n}\n</code></pre> <p>Will be flattened to parameters:</p> <pre><code>payload.mobile=android&amp;version=10&amp;version=11\n</code></pre> <p>This plugin supports dot paths in cookie headers and body - you can use them like this:</p> <pre><code>{\n  \"headers\": {\n    \"X-Custom-Header\": \"payload@some.field\"\n  }\n}\n</code></pre> <p>Paths will be replaced with current workflow values.</p>"},{"location":"getting_started/processes/workflow/actions/remote_call_action/#result","title":"Result","text":"<p>This plugin returns either the response (on response port) or and error on error port.</p> <p>Example of valid response</p> <pre><code>{\n  \"status\": 200,\n  \"content\": \"&lt;body&gt;\",\n  \"cookies\": {\n    \"key\": \"value\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/","title":"Has consents","text":"<p>This plugin checks if certain consents are granted by the current profile in a workflow. It is particularly useful for workflows that involve conditional processing based on user consents.</p>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/#version","title":"Version","text":"<p>0.6.2</p>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/#description","title":"Description","text":"<p>The 'Has consents' plugin operates by evaluating a set of specified consent IDs against the consents granted to a profile. It allows you to define a list of consent IDs and check whether these consents are granted and not revoked. The plugin can be configured to require all specified consents to be granted or to accept the granting of any one of the specified consents.</p> <p>Here's a step-by-step explanation of how the plugin works:</p> <ol> <li>The plugin first checks if the event is profile-less. If it is, the plugin cannot perform a consent check and will    return the payload on the 'false' port.</li> <li>It then processes each consent ID specified in the configuration. For each ID:<ul> <li>If the consent type does not exist, it raises an error.</li> <li>If the 'Require all' setting is enabled, it checks if all consents are granted; otherwise, it checks if at least   one consent is granted.</li> <li>For revokable consents, it also checks if the consent has not been revoked.</li> </ul> </li> </ol> <p>If all conditions are met, the payload is returned on the 'true' port; otherwise, it is returned on the 'false' port.</p>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Inputs:</p> <ul> <li>payload: Accepts any payload object.</li> </ul> <p>Outputs:</p> <ul> <li>true: Returns the payload if the defined consents are granted.</li> <li>false: Returns the payload if the defined consents are not granted.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/#configuration","title":"Configuration","text":"<ul> <li>IDs of required consents: List of consent IDs that the profile must grant. Multiple consents can be added.</li> <li>Require all: Determines if all specified consents must be granted (ON) or if only one granted consent is   sufficient (OFF).</li> </ul>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration in JSON format:</p> <pre><code>{\n  \"consent_ids\": [\n    {\n      \"id\": \"consent1\"\n    },\n    {\n      \"id\": \"consent2\"\n    }\n  ],\n  \"require_all\": true\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/require_consents_action/#errors","title":"Errors","text":"<ul> <li>\"There is no consent type with ID [ID]\": Occurs if a specified consent ID does not exist in the system.</li> <li>\"Corrupted data - no revoke date provided for revokable consent type [ID]\": Occurs if revoke data for a revokable   consent type is missing or corrupt.</li> <li>\"Cannot perform consent check on profile less event.\": Occurs if the event associated with the plugin execution   does not have an associated profile.</li> </ul> <p>The plugin is especially valuable in scenarios where consent management is crucial, ensuring that only profiles with the necessary consents can proceed through specific parts of a workflow.</p>"},{"location":"getting_started/processes/workflow/actions/reshape_payload_action/","title":"Create payload action","text":"<p>This node creates data as payload output. It can reference profile,  session, or flow in the created object. </p>"},{"location":"getting_started/processes/workflow/actions/reshape_payload_action/#configuration","title":"Configuration","text":"<p>In order to create payload user must provide transformation configuration. Below you can find an  example of such configuration. Use dot notation to access json properties from payload, profile, etc.</p> <p>You can mix regular values with values read from profile, session, etc.</p> <pre><code>{\n  \"new\": {\n    \"key\": \"value\",  // This is static value\n    \"value\": \"profile@id\"  // Reads value from profile and saves it in object new.value\n    \"list\": [1, \"payload@data\"] // Reads data value from payload and saves it as 2nf element of list\n    \"event\": \"event@...\"  // Saves in event all data from event.\n  }\n}\n</code></pre> <p>This configuration will return an object new with the following properties.</p> <pre><code>{\n  \"new\": {\n    \"key\": \"value\", \n    \"value\": &lt;profile_id&gt;\n    },\n    \"list\": [\n      1,\n      &lt;data_from_payload&gt;,\n    ],\n    \"event\": &lt;data_from_event&gt;\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/","title":"S3 Segments Uploader Plugin","text":"<p>This plugin allows the collection and transmission of user profile segments to AWS S3 storage in a JSON format. It's designed with simplicity in mind, enabling users to easily configure AWS credentials and specify the S3 bucket for storing data. By accepting a profile payload, it gathers profile segments and uploads them as a JSON file named with the current date and \"_segments\" suffix.</p>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#version","title":"Version","text":"<p>0.9.0</p>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#description","title":"Description","text":"<p>Upon execution, the plugin checks for the presence of \"smi_uid\" within the payload's traits. If this key is found, it proceeds to create or update a JSON file in the specified S3 bucket. The JSON file structure aggregates profiles by their \"smi_uid\" and associated segments, facilitating efficient data storage and retrieval.</p> <p>For new uploads, the plugin directly creates a JSON file with the relevant data. If a file for the current date already exists, it downloads this file, appends the new profile segment data, and re-uploads it to ensure all relevant data for the day is consolidated in a single file. This method ensures that the data remains organized and easily accessible.</p>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Inputs: The plugin requires a payload containing a user profile. The essential part of this profile is the \"traits\" section, which must include a \"smi_uid\" key for the plugin to function correctly.</p> <p>Outputs: There are two possible outcomes of the plugin's operation:</p> <ul> <li>success: This output indicates that the JSON data was successfully uploaded to the S3 bucket. The output includes   a message confirming the successful upload.</li> <li>error: This output signifies that an error occurred during the upload process. The error message provides details   about the issue encountered.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#configuration","title":"Configuration","text":"<p>To use the plugin, you must configure it with the following parameters:</p> <ul> <li>AWS Access Key ID: This is your AWS Access Key ID, used to authenticate your identity with AWS services.</li> <li>AWS Secret Access Key: This is your AWS Secret Access Key, acting as a secret password to secure your AWS account   access.</li> <li>S3 Bucket: Specify the name of the S3 bucket where the JSON data will be uploaded. This bucket should already   exist in your AWS account.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"aws_access_key_id\": \"your_access_key_id\",\n  \"aws_secret_access_key\": \"your_secret_access_key\",\n  \"s3_bucket\": \"your_s3_bucket_name\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#event-prerequisites","title":"Event prerequisites","text":"<p>The plugin works for all types of events and does not specifically require synchronous event processing.</p>"},{"location":"getting_started/processes/workflow/actions/s3_segment_upload/#errors","title":"Errors","text":"<ul> <li>\"Could not find payload.traits.smi_uid\": This error occurs when the payload does not include the \"traits\" section   with a \"smi_uid\" key. Ensure the payload structure is correct and includes the necessary information.</li> <li>\"S3 upload error: {err}\": Indicates an issue occurred during the upload process to S3. The specific error   details ({err}) will provide more insight into what went wrong. This could be due to incorrect AWS credentials,   permissions, or issues with the S3 service.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/","title":"Pushover push","text":"<p>Connects to Pushover app and pushes a message.</p>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#version","title":"Version","text":"<p>Version 0.7.1</p>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#description","title":"Description","text":"<p>The Pushover push plugin allows you to send a message to the Pushover service. It connects to the Pushover API and sends the specified message to the specified user. The plugin requires Pushover API credentials, including the API token and user key, which you can obtain by registering at https://pushover.net.</p>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#inputs","title":"Inputs","text":"<p>This plugin does not take any input.</p>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#outputs","title":"Outputs","text":"<ul> <li>payload: Returns the response from the Pushover API, including the status and request information.</li> <li>error: Gets triggered if an error occurs while connecting to the Pushover API.</li> </ul> <p>Example output from the payload port:</p> <pre><code>{\n  \"status\": 200,\n  \"response\": {\n    \"status\": 1,\n    \"request\": \"c759f16e-c10a-4066-b91d-05fd06504790\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#configuration","title":"Configuration","text":"<p>The Pushover push plugin requires the following configuration:</p> <ul> <li> <p>Resource: Select or configure a resource that holds the Pushover API credentials. This resource should contain the   following information:</p> <ul> <li>token: The API token obtained from Pushover.</li> <li>user: The user key obtained from Pushover.</li> </ul> </li> <li> <p>Message: Enter the message to be sent. The message can be a template that uses placeholders for data from the   profile. For example, if you want to include the name from the profile, you can use the   placeholder <code>{{profile@traits.private.pii.name}}</code>.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#json-configuration","title":"JSON Configuration","text":"<p>Example JSON configuration for the Pushover push plugin:</p> <pre><code>{\n  \"source\": {\n    \"name\": \"pushover\",\n    \"id\": \"&lt;resource-id&gt;\"\n  },\n  \"message\": \"Hello {{profile@traits.private.pii.name}}!\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#required-resources","title":"Required resources","text":"<p>This plugin requires a resource to be configured that holds the Pushover API credentials.</p>"},{"location":"getting_started/processes/workflow/actions/send_pushover_msg_action/#errors","title":"Errors","text":"<p>The following errors may occur:</p> <ul> <li>Could not connect to Pushover API: This error occurs when the plugin is unable to connect to the Pushover API. The   error response includes the status code and the response from the API.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/send_to_airtable_action/","title":"Send data to Airtable plugin","text":"<p>This plugin adds a new record to a given table in Airtable.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_airtable_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_airtable_action/#output","title":"Output","text":"<p>This plugin returns record data on port response if everything is OK, or some error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_airtable_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/send_to_airtable_action/#with-form","title":"With form","text":"<ul> <li>Airtable resource - here select your Airtable resource, containing your API key.</li> <li>Base ID - here paste in the ID of the Airtable base. You can check it while inspecting your base   in Airtable. It looks like https://airtable.com//... <li>Table name - here simply type in the name of your table in given base.</li> <li>Record mapping - provide key-value pairs. Key is the name of the field in the table for the new record,   and value is just a path to the value of this field, or the value itself.</li>"},{"location":"getting_started/processes/workflow/actions/send_to_airtable_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-airtable-resource&gt;\",\n    \"name\": \"&lt;name-of-your-airtable-resource&gt;\"\n  },\n  \"base_id\": \"&lt;id-of-your-airtable-base&gt;\",\n  \"table_name\": \"&lt;name-of-your-airtable-table&gt;\",\n  \"mapping\": {\n    \"field_name_1\": \"profile@field.example\",\n    \"field_name_2\": \"event@example.field\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/send_to_data_extension_action/","title":"Salesforce Data Extension plugin","text":"<p>This plugin creates/ updates a record in Salesforce Marketing Cloud Data Extension, according to given configuration.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_data_extension_action/#requirements","title":"Requirements","text":"<p>In your Marketing Cloud, click on your profile image. Then select Setup. On the left, select Apps &gt; Installed Packages. There click New button. Give some name and description to your package, then click Add Component button. Select API Integration, then Server-to-Server. Then select Data Extensions &gt; Write under Data header in scopes configuration and save it. Now you should see:</p> <ul> <li>Client Id</li> <li>Client Secret</li> <li>REST Base URI</li> </ul> <p>Paste Client ID and Client Secret while creating new resource, and to find your subdomain, take https://[THIS-PART] .rest.marketingcloudapis.com/ from REST Base URI. To use the plugin, you need to provide Data Extension ID. To find it, go to Audience Builder &gt; Contact Builder. Then select Data Extensions on the top. Then right-click on your Data Extension's name, and copy the link. Now paste https:// ... /data-extension/[THIS-PART]/properties/ as Data Extension ID in plugin configuration form.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_data_extension_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_data_extension_action/#outputs","title":"Outputs","text":"<p>This plugin returns given payload on port success if the action was successful, or some additional error information on port error if one occurred.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_data_extension_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-marketing-cloud-resource&gt;\",\n    \"name\": \"&lt;name-of-your-marketing-cloud-resource&gt;\"\n  },\n  \"extension_id\": \"&lt;id-of-your-data-extension&gt;\",\n  \"update\": \"&lt;bool-update-existing-records&gt;\",\n  \"mapping\": {\n    \"column1\": \"profile@id\",\n    \"column2\": \"event@properties.revenue\",\n    \"...\": \"...\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/","title":"Send to InfluxDB plugin","text":"<p>This plugin sends data to InfluxDB database.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/#outputs","title":"Outputs","text":"<p>This plugin returns given payload on port success if everything went OK, or on port error if an error occurred.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/#influxdb-data-structure","title":"InfluxDB data structure","text":"<p>Data in influxDb is more complex than regular data. It has on top Organisation, this is the equivalent of database instance. Bucket is the equivalent of database in SQL. Measure is a table, fields and values are records (e.i: columns and values in one record). Tags are additional metadata. Time is a timestamp of a particular set of fields (record).</p>"},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/#form-description","title":"Form description","text":"<ul> <li>InfluxDB resource - InfluxDB resource, containing your token and database URL to the database instance.</li> <li>Organization - The name of your organization, it is the equivalent of database instance.</li> <li>Bucket - The name of the bucket that you want to write to.</li> <li>Fields - Record in a key-value pairs format. Key is the name of the field of data in the bucket, and value is the   value for this field in a record. Feel free to use dotted notation for value part.</li> <li>Measurement name - Measurement name for the record.</li> <li>Time - Path to the field containing date of the record. This parameter is optional. Invalid data of date format will   be ignored and date time will be set to the moment of the execution.</li> <li>Record tags - Key-value pairs. Key is the tag name, and value is the value for this tag.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"&lt;name-of-your-influxdb-resource&gt;\",\n    \"id\": \"&lt;id-of-your-influxdb-resource&gt;\"\n  },\n  \"bucket\": \"&lt;name-of-your-influxdb-bucket&gt;\",\n  \"fields\": {\n    \"&lt;field-1&gt;\": \"payload@example.value\",\n    \"&lt;field-2&gt;\": \"event@properties.example\"\n  },\n  \"measurement\": \"&lt;measurement-name&gt;\",\n  \"time\": \"&lt;optional-path-to-field-containing-timestamp-data&gt;\",\n  \"tags\": {\n    \"&lt;tag-key-1&gt;\": \"event@properties.value\",\n    \"&lt;tag-key-2&gt;\": \"session@example.data\"\n  },\n  \"organization\": \"&lt;name-of-your-influxdb-organization&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/send_to_influx_db_action/#warning","title":"Warning","text":"<p>InfluxDB API does not always return information about error when trying to insert incorrect data (for example when some fields are missing). That causes plugin to sometimes trigger success port, even if data has not been inserted. However, with some major errors' occurrence (for example incorrect time field content), error port is triggered properly.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_mixpanel_action/","title":"Send to MixPanel plugin","text":"<p>This plugin sends currently processed event to given MixPanel project.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_mixpanel_action/#requirements","title":"Requirements","text":"<p>This plugin requires MixPanel account, project and resource, containing project's token and server prefix. Service account credentials are not required for this particular plugin.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_mixpanel_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_mixpanel_action/#outputs","title":"Outputs","text":"<p>This plugin returns given payload on port success if action was successful, or on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_mixpanel_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/send_to_mixpanel_action/#form-fields","title":"Form fields","text":"<ul> <li>MixPanel resource - Select your MixPanel resource, containing project's token and server prefix (either EU or US)</li> <li>Additional fields mapping - Here you can add custom mapping for your event. Feel free to use dotted notation.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/send_to_mixpanel_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-mixpanel-resource&gt;\",\n    \"name\": \"&lt;name-of-your-mixpanel-resource&gt;\"\n  },\n  \"mapping\": {\n    \"&lt;custom-key-1&gt;\": \"&lt;path-1&gt;\",\n    \"&lt;custom-key-2&gt;\": \"value-1\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/","title":"Post to Slack channel plugin","text":"<p>This plugin posts a text message to defined channel on Slack.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/#requirements","title":"Requirements","text":"<p>This plugin requires adding an app to your Slack workspace:</p> <ul> <li>Go to https://api.slack.com/apps - open account if you do not have one.</li> <li>Create new app</li> <li>Select from scratch option</li> <li>Type a name for the app and pick a workspace</li> <li>Install app into your workspace</li> <li>Allow this app to write into channels</li> <li>Copy this app's bot token</li> <li>Paste the token when creating Tracardi resource</li> </ul> <p>For more detail, check Slack apps creating documentation.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/#inputs","title":"Inputs","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/#outputs","title":"Outputs","text":"<p>This plugin returns a response from Slack API on port response or additional error info payload on port error if an error occurs.</p>"},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/#with-form","title":"With form","text":"<ul> <li>Slack resource - Here select your Slack resource, containing your app's bot token.</li> <li>Slack channel - Here type in the name of the channel that you want your bot to post to.</li> <li>Message - Here type in the message content. You can use dot templates.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-slack-resource&gt;\",\n    \"name\": \"&lt;name-of-your-slack-resource&gt;\"\n  },\n  \"channel\": \"&lt;name-of-slack-channel&gt;\",\n  \"message\": \"&lt;content-of-your-message&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/send_to_slack_channel_action/#warning","title":"Warning","text":"<p>Depending on your app's scopes, you may need to add your app to the channel that you want to post to. You can do it by typing @, sending it and inviting the app into the channel."},{"location":"getting_started/processes/workflow/actions/sendgrid_add_contact_to_list/","title":"Send bulk e-mail plugin","text":"<p>This plugin sends bulk email via Sendgrid API.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_contact_to_list/#requirements","title":"Requirements","text":"<p>You'll need a Sendgrid account to use this plugin. Then you'll need to generate API key </p> <p>Sendgrid requires a domain configuration to send e-mails, you'll need to add and configure your domain in Sendgrid settings. Please refer to Sendgrid documentation for details.</p> <p>The last thing is your Sendgrid plan - if you're on the trial version, you are able to send emails only within your own domain, so if your email is examplemail@example.com, then your domain is simply example.com and you can send messages only to emails ending with example.com.</p> <p>To get rid of this restriction, you need a paid plan on Sendgrid.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_contact_to_list/#input","title":"Input","text":"<p>This plugin takes any payload.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_contact_to_list/#output","title":"Output","text":"<p>This plugin returns a response from Sendgrid API. Depending on the response result it will trigger ether payload  port (if the response is successful) or error for if the response indicates that the e-mail was not sent.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_contact_to_list/#config","title":"Config","text":"<p>Plugin's configuration requires information about API key, sender email,  message recipient's email(s), message subject and message content.</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-sendgrid-resource&gt;\",\n    \"name\": \"&lt;name-of-your-elastic-email-resource&gt;\"\n  },\n  \"email\": \"&lt;path-to-email-of-new-contact&gt;\",\n  \"list_ids\": \"&lt;comma-seperated-list-of-list-ids&gt;\",\n  \"additional_mapping\": {\n    \"address_line_1\": \"&lt;path-to-country-data&gt;\",\n    \"first_name\": \"&lt;path-to-first-name&gt;\",\n    \"last_name\": \"&lt;path-to-last-name&gt;\",\n    \"...\": \"...\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_contact_to_list/#sendgrid-resource","title":"Sendgrid resource","text":"<p>Sendgrid token must be stored in Tracardi's resources. Please remember to provide both test and production API key  (token) in resource configuration.</p> <p>Sendgrid API Tokens can be found in settings -&gt; SMTP &amp; API Info on  It is a string with random characters.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_to_global_suppression/","title":"Add contact to Sendgrid plugin","text":"<p>This plugin adds new contact to Sendgrid, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_to_global_suppression/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_to_global_suppression/#outputs","title":"Outputs","text":"<p>This plugin returns response from Sendgrid API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_to_global_suppression/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/sendgrid_add_to_global_suppression/#form-fields","title":"Form fields","text":"<ul> <li>Token resource - please select your Token resource. It should contain:</li> <li>Sendgrid Client api key</li> <li>Email address - please type in the path to the email address you want the status changed.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/sendgrid_add_to_global_suppression/#json-configuration","title":"JSON configuration","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-token-resource&gt;\",\n    \"name\": \"&lt;name-of-your-token-resource&gt;\"\n  },\n  \"email\": \"&lt;path-to-email-of-contact&gt;\",\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/","title":"Send bulk e-mail plugin","text":"<p>This plugin sends bulk email via Sendgrid API.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#requirements","title":"Requirements","text":"<p>You'll need a Sendgrid account to use this plugin. Then you'll need to generate API key </p> <p>Sendgrid requires a domain configuration to send e-mails, you'll need to add and configure your domain in Sendgrid settings. Please refer to Sendgrid documentation for details.</p> <p>The last thing is your Sendgrid plan - if you're on the trial version, you are able to send emails only within your own domain, so if your email is examplemail@example.com, then your domain is simply example.com and you can send messages only to emails ending with example.com.</p> <p>To get rid of this restriction, you need a paid plan on Sendgrid.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#input","title":"Input","text":"<p>This plugin takes any payload.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#output","title":"Output","text":"<p>This plugin returns a response from Sendgrid API. Depending on the response result it will trigger ether payload  port (if the response is successful) or error for if the response indicates that the e-mail was not sent.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#config","title":"Config","text":"<p>Plugin's configuration requires information about API key, sender email,  message recipient's email(s), message subject and message content.</p> <pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-sendgrid-resource&gt;\",\n    \"name\": \"&lt;name-of-your-elastic-email-resource&gt;\"\n  },\n  \"sender_email\": \"sender@tracardi.com\",\n  \"message\": {\n    \"recipient\": \"payload@email\",\n    \"content\": {\n      \"type\": \"text/html\",\n      \"content\": \"Message body\"\n    },\n    \"subject\": \"subject\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#sendgrid-resource","title":"Sendgrid resource","text":"<p>Sendgrid token must be stored in Tracardi's resources. Please remember to provide both test and production API key  (token) in resource configuration.</p> <p>Sendgrid API Tokens can be found in settings -&gt; SMTP &amp; API Info on  It is a string with random characters.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#senders-e-mail","title":"Sender's e-mail","text":"<p>That's the email that you want to send emails from. It has to end with one of your domains registered in Sendgrid. For instance, if your shop is exampleshop.com,  then you may want to send emails from an address like office@exampleshop.com, and then that's the value that you want to insert into plugin configuration. Please notice that this address does not have to exist.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#message-recipients-email","title":"Message recipient's email","text":"<p>This is the destination email or emails. It can be in form of dot path to email address (for example profile@data.contact.email.main).  You can also insert the address itself. Please notice that merged profiles can have multiple values in one field -  if John Doe has two or more email addresses in his profile, then plugin will send the message to all of them.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#message-subject","title":"Message subject","text":"<p>That's message subject, if you type in payment, then recipient of the message will see  payment as the subject of received message.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#message-content","title":"Message content","text":"<p>You can select if your content should be HTML or just plain text.  You can also use templates for your emails - both in HTML and text format. </p> <p>Examples:</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#example-1-plain-text","title":"Example 1 - plain text","text":"<pre><code>Hello {{profile@data.pii.firstname}}, your order will be dispatched in next two days.\n</code></pre> <p>This message will have the {{profile@data.pii.firstname}} changed to the current profile's name, so John Doe will see 'Hello John, your order will be dispatched in next two days.' in his message.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#example-2-html","title":"Example 2 - HTML","text":"<p><pre><code>&lt;h1&gt;Hello {{profile@data.pii.firstname}}!&lt;/h1&gt;\n&lt;p&gt;Thanks for visiting our website on {{profile@metadata.time.visit.last}}!&lt;/p&gt;\n&lt;p style=\"color:red\"&gt;To thank you, we send you a photo of cute dog. Enjoy:&lt;/p&gt;\n&lt;img src=\"&lt;url-to-photo-of-cute-dog&gt;\"/&gt;\n</code></pre> Like before, recipient will see his name in the header, and the text with date of his last visit, together with the red text about a photo of a dog, and a photo itself.</p>"},{"location":"getting_started/processes/workflow/actions/sendgrid_send_email/#tip","title":"Tip","text":"<p>On Sendgrid site, you can turn on the test mode after clicking on you username in up-right corner. In the test mode, you can generate test API key. You can use it in Tracardi for test purposes -  messages won't be sent, but Sendgrid will act like they are, so you can test your configuration without being charged a single cent.</p>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/","title":"Show consent bar","text":"<p>This plugin displays a consent pop-up on the front-end of your application.</p>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/#description","title":"Description","text":"<p>The Show consent bar plugin is used to display a consent bar or pop-up on the front-end of the application. This is particularly useful when obtaining user consent for specific actions or features as required by regulations such as GDPR.</p> <p>The plugin's behavior can be configured based on several parameters in its configuration. The parameters include the API's endpoint, the location of the micro frontend for the consent bar (usually the location of the Tracardi API), and details such as the type, height, and position of the widget.</p> <p>The widget can be placed either at the top or bottom of the page, and its height can be adjusted as per requirements. There is also an option to enable or disable the widget as needed.</p> <p>The plugin doesn't manipulate received data. It passes through the plugin unmodified from the input port (labeled * payload) to the output port (also labeled payload*).</p>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin has one input port and one output port.</p> <p>Inputs:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul> <p>Outputs:</p> <ul> <li>payload: This port returns the input payload object.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/#configuration","title":"Configuration","text":"<p>The plugin can be configured via the following parameters:</p> <ul> <li>endpoint: This field is required to specify the location</li> <li>uix_source: This field has the location of the micro frontend for the consent bar. Usually, this is the Tracardi API   location. Different locations can be specified if using a CDN.</li> <li>event_type: This field specifies the type of event to be triggered.</li> <li>agree_all_event_type: This field specifies the type of event to be triggered when all consents are agreed to.</li> <li>position: This field can be adjusted to place the widget either at the top or the bottom of the application window.</li> <li>expand_height: This field can be adjusted to specify the height of the expanded widget.</li> <li>enabled: This field can be set to either true or false to enable or disable the widget respectively.</li> <li>always_display: If set to true the consent bar will always be displayed regardless if the consents were already given.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example configuration:</p> <pre><code>{\n  \"endpoint\": \"http://localhost:8686\",\n  \"uix_source\": \"http://localhost:8686\",\n  \"event_type\": \"user-consent-pref\",\n  \"agree_all_event_type\": \"agree-all-event-type\",\n  \"position\": \"bottom\",\n  \"expand_height\": 400,\n  \"enabled\": true,\n  \"always_display\": false\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/#required-resources","title":"Required resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/show_consent_bar/#errors","title":"Errors","text":"<ul> <li>\"This field should not be empty\": This error occurs when the endpoint or uix_source field in the configuration is   left empty.</li> <li>\"This field should be either [top] or [bottom]\": This error occurs when the position field in the configuration is   left empty or contains an invalid value.</li> <li>\"This field must be a number\": This error occurs when the expand_height field in the configuration contains a   non-numeric value.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/sleep/","title":"Sleep","text":"<p>The Sleep plugin is a time-based action plugin within Tracardi's workflow system. It pauses the workflow operation for a certain duration, defined by the user in the plugin's configuration. This delay allows the system to wait a specified number of seconds before proceeding to the next plugins.</p>"},{"location":"getting_started/processes/workflow/actions/sleep/#version","title":"Version","text":"<p>0.1.2</p>"},{"location":"getting_started/processes/workflow/actions/sleep/#description","title":"Description","text":"<p>Upon calling the Sleep plugin's \"run\" method, the system will pause for a designated time, specified in the plugin's configuration field, 'wait'. The time unit is in seconds, and fractions of seconds can also be used.</p> <p>The paused workflow will not process any additional actions or plugins during this wait time. Once the wait time is completed, the plugin returns the same payload that was received, enabling the workflow to continue processing.</p>"},{"location":"getting_started/processes/workflow/actions/sleep/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Regarding the Sleep plugin's inputs and outputs - the plugin only has one port each for input and output, named ' payload'. The input payload can be any JSON-like object and it's passed to this plugin via the workflow. After the pause, this payload is outputted exactly as it was received.</p> <p>The Sleep plugin cannot start the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/sleep/#configuration","title":"Configuration","text":"<p>The Sleep plugin has only one configuration parameter:</p> <ul> <li>wait: The duration (in seconds) for which the workflow will pause before continuing processing. This value must be   greater than or equal to zero. Fractions of seconds can be put into this field.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/sleep/#json-configuration","title":"JSON Configuration","text":"<p>Below is an example JSON configuration for the Sleep plugin:</p> <pre><code>{\n  \"wait\": 1\n}\n</code></pre> <p>In this example, the Sleep plugin will pause the workflow for one second before returning the payload and continuing the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/sleep/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/sleep/#errors","title":"Errors","text":"<ul> <li>\"Wait value has to be greater than or equal to 0.\": This error occurs when the value entered for 'wait' in   configuration is less than zero. Sufficient time in seconds is essential for the plugin to correctly pause the   workflow.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/","title":"E-mail via SMTP","text":"<p>The purpose of this plugin is to send e-mail using SMTP servers. The plugin supports sending HTML messages.</p>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#configuration","title":"Configuration","text":"<p>This node requires configuration.</p>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#example-of-configuration","title":"Example of configuration","text":"<pre><code>{\n  \"message\": {\n    \"send_to\": \"to@email.com\",\n    \"send_from\": \"from@email.com\",\n    \"reply_to\": \"reply-to@email.com\",\n    \"title\": \"E-mail subject\",\n    \"message\": \"My name is {{profile@pii.name}}\"\n  },\n  \"source\": {\n    \"id\": \"resource-id\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#configuration-description","title":"Configuration description","text":"<ul> <li>to: None, - Choose e-mail recipient</li> <li>from: None, - Choose your e-mail</li> <li>replyTo: None,- Select to whom the reply should be sent</li> <li>title: Enter an E-mail subject,</li> <li>message: Enter your message, HTML is allowed as well as message template.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#message","title":"Message","text":"<p>Message can be a Tracardi template. Tracardi templates can merge plain text or HTML with data from profile, event,  or session. </p> <p>Example of Tracardi message template</p> <pre><code>My name is {{profile@pii.name}}\n</code></pre> <p>The {{profile@pii.name}} placeholder will be replaced by data from profile. Path to data is  traits.private.pii.name.</p>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#resource-configuration","title":"Resource configuration","text":"<p>This node needs SMTP server credentials that are defined in resources. To access defined credentials you will have to pass resource id.</p>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#resources","title":"Resources","text":"<p>This node needs access to resource that configures SMTP server credentials:</p> <p>Needed credentials:</p> <ul> <li>smtp: smtp.gmail.com - Choose a smtp server</li> <li>port: 587 - Select the port on which smtp will run</li> <li>username: - enter your username</li> <li>password: - enter your password</li> <li>timeout: 15</li> </ul>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#example-of-resource-configuration","title":"Example of resource configuration","text":"<pre><code>{\n  \"smtp\": \"smtp.gmail.com\", \n  \"port\": 587, \n  \"username\": \"enter your username\",\n  \"password\": \"enter your password\",\n  \"timeout\": 15\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#input-payload","title":"Input payload","text":"<p>This node does not process input payload.</p>"},{"location":"getting_started/processes/workflow/actions/smtp_connector_action/#output","title":"Output","text":"<p>This node returns true if mail was sent or false if there was an error.</p>"},{"location":"getting_started/processes/workflow/actions/sort_array_action/","title":"Sort array action","text":"<p>Developer have not provided the documentation.</p>"},{"location":"getting_started/processes/workflow/actions/sorted_dict_action/","title":"Sort dictionary","text":"<p>Sorts the referenced dictionary and returns it as a list of tuples of key and value.</p>"},{"location":"getting_started/processes/workflow/actions/sorted_dict_action/#configuration","title":"Configuration","text":"<p>Example:</p> <pre><code>{\n  \"data\": {\"first\": 1, \"second\": 2, \"fifth\": 5, \"third\": 3},\n  \"direction\": \"asc\",\n  \"sort_by\": \"key\"\n}\n</code></pre> <p>This configuration will sort the dictionary</p> <pre><code>{\"first\": 1, \"second\": 2, \"fifth\": 5, \"third\": 3}\n</code></pre> <p>with the order provided by direction (default: \"asc\")</p> <p>The dictionary is provided as a path to data in event. Example of such configuration.</p> <pre><code>{\n  \"data\": \"event@properties.data\",\n  \"direction\": \"asc\",\n  \"sort_by\": \"key\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/sorted_dict_action/#input","title":"Input","text":"<p>This plugin does not process input.</p>"},{"location":"getting_started/processes/workflow/actions/sorted_dict_action/#output","title":"Output","text":"<p>Returns the ordered list of tuples with keys and values.</p> <p>Example:</p> <pre><code>{\n  \"result\": [\n    [\"first\", 1], \n    [\"second\", 2], \n    [\"third\", 3], \n    [\"fifth\", 5]\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/start_action/","title":"Start plugin","text":"<p>This plugin starts every workflow.</p>"},{"location":"getting_started/processes/workflow/actions/start_action/#configuration","title":"Configuration","text":""},{"location":"getting_started/processes/workflow/actions/start_action/#production-run-configuration","title":"Production run configuration","text":"<ul> <li>Collect debugging information - Set if you want to collect debugging information. Debugging collects a lot of data if   you no longer need to test your workflow disable it to save data and compute power.</li> <li>Trigger start on these event types - Workflow does not execute if incoming event type is not mentioned in this field.   However, if left empty, workflow will be triggered regardless event type.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/start_action/#debug-run-configuration","title":"Debug run configuration","text":"<ul> <li>Profile-less event - enable this option if you want to test your workflow without profile data.</li> <li>Session-less event - enable this option if you want to test your workflow without session data attached.</li> <li>Event properties - You can manually specify event properties for debug purpose. However, this option does not apply if   one of fields below are filled.</li> <li>Event ID - use this option if you want to test your workflow with one, particular event.</li> <li>Event type - use this option if you want to test your data with real event of selected type, instead of auto-generated   one. Does not apply if Event ID field is filled.</li> </ul> <pre><code>{\n  \"debug\": \"&lt;bool&gt;\",\n  \"event_types\": [\n    {\n      \"id\": \"&lt;event-type-1&gt;\",\n      \"name\": \"&lt;event-type-1&gt;\"\n    },\n    {\n      \"id\": \"&lt;event-type-2&gt;\",\n      \"name\": \"&lt;event-type-2&gt;\"\n    }\n  ],\n  \"profile_less\": \"&lt;bool&gt;\",\n  \"session_less\": \"&lt;bool&gt;\",\n  \"properties\": \"&lt;serialized-json&gt;\",\n  \"event_id\": \"&lt;some-uuid&gt;\",\n  \"event_type\": {\n    \"name\": \"&lt;event-type-1&gt;\",\n    \"id\": \"&lt;event-type-1\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/starts_with_action/","title":"StartsWith Plugin","text":"<p>This plugin checks if data field starts with defined prefix.</p>"},{"location":"getting_started/processes/workflow/actions/starts_with_action/#json-configuration","title":"JSON Configuration","text":"<p>Example input:</p> <pre><code>{\n  \"field\": \"payload@field\",\n  \"prefix\": \"string\"\n}\n</code></pre> <p>Output:</p> <p>Plugin outputs the payload on ports TRUE if field contains prefix or FALSE if otherwise.</p>"},{"location":"getting_started/processes/workflow/actions/string_join_action/","title":"Join string list","text":"<p>This plugin joins each element in the list with a given delimiter.</p>"},{"location":"getting_started/processes/workflow/actions/string_join_action/#configuration","title":"Configuration","text":"<p>Example:</p> <pre><code>{\n  \"string\": ['a','b','c'],\n  \"delimiter\": \",\"\n}\n</code></pre> <p>This configuration will join each element in the list ['a','b','c'] with a given delimiter ','. It converts the list into a string 'a,b,c'. String can be provided as a path to data in profile, event, session, etc. Example of such configuration.</p> <pre><code>{\n  \"string\": \"event@properties.data\",\n  \"delimiter\": \",\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_join_action/#input","title":"Input","text":"<p>This plugin does not process input.</p>"},{"location":"getting_started/processes/workflow/actions/string_join_action/#output","title":"Output","text":"<p>Returns the string converted from a string list using a given delimiter.</p> <p>Example:</p> <pre><code>{\n  \"result\": \"a,b,c\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_properties_action/","title":"String properties and transformations","text":"<p>The purpose of this plugin is return string properties and some transformations as upper case, etc.</p>"},{"location":"getting_started/processes/workflow/actions/string_properties_action/#configuration","title":"Configuration","text":"<p>This node requires configuration. </p> <p>You have to provide a path to string that needs to be transformed. </p> <pre><code>{\n  \"string\": \"event@path.to.data\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_properties_action/#input-payload","title":"Input payload","text":"<p>This node does not process input payload.</p>"},{"location":"getting_started/processes/workflow/actions/string_properties_action/#output","title":"Output","text":"<p>This plugin returns an object with transformed string and all its properties such as: isdigit, isupper, etc.</p>"},{"location":"getting_started/processes/workflow/actions/string_properties_action/#available-properties-and-transformations","title":"Available properties and transformations","text":"<ul> <li>capitalize - Converts the first character to upper case</li> <li>casefold - Converts string into lower case</li> <li>isalnum - Returns True if all characters in the string are alphanumeric</li> <li>isalpha - Returns True if all characters in the string are in the alphabet </li> <li>isascii - Returns True if all characters in the string are ascii characters</li> <li>isdecimal - Returns True if all characters in the string are decimals</li> <li>isdigit - Returns True if all characters in the string are digits</li> <li>isidentifier - Returns True if the string is an identifier</li> <li>islower - Returns True if all characters in the string are lower case</li> <li>isnumeric - Returns True if all characters in the string are numeric</li> <li>isprintable - Returns True if all characters in the string are printable</li> <li>isspace - Returns True if all characters in the string are whitespaces</li> <li>istitle - Returns True if the string follows the rules of a title</li> <li>isupper - Returns True if all characters in the string are upper case</li> <li>lstrip - Returns a left trim version of the string</li> <li>swapcase - Swaps cases, lower case becomes upper case and vice ver sa</li> <li>title - Converts the first character of each word to upper case</li> <li>upper - Converts a string into upper case</li> <li>lower - Converts a string into lower case</li> </ul>"},{"location":"getting_started/processes/workflow/actions/string_properties_action/#output_1","title":"Output","text":"<p>Example</p> <pre><code>{\n    \"capitalize\": \"1\",\n    \"casefold\": \"1\",\n    \"encode\": \"1\",\n    \"isalnum\": true,\n    \"isalpha\": false,\n    \"isascii\": true,\n    \"isdecimal\": true\n    \"isdigit\": true,\n    \"isidentifier\": false,\n    \"islower\": false,\n    \"isnumeric\": true,\n    \"isprintable\": true,\n    \"isspace\": false,\n    \"istitle\": false,\n    \"isupper\": false,\n    \"lower\": \"1\",\n    \"lstrip\": \"1\",\n    \"swapcase\": \"1\",\n    \"title\": \"1\",\n    \"upper\": \"1\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_replace/","title":"String Replace","text":"<p>This plugin is designed to replace a specific substring within a text field in the payload of a Tracardi workflow. It's particularly useful for modifying text data, such as correcting misspellings or standardizing terminology.</p>"},{"location":"getting_started/processes/workflow/actions/string_replace/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/string_replace/#description","title":"Description","text":"<p>The String Replace plugin operates on a specified field in the workflow's payload. It searches for a defined substring ( the 'find' value) and replaces it with another string (the 'replace' value). For instance, if the field contains \"Hello World\" and the find value is \"World\", replacing it with \"Tracardi\" would change the text to \"Hello Tracardi\". The plugin then updates the payload with this new value. If the specified field is not a string, the plugin returns an error message.</p>"},{"location":"getting_started/processes/workflow/actions/string_replace/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin accepts a payload object which should contain the field to be operated on.</li> <li>Outputs:<ul> <li>Output: Returns the modified value with the string replacement applied.</li> <li>Error: If the specified field is not a string, an error message is returned.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/string_replace/#configuration","title":"Configuration","text":"<ul> <li>Field: The field for string replacement.</li> <li>Find: The substring to be replaced.</li> <li>Replace: The string to replace the found substring.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/string_replace/#result","title":"Result","text":"<p>Example:</p> <pre><code>{\n  \"value\": \"string with replaced substring\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_replace/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"field\": \"profile@data.exampleField\",\n  \"find\": \"oldText\",\n  \"replace\": \"newText\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_replace/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/string_replace/#errors","title":"Errors","text":"<ul> <li>\"Field '{field}' is not a string.\": This error occurs if the specified field in the payload is not a string type.   For example, if a numeric or object field is specified, this error will be returned.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/","title":"String similarity","text":"<p>This plugin checks similarity between two strings according to similarity algorithms.</p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#configuration","title":"Configuration","text":"<p>Example:</p> <pre><code>{\n   \"first_string\": \"event@properties.some_value1\",\n   \"second_string\": \"event@properties.some_value2\",\n   \"algorithm\": \"Levenshtein\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#input","title":"Input","text":"<p>This plugin takes payload as input</p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#output","title":"Output","text":"<p>Returns the result of similarity check.</p> <p>Example:</p> <pre><code>{\n  \"similarity\": \"1\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#string-similarity-algorithms-from-strsimpy-documentation","title":"String similarity algorithms <sup>from strsimpy documentation</sup>","text":"<p>The main characteristics of each implemented algorithm are presented below. The \"cost\" column gives an estimation of the computational cost to compute the similarity between two strings of length m and n respectively.</p> Normalized? Metric? Type Cost Typical usage Levenshtein distance No Yes O(m*n) <sup>1</sup> Normalized Levenshtein distancesimilarity Yes No O(m*n) Weighted Levenshtein distance No No O(m*n) OCR Damerau-Levenshtein distance No Yes O(m*n) <sup>1</sup> Optimal String Alignment distance No No O(m*n) <sup>1</sup> Jaro-Winkler similaritydistance Yes No O(m*n) typo correction Longest Common Subsequence distance No No O(m*n) diff utility, GIT reconciliation"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#levenshtein","title":"Levenshtein","text":"<p>The Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. It is a metric string distance. </p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#normalized-levenshtein","title":"Normalized Levenshtein","text":"<p>This distance is computed as levenshtein distance divided by the length of the longest string. The resulting value is always in the interval [0.0 1.0] but it is not a metric anymore!</p> <p>The similarity is computed as 1 - normalized distance.</p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#weighted-levenshtein","title":"Weighted Levenshtein","text":"<p>An implementation of Levenshtein that allows to define different weights for different character substitutions.</p> <p>This algorithm is usually used for optical character recognition (OCR) applications. For OCR, the cost of substituting P and R is lower then the cost of substituting P and M for example because because from and OCR point of view P is similar to R.</p> <p>It can also be used for keyboard typing auto-correction. Here the cost of substituting E and R is lower for example because these are located next to each other on an AZERTY or QWERTY keyboard. Hence the probability that the user mistyped the characters is higher.</p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#damerau-levenshtein","title":"Damerau-Levenshtein","text":"<p>Similar to Levenshtein, Damerau-Levenshtein distance with transposition (also sometimes calls unrestricted Damerau-Levenshtein distance) is the minimum number of operations needed to transform one string into the other, where an operation is defined as an insertion, deletion, or substitution of a single character, or a transposition of two adjacent characters.</p> <p>It does respect triangle inequality, and is thus a metric distance.</p> <p>This is not to be confused with the optimal string alignment distance, which is an extension where no substring can be edited more than once.</p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#optimal-string-alignment","title":"Optimal String Alignment","text":"<p>The Optimal String Alignment variant of Damerau\u2013Levenshtein (sometimes called the restricted edit distance) computes the number of edit operations needed to make the strings equal under the condition that no substring is edited more than once, whereas the true Damerau\u2013Levenshtein presents no such restriction. The difference from the algorithm for Levenshtein distance is the addition of one recurrence for the transposition operations.</p> <p>Note that for the optimal string alignment distance, the triangle inequality does not hold and so it is not a true metric.</p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#jaro-winkler","title":"Jaro-Winkler","text":"<p>Jaro-Winkler is a string edit distance that was developed in the area of record linkage (duplicate detection) (Winkler, 1990). The Jaro\u2013Winkler distance metric is designed and best suited for short strings such as person names, and to detect transposition typos.</p> <p>Jaro-Winkler computes the similarity between 2 strings, and the returned value lies in the interval [0.0, 1.0]. It is (roughly) a variation of Damerau-Levenshtein, where the transposition of 2 close characters is considered less important than the transposition of 2 characters that are far from each other. Jaro-Winkler penalizes additions or substitutions that cannot be expressed as transpositions.</p> <p>The distance is computed as 1 - Jaro-Winkler similarity.</p>"},{"location":"getting_started/processes/workflow/actions/string_similarity_action/#longest-common-subsequence","title":"Longest Common Subsequence","text":"<p>The longest common subsequence (LCS) problem consists in finding the longest subsequence common to two (or more) sequences. It differs from problems of finding common substrings: unlike substrings, subsequences are not required to occupy consecutive positions within the original sequences.</p> <p>It is used by the diff utility, by Git for reconciling multiple changes, etc.</p> <p>The LCS distance between strings X (of length n) and Y (of length m) is n + m - 2 |LCS(X, Y)| min = 0 max = n + m</p> <p>LCS distance is equivalent to Levenshtein distance when only insertion and deletion is allowed (no substitution), or when the cost of the substitution is the double of the cost of an insertion or deletion.</p> <p>This class implements the dynamic programming approach, which has a space requirement O(m.n), and computation cost O(m.n).</p> <p>In \"Length of Maximal Common Subsequences\", K.S. Larsen proposed an algorithm that computes the length of LCS in time O(log(m).log(n)). But the algorithm has a memory requirement O(m.n\u00b2) and was thus not implemented here.</p>"},{"location":"getting_started/processes/workflow/actions/string_splitter_action/","title":"String splitter","text":"<p>This plugin splits any string with a given delimiter.</p>"},{"location":"getting_started/processes/workflow/actions/string_splitter_action/#configuration","title":"Configuration","text":"<p>Example:</p> <pre><code>{\n  \"string\": \"a.b.c\",\n  \"delimiter\": \".\"\n}\n</code></pre> <p>This configuration will split <code>a.b.c</code> string into [\"a\", \"b\", \"c\"], using '.' as delimiter. String can be provided as a path to data in profile, event, session, etc. Example of such configuration.</p> <pre><code>{\n  \"string\": \"event@properties.data\",\n  \"delimiter\": \".\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_splitter_action/#input","title":"Input","text":"<p>This plugin does not process input.</p>"},{"location":"getting_started/processes/workflow/actions/string_splitter_action/#output","title":"Output","text":"<p>Returns array with separated values.</p> <p>Example:</p> <pre><code>{\n  \"result\": [\n    \"a\",\n    \"b\",\n    \"c\"\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_stripper_action/","title":"String splitter","text":"<p>This plugin strips the given string off all the characters that appear in to_remove string.</p>"},{"location":"getting_started/processes/workflow/actions/string_stripper_action/#configuration","title":"Configuration","text":"<p>Example:</p> <pre><code>{\n  \"string\": \"Hello, World!\",\n  \"to_remove\": \"Ho\"\n}\n</code></pre> <p>This configuration will strip off the string <code>Hello, World!</code> off of the character <code>Ho</code>, resulting in <code>ell, Wrld!</code>.</p>"},{"location":"getting_started/processes/workflow/actions/string_stripper_action/#output","title":"Output","text":"<p>Returns the string with the specified characters removed.</p> <p>Example:</p> <pre><code>{\n  \"value\": \"ell, Wrld!\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/","title":"String to Date","text":"<p>The String to Date plugin is used to convert a string representing a date into a date object. This can be useful for transforming date strings from various sources into a consistent format for further processing in your workflows.</p>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/#version","title":"Version","text":"<p>This documentation is for plugin version 0.8.2.</p>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/#description","title":"Description","text":"<p>The String to Date plugin takes a date string as input and attempts to convert it into a date object. If the conversion is successful, it returns the date object on the \"date\" output port. If the conversion fails, it returns an error message on the \"error\" output port.</p> <p>The plugin uses the dateparser library to parse date strings. The date string to be converted is specified in the plugin's configuration.</p> <p>Example:</p> <p>If the plugin is configured with a date string like \"2023-10-12,\" it will attempt to convert this string into a date object representing October 12, 2023.</p>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li> <p>Input: This plugin has one input port named \"payload,\" which accepts any payload data.</p> </li> <li> <p>Outputs:</p> <ul> <li>\"date\": If the date string is successfully converted, the date object is returned on this port.</li> <li>\"error\": If the conversion fails, an error message is returned on this port.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/#configuration","title":"Configuration","text":"<p>The String to Date plugin has the following configuration parameters:</p> <ul> <li>String: This is where you specify the path to the text or the text itself that you want to convert to a date. The   plugin will attempt to convert the value located at this path within the payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of the JSON configuration for the String to Date plugin:</p> <pre><code>{\n  \"string\": \"event@path.to.date.string\"\n}\n</code></pre> <p>In this example, the plugin is configured to convert the date string located in event at \"path.to.date.string\".</p>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/string_to_date_action/#errors","title":"Errors","text":"<p>The String to Date plugin may encounter the following error:</p> <ul> <li> <p>Error Message: If the date string provided in the configuration cannot be parsed as a date, an error will be   generated.</p> </li> <li> <p>When It May Occur: This error may occur if the date string is not in a valid format or if the parsing process   encounters an issue. It's essential to ensure that the date strings provided are in a format that can be recognized by   the dateparser library.</p> </li> </ul> <p>Note: This plugin's functionality relies on the dateparser library, so the success of date conversion depends on the library's ability to parse the provided date string.</p>"},{"location":"getting_started/processes/workflow/actions/string_validator_action/","title":"String Validator Action","text":"<p>The purpose of this plugin is to validate data. We need to specify a type of validation. </p> <p>We can choose from:</p> <ul> <li>email - for example example@mail.com</li> <li>url - for example tracardi.com</li> <li>ipv4 for example 192.168.1.1</li> <li>date for example 01.01.1900</li> <li>time for example 01:01</li> <li>int for example 3</li> <li>float for example 3.4</li> <li>number_phone for example +48123456789</li> </ul>"},{"location":"getting_started/processes/workflow/actions/string_validator_action/#configuration","title":"Configuration","text":"<p>This node require configuration.</p> <p>Configuration values</p> <ul> <li>validator - type of validation.</li> <li>data - the string that we would like to validate</li> </ul> <p>Data can be a dotted notation path to value inside profile, event, session, etc. or any string.</p>"},{"location":"getting_started/processes/workflow/actions/string_validator_action/#examples","title":"Examples","text":"<pre><code>{\n  \"validator\" : \"url\",\n  \"data\" : \"profile@traits.private.email\"\n}\n</code></pre> <p>It will return <code>payload</code> on <code>valid</code> output port. <code>invalid</code> port will stay inactive. </p> <pre><code>{\n  \"validator\" : \"email\",\n  \"data\" : \"12341232\"\n}\n</code></pre> <p>It will return <code>payload</code> on <code>invalid</code> output port. <code>valid</code> port will stay inactive. </p>"},{"location":"getting_started/processes/workflow/actions/string_validator_action/#input-payload","title":"Input payload","text":"<p>This node does not process input payload. Input payload will not be returned on output. </p>"},{"location":"getting_started/processes/workflow/actions/string_validator_action/#output","title":"Output","text":"<p>This plugin has to port valid and invalid. Depending on validation result the appropriate ports will be launched with payload copied as data.</p>"},{"location":"getting_started/processes/workflow/actions/summarization_action/","title":"Summarize text plugin","text":"<p>This plugin sends given text to MeaningCloud's summarization API to summarize it.</p>"},{"location":"getting_started/processes/workflow/actions/summarization_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/summarization_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from API on port response, or optional error info on error port if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/summarization_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/summarization_action/#with-form","title":"With form","text":"<ul> <li>MeaningCloud resource - select your MeaningCloud resource, containing your MeaningCloud   API token.</li> <li>Path to text - type in the path to the text that you want to summarize.</li> <li>Path to language - type in the path to the language of the text (es, en)   you can type the language itself as well. This option can be left as auto for automatic   language detection.</li> <li>Sentences - type in the number of sentences for text to be summarized to. This field does   not support dotted notation.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/summarization_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"&lt;name-of-your-meaningcloud-resource&gt;\",\n    \"id\": \"&lt;id-of-your-meaningcloud-resource&gt;\"\n  },\n  \"text\": \"&lt;path-to-text-to-analyze&gt;\",\n  \"lang\": \"&lt;path-to-language-code-or-language-itself&gt;\",\n  \"sentences\": \"&lt;numeric-string&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/tag_event/","title":"Tag Event","text":"<p>Tag Event is a Tracardi action plugin that ads tags to the current event.</p>"},{"location":"getting_started/processes/workflow/actions/tag_event/#version","title":"Version","text":"<p>The documentation was created for version 0.8.0 of the Tag Event plugin.</p>"},{"location":"getting_started/processes/workflow/actions/tag_event/#description","title":"Description","text":"<p>The Tag Event plugin, as its name suggests, is primarily used to add tags to the current event. This plugin does not modify the payload.</p>"},{"location":"getting_started/processes/workflow/actions/tag_event/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Tag Event plugin accepts one input called \"payload\". While it also returns the input payload on the output port \"payload\".</p> <p>Sample Input: <pre><code>{\n  // payload to be processed by the plugin\n}\n</code></pre></p> <p>Sample Output: <pre><code>{\n  // returned input payload\n}\n</code></pre></p>"},{"location":"getting_started/processes/workflow/actions/tag_event/#configuration","title":"Configuration","text":"<p>The plugin is configured using the following parameters:</p> <ul> <li><code>tags</code>: A string containing the tags to be added to the current event.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/tag_event/#json-configuration","title":"JSON Configuration","text":"<p>The initial configuration of the plugin can look like:</p> <pre><code>{\n  \"tags\": \"tag1, tag2, tag3\"\n}\n</code></pre> <p>In the above configuration, the plugin will add the tags 'tag1', 'tag2', and 'tag3' to the current event.</p>"},{"location":"getting_started/processes/workflow/actions/tag_event/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/tag_event/#errors","title":"Errors","text":"<p>Tag Event plugin does not return any error under normal conditions.</p> <p>If you see any error, it might be related to internal problems in the system or issues with the payload schema. Please check your configuration parameters and payload.</p>"},{"location":"getting_started/processes/workflow/actions/template_action/","title":"Template Plugin","text":"<p>Returns a string build from template.</p>"},{"location":"getting_started/processes/workflow/actions/template_action/#input","title":"Input","text":"<p>Plugin requires template that contains placeholders with referenced data. Placeholders start with {{ and end with }}. Placeholders are replaced by the referenced data. See how to reference data for more information: </p> <p>Example <pre><code>Hello {{profile@pii.name}}\n</code></pre></p> <p>where <code>profile@pii.name</code> is path to variable in payload that is located at pii.name. </p> <p>Plugin returns string with placeholder replaced by values from referenced data. See workflow internal state  for more information on data saved inside workflow.</p>"},{"location":"getting_started/processes/workflow/actions/template_action/#output","title":"Output","text":"<p>Example</p> <pre><code>{\n  \"template\": \"Hello Adam\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/text_classification_action/","title":"Text Classification","text":"<p>This plugin classifies provided text.</p>"},{"location":"getting_started/processes/workflow/actions/text_classification_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"Text classification\",\n    \"id\": \"e7a3979e-7f31-452b-a571-8ca613de77fb\"\n  },\n  \"language\": \"en\",\n  \"model\": \"press\",\n  \"title\": \"The iPhone 13 isn\u2019t a game changer\",\n  \"text\": \"The iPhone 13 isn\u2019t a game changer for Apple\u2019s series of smartphones, but it\u2019s an ...\"\n}\n</code></pre> <ul> <li>source.id - ID that points to resource with an access token. See below for resource configuration schema.</li> <li>language - language of the text to classify. (en|sp|it|pt|ct|fr)</li> <li>title - optional title of the text</li> <li>text - text to classify</li> </ul>"},{"location":"getting_started/processes/workflow/actions/text_classification_action/#resource-configuration","title":"Resource configuration","text":"<pre><code>{\n  \"token\": \"dgrhfcd6hhdj706...\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/text_classification_action/#output","title":"Output","text":"<p>Example</p> <pre><code>{\n  \"categories\": [\n    {\n      \"code\": \"13016000\",\n      \"label\": \"science and technology - electronics\",\n      \"abs_relevance\": \"0.2833175\",\n      \"relevance\": \"100\"\n    }\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/throw_error_action/","title":"Throw error plugin","text":"<p>This plugin ends workflow with given error message.</p>"},{"location":"getting_started/processes/workflow/actions/throw_error_action/#input","title":"Input","text":"<p>This plugin takes any payload as input</p>"},{"location":"getting_started/processes/workflow/actions/throw_error_action/#output","title":"Output","text":"<p>This plugin has no output ports.</p>"},{"location":"getting_started/processes/workflow/actions/throw_error_action/#configuration","title":"Configuration","text":"<pre><code>{\n  \"message\": \"&lt;your-message&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/time_delay/","title":"Time Delay","text":"<p>This plugin calculates a date based on a specified date and a time delay. It can either add or subtract the delay, which is defined in seconds.</p>"},{"location":"getting_started/processes/workflow/actions/time_delay/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/time_delay/#description","title":"Description","text":"<p>The Time Delay plugin is designed to calculate a new date by adding or subtracting a specified delay from a reference date. This plugin takes a date, which can be either a specific datetime object or a string, and applies a time delay to it. The delay can be added or subtracted based on the user's choice.</p> <p>The process starts by receiving a payload. The plugin then extracts the reference date from the payload using dot notation, a method that retrieves data from the workflow's internal state. This reference date is either a specific datetime object or a string like 'now', which represents the current date and time.</p> <p>Next, the plugin calculates the new date by adding or subtracting the specified delay, in seconds, from the reference date. This calculation depends on the chosen operation (addition or subtraction). The result is a new date, which is then returned as the output of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/time_delay/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Inputs:</p> <ul> <li>payload: This is the input payload object from which the reference date is extracted.</li> </ul> <p>Outputs:</p> <ul> <li>date: This output port returns the calculated date after applying the time delay.</li> <li>error: In case of any errors during the process, this output port returns an error message.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/time_delay/#configuration","title":"Configuration","text":"<ul> <li>Reference Date: Path to the date in the payload, specified in dot notation.</li> <li>Operation: Choice of operation, either to add or subtract the delay.</li> <li>Delay: The time delay in seconds to be added or subtracted from the reference date.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/time_delay/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"reference_date\": \"profile@metadata.time.insert\",\n  \"sign\": \"+\",\n  \"delay\": \"60\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/time_delay/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/time_delay/#event-prerequisites","title":"Event prerequisites","text":"<p>This plugin works for all types of events and does not require the event to be synchronous.</p>"},{"location":"getting_started/processes/workflow/actions/time_delay/#errors","title":"Errors","text":"<ul> <li>\"Could not parse data {date}\": This error occurs if the plugin is unable to parse the provided date.</li> <li>\"Date can be either string or datetime object\": This error is raised if the provided date is neither a string nor a   datetime object.</li> <li>Any other exceptions will return a general error message containing the exception's text. This typically occurs if   there are issues with the payload or the configuration parameters.</li> </ul> <p>This documentation provides a comprehensive overview of the Time Delay plugin, detailing its functionality, configuration, and potential errors. It's designed to be understandable even for individuals without technical background in coding or software development.</p>"},{"location":"getting_started/processes/workflow/actions/time_difference/","title":"Time Difference","text":"<p>This plugin, Time Difference, calculates the difference between two dates.</p>"},{"location":"getting_started/processes/workflow/actions/time_difference/#version","title":"Version","text":"<p>0.6.0.1</p>"},{"location":"getting_started/processes/workflow/actions/time_difference/#description","title":"Description","text":"<p>The Time Difference plugin calculates the time difference between two given dates. These dates are provided using the dot notation from the payload. The dates can be of any format, but they're often either a string which represents a date or a Python datetime object.</p> <p>The Time Difference plugin takes two inputs - a reference date (the starting point) and a secondary date (the end point). It uses these inputs to compute the time difference in various units: seconds, minutes, hours, days, and weeks.</p> <p>Steps:</p> <ol> <li>The plugin first retrieves the payload passed to it. It uses a DotAccessor to extract the dates defined in the    configuration from this payload.</li> <li>For each date, it performs a check. If the input is a string and equals 'now', the plugin substitutes it with the    current date and time (in UTC). If it's simply a string that represents a date, it parses the string into a datetime    object. If it's already a datetime object, it uses the datetime as it is. If none of these conditions are met, it    raises an exception.</li> <li>Once both dates are ensured to be datetime objects, the plugin calculates the difference between these two dates. It    does this by subtracting the reference date from the secondary date.</li> <li>The resulting time delta (difference), originally in seconds, is converted into minutes, hours, days, and weeks for    convenience.</li> </ol> <p>Note: If the reference date is later than the secondary date ('now' or otherwise), the values returned by the plugin will be negative.</p>"},{"location":"getting_started/processes/workflow/actions/time_difference/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Time Difference plugin accepts two inputs using the payload:</p> <ol> <li>reference_date : It is the starting point for time difference calculation. It can be in any format - a string    representing a date/time, or a Python datetime object,</li> <li>now : It is the end point for time difference calculation. It can also be in any format - a string representing a    date/time, the string 'now' to use the current date/time, or a Python datetime object.</li> </ol> <p>Once the plugin finishes execution, it returns the time difference on the port \"time_difference\". The result is a dictionary containing the time difference in various units : seconds, minutes, hours, days, and weeks.</p>"},{"location":"getting_started/processes/workflow/actions/time_difference/#configuration","title":"Configuration","text":"<p>The Time Difference plugin needs to be configured with dot notation paths to two dates -</p> <ul> <li>Reference date : The path in the payload to the reference date, i.e., the start date.</li> <li>Second date : The path in the payload to the second date, i.e., the end date. The configuration accepts the   string 'now' in place of a path to signify the current UTC time.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/time_difference/#json-configuration","title":"JSON Configuration","text":"<p>Here's an example configuration in JSON format:</p> <pre><code>{\n  \"reference_date\": \"event@session.start\",\n  \"now\": \"event@session.end\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/time_difference/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/time_difference/#errors","title":"Errors","text":"<ul> <li>\"Could not parse data {}\": This error is raised when the plugin fails to parse the provided date. It usually occurs   when the provided date does not follow a recognizable format.</li> <li>\"Date can be either string or datetime object\": This error is raised when the plugin encounters a date input that   isn't a string or datetime object. It may occur if the data at the payload path provided in the configuration is   neither a string nor a datetime object.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/today_action/","title":"Today","text":"<p>The \"Today\" plugin provides detailed information about the current date and time, including day of the week, month, year, and exact time. This plugin is particularly useful for tasks that require date and time-related data processing.</p>"},{"location":"getting_started/processes/workflow/actions/today_action/#version","title":"Version","text":"<p>0.8.2</p>"},{"location":"getting_started/processes/workflow/actions/today_action/#description","title":"Description","text":"<p>The Today plugin operates by determining the current date and time based on a specified timezone. It then outputs detailed information including the UTC time, local time, server time, and timestamps. The plugin can handle different time zones, allowing for flexibility in workflows that involve users or events across various geographic locations.</p>"},{"location":"getting_started/processes/workflow/actions/today_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Inputs:</p> <ul> <li>Payload: Accepts any JSON-like object. The plugin uses this input to extract the specified timezone.</li> </ul> <p>Outputs:</p> <ul> <li>Payload: Outputs a JSON object containing detailed current date and time information.</li> <li>Error: In case of issues, such as an unavailable time zone, this output provides an error message.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/today_action/#configuration","title":"Configuration","text":"<ul> <li>Timezone: Specify the path to the field containing the timezone information. This can be a direct timezone string   or a path using dot notation, such as \"session@context.time.tz\".</li> </ul>"},{"location":"getting_started/processes/workflow/actions/today_action/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"timezone\": \"session@context.time.tz\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/today_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/today_action/#event-prerequisites","title":"Event prerequisites","text":"<p>The Today plugin is compatible with all event types and does not require synchronous events to operate.</p>"},{"location":"getting_started/processes/workflow/actions/today_action/#errors","title":"Errors","text":"<ul> <li>\"Unavailable time zone in current session\": This error occurs if the specified timezone is not found or is invalid in   the current session. The workflow will proceed through the \"error\" output port in this case.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/topics_extraction_action/","title":"Extract topics plugin","text":"<p>This plugin sends given text to MeaningCloud's Topics extraction API to extract topics from it.</p>"},{"location":"getting_started/processes/workflow/actions/topics_extraction_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/topics_extraction_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from API on port response, or optional error info on error port if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/topics_extraction_action/#plugin-configuration","title":"Plugin configuration","text":""},{"location":"getting_started/processes/workflow/actions/topics_extraction_action/#with-form","title":"With form","text":"<ul> <li>MeaningCloud resource - select your MeaningCloud resource, containing your MeaningCloud   API token.</li> <li>Path to text - type in the path to the text that you want to summarize.</li> <li>Path to language - type in the path to the language of the text (es, en)   you can type the language itself as well. This option can be left as auto for automatic   language detection.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/topics_extraction_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"source\": {\n    \"name\": \"&lt;name-of-your-meaningcloud-resource&gt;\",\n    \"id\": \"&lt;id-of-your-meaningcloud-resource&gt;\"\n  },\n  \"text\": \"&lt;path-to-text-to-analyze&gt;\",\n  \"lang\": \"&lt;path-to-language-code-or-language-itself&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/twitter_tweet_action/","title":"Send Twitter tweet plugin","text":"<p>This plugin adds tweets on your Twitter feed.</p>"},{"location":"getting_started/processes/workflow/actions/twitter_tweet_action/#requirements","title":"Requirements","text":"<p>You'll need a Twitter account where you need to create an application and generate access keys. There are 4 keys in total. For more details check twitter resource documentation.</p>"},{"location":"getting_started/processes/workflow/actions/twitter_tweet_action/#input","title":"Input","text":"<p>This plugin takes any payload.</p>"},{"location":"getting_started/processes/workflow/actions/twitter_tweet_action/#output","title":"Output","text":"<p>Depending on the response, the plugin will trigger data on response port (if the response was successful) or on  error port if the response had an error.</p>"},{"location":"getting_started/processes/workflow/actions/twitter_tweet_action/#config-example","title":"Config example","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-twitter-resource&gt;\",\n    \"name\": \"&lt;name-of-your-twitter-resource&gt;\"\n  },\n  \"tweet\": \"Tweet content\"\n}\n</code></pre> <p>Tweet can be a message template. Template is a text file with special mark-up. Within double curly braces you can place dot notation that reads data from internal state of the workflow.</p> <p>Example</p> <pre><code>Hello {{profile@pii.name}}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/update_event_action/","title":"Update Event Action","text":"<p>When there is new information appended to event that needs to be saved, an update actions should be executed.  To do that use this node. Once the node is connected in flow it will mark event to be updated just after the flow ends.   </p>"},{"location":"getting_started/processes/workflow/actions/update_event_action/#configuration","title":"Configuration","text":"<p>This node needs no configuration. It does not require any input data. </p>"},{"location":"getting_started/processes/workflow/actions/update_profile_action/","title":"Update Event Action","text":"<p>When there is new information appended to event that needs to be saved, an update actions should be executed.  To do that use this node. Once the node is connected in flow it will mark event to be updated just after the flow ends.   </p>"},{"location":"getting_started/processes/workflow/actions/update_profile_action/#configuration","title":"Configuration","text":"<p>This node needs no configuration. It does not require any input data. </p>"},{"location":"getting_started/processes/workflow/actions/update_profile_action/#side-effect","title":"Side effect","text":"<p>Update will not be triggered in debug mode.</p>"},{"location":"getting_started/processes/workflow/actions/update_session_action/","title":"Update Session Action","text":"<p>When there is new information appended to session that needs to be saved, an update actions should be executed.  To do that use this node. Once the node is connected in flow it will mark session to be updated just after the flow ends.   </p>"},{"location":"getting_started/processes/workflow/actions/update_session_action/#configuration","title":"Configuration","text":"<p>This node needs no configuration. It does not require any input data. </p>"},{"location":"getting_started/processes/workflow/actions/update_session_action/#side-effect","title":"Side effect","text":"<p>Update will not be triggered in debug mode.</p>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/","title":"Parse URL","text":"<p>This plugin is designed to read a URL from the context provided within a workflow and extract various components of the URL, such as the scheme, hostname, path, query parameters, and fragment.</p>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/#version","title":"Version","text":"<p>0.6.0.1</p>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/#description","title":"Description","text":"<p>When this plugin is activated, it begins by locating a specific URL within the workflow's context. It then proceeds to dissect the URL into its constituent parts. Each section of the URL, from the scheme (like HTTP or HTTPS) to the individual query parameters, is separated and cataloged. The result is a structured representation of the URL, with each element neatly organized for easy reference.</p> <p>Here's a step-by-step description of what the plugin does:</p> <ol> <li>It takes a URL from the workflow's context or session data.</li> <li>It analyzes the URL, separating it into the scheme, hostname, path, query string, individual query parameters, and    fragment (also known as the hash).</li> <li>It constructs an output that is a detailed map of all these parts for use in subsequent steps of the workflow.</li> </ol> <p>For example, if the plugin is given a URL like http://web.address.com/path/index.html?param1=1#hash, it will produce an output that organizes the URL's components into a structured format:</p> <pre><code>{\n  \"url\": \"http://web.address.com/path/index.html?param1=1#hash\",\n  \"scheme\": \"http\",\n  \"hostname\": \"web.address.com\",\n  \"path\": \"/path/index.html\",\n  \"query\": \"param1=1\",\n  \"params\": {\n    \"param1\": \"1\"\n  },\n  \"fragment\": \"hash\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin receives data through a single input port named \"payload\". However, it does not process this input payload directly; instead, it uses it to access the URL from the workflow's context.</p> <p>The output is then passed on through a port, also named \"payload\", and includes the parsed URL data in a structured format.</p> <p>This plugin is not a starting point in a workflow; it requires some data to be passed into it to function.</p>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/#configuration","title":"Configuration","text":"<p>To configure this plugin, the following parameter must be set:</p> <ul> <li>Path to page URL: You need to specify the path to the page URL. The default location for this is within the   session's context, specifically at context.page.url.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of a JSON configuration for this plugin:</p> <pre><code>{\n  \"url\": \"session@context.page.url\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/url_parser_action/#errors","title":"Errors","text":"<p>This plugin documentation does not include any specific errors or exceptions. However, general errors may occur if the URL path is not correctly specified or if the URL format is not valid for parsing. Ensure that the URL path is correctly provided and that the URL is in a standard, parseable format to avoid these issues.</p>"},{"location":"getting_started/processes/workflow/actions/uuid4/","title":"UUID4","text":"<p>UUID4 is a Tracardi plugin that generates a random UUID.</p>"},{"location":"getting_started/processes/workflow/actions/uuid4/#version","title":"Version","text":"<p>The documentation was created for the 0.6.2 version of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/uuid4/#description","title":"Description","text":"<p>The GetUuid4Action plugin serves one primary purpose - it generates a random UUID that can be used by other modules or stored for later use. The generation of UUID is carried out within the 'run' method, which executes the primary operation of the plugin.</p> <p>The output of this action is in the form of a UUID that is passed through the 'uuid4' port. As an example, the generated UUID might look something like this: '123e4567-e89b-12d3-a456-426655440000'.</p>"},{"location":"getting_started/processes/workflow/actions/uuid4/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin accepts a payload object in its input port. The output port named 'uuid4' returns the generated UUID4.</p> <p>Example of an input payload:</p> <pre><code>{\n  \"example_key\": \"example_value\"\n}\n</code></pre> <p>Example of the output format:</p> <pre><code>{\n  \"uuid4\": \"generated-uuid-string\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/uuid4/#configuration","title":"Configuration","text":"<p>The UUID4 plugin does not require any configuration. </p>"},{"location":"getting_started/processes/workflow/actions/uuid4/#json-configuration","title":"JSON Configuration","text":"<p>As the plugin does not require any configurations, an empty JSON object is used as an example:</p> <pre><code>{}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/uuid4/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/uuid4/#errors","title":"Errors","text":"<p>Since the plugin's sole function is to generate a random UUID and it does not have any set configurations, it does not usually raise exceptions or errors. However, errors might occur due to external issues like system irregularities or memory shortages.</p>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/","title":"Validate with JSON schema plugin","text":"<p>The Validate with JSON schema plugin is used to validate objects using a provided JSON schema.</p>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/#version","title":"Version","text":"<p>This documentation is based on version 0.7.4 of the Validate with JSON schema plugin.</p>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/#description","title":"Description","text":"<p>The Validate with JSON schema plugin allows you to validate objects using a JSON schema. It takes a payload as input and applies the specified JSON schema for validation. If the payload passes the defined validation, it is returned on the \" true\" output port. If the payload fails the validation, it is returned on the \"false\" output port. If there is an error in the validation schema itself, the payload is returned on the \"error\" output port.</p> <p>The plugin uses the <code>EventValidator</code> class from the Tracardi domain to perform the validation. The JSON schema is provided in the plugin's configuration and can be any valid JSON object.</p>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Input: payload (dict)</p> <ul> <li>This port accepts a payload object.</li> </ul> <p>Output: true (dict)</p> <ul> <li>If the payload passes the defined validation, it is returned on this port.</li> </ul> <p>Output: false (dict)</p> <ul> <li>If the payload fails the defined validation, it is returned on this port.</li> </ul> <p>Output: error (dict)</p> <ul> <li>If there is an error in the validation schema itself, the payload is returned on this port.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/#configuration","title":"Configuration","text":"<p>The Validate with JSON schema plugin has the following configuration parameter:</p> <ul> <li>JSON validation schema: Specify a JSON validation schema that you want to validate the data with. Provide a valid   JSON object as the schema.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of the JSON configuration for the Validate with JSON schema plugin:</p> <pre><code>{\n  \"validation_schema\": {\n    \"payload@properties.sale\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"price\": {\n          \"type\": \"number\"\n        },\n        \"name\": {\n          \"type\": \"string\",\n          \"maxLength\": 15\n        }\n      }\n    },\n    \"profile@context.timestamp\": {\n      \"type\": \"integer\"\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/validate_with_json_schema_action/#errors","title":"Errors","text":"<p>The Validate with JSON schema plugin may raise the following exception:</p> <ul> <li>EventValidationException</li> </ul> <p>This exception occurs if the payload does not pass the defined validation or if there is an error in the validation   schema itself.</p>"},{"location":"getting_started/processes/workflow/actions/weather_action/","title":"Weather plugin","text":"<p>This plugin connects to weather server and retrieves weather information.</p>"},{"location":"getting_started/processes/workflow/actions/weather_action/#configuration","title":"Configuration","text":"<p>First you need to configure what type of temperature you need. Either in Celsius (C) of Fahrenheit (F)</p> <p>Example of configuration.</p> <pre><code>{\n  \"system\": \"C\",\n  \"city\": \"profile@traits.city\"\n}\n</code></pre> <p>City can ba a path to data or a plain text.</p> <pre><code>{\n  \"city\": \"Paris\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/weather_action/#input","title":"Input","text":"<p>Input payload is not processed by this plugin.</p>"},{"location":"getting_started/processes/workflow/actions/weather_action/#output","title":"Output","text":"<p>Example</p> <pre><code>{\n  \"temperature\": 4,\n  \"humidity\": 87,\n  \"wind_speed\": 15,\n  \"description\": \"Sunny\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/weekdays_checker_action/","title":"Weekdays checker plugin","text":"<p>This plugin checks if current day is weekend day and set flag true or false depends on result.</p>"},{"location":"getting_started/processes/workflow/actions/weekdays_checker_action/#json-configuration","title":"JSON Configuration","text":"<p>Example output:</p> <pre><code>{\n  \"today\": \"monday\",\n  \"weekend\": false,\n  \"day_number\": 1\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/whois/","title":"Whois Plugin","text":"<p>The Whois plugin is a connector that allows you to check a specified domain using the Whois service. It checks whether a domain exists or not and returns the details related to the domain like registrar, creation date, expiration date, etc.</p>"},{"location":"getting_started/processes/workflow/actions/whois/#version","title":"Version","text":"<p>This documentation was created for the Whois plugin version 0.8.0.</p>"},{"location":"getting_started/processes/workflow/actions/whois/#description","title":"Description","text":"<p>The Whois plugin receives a payload containing the domain to be checked. It communicates with the Whois service to enquire about the domain. The obtained details are then encapsulated into a result, which is then passed onto the next port as per the workflow. In case of any issues while fetching the details, the plugin returns an error message.</p>"},{"location":"getting_started/processes/workflow/actions/whois/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Whois plugin accepts one input:</p> <ul> <li>payload: This port accepts payload object.</li> </ul> <p>The Whois plugin provides two outputs:</p> <ul> <li>result: Returns the response from the Whois service containing detail information about the domain.</li> <li>error: Returns error message if the plugin fails to retrieve the domain information.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/whois/#configuration","title":"Configuration","text":"<p>The configuration for the Whois plugin is as follows:</p> <ul> <li>domain: This field requires the user to provide the domain to be checked in the Whois service.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/whois/#json-configuration","title":"JSON Configuration","text":"<p>Below is an example of the JSON configuration:</p> <pre><code>{\n  \"domain\": \"example.com\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/whois/#required-resources","title":"Required resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/whois/#errors","title":"Errors","text":"<p>If an error occurs during the execution of the plugin, an error message is returned with the following format:</p> <ul> <li>{'message': 'error message'}</li> </ul> <p>The possible error scenarios include:</p> <ul> <li>Failure in retrieving the domain's information from the Whois service.</li> <li>Providing an empty string for the domain input. In this case, the error message will be - \"Domain must not be empty.\"</li> </ul>"},{"location":"getting_started/processes/workflow/actions/write_to_memory_action/","title":"Write to memory plugin","text":"<p>This plugin allows you to write to cross-instance Tracardi user memory, using given key and value path.</p>"},{"location":"getting_started/processes/workflow/actions/write_to_memory_action/#requirements","title":"Requirements","text":"<p>Redis database has to be installed and running in order for this plugin to work.</p>"},{"location":"getting_started/processes/workflow/actions/write_to_memory_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/write_to_memory_action/#outputs","title":"Outputs","text":"<p>This plugin return payload on port success if the value was successfully written to memory, or error detail on port error if one occurred.</p>"},{"location":"getting_started/processes/workflow/actions/write_to_memory_action/#configuration","title":"Configuration","text":"<ul> <li>Key - A name of the variable that will hold saved data.</li> <li>Value - Any string or reference to data inside workflow. This can be an object, or any value. </li> <li>Time to live - The number of seconds, after which the value will be deleted.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/write_to_memory_action/#advanced-configuration","title":"Advanced configuration","text":"<pre><code>{\n  \"key\": \"&lt;key-to-value-in-memory&gt;\",\n  \"value\": \"&lt;path-to-value&gt;\",\n  \"ttl\" : \"&lt;time-to-live-of-the-value&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/","title":"XPATH HTML Scrapper","text":"<p>The XPATH HTML Scrapper plugin is used to extract specific data from HTML content using the XPATH syntax. </p>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/#version","title":"Version","text":"<p>The documented version of this plugin is 0.6.1.</p>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/#description","title":"Description","text":"<p>This plugin is for scrapbooking data from HTML content. It uses XPATH to point to the data you want to scrap. The plugin works by accepting an HTML payload input and then using the XPATH provided in the configuration, it navigates the HTML and extracts the targeted data. The result is returned on the \"result\" port.</p> <p>If the plugin does not find data at the provided XPATH, an error occurs. The error message along with the plugin configuration details are returned on the \"error\" port. </p>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin accepts a payload object on its input port and gives out its results on two output ports:</p> <ul> <li>result: This port returns the scraped data from the HTML content.</li> <li>error: If the plugin is unable to scrape data, it returns the plugin configuration along with the error message. </li> </ul> <p>The plugin cannot start a workflow because it requires an HTML payload input to function. </p>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/#configuration","title":"Configuration","text":"<p>The plugin requires you to configure the following fields:</p> <ul> <li>xpath: The XPATH that points to the data you would like to scrape from the HTML.</li> <li>content: The path to the HTML content.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/#json-configuration","title":"JSON Configuration","text":"<p>Below is an example of how the plugin can be configured:</p> <p><pre><code>{\n    \"xpath\": \"//div[@class='myClass']\",\n    \"content\": \"event@data.html\"\n}\n</code></pre> This configuration tells the plugin to extract the data within a div tag with the class name 'myClass' from the HTML content accessed through the event@data.html path.</p>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/xpath_html_scrapper/#errors","title":"Errors","text":"<p>The plugin could throw an error that states: \"Could not find any data at path ''\". This error may occur when the XPATH provided in the configuration does not match any element in the HTML content. The error message is returned with the plugin configuration details for debugging."},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/","title":"Zapier webhook","text":"<p>This plugin is designed to send messages to a Zapier webhook, which is a way for different apps and services to communicate with Zapier.</p>"},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/#version","title":"Version","text":"<p>0.7.0</p>"},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/#description","title":"Description","text":"<p>When you use this plugin, it performs the action of sending a JSON-formatted message to a specified Zapier webhook URL. Here's a step-by-step breakdown of what the plugin does:</p> <ol> <li>It takes a message, which you need to provide in JSON format.</li> <li>It sends this message to the Zapier webhook URL that you have configured.</li> <li>If the message is successfully received by Zapier, the plugin will consider the action successful and provide you    with a response indicating that success.</li> <li>In case something goes wrong, like a timeout or connectivity issue, it will give you an error message.</li> </ol> <p>An example of what you might receive if everything works as expected:</p> <pre><code>{\n  \"status\": 200,\n  \"json\": {\n    \"some-key\": \"some-value\",\n    \"...\": \"...\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin takes in a payload, which is the JSON message you want to send to Zapier. The payload should be formatted as a JSON object.</p> <p>The plugin can output through two ports:</p> <ul> <li>response: If the message is sent successfully, the output will be a JSON object that contains the status of the   request and the JSON response from Zapier.</li> <li>error: If there is an error in sending the message, like a connection issue or a timeout, the output will be an   error message.</li> </ul> <p>This plugin does not start the workflow. It is an action to be taken at some point after the workflow has started.</p>"},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/#configuration","title":"Configuration","text":"<ul> <li>URL: The webhook URL provided by Zapier where the message will be sent.</li> <li>Timeout: A time limit in seconds for the webhook call. If the call takes longer, the plugin will time out.</li> <li>Body: The JSON-formatted message you want to send to Zapier. This needs to be valid JSON.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/#json-configuration","title":"JSON Configuration","text":"<p>Here's an example configuration for this plugin:</p> <pre><code>{\n  \"url\": \"https://hooks.zapier.com/hooks/catch/10523213728/b4basesz/\",\n  \"timeout\": 30,\n  \"body\": \"{\\\"message\\\":\\\"Hello, Zapier!\\\"}\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/zapier_webhook_action/#errors","title":"Errors","text":"<ul> <li>Connection to Zapier webhook failed: This error occurs if the plugin cannot connect to the specified Zapier   webhook URL. It could be due to network issues, a wrong URL, or Zapier service downtime.</li> <li>Zapier webhook timed out: This message appears if the plugin does not receive a response from the Zapier webhook   within the specified timeout period.</li> <li>: If the body of the message is not correctly formatted as JSON, you will   receive an error with the message detailing what went wrong while decoding the JSON."},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/","title":"Zendesk widget","text":"<p>The Zendesk widget plugin is designed to add a Zendesk chat interface to webpages, enhancing customer interaction and support.</p>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#version","title":"Version","text":"<p>0.7.3</p>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#description","title":"Description","text":"<p>This plugin integrates the Zendesk chat widget into webpages. The widget facilitates customer support and engagement directly from the website. It requires a specific Zendesk script URL to function. Once configured, the plugin appends a script tag to the webpage, which activates the Zendesk widget. This addition can significantly enhance the user experience by providing a direct and convenient communication channel with support or sales teams.</p>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin takes a payload object. This payload serves as a container for data within the workflow but is   not directly modified by this plugin.</li> <li>Outputs:<ul> <li>response: Outputs the original payload after processing. The main function of this plugin is to append the   Zendesk widget to the webpage.</li> <li>error: Outputs in case of any execution error.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#configuration","title":"Configuration","text":"<ul> <li>Script URL: The URL of the Zendesk script. This URL is provided when you set up an account with Zendesk. Refer to   Zendesk's documentation for more details.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"script_url\": \"https://static.zdassets.com/ekr/snippet.js?key={your-key}\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#event-prerequisites","title":"Event prerequisites","text":"<p>Plugins like the Zendesk widget, which fall under the \"UIX Widgets\" category, require a synchronous event. It will not work if sent event is asynchronous.</p>"},{"location":"getting_started/processes/workflow/actions/zendesk_widget_action/#errors","title":"Errors","text":"<ul> <li>\"Script URL can not be empty.\": This error occurs when the script URL for the Zendesk widget is not provided in the   plugin configuration. The script URL is essential for the widget's operation.</li> <li>General script-related errors might occur, typically related to the execution of the appended JavaScript in the   webpage environment. These could be due to conflicts with other scripts or issues in the webpage's structure.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/background/","title":"Run In Background","text":"<p>The Run In Background plugin allows you to run a whole workflow branch as a background task. It is designed to be used as a starting node in the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/background/#description","title":"Description","text":"<p>The Run In Background plugin causes the entire workflow branch to be executed as a background task. It schedules the task to run in the background and continues the workflow execution without waiting for the task to complete. This plugin is part of the Tracardi Pro License.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/background/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload (dict): This port accepts a payload object.</li> </ul> <p>This plugin has two outputs:</p> <ul> <li>output: This port is triggered when the background task is scheduled successfully. It returns an empty value.</li> <li>error: This port is triggered when an error occurs during the scheduling of the background task. It returns an   error message along with the payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/background/#configuration","title":"Configuration","text":"<p>The configuration of the Run In Background plugin includes the following parameters:</p> <ul> <li>Event type: If you want the background task to be registered as a separate event type, you can specify the event   type in this field. Leave it empty if you don't want to generate a separate event.</li> <li>Event properties: If you want the resumed workflow to receive different properties than the original event   properties, you can specify them in this field. Leave it empty to resume the workflow with the original event   properties.</li> <li>Collect debugging information: Enable this option if you want to collect debugging information during the   background task execution. This option collects additional data for debugging purposes. Disable it if you no longer   need to test your workflow to save data and compute power.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/background/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/background/#errors","title":"Errors","text":"<p>The Run In Background plugin may encounter the following error:</p> <ul> <li>Error: This error occurs when an exception is raised during the scheduling of the background task. The error   message provides more information about the specific error that occurred.</li> </ul> <p>Note: The error message will be returned in the error output port along with the payload.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/chat_gpt_prompt/","title":"ChatGPT prompt","text":"<p>The ChatGPT prompt plugin sends a request to ChatGPT and returns the response.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/chat_gpt_prompt/#description","title":"Description","text":"<p>The ChatGPT prompt plugin utilizes the OpenAI GPT-3 model to generate text based on a given prompt. It sends a request to the ChatGPT API, providing a prompt as input, and retrieves the generated response. The prompt can include references to data from the payload using the <code>{{ }}</code> placeholder syntax. The generated response is returned as the output of the plugin.</p> <p>This documentation is for version 0.8.1 of the ChatGPT prompt plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/chat_gpt_prompt/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul> <p>This plugin has two outputs:</p> <ul> <li>result: Returns the generated response from ChatGPT if the request is successful. The response is provided as a   dictionary with two fields:<ul> <li>\"answer\": Contains the generated text.</li> <li>\"response\": Contains the raw response from the ChatGPT API.</li> </ul> </li> <li>error: Returns an error message if an error occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/chat_gpt_prompt/#configuration","title":"Configuration","text":"<p>The ChatGPT prompt plugin has the following configuration parameters:</p> <ul> <li>ChatGPT Resource: Select the ChatGPT resource from the available options. This resource represents the API key   required to access the ChatGPT API.</li> <li>ChatGPT Prompt: Enter the prompt to be used for generating the response. The prompt can include references to data   from the payload using the <code>{{ }}</code> placeholder syntax.</li> <li>Select engine type: Select the engine type to be used for generating the response. Available options are:<ul> <li>Davinci</li> <li>Curie</li> <li>Babbage</li> <li>Ada</li> </ul> </li> <li>Temperature: Set the sampling temperature to control the randomness of the generated text. Higher values (e.g.,   0.8) make the output more random, while lower values (e.g., 0.2) make it more focused and deterministic.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/chat_gpt_prompt/#required-resources","title":"Required resources","text":"<p>This plugin requires the configuration of a ChatGPT resource. The ChatGPT resource represents the API key required to access the ChatGPT API.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/chat_gpt_prompt/#errors","title":"Errors","text":"<p>The ChatGPT prompt plugin may encounter the following error:</p> <ul> <li>Error: This error occurs when an exception is raised during the execution of the plugin. The error message   provides more information about the specific error that occurred.</li> </ul> <p>Note: The error message will be returned in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/","title":"Event Aggregator","text":"<p>This plugin collects and tallies up the occurrences of a specific category of information during a certain period of time for the current profile.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#description","title":"Description","text":"<p>The Event Aggregator plugin counts how many times something happens for the current profile over a defined amount of time. It aggregates events based on a specified field and returns the aggregation result.</p> <p>This documentation is for version 0.8.1 of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#inputs","title":"Inputs","text":"<ul> <li><code>payload</code>: This port accepts a payload object.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#outputs","title":"Outputs","text":"<ul> <li><code>payload</code>: Returns the aggregation result.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#configuration","title":"Configuration","text":"<p>The Event Aggregator plugin requires the following configuration:</p> <ul> <li> <p>Aggregate by field: Select the field you would like to aggregate. This field determines the category of   information for which the occurrences will be counted. The available options are retrieved from   the <code>/storage/mapping/event/metadata</code> endpoint.</p> </li> <li> <p>Time span: Specify the time span over which the occurrences will be counted. Enter the time span in a format   like <code>-15minutes</code>. This field determines the period of time during which the events will be aggregated.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example JSON configuration for the Event Aggregator plugin:</p> <pre><code>{\n  \"field\": {\n    \"name\": \"example_field\",\n    \"id\": \"example_field_id\"\n  },\n  \"time_span\": \"-15m\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/event_aggregator/#errors","title":"Errors","text":"<ul> <li> <p>Profile ID not found: The profile ID is not found or is not correctly configured. This error may occur if the   profile ID is set to <code>@debug-profile-id</code>. Make sure to load the correct profile to ensure that the plugin can find the   necessary data.</p> </li> <li> <p>Event field not specified: The aggregate by field is not specified in the configuration. This error may occur if   the \"Aggregate by field\" configuration field is left empty. Please select a field to aggregate.</p> </li> <li> <p>Invalid time span format: The specified time span format is invalid. This error may occur if the \"Time span\"   configuration field is not formatted correctly. Make sure to enter the time span in a valid format, such   as <code>-15minutes</code>.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/event_counter/","title":"Event Counter","text":"<p>The Event Counter plugin reads how many events of a defined type were triggered within a specified time frame.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/event_counter/#description","title":"Description","text":"<p>The Event Counter plugin is designed to count the number of events of a specific type that occurred within a defined time span. This plugin can be useful for tracking and monitoring event activity and analyzing event patterns.</p> <p>When the plugin is executed, it retrieves the specified event type and time span from the plugin's configuration. It then queries the event database to count the number of events of the specified type that occurred within the specified time span. The plugin returns the count of events as the output.</p> <p>This documentation is for version 0.8.1 of the Event Counter plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/event_counter/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Event Counter plugin has one input:</p> <ul> <li><code>payload</code> (object): This port accepts a payload object.</li> </ul> <p>The Event Counter plugin has one output:</p> <ul> <li><code>payload</code> (object): Returns the number of events of the specified type within the defined time span.</li> </ul> <p>Example:</p> <p>Input:</p> <pre><code>{\n  \"payload\": {}\n}\n</code></pre> <p>Output:</p> <pre><code>{\n  \"payload\": {\n    \"events\": 42\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/event_counter/#configuration","title":"Configuration","text":"<p>The Event Counter plugin requires the following configuration:</p> <ul> <li><code>Event type</code>: Select the event type you would like to count.</li> <li><code>Time span</code>: Enter the time span in a format like \"-15minutes\" to define the period for counting the events.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/event_counter/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of a JSON configuration for the Event Counter plugin:</p> <pre><code>{\n  \"event_type\": {\n    \"name\": \"example_event\",\n    \"id\": \"example_event_id\"\n  },\n  \"time_span\": \"-15m\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/event_counter/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/event_counter/#errors","title":"Errors","text":"<p>The Event Counter plugin may raise the following exceptions:</p> <ul> <li><code>ValueError: profile event sequencing cannot be performed without a profile. Is this a profile-less event?</code>: This   error occurs when the plugin attempts to perform profile event sequencing without a profile. Make sure the event   contains a profile.</li> <li><code>Some other exception</code>: This error occurs when some other exception is raised during the execution of the plugin.</li> </ul> <p>Note: The specific conditions that may trigger these errors depend on the context and usage of the plugin within the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/","title":"Generic UIX Plugin","text":"<p>The Generic UIX Plugin is a Tracardi plugin that allows you to display a custom JavaScript widget in your workflow. It is designed to integrate external JavaScript code into Tracardi and extend its functionality.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/#version","title":"Version","text":"<p>This documentation is based on version 0.8.1 of the Generic UIX Plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/#description","title":"Description","text":"<p>The Generic UIX Plugin enables you to embed custom JavaScript widgets within your Tracardi workflow. It takes the payload as input, processes it, and displays the custom widget based on the provided configuration. The plugin adds a <code>&lt;div&gt;</code> element with the specified properties to the user interface and injects the JavaScript code by appending a <code>&lt;script&gt;</code> element with the source URL.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The Generic UIX Plugin has the following input and output:</p> <p>Input: payload (dict)</p> <ul> <li>This port accepts a payload object.</li> </ul> <p>Output: payload (dict)</p> <ul> <li>The plugin returns the same payload object.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/#configuration","title":"Configuration","text":"<p>The Generic UIX Plugin has the following configuration parameters:</p> <ul> <li> <p>JavaScript source: Specify the URL of the JavaScript source code for the custom widget. This URL should point to   the location where the JavaScript file is hosted.</p> </li> <li> <p>Widget props: Specify properties as key-value pairs for the widget. You can reference the values using dot   notation, which allows you to access data from the internal state of the workflow.</p> </li> </ul> <pre><code>{\n  \"uix_source\": \"&lt;url-of-uix-source-code&gt;\",\n  \"props\": {\n    \"&lt;props_mapping&gt;\": \"...\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of the JSON configuration for the Generic UIX Plugin:</p> <pre><code>{\n  \"uix_source\": \"https://example.com/custom-widget.js\",\n  \"props\": {\n    \"color\": \"red\",\n    \"size\": 12,\n    \"text\": \"@payload.path.to.data\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/generic_js_ux/#errors","title":"Errors","text":"<p>This plugin does not raise any exceptions or errors.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/","title":"Limiter","text":"<p>This node throttles the workflow execution.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#description","title":"Description","text":"<p>The Limiter plugin is used to control the rate at which the workflow executes. It allows you to set limits on the number of allowed executions within a defined time range. If the execution exceeds the specified limit, the plugin can either allow the execution to pass through or block it based on the configured parameters.</p> <p>This documentation is based on version 0.7.3 of the Limiter plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#inputs","title":"Inputs","text":"<p>The Limiter plugin accepts the following input:</p> <ul> <li>payload: This port takes a payload object as input.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#outputs","title":"Outputs","text":"<p>The Limiter plugin provides the following outputs:</p> <ul> <li>pass: Returns the input payload if the execution is not throttled.</li> <li>block: Returns the input payload if the execution is throttled.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#configuration","title":"Configuration","text":"<p>The Limiter plugin supports the following configuration parameters:</p> <ul> <li>Number of allowed executions: Specify the number of allowed passes through this plugin within the defined time.</li> <li>Time range (Time to live): Specify the time period (in seconds) that must pass for the limit to be reset to 0.</li> <li>Throttle key identifier: Select the throttle identifiers. This defines the resource that is protected by this limiter.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example JSON configuration for the Limiter plugin:</p> <pre><code>{\n    \"keys\": [\"profile\"],\n    \"limit\": 1,\n    \"ttl\": 60\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/limiter/#errors","title":"Errors","text":"<p>The Limiter plugin does not throw any specific errors.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/load_report/","title":"Load report data","text":"<p>The Load report data plugin is used to load the results of a specified report into the payload. It allows you to select a report and provide the necessary configuration to retrieve the report data. This plugin is part of the Tracardi Pro License.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/load_report/#description","title":"Description","text":"<p>The Load report data plugin loads the results of a selected report and adds them to the payload. It uses the Tracardi Reports to retrieve the report data based on the provided configuration.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/load_report/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload (dict): This port accepts a payload object.</li> </ul> <p>This plugin has two outputs:</p> <ul> <li>result: Returns the results of the selected report if the report data retrieval is successful.</li> <li>error: Returns an error message if an exception occurs during the report data retrieval.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/load_report/#configuration","title":"Configuration","text":"<p>The configuration of the Load report data plugin includes the following parameters:</p> <ul> <li>Report configuration: Select the report and provide the necessary configuration. You can use dot paths as values   to specify the report parameters.</li> </ul> <p>Here is an example configuration:</p> <ul> <li>Report configuration:<ul> <li>Report:<ul> <li>ID: \"report_id\"</li> <li>Name: \"report_name\"</li> </ul> </li> <li>Params: \"{}\"</li> </ul> </li> </ul> <p>Note: The report configuration includes the report ID, report name, and the parameters required to retrieve the report data.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/load_report/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/load_report/#errors","title":"Errors","text":"<p>The Load report data plugin may encounter the following error:</p> <ul> <li>Error detail: This error occurs when an exception is raised during the report data retrieval. The error detail   provides more information about the specific error that occurred.</li> </ul> <p>Note: The error message will be returned in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/open_replay_ux/","title":"OpenReplay UX","text":"<p>The OpenReplay UX plugin injects the OpenReplay tracing script into a webpage. The tracing script allows you to capture and analyze user interactions and behaviors on your website. By integrating OpenReplay, you can gain valuable insights into how users navigate your site, identify potential issues, and optimize user experiences.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/open_replay_ux/#description","title":"Description","text":"<p>The OpenReplay UX plugin is designed to inject the OpenReplay tracing script into a webpage. This script is responsible for capturing and recording user interactions and behaviors on the website. The plugin appends the OpenReplay tracing script to the HTML of the webpage, enabling the collection of data related to user sessions.</p> <p>When the plugin is executed, it injects the tracing script into the webpage using the provided OpenReplay project key. The project key is a unique identifier for your OpenReplay project. By configuring the plugin with your project key, the tracing script will send the captured data to your OpenReplay account for analysis.</p> <p>Example output from the plugin:</p> <pre><code>{\n  \"port\": \"response\",\n  \"value\": {\n    // some data\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/open_replay_ux/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The OpenReplay UX plugin has a single input and output port:</p> <ul> <li>Input: <code>payload</code> - This port accepts a payload object.</li> <li>Output: <code>response</code> - This port returns the input payload without any changes.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/open_replay_ux/#configuration","title":"Configuration","text":"<p>The OpenReplay UX plugin requires the following configuration:</p> <ul> <li><code>Your Open Replay token</code>: This configuration field expects your OpenReplay project key. To obtain the project key, log in to openreplay.com, navigate to \"Settings\" &gt; \"Projects,\" and locate the Project Key associated with your project.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/open_replay_ux/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example JSON configuration for the OpenReplay UX plugin:</p> <pre><code>{\n  \"token\": \"your_open_replay_token\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/commercial/open_replay_ux/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/open_replay_ux/#errors","title":"Errors","text":"<p>The following error may occur while using the OpenReplay UX plugin:</p> <ul> <li>Project key can not be empty.: This error occurs when the provided project key is empty. The project key is a required configuration parameter, and it cannot be left empty.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/pause_and_resume/","title":"Pause and Resume","text":"<p>The \"Pause and Resume\" plugin in Tracardi allows you to pause the workflow for a specified duration and then resume it at the same node. This plugin is useful for introducing delays or scheduling events within a workflow.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/pause_and_resume/#description","title":"Description","text":"<p>The \"Pause and Resume\" plugin is a time-based plugin that waits for a specified number of seconds and then resumes the workflow. During the pause, no actions or transitions occur in the workflow. Once the pause is complete, the workflow continues from the same node where it was paused.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/pause_and_resume/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li> <p>Input: This plugin accepts any payload as input.</p> </li> <li> <p>Output Ports:</p> </li> <li>output: This port is triggered when the pause is complete, indicating that the workflow can resume.</li> <li>error: This port is triggered if an error occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/pause_and_resume/#configuration","title":"Configuration","text":"<p>The \"Pause and Resume\" plugin has the following configuration options:</p> <ul> <li> <p>Wait in seconds: This parameter specifies the duration of the pause in seconds. The plugin will wait for the specified number of seconds before resuming the workflow.</p> </li> <li> <p>Event type: If you want the resumed workflow to be registered as a separate event type, you can specify the event type in this field. Otherwise, leave it empty, and no event will be generated when the workflow resumes.</p> </li> <li> <p>Event properties: If you want the resumed workflow to have different properties than the original event, you can specify them here. Otherwise, leave it empty, and the workflow will resume with the original event properties.</p> </li> <li> <p>Collect debugging information: Enable this option if you want to collect debugging information during the execution of the workflow. Debugging information includes additional data for testing and troubleshooting purposes.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/pause_and_resume/#example-usage","title":"Example Usage","text":"<p>Here's an example of how the \"Pause and Resume\" plugin can be used:</p> <pre><code>- pause_and_resume:\n    wait: 60\n    event_type:\n        id: \"custom-event\"\n        name: \"Custom Event Type\"\n    properties: '{\"custom_property\": \"value\"}'\n    debug: true\n</code></pre> <p>In this example, the plugin is configured to pause the workflow for 60 seconds. After the pause, the workflow will resume from the same node. The resumed workflow will generate a custom event of type \"Custom Event Type\" with the specified custom properties. Debugging information will also be collected during the execution of the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequence_matcher/","title":"Sequencer Matcher","text":"<p>The Sequencer Matcher plugin is used to look for a sequence of events in a given list of events. It allows you to define a sequence of events and check if that sequence occurs in the list of events. This plugin is part of the Tracardi Pro License.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequence_matcher/#description","title":"Description","text":"<p>The Sequencer Matcher plugin searches for a sequence of events in a delivered list of events. It compares the defined sequence of events with the events in the list and determines whether the sequence occurs. The plugin provides options to control the matching behavior, such as strict ordering and disallowing intermediate events.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequence_matcher/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload (dict): This port accepts a payload object.</li> </ul> <p>This plugin has three outputs:</p> <ul> <li>true: Returns the defined sequence of events if the sequence is found in the list of events.</li> <li>false: Returns the defined sequence of events if the sequence is not found in the list of events.</li> <li>error: Returns an error message if an exception occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/sequence_matcher/#configuration","title":"Configuration","text":"<p>The configuration of the Sequencer Matcher plugin includes the following parameters:</p> <ul> <li>Sequence: Type the sequence of events to look for.</li> <li>List of events: Type the reference to the list of events. This is usually the output of the \"Event sequence\" action, which returns the list of events at <code>payload@sequence</code>.</li> <li>Disallow intermediate events: If enabled, the defined sequence must occur in the precise order without any intermediate events. For example, if the sequence is [event1, event3], it will match [event1, event3], but not [event1, event2, event3]. If intermediate events are allowed, [event1, event2, event3] will be considered a valid match for [event1, event3].</li> </ul> <p>Here is an example configuration:</p> <ul> <li>Sequence: [event1, event2, event3]</li> <li>List of events: <code>payload@sequence</code></li> <li>Disallow intermediate events: Yes</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/sequence_matcher/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequence_matcher/#errors","title":"Errors","text":"<p>The Sequencer Matcher plugin may encounter the following error:</p> <ul> <li>Exception message: This error occurs when an exception is raised during the execution of the plugin. The error message provides details about the specific exception that occurred.</li> </ul> <p>Note: The payload will be returned along with the error message in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequencer/","title":"Event Sequence","text":"<p>The Sequencer Query plugin is used to retrieve an events sequence from the database based on a defined time range and context. It allows you to filter events using a query and set up the context for sequence matching. This plugin is part of the Tracardi Pro License.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequencer/#description","title":"Description","text":"<p>The Sequencer Query plugin selectively loads events into the payload for a specified time period. It searches for events that match the defined query and retrieves the sequence of event types. The plugin supports filtering events based on time range, session, and other criteria. The retrieved sequence can be used for further processing in the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequencer/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload (dict): This port accepts a payload object.</li> </ul> <p>This plugin has two outputs:</p> <ul> <li>result: Returns the sequence of event types if the query is successful.</li> <li>error: Returns an error message if an exception occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/sequencer/#configuration","title":"Configuration","text":"<p>The configuration of the Sequencer Query plugin includes the following parameters:</p> <ul> <li>Filter events: Query to filter the events and set up the context for sequence matching. You can reference data by   using <code>{{ }}</code> placeholder. For example, <code>{{event@properties.product_id}}</code>.</li> <li>Events must occur in current session: If enabled, events must be in the current event session. This means that the   customer traveled the sequence during the current visit.</li> <li>Maximal time span to look for the sequence: Defines the maximum time span to look for the sequence. The value is   rounded down to UTC 00:00. For example, a time period of 1 day is not 24 hours but one day.</li> <li>Time unit for the time span: A unit of measurement for the time span, such as seconds, minutes, hours, or days.</li> </ul> <p>Here is an example configuration:</p> <ul> <li>Query: <code>properties.product_id: {{event@properties.product_id}}</code></li> <li>Events must occur in current session: No</li> <li>Maximal time span to look for the sequence: 7</li> <li>Time unit for the time span: Days</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/sequencer/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/sequencer/#errors","title":"Errors","text":"<p>The Sequencer Query plugin may encounter the following errors:</p> <ul> <li>ValueError: Profile event sequencing can not be performed without profile. Is this a profile less event?: This   error occurs when the plugin is unable to perform profile event sequencing because there is no profile associated with   the event. Make sure the event has a valid profile.</li> <li>ValueError: Can not find events in the context of the session when there is no session in the event. Is this a   profile less or events less event?: This error occurs when the plugin is unable to find events in the context of the   session because there is no session associated with the event. Ensure that the event has a valid session when using   the \"Events must occur in the current session\" option.</li> </ul> <p>Note: The payload will be returned along with the error message in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/twillio_sms/","title":"Send SMS","text":"<p>The \"Send SMS\" plugin in Tracardi enables you to send SMS messages using the Twilio gateway. With this plugin, you can integrate SMS messaging functionality into your Tracardi workflows.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/twillio_sms/#description","title":"Description","text":"<p>The \"Send SMS\" plugin allows you to send SMS messages to a specified phone number using the Twilio gateway. You can customize the sender's phone number, the recipient's phone number, and the message content. The plugin uses the Twilio API to send the SMS messages.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/twillio_sms/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li> <p>Input: This plugin accepts any payload as input.</p> </li> <li> <p>Output Ports:</p> <ul> <li>result: This port returns the result of the SMS sending operation, including details such as the status of the   message, price, direction, and more.</li> <li>error: This port is triggered if an error occurs during the execution of the plugin.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/twillio_sms/#configuration","title":"Configuration","text":"<p>The \"Send SMS\" plugin has the following configuration options:</p> <ul> <li> <p>Twilio Resource: Select the Twilio resource to use for sending SMS messages. You can choose an existing Twilio   resource from the available options.</p> </li> <li> <p>From phone number: Specify the phone number from which you want to send the SMS. You can use dot notation to   reference the phone number from the payload.</p> </li> <li> <p>To phone number: Specify the phone number to which you want to send the SMS. You can use dot notation to reference   the phone number from the payload.</p> </li> <li> <p>SMS Message: Enter the content of the SMS message that you want to send. You can include placeholders in the   message using double curly braces ({{ }}) and referencing data from the payload. For example, you can reference the   product ID using <code>{{event@properties.product_id}}</code>.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/twillio_sms/#example-usage","title":"Example Usage","text":"<p>Here's an example of how the \"Send SMS\" plugin can be used:</p> <pre><code>- send_sms:\n    resource:\n      name: \"My Twilio Resource\"\n      id: \"12345678\"\n    from_number: \"event@properties.sender_number\"\n    to_number: \"event@properties.recipient_number\"\n    message: \"Your order {{event@properties.order_id}} has been shipped. Thank you!\"\n</code></pre> <p>In this example, the plugin is configured to send an SMS using the Twilio resource with the name \"My Twilio Resource\" and ID \"12345678\". The sender's phone number is retrieved from the payload using the dot notation <code>event@properties.sender_number</code>. The recipient's phone number is also retrieved from the payload using <code>event@properties.recipient_number</code>. The message content includes the order ID from the payload using <code>{{event@properties.order_id}}</code>.</p> <p>Please note that the above example assumes that the necessary data is available in the payload. Make sure to adjust the dot notation and payload structure according to your specific use case.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_delete/","title":"Delete vector","text":"<p>Deletes a vector with a defined ID in the Weaviate schema.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_delete/#description","title":"Description","text":"<p>The Delete vector plugin is used to delete a vector with a specified ID from the Weaviate schema. It connects to the Weaviate instance and deletes the vector associated with the given ID. This plugin is useful for removing vectors that are no longer needed or updating existing vectors in the Weaviate schema.</p> <p>This documentation is for version 0.8.1 of the Delete vector plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_delete/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul> <p>This plugin has two outputs:</p> <ul> <li>result: Returns the response from Weaviate if the vector deletion is successful. The response contains the data   UUID of the deleted vector.</li> <li>error: Returns an error message if an error occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_delete/#configuration","title":"Configuration","text":"<p>The Delete vector plugin has the following configuration parameters:</p> <ul> <li>Weaviate Resource: Select the Weaviate resource from the available options. This resource represents the Weaviate   vector store.</li> <li>Schema class: Select the schema class from which the vector will be deleted. This class represents the type of   data associated with the vector.</li> <li>Object ID: Type or reference the ID of the object for which the vector should be deleted. The object ID is   required when deleting data from the schema.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_delete/#required-resources","title":"Required resources","text":"<p>This plugin requires the configuration of a Weaviate resource. The Weaviate resource represents the connection information and credentials required to access the Weaviate instance.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_delete/#errors","title":"Errors","text":"<p>The Delete vector plugin may encounter the following error:</p> <ul> <li>Error: This error occurs when an exception is raised during the execution of the plugin. The error message   provides more information about the specific error that occurred.</li> </ul> <p>Note: The error message will be returned in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_exists/","title":"Vector exists","text":"<p>Checks if a vector with a defined ID exists in the Weaviate schema.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_exists/#description","title":"Description","text":"<p>The Vector exists plugin is used to check if a vector with a specified ID exists in the Weaviate schema. It connects to the Weaviate instance and verifies the presence of the vector associated with the given ID. This plugin is useful for conditional branching in workflows based on the existence of vectors in the Weaviate schema.</p> <p>This documentation is for version 0.8.1 of the Vector exists plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_exists/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul> <p>This plugin has three outputs:</p> <ul> <li>true: Returns the payload if the vector with the defined ID exists in the Weaviate schema.</li> <li>false: Returns the payload if the vector with the defined ID does not exist in the Weaviate schema.</li> <li>error: Returns an error message if an error occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_exists/#configuration","title":"Configuration","text":"<p>The Vector exists plugin has the following configuration parameters:</p> <ul> <li>Weaviate Resource: Select the Weaviate resource from the available options. This resource represents the Weaviate   vector store.</li> <li>Schema class: Select the schema class to check for the existence of the vector. This class represents the type of   data associated with the vector.</li> <li>Object ID: Type or reference the ID of the object for which the vector existence should be checked. The object ID   is required when checking the existence of data in the schema.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_exists/#required-resources","title":"Required resources","text":"<p>This plugin requires the configuration of a Weaviate resource. The Weaviate resource represents the connection information and credentials required to access the Weaviate instance.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_exists/#errors","title":"Errors","text":"<p>The Vector exists plugin may encounter the following error:</p> <ul> <li>Error: This error occurs when an exception is raised during the execution of the plugin. The error message   provides more information about the specific error that occurred.</li> </ul> <p>Note: The error message will be returned in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_load/","title":"Load vector","text":"<p>Loads a vector by ID from Weaviate.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_load/#description","title":"Description","text":"<p>The Load vector plugin is used to retrieve a vector from the Weaviate schema based on the specified ID. It connects to the Weaviate instance and fetches the vector associated with the given ID. This plugin is useful for retrieving vectors from the Weaviate schema for further processing in Tracardi workflows.</p> <p>This documentation is for version 0.8.1 of the Load vector plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_load/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul> <p>This plugin has two outputs:</p> <ul> <li>result: Returns the loaded vector from Weaviate as a response object.</li> <li>error: Returns an error message if an error occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_load/#configuration","title":"Configuration","text":"<p>The Load vector plugin has the following configuration parameters:</p> <ul> <li>Weaviate Resource: Select the Weaviate resource from the available options. This resource represents the Weaviate   vector store.</li> <li>Schema class: Select the schema class from which to load the vector. This class represents the type of data   associated with the vector.</li> <li>Object ID: Type or reference the ID of the object for which the vector should be loaded. The object ID is required   to fetch the associated vector from Weaviate.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_load/#required-resources","title":"Required resources","text":"<p>This plugin requires the configuration of a Weaviate resource. The Weaviate resource represents the connection information and credentials required to access the Weaviate instance.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_load/#errors","title":"Errors","text":"<p>The Load vector plugin may encounter the following error:</p> <ul> <li>Error: This error occurs when an exception is raised during the execution of the plugin. The error message   provides more information about the specific error that occurred.</li> </ul> <p>Note: The error message will be returned in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_store/","title":"Store vector","text":"<p>Stores a vector in Weaviate. This plugin can create or update a vector in the Weaviate Vector Store.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_store/#description","title":"Description","text":"<p>The Store vector plugin is used to store a vector in the Weaviate schema. It connects to the Weaviate instance and performs the specified operation (insert or update) on the vector based on the provided configuration. The plugin accepts a payload object as input and stores the vector in the specified schema class.</p> <p>This documentation is for version 0.8.1 of the Store vector plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_store/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul> <p>This plugin has two outputs:</p> <ul> <li>result: Returns the response from Weaviate after storing the vector.</li> <li>error: Returns an error message if an error occurs during the execution of the plugin.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_store/#configuration","title":"Configuration","text":"<p>The Store vector plugin has the following configuration parameters:</p> <ul> <li>Weaviate Resource: Select the Weaviate resource from the available options. This resource represents the Weaviate   vector store.</li> <li>Schema class: Select the schema class in which to store the vector. This class represents the type of data   associated with the vector.</li> <li>Operation: Select the type of operation to perform on the vector. The available options are \"Insert\" and \"Update\".</li> <li>Object ID: Type or reference the ID of the object for which the vector should be stored. The object ID is required   for update operations.</li> <li>Data object: Provide the vector data as a JSON object. This object represents the vector to be stored in Weaviate.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_store/#required-resources","title":"Required resources","text":"<p>This plugin requires the configuration of a Weaviate resource. The Weaviate resource represents the connection information and credentials required to access the Weaviate instance.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/weaviate_store/#errors","title":"Errors","text":"<p>The Store vector plugin may encounter the following error:</p> <ul> <li>Error: This error occurs when an exception is raised during the execution of the plugin. The error message   provides more information about the specific error that occurred.</li> </ul> <p>Note: The error message will be returned in the error output port.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/youtube_player/","title":"YouTube widget","text":"<p>Shows a YouTube video widget.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/youtube_player/#description","title":"Description","text":"<p>The YouTube widget plugin allows you to embed a YouTube video widget in Tracardi. This plugin displays a YouTube video based on the provided configuration. You can customize the display type, position, and other settings to suit your needs.</p> <p>This documentation is for version 0.8.1 of the YouTube widget plugin.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/youtube_player/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>This plugin has one input:</p> <ul> <li>payload: This port accepts a payload object.</li> </ul> <p>This plugin has one output:</p> <ul> <li>payload: This port returns the given payload without any changes.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/youtube_player/#configuration","title":"Configuration","text":"<p>The YouTube widget plugin has the following configuration parameters:</p> <ul> <li>YouTube ID: Please provide the YouTube ID of the video you want to display.</li> <li>Video Title: Please provide the title of the video.</li> <li>Popup lifetime: Please provide the number of seconds for the popup to be displayed.</li> <li>Display type: Please select how you would like the video to be displayed. The available options are \"Pop-up box\"   and \"Modal window\".</li> <li>Horizontal position: Select the horizontal position of the popup. The available options are \"Left\", \"Center\",   and \"Right\".</li> <li>Vertical position: Select the vertical position of the popup. The available options are \"Top\" and \"Bottom\".</li> </ul>"},{"location":"getting_started/processes/workflow/actions/commercial/youtube_player/#required-resources","title":"Required resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/commercial/youtube_player/#errors","title":"Errors","text":"<p>The YouTube widget plugin does not raise any specific errors. However, if there are any issues with loading or displaying the YouTube video, they will be handled by the YouTube widget itself.</p> <p>Note: The YouTube widget may display an error message if the provided YouTube ID is invalid or if there are any issues with the YouTube API.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/","title":"Circular Geo Fence","text":"<p>The Circular Geo Fence plugin for Tracardi is a location-based automation tool that enables geofencing capabilities, allowing you to trigger actions based on geographic location.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#version","title":"Version","text":"<p>This documentation is created for version 0.6.1 of the Circular Geo Fence plugin.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#description","title":"Description","text":"<p>The Circular Geo Fence plugin is designed to determine whether a set of test geo-location coordinates falls within a defined radius threshold from a center point's coordinates. This plugin can be used to create geofences for location-based automation and personalized user experiences.</p> <p>The plugin accepts a set of configuration parameters that specify the center coordinates, the test coordinates to be evaluated, and the radius within which the test coordinates should fall to trigger an action. The output is a boolean value, indicating whether the test coordinates are inside the defined radius.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>Inputs:</p> <ul> <li>Geofence coordinates (center and test coordinates)</li> <li>Geofence radius</li> <li>Trigger event (entry or exit)</li> </ul> <p>Outputs:</p> <ul> <li>Returns a boolean value: true if the test coordinates are inside the radius, false if they are outside.</li> </ul> <p>This plugin does not start the workflow; it is typically used as part of a larger automation sequence.</p> <p>Example Input (Payload):</p> <pre><code>{\n  \"center_coordinate\": {\n    \"lat\": 40.7128,\n    \"lng\": -74.0060\n  },\n  \"test_coordinate\": {\n    \"lat\": 40.748817,\n    \"lng\": -73.985428\n  },\n  \"radius\": 10.0\n}\n</code></pre> <p>Example Output:</p> <pre><code>{\n  \"inside\": true\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#configuration","title":"Configuration","text":"<p>The Circular Geo Fence plugin is configured using the following parameters:</p> <ul> <li> <p>Geofence Center Coordinate (Latitude and Longitude): Specifies the central point of the geofence.</p> </li> <li> <p>Geofence Test Coordinate (Latitude and Longitude): Defines the location to be tested against the geofence.</p> </li> <li> <p>Radius: Sets the radius in kilometers within which the test coordinate should fall to trigger an action.</p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"center_coordinate\": {\n    \"lat\": 40.7128,\n    \"lng\": -74.0060\n  },\n  \"test_coordinate\": {\n    \"lat\": 40.748817,\n    \"lng\": -73.985428\n  },\n  \"radius\": 10.0\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#errors","title":"Errors","text":"<p>Possible errors that may occur with this plugin:</p> <ol> <li> <p>Invalid Coordinate Format: If the provided coordinates are not in the correct format (latitude and longitude),    the plugin may raise an error.</p> </li> <li> <p>Radius Out of Range: If the specified radius is outside a valid range (e.g., negative or excessively large), it    may result in an error.</p> </li> <li> <p>Invalid Payload: If the input payload is missing required fields or contains invalid data, it may cause    unexpected errors.</p> </li> <li> <p>Configuration Issues: Incorrect configuration parameters may lead to geofence results that do not align with    expectations.</p> </li> </ol> <p>Please ensure that the input payload and configuration parameters are correctly formatted to avoid errors.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_fence/#output","title":"Output","text":"<p>The plugin returns a result on the output port in the following schema:</p> <pre><code>{\n  \"inside\": true\n}\n</code></pre> <p>The \"inside\" field indicates whether the test coordinates are inside the defined geofence (true) or outside (false).</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/","title":"GeoIp service","text":"<p>This plugin, named 'GeoIp service', is designed to convert an IP address into detailed location information. It leverages MaxMind's GeoLite2 services to identify the geographical location associated with a given IP address.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/#version","title":"Version","text":"<p>0.6.1</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/#description","title":"Description","text":"<p>When the GeoIp service plugin receives an IP address, it communicates with the MaxMind GeoLite2 server to fetch location data corresponding to that IP. This data includes city, country (with name and ISO code), county, postal code, and geographic coordinates (latitude and longitude). If configured, the plugin can also add the fetched location details to the user's profile, updating the last known location of the device. The plugin outputs the location data, and in case of any errors during the process, it provides an error output with details.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs: The plugin takes a payload object, which should contain the IP address.</li> <li>Outputs: There are two output ports:<ul> <li>location: Outputs location details in a structured format.</li> <li>error: Triggered if there is an error during execution, providing details of the payload and error.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/#configuration","title":"Configuration","text":"<ul> <li>Source: Select the Maxmind Geolite2 server resource for connecting to the service.</li> <li>IP Path: Specify the path to the IP data or directly input the IP address.</li> <li>Add to Profile: Choose whether to add the discovered location to the profile's last device location.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/#json-configuration","title":"JSON Configuration","text":"<p>Example configuration:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"5600c92a-835d-4fbe-a11d-7076fd983434\",\n    \"name\": \"MaxMind Geo Locator\"\n  },\n  \"ip\": \"payload@ip\",\n  \"add_to_profile\": false\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/#required-resources","title":"Required resources","text":"<p>This plugin requires the configuration of an external resource: a Maxmind Geolite2 server. The resource should include credentials such as the host, license key, and account ID.</p>"},{"location":"getting_started/processes/workflow/actions/geo/geo_ip_locator/#errors","title":"Errors","text":"<ul> <li>\"An error occurred during location fetching\": This message indicates a failure in retrieving location information from   the GeoLite2 server. It may occur due to network issues, incorrect resource configuration, or invalid IP address   input.</li> <li>\"Failed to update the profile with location data\": This error occurs if there is an issue in adding the fetched   location to the user's profile, possibly due to profile access or update rights.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/","title":"Plugin documentation","text":"<p>This plugin adds new company to HubSpot, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from HubSpot API on port response, or error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/#hubspot-resource","title":"HubSpot resource","text":"<p>To connect Tracardi with HubSpot you need a HubSpot resource. If you do not have HubSpot resource set, go to Resources and create a new resource. More details on how to do it you can find in resource tab. If you did not install Hubspot then go to extensions and install it. It will create both resource and plugins.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/#resource-scope","title":"Resource scope","text":"<p>In order to connect to the HubSpot you need a private app. The information on how to create it is provided during creating the HubSpot resource. If you have resource you most probably have everything set up. There is only one important information regarding using this plugin. The resource that you create must have the following rights.  It was set when you created \"private app\" in hubspot.</p> <pre><code> crm.objects.companies.write, \n crm.objects.companies.read\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/#plugin-configuration","title":"Plugin configuration","text":"<p>Use one of the following forms of configuration. Configuration via FORM or advanced configuration with JSON.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/#with-form","title":"With form","text":"<ul> <li>HubSpot's resource - please select your HubSpot resource.</li> <li>Properties - you can add properties for your contact. Remember to use field aliases from HubSpot.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_company_action/#json-configuration-example","title":"JSON configuration - example","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;resource-id&gt;\",\n    \"name\": \"&lt;resource-name&gt;\"\n  },\n  \"properties\": {\n    \"name\": \"&lt;a-company-name&gt;\",\n    \"description\": \"&lt;a-company-description&gt;\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/","title":"Plugin documentation","text":"<p>This plugin adds new contact to HubSpot, based on provided data.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/#outputs","title":"Outputs","text":"<p>This plugin returns response from HubSpot API on port response, or error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/#hubspot-resource","title":"HubSpot resource","text":"<p>To connect Tracardi with HubSpot you need a HubSpot resource. If you do not have HubSpot resource set, go to Resources and create a new resource. More details on how to do it you can find in resource tab. If you did not install Hubspot then go to extensions and install it. It will create both resource and plugins.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/#resource-scope","title":"Resource scope","text":"<p>In order to connect to the HubSpot you need a private app. The information on how to create it is provided during creating the HubSpot resource. If you have resource you most probably have everything set up. There is only one important information regarding using this plugin. The resource that you create must have the following rights.  It was set when you created \"private app\" in hubspot.</p> <pre><code> crm.objects.contacts.write, \n crm.schemas.contacts.read\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/#plugin-configuration","title":"Plugin configuration","text":"<p>Use one of the following forms of configuration. Configuration via FORM or advanced configuration with JSON.</p>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/#with-form","title":"With form","text":"<ul> <li>HubSpot's resource - please select your HubSpot resource.</li> <li>Type contact properties such as: email, firstname, lastname, phone, etc.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/hubspot/hubspot_add_contact_action/#json-configuration-example","title":"JSON configuration - example","text":"<pre><code>{\n  \"source\": {\n    \"id\": \"&lt;resource-id&gt;\",\n    \"name\": \"&lt;resource-name&gt;\"\n  },\n  \"properties\": {\n    \"email\": \"&lt;a-contact-email&gt;\",\n    \"firstname\": \"&lt;a-contact-firstname&gt;\",\n    \"lastname\": \"&lt;a-contact-lastname&gt;\"\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/","title":"Add Empty Profile","text":"<p>This plugin adds an empty profile to the event. An empty profile is created with a random ID and can be used to store information about a user.</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#version","title":"Version","text":"<p>Version 0.8.0</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#description","title":"Description","text":"<p>The Add Empty Profile plugin adds an empty profile to the event. It creates a new profile with a random ID and sets it as the profile for the event. Additionally, it updates the metadata of the event and sets the <code>profile_less</code> flag to <code>False</code> to indicate that a profile is associated with the event. The plugin also updates the execution graph to include the new profile.</p> <p>If configured, the plugin can also create a new session for the profile. The session ID is set in the tracker payload and can be used by other plugins in the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#inputs","title":"Inputs","text":"<ul> <li>payload: Accepts a payload object.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#outputs","title":"Outputs","text":"<ul> <li>payload: Returns the input payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#configuration","title":"Configuration","text":"<ul> <li>New session: Specifies whether to create a new session for the profile. The available options are:</li> <li>If not exists: Creates a new session only if a session does not already exist.</li> <li>Always: Always creates a new session.</li> <li>Never: Does not create a new session.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#json-configuration","title":"JSON Configuration","text":"<p>Example JSON configuration for the Add Empty Profile plugin:</p> <pre><code>{\n  \"session\": \"always\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#required-resources","title":"Required resources","text":"<p>This plugin does not require any external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_profile/#errors","title":"Errors","text":"<p>No errors are documented for this plugin.</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_session/","title":"Add Empty Session","text":"<p>Adds a new session to the event. An empty session is created with a random ID.</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_session/#version","title":"Version","text":"<p>This documentation is for version 0.7.0 of the plugin.</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_session/#description","title":"Description","text":"<p>The AddEmptySessionAction plugin is used to add an empty session to the event. It creates a new session with a random ID and assigns it to the event. The session is also saved in the database for future reference. This plugin is typically used in workflows where session data is required.</p> <p>The plugin performs the following steps:</p> <ol> <li>Generates a random ID for the session.</li> <li>Creates a new session object with the generated ID.</li> <li>Assigns the session to the event.</li> <li>Updates the event's session metadata with the session ID, start time, and duration.</li> <li>Updates the event's operation to indicate that it has been modified.</li> <li>Sets the \"saveSession\" option in the tracker to True.</li> <li>Returns the input payload.</li> </ol> <p>Example output:</p> <pre><code>{\n  \"payload\": {\n    \"someData\": \"value\",\n    \"session\": {\n      \"id\": \"a1b2c3d4e5f6\",\n      \"start\": \"2023-07-10T12:00:00Z\",\n      \"duration\": 3600\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_session/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Input: This plugin takes the payload object as input.</li> <li>Output: This plugin returns the input payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_session/#configuration","title":"Configuration","text":"<p>This plugin does not require any configuration.</p>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_session/#json-configuration","title":"JSON Configuration","text":"<pre><code>{}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/internal/add_empty_session/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/","title":"Find Max Value","text":"<p>The Find Max Value plugin is a simple plugin designed to find the key with the maximum numeric value within a dictionary. It operates on data from the internal state of a workflow, which is provided through the configuration. This plugin checks the data's structure, ensuring that it is a dictionary with string keys and numeric values (int or float). It then identifies the key associated with the maximum value and returns this information.</p>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/#version","title":"Version","text":"<p>This documentation is based on plugin version 0.8.2.</p>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/#description","title":"Description","text":"<p>The Find Max Value plugin serves as a utility for extracting the key with the maximum numeric value from a dictionary in the internal state of a workflow. It performs the following steps:</p> <ol> <li>Access the specified data from the internal state using the dot-notation path provided in the configuration.</li> <li>Verify that the data is in the form of a dictionary with string keys and numeric values.</li> <li>Determine the key with the highest numeric value within the dictionary.</li> <li>Return the identified key and its corresponding maximum value as the plugin's result.</li> </ol> <p>The plugin is useful for scenarios where you need to find and work with the most significant value within a dictionary, such as identifying the most visited page on a website or the most common item in a list.</p> <p>Example Output:</p> <pre><code>{\n  \"key\": \"most_visited_page\",\n  \"max_value\": 500\n}\n</code></pre> <p>In the above example, the plugin has found that the key \"most_visited_page\" is associated with the maximum numeric value of 500 in the provided dictionary.</p>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li> <p>Input: This plugin accepts a payload object, which typically contains data from the internal state of the   workflow.</p> </li> <li> <p>Output Ports:</p> <ul> <li>result: Returns the key with the maximum numeric value in the form of a dictionary containing the key and its   value.</li> <li>error: Returns an error message in case any issues occur during the plugin's execution.</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/#configuration","title":"Configuration","text":"<p>The Find Max Value plugin has a single configuration parameter:</p> <ul> <li>Source Path (Configuration Key: source):<ul> <li>Description: This is the dot-notation path to access the internal data in the workflow. The plugin will operate on   this data to find the key with the maximum numeric value.</li> <li>Example Configuration: \"source\": \"profile@visted.pages\"</li> </ul> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example JSON configuration for the Find Max Value plugin:</p> <pre><code>{\n  \"source\": \"profile@visted.pages\"\n}\n</code></pre> <p>In this example, the plugin is configured to use the \"visted.pages\" data within the \"profile\".</p>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/list/find_max_value/#errors","title":"Errors","text":"<p>The Find Max Value plugin can encounter the following errors, along with their associated error messages:</p> <ol> <li> <p>ValueError: Source data is not a dictionary.</p> <ul> <li>Description: This error occurs when the data retrieved from the specified source path is not a dictionary.</li> <li>Possible Condition: The data at the provided source path is not in the expected format, and it is not possible to   find the maximum value.</li> </ul> </li> <li> <p>ValueError: Not all values in the dictionary are numeric.</p> <ul> <li>Description: This error occurs when the values within the dictionary retrieved from the specified source path are   not all numeric (int or float).</li> <li>Possible Condition: The dictionary contains values that are not numeric, preventing the plugin from identifying   the maximum value.</li> </ul> </li> <li> <p>Exception (General Error Message)</p> <ul> <li>Description: This error occurs if any unexpected exception is raised during the plugin's execution.</li> <li>Possible Condition: This error may occur due to issues such as invalid dot-notation path, internal workflow state   not containing the expected data, or other unforeseen problems during execution.</li> </ul> </li> </ol>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/","title":"Set Operation Plugin","text":"<p>The Set Operation Plugin is used to perform various set operations on two sets of data. These sets can be referenced from the internal state of the workflow. This plugin takes two sets of data as input, performs the specified set operation, and returns the result.</p>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/#version","title":"Version","text":"<p>This documentation is created for Set Operation Plugin version 8.2.0.</p>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/#description","title":"Description","text":"<p>The Set Operation Plugin allows you to perform set operations on two sets of data. Sets can be referenced from the internal state of the workflow. The plugin supports the following set operations:</p> <ul> <li>Intersection: Finds the common elements between two sets.</li> <li>Union: Finds the combined set of unique elements from two sets.</li> <li>Difference: Finds the elements that exist in one set but not in another.</li> <li>Symmetric Difference: Finds the elements that exist in either of the sets but not in both.</li> <li>Subset Check: Checks if one set is a subset of another.</li> <li>Superset Check: Checks if one set is a superset of another.</li> </ul> <p>The operation to be performed is specified in the plugin's configuration.</p>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Input: This plugin accepts a payload object.</li> </ul> <p>Example Input:   <pre><code>{\n  \"set1\": [1, 2, 3, 4],\n  \"set2\": [3, 4, 5, 6],\n  \"operation\": \"intersection\"\n}\n</code></pre></p> <ul> <li> <p>Outputs: The plugin has two output ports:</p> </li> <li> <p>result: Returns the result of the intersection operation.</p> <p>Example Output:  <pre><code>{\n  \"result\": [3, 4]\n}\n</code></pre></p> </li> <li> <p>error: Returns an error message if an exception occurs during the operation.</p> <p>Example Error Output:  <pre><code>{\n  \"message\": \"Invalid operation specified.\"\n}\n</code></pre></p> </li> </ul>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/#configuration","title":"Configuration","text":"<p>The Set Operation Plugin has the following configuration parameters:</p> <ul> <li>Set 1: Reference to the first set data.</li> <li>Set 2: Reference to the second set data.</li> <li>Set Operation: Select the set operation to perform.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/#json-configuration","title":"JSON Configuration","text":"<p>Here is an example of the JSON configuration for the Set Operation Plugin:</p> <pre><code>{\n  \"set1\": \"payload@data.set1\",\n  \"set2\": \"event@data.set2\",\n  \"operation\": \"intersection\"\n}\n</code></pre> <p>In this example, the plugin is configured to perform the \"intersection\" operation on two sets of data located at \" payload@data.set1\" and \"event@data.set2.\"</p>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/#required-resources","title":"Required Resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/list/sets_operations/#errors","title":"Errors","text":"<p>The Set Operation Plugin may raise the following exceptions along with the conditions under which they may occur:</p> <ul> <li>ValueError: Invalid operation specified. This error occurs when an invalid set operation is specified in the   configuration.</li> <li>TypeError: The 'issubset', 'issuperset', etc. operations can only be applied to sets. This error occurs when the \"   is_subset\" or \"is_superset\", etc operation is applied to non-set data.</li> <li>KeyError: 'set1' or 'set2'. This error occurs if the specified paths for \"set1\" or \"set2\" in the configuration do   not exist in the internal state of the workflow.</li> <li>Exception: An unexpected error occurred. This is a generic error that may occur due to unexpected issues during   the set operation.</li> </ul> <p>Please make sure the configuration is correctly set and that the specified paths for the sets exist in the internal state of the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/matomo/register_event/","title":"Matomo register event","text":"<p>Registers an event in matomo.</p>"},{"location":"getting_started/processes/workflow/actions/matomo/register_event/#required-fields","title":"Required fields","text":"<ul> <li>Resource</li> <li>SiteID</li> </ul> <p>Other fields are optional. </p>"},{"location":"getting_started/processes/workflow/actions/matomo/register_event/#how-to-find-siteid","title":"How to find SiteID","text":"<p>To find out the idSite value for a given website, you can follow these steps:</p> <ul> <li>Log into your Matomo.</li> <li>Go to Administration (click on the gear icon in the top right of the screen).</li> <li>Click on the Measurables(or Websites) &gt; Manage page. You will find a list of all websites on this page.</li> <li>The website ID is on the left of the table listing all websites directly below the website name.</li> <li>SiteID is a integer number, eg. 1</li> </ul>"},{"location":"getting_started/processes/workflow/actions/memory/payload_memory_collector/","title":"Memory payload collector","text":"<p>This action node collects input payloads in a defined key inside memory object. Memory object is kept inside workflow and can be references with copy data plugin or any dotted notation string, e.g. memory@defined_key.</p> <p>One node can be connected to nodes. This means that it will be executed as many times as there were nodes connected to it at the input port. Each of the preceding node sends the result of its operation (payload). In order to collect data into one object, it is necessary to combine previous results. The node \"collect payloads\" collects the payloads and saves them in the memory object under the given key.</p> <p>Two types of connections are possible.</p>"},{"location":"getting_started/processes/workflow/actions/memory/payload_memory_collector/#list-type","title":"List type.","text":"<p>It allows you to see all incoming payloads in the list. e.g.</p> <pre><code>{\n  \"my-key\": [\n    {\n      \"key\": \"payload1\"\n    },\n    {\n      \"key\": \"payload2\"\n    },\n    {\n      \"key\": \"payload3\"\n    }\n  ]\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/memory/payload_memory_collector/#dictionary-type","title":"Dictionary type.","text":"<p>It combines all incoming payloads into a dictionary type where the key for each payload is the name of the connection (called sometimes graph edge) it came from, e.g.</p> <pre><code>{\n  \"my-key\": {\n    \"edge-name1\": {\n      \"key\": \"payload1\"\n    },\n    \"edge-name2\": {\n      \"key\": \"payload2\"\n    },\n    \"edge-name3\": {\n      \"key\": \"payload3\"\n    }\n  }\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/memory/payload_memory_collector/#advanced-configuration","title":"Advanced Configuration","text":"<p>Example</p> <pre><code>{\n  \"name\": \"my-key\",\n  \"type\": \"list\"\n}\n</code></pre> <ul> <li>name - the name (key in memory object) that will hold the collected payloads.</li> <li>type - type of collection. Possible values: \"list\", \"dict\"</li> </ul>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/","title":"Regex Match","text":"<p>The purpose of this plugin is to display particular groups of regexes that we specify in a pattern.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/#configuration","title":"Configuration","text":"<p>This node requires configuration.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/#example-of-configuration","title":"Example of configuration","text":"<pre><code>{\n  \"pattern\": \"(\\\\b[A-Z]+\\\\b).+(\\\\b\\\\d+)\",\n  \"text\": \"The price of PINEAPPLE ice cream is 20\",\n  \"group_prefix\": \"Group\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/#output-example","title":"Output example:","text":"<pre><code>{\n  \"Group-A\": \"PINEAPPLE\",\n  \"Group-B\": \"20\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/#configuration-description","title":"Configuration description","text":"<ul> <li>pattern - Provide regex pattern.</li> <li>text - Enter your text. You can use dot notation to access profile or event data.</li> <li>group_prefix - Enter the prefix for groups</li> </ul>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/#examples-of-errors","title":"Examples of errors","text":"<ul> <li>Regex couldn't find anything matching the pattern from supplied string. - This means that the pattern you specified is   incorrect, because the plugin cannot find any text. This error will not stop workflow but will be logged as a warning.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/#input-payload","title":"Input payload","text":"<p>This node does not process input payload.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_match/#output","title":"Output","text":"<p>This node returns dictionary containing matched data with groups</p> <p>Example</p> <pre><code>{\n  \"Group-A\": \"PINEAPPLE\",\n  \"Group-B\": \"20\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/regex/regex_replace_action/","title":"Regex string replace plugin","text":"<p>This plugin takes string as an input and replaces its fragments that match given regex.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_replace_action/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_replace_action/#output","title":"Output","text":"<p>This plugin returns regex after operations on port replaced if matches were found, or given string on port not_found if given value was not containing any fragment matching given regex.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_replace_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"string\": \"&lt;path-to-string-that-you-want-to-operate-on&gt;\",\n  \"find_regex\": \"&lt;regex-that-will-match-fragments-to-replace&gt;\",\n  \"replace_with\": \"&lt;path-to-string-that-you-want-to-replace-with&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/regex/regex_validator_action/","title":"String Validator","text":"<p>This plugin validates data with regex pattern.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_validator_action/#configuration","title":"Configuration","text":"<p>This node requires configuration.</p> <ul> <li>validation_regex - this is regex pattern.</li> <li>data - data what we want to validate. this value can also be a path to date in profile, session, event.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/regex/regex_validator_action/#examples","title":"Examples","text":"<pre><code>{\n  \"validation_regex\": \"^H\",\n  \"data\": \"payload@properties.hello\"   // This will return e.g. Hello world\n}\n</code></pre> <p>It will return <code>payload</code> on <code>valid</code> output port. <code>invalid</code> port will stay inactive. </p> <pre><code>{\n  \"validation_regex\": \"^a\",\n  \"data\": \"hello!\"  // Now we use plain string instead of path to data.\n}\n</code></pre> <p>It will return <code>payload</code> on <code>invalid</code> output port. <code>valid</code> port will stay inactive. </p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_validator_action/#input","title":"Input","text":"<p>This node does not process input payload.</p>"},{"location":"getting_started/processes/workflow/actions/regex/regex_validator_action/#output","title":"Output","text":"<p>This plugin has to port valid and invalid. Depending on validation result the appropriate ports will be launched with payload copied as data.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/","title":"Add segment","text":"<p>This plugin enables adding a specific segment to a profile. When activated, it appends the designated segment or segments to the profile, helping categorize or tag profiles based on specific criteria or behaviors.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#version","title":"Version","text":"<p>0.8.1</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#description","title":"Description","text":"<p>The Add Segment plugin is designed to enhance profile segmentation by adding predefined segments to a profile. This process involves checking the profile's current segments and adding new ones if they are not already present. The plugin operates by examining the incoming payload and the specified segment configuration. If the targeted segment(s) are not part of the profile's existing segments, they are added, and the profile's segmentation timestamp is updated to the current UTC time. The plugin supports both single segments (as a string) and multiple segments (as a list of strings). It employs a dynamic approach to handle the addition of segments, ensuring that the operation can adapt based on the provided segment configuration. The output of the plugin is the original payload, indicating that the primary purpose of the plugin is to update the profile's segmentation without altering the workflow's data flow.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#inputs-and-outputs","title":"Inputs and Outputs","text":"<p>The plugin accepts any payload through its input port and returns the input payload unchanged through its output port, labeled \"payload\". This design signifies that the plugin's primary function is to update the profile's segmentation based on the specified configuration without modifying the incoming data.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#inputs","title":"Inputs:","text":"<ul> <li>payload: Accepts any payload object, serving as a pass-through for the workflow data.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#outputs","title":"Outputs:","text":"<ul> <li>payload: Returns the input payload, indicating the plugin's operation does not alter the data flow.</li> <li>error: Outputs error information if issues occur during the segment addition process.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#configuration","title":"Configuration","text":"<ul> <li>Segment name: The name of the segment to be added to the profile. This can be a single segment name (string) or a   list of segment names (list of strings). The plugin validates that this configuration is not empty to ensure a segment   is specified for addition.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"segment\": \"example_segment_name\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#event-prerequisites","title":"Event prerequisites","text":"<p>The plugin works with all types of events. It does not have a specific requirement for the event to be synchronous or asynchronous, making it versatile for various workflow scenarios.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/add_segment_action/#errors","title":"Errors","text":"<ul> <li>\"Segment cannot be empty\": This error occurs if the segment configuration is left empty. The plugin requires at   least one segment name to function correctly.</li> <li>\"Not acceptable segmentation type. Allowed type: string or list of strings\": This error is triggered if the   provided segment configuration is neither a string nor a list of strings. The plugin is designed to handle these two   types for segment addition.</li> <li>KeyError: This exception might happen if there's an issue accessing the segment data within the provided payload   or configuration. It indicates a mismatch or absence of expected data paths.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/","title":"Delete segment","text":"<p>This plugin facilitates the removal of a specified segment from a profile. When activated, it identifies and deletes the designated segment from the profile's segment list, if present.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#version","title":"Version","text":"<p>0.8.1</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#description","title":"Description","text":"<p>The Delete Segment plugin is designed to streamline the process of managing profile segmentation by allowing for the removal of specific segments from a profile. Upon execution, the plugin checks if the specified segment exists within the profile's current segment list. If found, the segment is removed, and the profile's segmentation timestamp is updated to reflect the change at the current UTC time. This operation is essential for maintaining accurate and up-to-date segmentation information within profiles, ensuring that profiles are only associated with relevant segments. The plugin operates seamlessly, requiring only the name of the segment to be removed as input and returning the original payload, thereby indicating that the main function of the plugin has been executed without altering the workflow's data flow.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#inputs","title":"Inputs:","text":"<ul> <li>payload: Accepts any payload object, serving as a conduit for data flow within the workflow.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#outputs","title":"Outputs:","text":"<ul> <li>payload: Outputs the original payload, signifying that the primary function of the plugin is the modification of   the profile's segments rather than the data itself.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#configuration","title":"Configuration","text":"<ul> <li>Segment name: The name of the segment you wish to remove from the profile. This field must be filled in to   identify the specific segment targeted for deletion. The plugin ensures that this configuration is not left empty to   prevent operational errors.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"segment\": \"specified_segment_name\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#event-prerequisites","title":"Event prerequisites","text":"<p>The Delete Segment plugin can be utilized with all types of events, without any specific requirement for the event to be synchronous. It is suitable for integration into various workflow scenarios, providing flexibility in its application.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/delete_segment_action/#errors","title":"Errors","text":"<ul> <li>\"Segment cannot be empty\": This error occurs if the segment name is not provided in the configuration. A segment   name is required for the plugin to perform its function correctly. This validation ensures that the plugin has a   specific target for segment deletion.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/","title":"Force segmentation","text":"<p>This plugin is designed to ensure that a profile is marked for segmentation at the end of a workflow. It is particularly useful for cases where the segmentation process needs to be explicitly invoked, ensuring that profiles are categorized based on predefined conditions after the workflow execution.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#version","title":"Version","text":"<p>0.6.0.1</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#description","title":"Description","text":"<p>The Force Segmentation plugin plays a critical role in the post-event segmentation process by marking a profile for segmentation once a workflow concludes. This action is typically automatic, triggered by updates to a profile during the workflow. However, there are scenarios where manual invocation of segmentation is necessary or desired. This plugin provides the functionality to do so, ensuring that profiles are segmented according to the latest data and interactions recorded during the workflow. Upon execution, if the profile exists, it is marked for segmentation, and its segmentation timestamp is updated. If no profile is found, the plugin issues a warning or error message based on the context (e.g., profile-less events or missing profiles).</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#inputs","title":"Inputs:","text":"<ul> <li>payload: The plugin can process any input payload, which remains unaltered through its operation.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#outputs","title":"Outputs:","text":"<ul> <li>payload: Outputs the original payload, indicating that the plugin's primary function does not modify the data flow   but affects the profile's state.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#configuration","title":"Configuration","text":"<p>This plugin does not require any configuration. It is designed to operate without needing any input parameters, making it straightforward to incorporate into any workflow where manual segmentation triggering is needed.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#event-prerequisites","title":"Event prerequisites","text":"<p>The Force Segmentation plugin is compatible with all types of events. It functions independently of the event's nature, focusing solely on the profile segmentation process.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/force_segment_action/#errors","title":"Errors","text":"<p>There are no specific errors generated by the plugin itself during its operation. However, it provides feedback through console warnings or errors in scenarios where segmentation cannot be performed, such as when handling profile-less events or when a profile is absent.</p> <ul> <li>Warning: \"Can not segment profile when processing profile less events.\" This warning occurs if the event being   processed does not have an associated profile.</li> <li>Error: \"Can not segment profile. Profile is empty.\" This error is logged when the profile expected to be segmented   is missing or empty.</li> </ul> <p>By using the Force Segmentation plugin, workflows can ensure that profiles are always segmented according to the latest interactions and data, even when manual intervention is required to trigger the segmentation process. This capability ensures that profiles are accurately categorized for targeted actions and analysis.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/","title":"Has segment","text":"<p>This plugin checks if a profile is part of a defined segment. If the profile is in the specified segment, the workflow will continue along the \"True\" path; otherwise, it will proceed along the \"False\" path.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#version","title":"Version","text":"<p>0.7.3</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#description","title":"Description","text":"<p>The Has Segment plugin serves a conditional role within a workflow, determining the path of execution based on the profile's membership in a specified segment. Upon execution, the plugin examines the profile's segment list to check for the presence of the configured segment. If the profile includes the specified segment, the plugin outputs the payload through the \"True\" port, indicating that the condition has been met. If the segment is not found, the payload is returned through the \"False\" port, suggesting the condition has not been fulfilled. This functionality is essential for workflows that require conditional logic based on profile segmentation, allowing for more personalized and targeted actions within the workflow.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#inputs","title":"Inputs:","text":"<ul> <li>payload: Accepts any form of payload, which is passed through the plugin without modification.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#outputs","title":"Outputs:","text":"<ul> <li>True: The output port used if the profile is in the defined segment. It returns the input payload.</li> <li>False: The output port used if the profile is not in the defined segment. It also returns the input payload.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#configuration","title":"Configuration","text":"<ul> <li>Profile segment to check: The name of the segment you wish to check against the profile. This configuration must   be specified to identify the target segment for the check.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"segment\": \"specified_segment_name\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#event-prerequisites","title":"Event prerequisites","text":"<p>The plugin works with all types of events. It is designed to function within workflows regardless of the event's synchronous or asynchronous nature, making it versatile for various use cases.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/has_segment_action/#errors","title":"Errors","text":"<ul> <li>\"Segment cannot be empty\": This error occurs if the segment configuration is left empty. A segment name is   required for the plugin to perform its function effectively. This validation ensures that the plugin has a specific   segment to check for within the profile.</li> </ul> <p>By incorporating the Has Segment plugin into a workflow, users can implement conditional logic based on profile segmentation, enabling more granular control over the workflow's execution path based on profile characteristics.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/","title":"Move segment","text":"<p>This plugin allows for the transition of a profile from one segment to another, effectively updating the profile's segmentation in the process.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#version","title":"Version","text":"<p>0.8.1</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#description","title":"Description","text":"<p>The Move Segment plugin is designed to facilitate the reclassification of profiles within different segments. This operation involves removing the profile from an existing (\"from\") segment and adding it to another (\"to\") segment. During this process, the plugin ensures that the profile's segment list is unique and up-to-date. If the profile is already part of the \"from\" segment, it will be removed from that segment. Conversely, if the profile is not yet a part of the \"to\" segment, it will be added. This resegmentation reflects immediately in the profile's metadata, marking the time of segmentation to the current UTC time. The plugin ensures that profiles maintain relevant and accurate segment associations by moving them between segments as needed.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#inputs-and-outputs","title":"Inputs and Outputs","text":""},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#inputs","title":"Inputs:","text":"<ul> <li>payload: The plugin accepts any form of payload, which is passed through unchanged.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#outputs","title":"Outputs:","text":"<ul> <li>payload: The original payload is returned, indicating that the data flow remains unaffected by the plugin's   operations.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#configuration","title":"Configuration","text":"<ul> <li>Move from segment: The name of the segment from which the profile is to be moved. This field must be filled out to   identify the source segment accurately.</li> <li>Move to segment: The name of the segment to which the profile is to be moved. This field must also be filled out   to define the target segment for the reclassification.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#json-configuration","title":"JSON Configuration","text":"<pre><code>{\n  \"from_segment\": \"current_segment_name\",\n  \"to_segment\": \"target_segment_name\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#required-resources","title":"Required resources","text":"<p>This plugin does not require external resources to be configured.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#event-prerequisites","title":"Event prerequisites","text":"<p>The Move Segment plugin is compatible with all event types, facilitating its integration into various workflow scenarios without the need for synchronous event processing.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/move_segment_action/#errors","title":"Errors","text":"<ul> <li>\"Segment cannot be empty\": This error occurs if either the \"from_segment\" or \"to_segment\" configuration fields are   left empty. A valid segment name is required for both the source and target segments to ensure the plugin can execute   its function correctly.</li> </ul> <p>Through the application of the Move Segment plugin, users are empowered to dynamically manage and update profile segmentations, ensuring that profiles are always associated with the most relevant segments according to their latest interactions or behaviors.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/profile_segment/","title":"Profile segmentation","text":"<p>This action will add/remove segment to/from the profile. This action needs profile update to save changes to the profile.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/profile_segment/#configuration","title":"Configuration","text":"<pre><code>{\n  \"true_segment\": \"frequent-user\",\n  \"true_action\": \"add\",\n  \"false_segment\": \"frequent-user\",\n  \"false_action\": \"remove\",\n  \"condition\": \"profile@stats.visits&gt;10\"\n}\n</code></pre> <ul> <li>true_segment - Segment name when the condition is met. Please use dashes instead of spaces.</li> <li>true_action - What action would you like to perform when the condition is met. The default action if \"add\". Though   we have add, remove, none to choose from.</li> <li>false_segment - Segment name when the condition is NOT met. Please use dashes instead of spaces.</li> <li>true_action - What action would you like to perform when the condition is NOT met. The default action if \"add\".   Though we have add, remove, none to choose from.</li> <li>condition - Condition for segmentation. If the condition is met then the profile will be added or removed to/from   defined segment.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/segmentation/profile_segment/#input","title":"Input","text":"<p>This action does not process input.</p>"},{"location":"getting_started/processes/workflow/actions/segmentation/profile_segment/#output","title":"Output","text":"<p>Input payload.</p>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/","title":"Send SMS with Sms77 gateway","text":"<p>This plugin sends SMS with sms77 gateway. </p>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/#input","title":"Input","text":"<p>This plugin takes any payload as input.</p>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/#outputs","title":"Outputs","text":"<p>This plugin returns response from Sms77 API on port response, or optional error info on port error if one occurs.</p>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/#json-configuration","title":"JSON Configuration","text":"<p>Json configuration contains of resource, message, recipient, and sender.</p> <pre><code>{\n  \"resource\": {\n    \"id\": \"\",\n    \"name\": \"\"\n  },\n  \"message\": \"\",\n  \"recipient\": \"profile@pii.telephone\",\n  \"sender\": \"\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/#message","title":"Message","text":"<p>Massage is a message template. That means you can use template placeholders.  </p>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/#example","title":"Example","text":"<pre><code>Hello {{profile@pii.name}}, your order will be dispatched in next two hours.\n</code></pre> <p>This message will have the {{profile@pii.name}} changed to the current profile's name, so the recipient will see 'Hello John, your order will be dispatched in next two hours.' in his SMS.</p>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/#sender","title":"Sender","text":"<p>Please leave sender blank if you want to use default sms77 sender. If you would like to use custom sender phone number  please set the sender in sms77 system and paste its number or name here. </p>"},{"location":"getting_started/processes/workflow/actions/sms77/sms77_send_sms_plugin/#recipient","title":"Recipient","text":"<p>Recipient can be pointed from the profile (default value comes from profile@pii.telephone) or it can be static phone number e.g. \"+49374882833\"</p>"},{"location":"getting_started/processes/workflow/actions/telegram/telegram_post_plugin/","title":"Telegram post plugin","text":"<p>Developer did not provide the documentation</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/","title":"Add Trello card plugin","text":"<p>This plugin adds a card to a list in Trello.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#input","title":"Input","text":"<p>This plugin takes any payload object.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#output","title":"Output","text":"<p>This plugin returns response from Trello API on port response, or empty payload on error port, if an error occurs.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#trello-resource-configuration","title":"Trello Resource Configuration","text":"<p>To begin working with Trello inside Tracardi, you need an API key and token. These can be typed inside Tracardi resources. Resources can be found under Traffic -&gt; Outbound resources. More information on how to create a resource can be found below.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#trello-api-key","title":"Trello API KEY","text":"<p>Every Trello user is given an API key. You can retrieve your  API key by logging into Trello and visiting https://trello.com/app-key/.</p> <p>When the page loads you should see the header Developer API Keys and a Key which looks like this:</p> <pre><code>164a9547a52d0951f3ed781b723d03c1b60d9abd\n</code></pre> <p>You will need this key to copy to Trello Resource in Tracardi.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#trello-token","title":"Trello TOKEN","text":"<p>The below the key you will see the following message:</p> <pre><code>  Most developers will need to ask each user to authorize your application. If you are looking to build an application \n  for yourself, or are doing local testing, you can manually generate a Token. \n</code></pre> <p>Click on Token link. It will move you to the page with the information on the scope of the token. Click allow at the bottom of the page. </p> <p>You should see the message You have granted access to your Trello account via the token below and the token that looks  like this:</p> <pre><code>b723d03c1b60d9abd164a9547a52d0951f3ed781b164a9547a52d0951f3ed781723d0\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#trello-resource","title":"Trello Resource","text":"<p>Now it is time to create a Tracardi Trello Resource.</p> <ul> <li>Go to Traffic -&gt; Outbound resources. </li> <li>Click new resource</li> <li>Fill the form and replace  with the generated token and __ with api key in the credentials section. <li>Replace it int the test and production tab. </li> <p>Example of the credentials JSON</p> <pre><code>{\n  \"token\": \"&lt;token&gt;\",\n  \"api_key\": \"&lt;api-key&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#trello-configuration-form","title":"Trello Configuration Form","text":"<ul> <li>Trello resource - Select any resource, tagged trello, containing your API key   and token.</li> <li>URL of Trello board - Trello board's URL. That's the same URL you can see   on top of your browser window while visiting the board.</li> <li>Name of Trello list - The name of the list that you want to add card to.</li> <li>Name of your card - Dot path to field that contains text. This text will become your   card's name.</li> <li>Card description - Card description. Here you can type in regular text, or    dot template, so for example Customer {{profile@pii.name}} has ordered something.   This configuration parameter is optional.</li> <li>Card link - You can add link to your card as an attachment. This configuration parameter is optional.</li> <li>Card coordinates - You can add coordinates to your Trello card to use in Trello app. The path should   point at an object in payload, containing fields called latitude and longitude. This   feature works well with GeoIp service plugin. This configuration parameter is optional.</li> <li>Card due date - You can add due date to your card. This parameter is a path to a field   containing date. Best format to use is UTC, but for example YYYY-MM-DD should also work.   This configuration parameter is optional.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#advanced-json-configuration","title":"Advanced JSON configuration","text":"<p><pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-trello-resource&gt;\",\n    \"name\": \"&lt;name-of-your-trello-resource&gt;\"\n  },\n  \"board_url\": \"&lt;full-url-to-your-board-in-trello&gt;\",\n  \"list_name\": \"&lt;exact-name-of-your-trello-list&gt;\",\n  \"list_id\": \"&lt;check-note-below&gt;\",\n  \"card\": {\n    \"name\": \"&lt;dot-path-to-card-name-or-name-itself&gt;\",\n    \"desc\": \"&lt;card-description&gt;\",\n    \"urlSource\": \"&lt;url-that-you-want-to-attach-to-your-card&gt;\",\n    \"coordinates\": \"&lt;dot-path-to-object-containing-coordinates&gt;\",\n    \"due\": \"&lt;dot-path-to-field-containing-due-date&gt;\"\n  }\n}\n</code></pre> NOTE: list_id parameter does not matter. Tracardi uses it to store ID of found list. It should be left as \"\" or null.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_card_action/#warning","title":"Warning","text":"<p>If you have two lists with same names on one board, then Tracardi will pick one of them, There is no method of specifying which one will be picked.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/","title":"Add Trello member plugin","text":"<p>This plugin adds a member to a given card in Trello.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#input","title":"Input","text":"<p>This plugin takes any payload.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#output","title":"Output","text":"<p>This plugin returns response from Trello API on port response, or empty payload on error port, if an error occurs.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#trello-resource-configuration","title":"Trello Resource Configuration","text":"<p>To begin working with Trello inside Tracardi, you need an API key and token. These can be typed inside Tracardi resources. Resources can be found under Traffic -&gt; Outbound resources. More information on how to create a resource can be found below.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#trello-api-key","title":"Trello API KEY","text":"<p>Every Trello user is given an API key. You can retrieve your  API key by logging into Trello and visiting https://trello.com/app-key/.</p> <p>When the page loads you should see the header Developer API Keys and a Key which looks like this:</p> <pre><code>164a9547a52d0951f3ed781b723d03c1b60d9abd\n</code></pre> <p>You will need this key to copy to Trello Resource in Tracardi.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#trello-token","title":"Trello TOKEN","text":"<p>The below the key you will see the following message:</p> <pre><code>  Most developers will need to ask each user to authorize your application. If you are looking to build an application \n  for yourself, or are doing local testing, you can manually generate a Token. \n</code></pre> <p>Click on Token link. It will move you to the page with the information on the scope of the token. Click allow at the bottom of the page. </p> <p>You should see the message You have granted access to your Trello account via the token below and the token that looks  like this:</p> <pre><code>b723d03c1b60d9abd164a9547a52d0951f3ed781b164a9547a52d0951f3ed781723d0\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#trello-resource","title":"Trello Resource","text":"<p>Now it is time to create a Tracardi Trello Resource.</p> <ul> <li>Go to Traffic -&gt; Outbound resources. </li> <li>Click new resource</li> <li>Fill the form and replace  with the generated token and __ with api key in the credentials section. <li>Replace it int the test and production tab. </li> <p>Example of the credentials JSON</p> <pre><code>{\n  \"token\": \"&lt;token&gt;\",\n  \"api_key\": \"&lt;api-key&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#form-fields","title":"Form fields","text":"<ul> <li>Trello resource - Select your resource, tagged trello, containing your API key   and token.</li> <li>URL of Trello board - Paste in your Trello board's URL. That's the same URL you can see   on top of your browser window while seeing the board.</li> <li>Name of Trello list - Type in the name of the list containing the card, that you want   to add a member to.</li> <li>Name of your card - Provide the path to the field containing name of the card that you   want to add a member to.</li> <li>ID of the member - Provide the path to the field containing the ID of Trello member, that   you want to add to your card.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#json-configuration","title":"JSON configuration","text":"<p><pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-trello-resource&gt;\",\n    \"name\": \"&lt;name-of-your-trello-resource&gt;\"\n  },\n  \"board_url\": \"&lt;full-url-to-your-board-in-trello&gt;\",\n  \"list_name\": \"&lt;exact-name-of-your-trello-list&gt;\",\n  \"list_id\": \"&lt;check-note-below&gt;\",\n  \"card_name\": \"&lt;exact-name-of-your-trello-card&gt;\",\n  \"member_id\": \"&lt;path-to-the-field-containing-id-of-the-member&gt;\"\n}\n</code></pre> NOTE: list_id parameter does not matter. Tracardi uses it to store ID of found list. It should be left as \"\" or null.</p>"},{"location":"getting_started/processes/workflow/actions/trello/add_trello_member_action/#warning","title":"Warning","text":"<p>If you have two lists with same names on one board, then Tracardi will pick one of them, without a method of specifying which one will be picked. This rule also applies to the cards.</p>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/","title":"Remove Trello card plugin","text":"<p>This plugin removes a card from given list in Trello.</p>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#input","title":"Input","text":"<p>This plugin takes any payload object.</p>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#output","title":"Output","text":"<p>This plugin returns response from Trello API on port response, or empty payload on error port, if an error occurs.</p>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#trello-resource-configuration","title":"Trello Resource Configuration","text":"<p>To begin working with Trello inside Tracardi, you need an API key and token. These can be typed inside Tracardi resources. Resources can be found under Traffic -&gt; Outbound resources. More information on how to create a resource can be found below.</p>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#trello-api-key","title":"Trello API KEY","text":"<p>Every Trello user is given an API key. You can retrieve your  API key by logging into Trello and visiting https://trello.com/app-key/.</p> <p>When the page loads you should see the header Developer API Keys and a Key which looks like this:</p> <pre><code>164a9547a52d0951f3ed781b723d03c1b60d9abd\n</code></pre> <p>You will need this key to copy to Trello Resource in Tracardi.</p>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#trello-token","title":"Trello TOKEN","text":"<p>The below the key you will see the following message:</p> <pre><code>  Most developers will need to ask each user to authorize your application. If you are looking to build an application \n  for yourself, or are doing local testing, you can manually generate a Token. \n</code></pre> <p>Click on Token link. It will move you to the page with the information on the scope of the token. Click allow at the bottom of the page. </p> <p>You should see the message You have granted access to your Trello account via the token below and the token that looks  like this:</p> <pre><code>b723d03c1b60d9abd164a9547a52d0951f3ed781b164a9547a52d0951f3ed781723d0\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#trello-resource","title":"Trello Resource","text":"<p>Now it is time to create a Tracardi Trello Resource.</p> <ul> <li>Go to Traffic -&gt; Outbound resources. </li> <li>Click new resource</li> <li>Fill the form and replace  with the generated token and __ with api key in the credentials section. <li>Replace it int the test and production tab. </li> <p>Example of the credentials JSON</p> <pre><code>{\n  \"token\": \"&lt;token&gt;\",\n  \"api_key\": \"&lt;api-key&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#trello-plugin-form","title":"Trello Plugin Form","text":"<ul> <li>Trello resource - Select your resource, tagged trello, containing your API key   and token.</li> <li>URL of Trello board - Paste in your Trello board's URL. That's the same URL you can see   on top of your browser window while seeing the board.</li> <li>Name of Trello list - Type in the name of the list that you want to delete a card from.   In fact, Trello requires its ID, but Tracardi will find it for you, using provided list name.</li> <li>Name of your card - That's the name of the card that you want to delete. It can be either a name or a dot path to the    data inside event, payload, etc.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#advanced-configuration","title":"Advanced configuration","text":"<p><pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-trello-resource&gt;\",\n    \"name\": \"&lt;name-of-your-trello-resource&gt;\"\n  },\n  \"board_url\": \"&lt;full-url-to-your-board-in-trello&gt;\",\n  \"list_name\": \"&lt;exact-name-of-your-trello-list&gt;\",\n  \"list_id\": \"&lt;check-note-below&gt;\",\n  \"card_name\": \"&lt;exact-name-of-your-trello-card&gt;\",\n}\n</code></pre> NOTE: list_id parameter does not matter. Tracardi uses it to store ID of found list. It should be left as \"\" or null.</p>"},{"location":"getting_started/processes/workflow/actions/trello/delete_trello_card_action/#warning","title":"Warning","text":"<p>If you have two lists with same names on one board, then Tracardi will pick one of them, without a method of specifying which one will be picked. This rule also applies to the cards.</p>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/","title":"Move Trello card plugin","text":"<p>This plugin moves a Trello card from one list to another.</p>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#input","title":"Input","text":"<p>This plugin takes any payload object.</p>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#output","title":"Output","text":"<p>This plugin returns response from Trello API on port response, or empty payload on error port, if an error occurs.</p>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#trello-resource-configuration","title":"Trello Resource Configuration","text":"<p>To begin working with Trello inside Tracardi, you need an API key and token. These can be typed inside Tracardi resources. Resources can be found under Traffic -&gt; Outbound resources. More information on how to create a resource can be found below.</p>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#trello-api-key","title":"Trello API KEY","text":"<p>Every Trello user is given an API key. You can retrieve your  API key by logging into Trello and visiting https://trello.com/app-key/.</p> <p>When the page loads you should see the header Developer API Keys and a Key which looks like this:</p> <pre><code>164a9547a52d0951f3ed781b723d03c1b60d9abd\n</code></pre> <p>You will need this key to copy to Trello Resource in Tracardi.</p>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#trello-token","title":"Trello TOKEN","text":"<p>The below the key you will see the following message:</p> <pre><code>  Most developers will need to ask each user to authorize your application. If you are looking to build an application \n  for yourself, or are doing local testing, you can manually generate a Token. \n</code></pre> <p>Click on Token link. It will move you to the page with the information on the scope of the token. Click allow at the bottom of the page. </p> <p>You should see the message You have granted access to your Trello account via the token below and the token that looks  like this:</p> <pre><code>b723d03c1b60d9abd164a9547a52d0951f3ed781b164a9547a52d0951f3ed781723d0\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#trello-resource","title":"Trello Resource","text":"<p>Now it is time to create a Tracardi Trello Resource.</p> <ul> <li>Go to Traffic -&gt; Outbound resources. </li> <li>Click new resource</li> <li>Fill the form and replace  with the generated token and __ with api key in the credentials section. <li>Replace it int the test and production tab. </li> <p>Example of the credentials JSON</p> <pre><code>{\n  \"token\": \"&lt;token&gt;\",\n  \"api_key\": \"&lt;api-key&gt;\"\n}\n</code></pre>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#trello-plugin-form","title":"Trello Plugin Form","text":"<ul> <li>Trello resource - Select your resource, tagged trello, containing your API key   and token.</li> <li>URL of Trello board - Paste in your Trello board's URL. That's the same URL you can see   on top of your browser window while visiting the board.</li> <li>Name of Trello list - Type in the name of the list that you want to move a card from.</li> <li>Name of your card - That's the name of the card that you want to move. It can be either a name or a dot path to the    data inside event, payload, etc.</li> </ul>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#advanced-configuration","title":"Advanced configuration","text":"<p><pre><code>{\n  \"source\": {\n    \"id\": \"&lt;id-of-your-trello-resource&gt;\",\n    \"name\": \"&lt;name-of-your-trello-resource&gt;\"\n  },\n  \"board_url\": \"&lt;full-url-to-your-board-in-trello&gt;\",\n  \"list_name\": \"&lt;exact-name-of-your-trello-list&gt;\",\n  \"list_id\": \"&lt;check-note-below&gt;\",\n  \"card_name\": \"&lt;exact-name-of-your-trello-card&gt;\",\n}\n</code></pre> NOTE: list_id parameter does not matter. Tracardi uses it to store ID of found list. It should be left as \"\" or null.</p>"},{"location":"getting_started/processes/workflow/actions/trello/move_trello_card_action/#warning","title":"Warning","text":"<p>If you have two lists with same names on one board, then Tracardi will pick one of them, without a method of specifying which one will be picked. This rule also applies to the cards.</p>"},{"location":"installation/","title":"Tracardi Installation","text":"<ul> <li>Dependencies - Tracardi dependencies.</li> <li>Open Source - Open source version installation.</li> <li>Commercial - Commercial installation</li> <li>Development - Development environments</li> </ul>"},{"location":"installation/_keyclock/","title":"How to Set Up Tracardi with OAuth2","text":""},{"location":"installation/_keyclock/#important-note","title":"Important Note","text":"<p>Please be aware that OAuth2 integration is a premium feature and is not included in the open-source version of Tracardi.</p>"},{"location":"installation/_keyclock/#getting-started-with-keycloak-for-tracardi","title":"Getting Started with Keycloak for Tracardi","text":"<p>Tracardi utilizes Keycloak as its identity management tool. To begin using Keycloak, execute the following Docker command:</p> <pre><code>docker run -p 8080:8080 -e KEYCLOAK_USER=admin_user_placeholder -e KEYCLOAK_PASSWORD=admin_password_placeholder jboss/keycloak\n</code></pre> <p>In the command above, ensure that you replace <code>admin_user_placeholder</code> and <code>admin_password_placeholder</code> with your chosen admin username and password, respectively.</p>"},{"location":"installation/_keyclock/#important-warning","title":"Important Warning","text":"<p>Be cautious of port conflicts; specifically, the default port <code>8080</code> may clash with Apache Pulsar's port. If you encounter an error like:</p> <pre><code>Bind for 0.0.0.0:8080 failed: port is already allocated.\n</code></pre> <p>It indicates that the port is in use. To resolve this, modify the port mapping argument from <code>-p 8080:8080</code> to <code>-p 8081:8080</code> in the Docker command. This change maps the container's internal port <code>8080</code> to the external port <code>8081</code>, effectively avoiding the conflict.</p>"},{"location":"installation/_keyclock/#configuring-keycloak","title":"Configuring Keycloak","text":"<p>Once you've logged into Keycloak, you'll need to set up the realm and other necessary configurations for Tracardi integration.</p> <ol> <li> <p>Log in to Keycloak: Access the Keycloak administration console and log in.</p> </li> <li> <p>Create a New Realm: Hover over the 'Master' drop-down menu in the top left corner. This menu lists all created    realms and includes the option to 'Add Realm'. Click this to create a new realm. On the 'Add Realm' page, specify the    realm name and click 'Create'.</p> </li> <li> <p>Define Realm Settings: After creating the realm, configure the settings such as tokens, sessions, and    client registration.</p> </li> <li> <p>Create Clients: Within your realm's configurations, proceed to create and set up clients that Tracardi will    utilize for its authentication and authorization processes. Add a new client and set 'tracardi' as the ClientId.    Client ID can be passed to the GUI as env variable KC_CLIENT_ID. Ensure you configure    the <code>Valid Redirect URIs</code>, <code>Web Origins</code>, and <code>Backchannel Logout URL</code> are filled.</p> </li> <li> <p>In a development the setting, looks like this:</p> <ul> <li><code>Valid Redirect URIs</code> - http://localhost:8787/*</li> <li><code>Web Origins</code> - http://localhost:8787 or you man allow all sites then set *</li> <li><code>Backchannel Logout URL</code> http://localhost:8787 or leave it empty</li> </ul> </li> <li> <p>Manage Users and Roles: Set up users and define roles within the realm for access control.</p> </li> <li> <p>Configure Identity Providers: If integrating with external identity providers, configure them in the realm    settings.</p> </li> </ol>"},{"location":"installation/_pulsar/pulsar_k8s_apache_helm/","title":"Installing Pulsar on Kubernetes (K8s)","text":"<p>This tutorial provides step-by-step instructions for installing Apache Pulsar on a Kubernetes (K8s) cluster using the Apache Pulsar Helm chart. The following resources and dependencies are required:</p> <ul> <li>Pulsar Helm Chart Repository</li> <li>Pulsar Helm Chart Documentation</li> </ul>"},{"location":"installation/_pulsar/pulsar_k8s_apache_helm/#pulsar-dependencies","title":"Pulsar Dependencies","text":"<p>Before installing Apache Pulsar, ensure that the following dependencies are set up:</p>"},{"location":"installation/_pulsar/pulsar_k8s_apache_helm/#cert-manager","title":"Cert Manager","text":"<p>Cert Manager is used for managing TLS certificates in Kubernetes. We need to install it as a prerequisite for Pulsar.</p> <pre><code># Apply the Cert Manager CRDs (Custom Resource Definitions)\nkubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.13.0/cert-manager.crds.yaml\n\n# Add the Jetstack Helm repository\nhelm repo add jetstack https://charts.jetstack.io\nhelm repo update\n\n# Install Cert Manager\nhelm install --version v1.13.0 cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace\n</code></pre>"},{"location":"installation/_pulsar/pulsar_k8s_apache_helm/#certification-keys","title":"Certification Keys","text":"<p>To enable authentication in Apache Pulsar, both symmetric and asymmetric keys need to be installed as secrets.</p> <pre><code># Clone the Pulsar Helm Chart repository\ngit clone https://github.com/apache/pulsar-helm-chart\ncd pulsar-helm-chart\n\n# Generate secret keys and tokens for Pulsar super users\n# By default, it generates an asymmetric public/private key pair. Use --symmetric to generate a symmetric secret key.\n./scripts/pulsar/prepare_helm_release.sh -n pulsar -k pulsar --symmetric\n./scripts/pulsar/prepare_helm_release.sh -n pulsar -k pulsar\n</code></pre> <p>The <code>prepare_helm_release</code> script creates the following resources:</p> <ul> <li>A Kubernetes namespace named \"pulsar\" for installing the Pulsar release.</li> <li>JWT (JSON Web Token) secret keys and tokens for three super users: \"broker-admin,\" \"proxy-admin,\" and \"admin.\" These   roles have specific purposes in Pulsar:<ul> <li><code>broker-admin</code> role is used for inter-broker communications.</li> <li><code>proxy-admin</code> role is used for proxies to communicate with brokers.</li> <li><code>admin</code> role is used by the admin tools.</li> </ul> </li> </ul>"},{"location":"installation/_pulsar/pulsar_k8s_apache_helm/#local-path-provisioner","title":"Local Path Provisioner","text":"<p>Apache Pulsar requires local storage for certain functionalities. You can install the local path provisioner to provide this storage.</p> <pre><code># Apply the Local Path Provisioner YAML manifest\nkubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml\n</code></pre>"},{"location":"installation/_pulsar/pulsar_k8s_apache_helm/#pulsar-installation","title":"Pulsar Installation","text":"<p>With the dependencies in place, you can proceed to install Apache Pulsar using the Helm chart.</p> <pre><code># Install Pulsar using Helm\nhelm install pulsar -n pulsar -f /home/risto/pulsar/values.yaml apache/pulsar\n\n# To delete the Pulsar release, if needed\nhelm delete pulsar -n pulsar\n</code></pre> <p>Replace <code>/home/risto/pulsar/values.yaml</code> with the path to your Pulsar configuration values file if you have specific configurations to apply during the installation.</p> <p>This installation process deploys Apache Pulsar on your Kubernetes cluster, allowing you to utilize its powerful messaging and event streaming capabilities. Be sure to monitor the installation process and logs for any potential issues or errors.</p>"},{"location":"installation/_pulsar/pulsar_k8s_datastax_helm/","title":"Installing Pulsar using Datastax Helm Chart","text":""},{"location":"installation/_pulsar/pulsar_k8s_datastax_helm/#source","title":"Source","text":"<p>This tutorial is based on information form:</p> <ul> <li>https://datastax.github.io/pulsar-helm-chart/</li> <li>https://github.com/datastax/pulsar-helm-chart/blob/master/helm-chart-sources/pulsar/values.yaml</li> </ul>"},{"location":"installation/_pulsar/pulsar_k8s_datastax_helm/#helm-repository-installation","title":"Helm Repository Installation","text":"<pre><code>helm repo add datastax-pulsar https://datastax.github.io/pulsar-helm-chart\nhelm repo update\n</code></pre>"},{"location":"installation/_pulsar/pulsar_k8s_datastax_helm/#pulsar-dependencies","title":"Pulsar Dependencies","text":"<p>Before installing Apache Pulsar, ensure that the following dependencies are set up:</p>"},{"location":"installation/_pulsar/pulsar_k8s_datastax_helm/#cert-manager","title":"Cert Manager","text":"<p>Cert Manager is used for managing TLS certificates in Kubernetes. We need to install it as a prerequisite for Pulsar.</p> <pre><code># Apply the Cert Manager CRDs (Custom Resource Definitions)\nkubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.13.0/cert-manager.crds.yaml\n\n# Add the Jetstack Helm repository\nhelm repo add jetstack https://charts.jetstack.io\nhelm repo update\n\n# Install Cert Manager\nhelm install --version v1.13.0 cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace\n</code></pre>"},{"location":"installation/_pulsar/pulsar_k8s_datastax_helm/#pulsars-token-based-authentication","title":"Pulsar\u2019s Token Based Authentication","text":"<p>This token based authentication relies on a plugin provided by Apache Pulsar using the AuthenticationProviderToken class that ships with Pulsar.</p> <p>For authentication to work, the token-generation keys need to be stored in Kubernetes secrets along with some default tokens (for superuser access).</p> <p>The chart includes tooling to automatically create the necessary secrets, or you can do this manually. Automatic generation of secrets for token authentication</p> <p>Use these settings in <code>datastax-values.yaml</code> to enable automatic generation of the secrets and enable token-based authentication:</p> <pre><code>enableTokenAuth: true\nautoRecovery:\n  enableProvisionContainer: true\n</code></pre> <p>When the provision container is enabled, it will check if the required secrets exist. If they don\u2019t exist, it will generate new token keys and use those keys to generate the default set of tokens</p> <p>The name of the key secrets are:</p> <pre><code>token-private-key\ntoken-public-key\n</code></pre> <p>Using these keys, it will generate tokens for each role listed in superUserRoles. Based on the default settings, the following secrets will be created to store the tokens:</p> <pre><code>token-superuser\ntoken-admin\ntoken-proxy\ntoken-websocket\n</code></pre> <p>More information on token generation can be found here</p> <p>Tip</p> <p>Token stored in token-admin can be used to access Pulsar form client code. </p> <pre><code>helm upgrade --wait --install pulsar -f datastax-values.yaml datastax-pulsar/pulsar -n pulsar\n</code></pre>"},{"location":"installation/_pulsar/pulsar_k8s_datastax_helm/#example-of-datastax-valuesyaml","title":"Example of datastax-values.yaml","text":"<pre><code>#\n#  Copyright 2022 DataStax, Inc.\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n#\n#\n\nenableAntiAffinity: false\nenableTls: false\nenableTokenAuth: true\nrestartOnConfigMapChange:\n  enabled: true\nextra:\n  function: true\n  burnell: true\n  burnellLogCollector: true\n  pulsarHeartbeat: true\n  pulsarAdminConsole: false\n\nzookeeper:\n  replicaCount: 1\n  resources:\n    requests:\n      memory: 300Mi\n      cpu: 0.3\n  configData:\n    PULSAR_MEM: \"-Xms300m -Xmx300m -Djute.maxbuffer=10485760 -XX:+ExitOnOutOfMemoryError\"\n\nbookkeeper:\n  replicaCount: 1\n  resources:\n    requests:\n      memory: 512Mi\n      cpu: 0.3\n  configData:\n    BOOKIE_MEM: \"-Xms312m -Xmx312m -XX:MaxDirectMemorySize=200m -XX:+ExitOnOutOfMemoryError\"\n\nbroker:\n  component: broker\n  replicaCount: 1\n  ledger:\n    defaultEnsembleSize: 1\n    defaultAckQuorum: 1\n    defaultWriteQuorum: 1\n  resources:\n    requests:\n      memory: 600Mi\n      cpu: 0.3\n  configData:\n    PULSAR_MEM: \"-Xms400m -Xmx400m -XX:MaxDirectMemorySize=200m -XX:+ExitOnOutOfMemoryError\"\n\nautoRecovery:\n  replicaCount: 1\n  enableProvisionContainer: true\n  resources:\n    requests:\n      memory: 300Mi\n      cpu: 0.3\n\nfunction:\n  replicaCount: 1\n  functionReplicaCount: 1\n  resources:\n    requests:\n      memory: 512Mi\n      cpu: 0.3\n  configData:\n    PULSAR_MEM: \"-Xms312m -Xmx312m -XX:MaxDirectMemorySize=200m -XX:+ExitOnOutOfMemoryError\"\n\nproxy:\n  replicaCount: 1\n  resources:\n    requests:\n      memory: 512Mi\n      cpu: 0.3\n  wsResources:\n    requests:\n      memory: 512Mi\n      cpu: 0.3\n  configData:\n    PULSAR_MEM: \"-Xms400m -Xmx400m -XX:MaxDirectMemorySize=112m\"\n  autoPortAssign:\n    enablePlainTextWithTLS: true\n  service:\n    autoPortAssign:\n      enabled: false\n    ports:\n    - name: http\n      port: 8082\n      protocol: TCP\n    - name: pulsar\n      port: 6650\n      protocol: TCP\n    - name: ws\n      port: 8000\n      protocol: TCP\n\ngrafanaDashboards:\n  enabled: false\n\npulsarAdminConsole:\n  replicaCount: 1\n  service:\n    type: ClusterIP\n\nkube-prometheus-stack:\n  enabled: false\n  prometheusOperator:\n    enabled: false\n  grafana:\n    enabled: false\n    adminPassword: e9JYtk83*4#PM8\n</code></pre>"},{"location":"installation/commercial/","title":"Commercial Installation","text":"<p>This guide will provide step-by-step instructions for installing commercial Tracardi. Some aspects of this installation process are quite similar to the open-source installation.</p>"},{"location":"installation/commercial/#prerequisites","title":"Prerequisites","text":"<p>To set up Commercial Tracardi, you'll need access to DockerHub token and a valid commercial license key. This information will be sent to you after the purchase of the commercial license.</p>"},{"location":"installation/commercial/#docker-compose-installation","title":"Docker compose installation","text":"<p>The simplest approach to installing Tracardi is by using Docker Compose. It's important to note that this installation is intended for testing purposes only, as it doesn't configure and scale the dependant services properly.</p> <ol> <li>Installation via docker compose: One liner installation for testing purposes.</li> </ol>"},{"location":"installation/commercial/#kubernetes-installation-with-helm","title":"Kubernetes' installation with helm","text":"<ol> <li>Installation with Helm on K8S: Automates installation of all required Tracardi components.</li> </ol>"},{"location":"installation/commercial/#settings","title":"Settings","text":"<ol> <li>Open-source version env variables: Detailed information of open-source version    environment variables.</li> <li>Commercial version env variables: Detailed information of commercial version environment    variables.</li> </ol>"},{"location":"installation/commercial/env_variables/","title":"Commercial Tracardi Env Variables","text":"Environment Variable Description <code>PRIMARY_ID</code> Primary identifier for data. Default: <code>data.identifier.pk</code>. <code>PRIMARY_ID_AS_HASH</code> Whether to treat the primary identifier as a hash. Default: <code>no</code>. <code>EVENT_POOL</code> Size of the event pool. Default: <code>0</code>. <code>EVENT_POOL_INACTIVITY</code> Timeout for event pool inactivity (in seconds). Default: <code>5</code>. <code>ENABLE_PULSAR_FAIL_OVER_DB</code> Enable failover to the Pulsar database. Default: <code>no</code>. <code>ASYNC_STORE_BUFFER_TIMEOUT</code> Timeout for async store buffer (in milliseconds). Default: <code>1000</code>. <code>PULSAR_HOST</code> Pulsar host address. Default: <code>pulsar://localhost:6650</code>. <code>PULSAR_API</code> Pulsar API endpoint. Default: <code>http://localhost:8080</code>. <code>PULSAR_AUTH_TOKEN</code> Authentication token for Pulsar. Default: <code>None</code>. <code>PULSAR_TOPIC_TYPE</code> Pulsar topic type. Default: <code>persistent</code>. <code>PULSAR_TENANT</code> Pulsar tenant name. Default: <code>tracardi</code>. <code>PULSAR_CLUSTER</code> Pulsar cluster name. Default: <code>standalone</code>. <code>PULSAR_DISABLED</code> Whether Pulsar is disabled. Default: <code>no</code>. <code>PULSAR_SYSTEM_NAMESPACE</code> Pulsar system namespace. Default: <code>system</code>. <code>PULSAR_FUNCTION_TOPIC</code> Pulsar function topic. Default: <code>functions</code>. <code>PULSAR_COLLECTOR_POOL</code> Size of the Pulsar collector pool. Default: <code>1000</code>. <code>PULSAR_SERIALIZER</code> Serializer format for Pulsar messages. Default: <code>json</code>. <code>MAXMIND_HOST</code> MaxMind host. Default: <code>geolite.info</code>. <code>MAXMIND_LICENSE_KEY</code> License key for MaxMind. Default: <code>None</code>. <code>MAXMIND_ACCOUNT_ID</code> MaxMind account ID. Default: <code>0</code>. <code>AUDIENCE_ESTIMATION_MAX_CARDINALITY_COUNT</code> Maximum cardinality count for audience estimation. Default: <code>100000</code>."},{"location":"installation/commercial/services/","title":"Production services","text":"<p>This is the list services/dockers for production ready Tracardi installation.</p> Service Description Init Installation script. GUI Not exposed to the internet, VPN only. Public API Exposed to the internet, limited to collecting data only, no GUI. Private API Not exposed to the internet, VPN only, allows control of tracardi and its data. Background Worker Runs defined background process. APM Automatic profile merging worker. TMS Tracardi Tenant Managemetn System. Needed for multitenant setups. Update and Migration Set of workers for system migration and data import. Bridges Optional. Services for collecting data from different channels, bridges transportation protocol to Tracardi event source."},{"location":"installation/commercial/services/#collector-api","title":"Collector API","text":"<p>The Public API is the API that should be exposed to the internet. It has a limited API function that is designed specifically for collecting data. No GUI-like operations are available.</p>"},{"location":"installation/commercial/services/#access","title":"Access:","text":"<p>This API is accessible via the internet and can be utilized for collecting data.</p>"},{"location":"installation/commercial/services/#limitations","title":"Limitations:","text":"<p>The Collector API does not have any GUI operations available, and its functionality is limited to collecting data only.</p>"},{"location":"installation/commercial/services/#production-api","title":"Production API","text":"<p>The Production API is the API that should not be exposed to the internet. It has API functions that provide access to production data. Only users who are authorized to see real data should have opened accounts on this instance.</p>"},{"location":"installation/commercial/services/#access_1","title":"Access:","text":"<p>Access to the Production API is restricted and limited to authorized users only. Only users with opened accounts are allowed to access the production data through this API.</p>"},{"location":"installation/commercial/services/#limitations_1","title":"Limitations:","text":"<p>This API is not exposed to the internet, and access to production data is restricted to authorized users only.</p>"},{"location":"installation/commercial/services/#private-api","title":"Private API","text":"<p>The Staging API is the API that should not be exposed to the internet. It has API functions that provide access to test data. Access to this server should be limited to people working on data orchestration.</p>"},{"location":"installation/commercial/services/#access_2","title":"Access:","text":"<p>Access to the Staging API is restricted, and only personnel working on data orchestration should have access to this server.</p>"},{"location":"installation/commercial/services/#limitations_2","title":"Limitations:","text":"<p>This API is not exposed to the internet, and access to test data is restricted to personnel working on data orchestration.</p>"},{"location":"installation/commercial/services/#background-worker","title":"Background Worker","text":"<p>The Background Worker handles all background tasks, including triggering predefined workflows, storing events, and other similar jobs.</p>"},{"location":"installation/commercial/services/#update-and-migration","title":"Update and Migration","text":"<p>The Update and Migration is a set of workers responsible for system migration, data import, etc.</p>"},{"location":"installation/commercial/services/#functionality","title":"Functionality:","text":"<p>The Update and Migration workers are responsible for various tasks such as system migration and data import.</p>"},{"location":"installation/commercial/services/#bridges","title":"Bridges","text":"<p>This service is optional. The Bridges are services responsible for collecting data from different channels. They bridge the defined transportation protocol to tracardi event source.</p>"},{"location":"installation/commercial/services/#functionality_1","title":"Functionality:","text":"<p>The Bridges collect data from different channels and bridge the transportation protocol to the tracardi event source.</p>"},{"location":"installation/commercial/docker/docker/","title":"Docker-based Tracardi Commercial Installation","text":"<p>Note</p> <p>Make sure you have docker installed on your system.</p> <p>Note</p> <p>The following instalation description use the latest tracardi container version. If you would like to install stable version  of the system, what we strongly recommend, please add to <code>tracard/com-tracardi-api</code> a tag with version, e.g <code>tracardi/com-tracardi-api:0.8.1</code>.  The same applies to <code>tracardi/tracardi-gui</code>. Keep the version of API and GUI the same. </p>"},{"location":"installation/commercial/docker/docker/#prerequisites","title":"Prerequisites","text":""},{"location":"installation/commercial/docker/docker/#access-to-commercial-dockers","title":"Access to commercial dockers","text":"<p>When you buy a Tracardi license, you'll get a DockerHub token. This token lets you download the commercial dockers.</p> <p>Tracardi GUI looks the same in both the open-source and commercial versions. The only difference is the Tracardi API.</p> Login to Docker Hub<pre><code>docker login -u tracari -p &lt;token&gt;\n</code></pre> <p>Then create a file .env-docker and paste the LICENSE in it:</p> Set the LICENSE<pre><code>API_LICENSE=\"paste license here\"\n</code></pre> <p>When running linux:</p> Set the LICENSE<pre><code>set -a\nsource .env-docker\n</code></pre>"},{"location":"installation/commercial/docker/docker/#init-script","title":"Init script","text":"<p>Before you run any commercial docker please make sure that all dependencies are running and you start init script. This script will initialize all required databases, etc.:</p> docker run command to setup tracardi environment<pre><code>docker run \\\n-e LICENSE=xxx \\\n-e ELASTIC_HOST=http://&lt;elastic-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\n-e PULSAR_HOST=pulsar://&lt;pulsar-ip&gt;:6650 \\\n-e PULSAR_API=http://&lt;pulsar-ip&gt;:8080 \\\n-e LOGGING_LEVEL=info \\\ntracardi/init:&lt;last-version&gt;\n</code></pre> <p>Please ensure that you replace <code>&lt;...-ip&gt;</code> with the actual IP address of your service instance.</p>"},{"location":"installation/commercial/docker/docker/#tracardi-api","title":"Tracardi API","text":"<p>Pull and run Tracardi backend.</p> <pre><code>docker run -p 8686:80 \\\n-e LICENSE=xxx \\\n-e ELASTIC_HOST=http://&lt;elastic-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\n-e PULSAR_HOST=pulsar://&lt;pulsar-ip&gt;:6650 \\\n-e PULSAR_API=http://&lt;pulsar-ip&gt;:8080 \\\n-e LOGGING_LEVEL=info \\\ntracardi/com-tracardi-api:&lt;last-version&gt; #(1)\n</code></pre> <ol> <li>Replace <code>&lt;elastic-ip&gt;</code> with your elastic IP. Do the same for <code>&lt;redis-ip&gt;</code>, <code>&lt;mysq-ip&gt;</code>, and <code>&lt;pulsar-ip&gt;</code>. Replace &lt;    last-version&gt; with the latest version. Do not use latest.</li> </ol> <p>Tracardi must connect to elasticsearch. To do that you have to set ELASTIC_HOST variable to reference your elasticsearch instance.</p> <p>Please use the version tag</p> <p>Please use only docker with version tag. Do not use latest tag. See the the version in docker hub. </p> <p>Waiting for application startup</p> <p>Notice that when type <code>http://localhost:9200</code> you try to connect to Elastic on localhost. This means that you're connecting to the docker itself as localhost means local in docker. Obviously elastic is not there, so Tracardi will never connect. Pass external ip for elastic. This may be your laptop IP if you are running Tracardi locally.</p>"},{"location":"installation/commercial/docker/docker/#test-installation","title":"Test installation","text":"<p>To test API visit http://127.0.0.1:8686</p>"},{"location":"installation/commercial/docker/docker/#tracardi-gui","title":"Tracardi GUI","text":"<p>Pull and run Tracardi Graphical User Interface.</p> <pre><code>docker run -p 8787:80 tracardi/tracardi-gui:&lt;last-version&gt; #(1)\n</code></pre> <ol> <li>If you want a certain version of docker image add version tag, e.g. <code>tracardi/tracardi-gui:0.8.1</code></li> </ol> <p>Please use the version tag</p> <p>Please use only docker with version tag. See the latest version in docker hub. </p>"},{"location":"installation/commercial/docker/docker/#run-tracardi-gui","title":"Run Tracardi GUI","text":"<p>Visit http://127.0.0.1:8787 and follow the instructions to finish up the Tracardi set-up. When asked for Tracardi API type: http://127.0.0.1:8686.</p>"},{"location":"installation/commercial/docker/docker/#tracardi-workers-installation","title":"Tracardi Workers Installation","text":"<p>Tracardi relies on four different workers to ensure smooth operations and efficient processing of data. Each worker serves a specific purpose in the Tracardi ecosystem. Below are details about each worker and instructions on how to set them up.</p>"},{"location":"installation/commercial/docker/docker/#open-source-workers","title":"Open-source workers","text":""},{"location":"installation/commercial/docker/docker/#1-migration-and-update-worker","title":"1. Migration and Update Worker","text":"<p>The Migration and Update Worker is responsible for system upgrades and data import tasks, which are carried out in the background. It ensures a seamless transition when updating the Tracardi system and handles data imports efficiently.</p> <p>To run the Migration and Update Worker, execute the following Docker command:</p> docker run command<pre><code>docker run \\\n-e ELASTIC_HOST=http://&lt;elasitc-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\ntracardi/update-worker:&lt;last-version&gt;\n</code></pre> <p>Please ensure that you replace <code>&lt;...-ip&gt;</code> with the actual IP address of your service instance.</p>"},{"location":"installation/commercial/docker/docker/#2-automatic-profile-merging-worker-apm","title":"2. Automatic Profile Merging Worker (APM)","text":"<p>The APM Worker is responsible for auto merging profiles with the same emails.</p> <p>To run the APM Worker, execute the following Docker command:</p> docker run command<pre><code>docker run \\\n-e ELASTIC_HOST=http://&lt;elasitc-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\n-e MODE=worker \\\n-e PAUSE=5 \\\ntracardi/apm:&lt;last-version&gt;\n</code></pre> <p>Please ensure that you replace <code>&lt;...-ip&gt;</code> with the actual IP address of your service instance.</p>"},{"location":"installation/commercial/docker/docker/#commercial-workers","title":"Commercial workers","text":"<p>In order to install commercial version you will need to log-in to docker hub with our credentials.</p> <pre><code>docker login -u tracardi -p &lt;token&gt;\n</code></pre> <p>And paste the credentials that we have sent you.</p>"},{"location":"installation/commercial/docker/docker/#1-tenant-management-system-tms","title":"1. Tenant Management System (TMS)","text":"<p>The Tenant Management System (TMS) is a dedicated microservice responsible for managing various aspects related to tenants within a system or platform, particularly in a multi-tenant environment. I</p> <p>To run this worker, execute the following Docker command:</p> docker run command<pre><code>docker run -p 8081:80 \\\n-e API_KEY=&lt;random-api-key&gt; \\\n-e SECRET=&lt;random-secret&gt; \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\ntracardi/tms:&lt;last-version&gt;\n</code></pre> <p>Set  and  to random values."},{"location":"installation/commercial/docker/docker/#2-background-worker","title":"2. Background Worker","text":"<p>The Background Worker is a commercial worker responsible for processing background jobs.</p> <p>To run the Background Worker, execute the following Docker command:</p> docker run command<pre><code>docker run \\\n-e LICENSE=xxx \\\n-e ELASTIC_HOST=http://&lt;elastic-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\n-e PULSAR_HOST=pulsar://&lt;pulsar-ip&gt;:6650 \\\n-e PULSAR_API=http://&lt;pulsar-ip&gt;:8080 \\\n-e LOGGING_LEVEL=info \\\ntracardi/background-worker:&lt;last-version&gt;\n</code></pre> <p>Please ensure that you replace <code>&lt;...-ip&gt;</code> with the actual IP address of your service instance.</p>"},{"location":"installation/commercial/docker/docker_compose/","title":"Commercial Tracardi with docker compose","text":"<p>This guide provides a brief introduction on how to install and test the commercial version of Tracardi using docker-compose. Please note that this installation is not intended for production use, but rather for testing purposes only.</p> <p>In order to install commercial version you will need to log-in to docker hub with our credentials.</p> <pre><code>docker login -u tracardi -p &lt;token&gt;\n</code></pre> <p>And paste the credentials that we have sent you.</p>"},{"location":"installation/commercial/docker/docker_compose/#set-up-license-key","title":"Set up License Key","text":"<p>Then create a file .env-docker and paste the LICENSE in it:</p> <pre><code>API_LICENSE=\"paste license here\"\n</code></pre> <p>When running linux:</p> <pre><code>set -a\nsource .env-docker\n</code></pre>"},{"location":"installation/commercial/docker/docker_compose/#clone-tracardi-api","title":"Clone Tracardi API","text":"<pre><code>git clone https://github.com/Tracardi/tracardi-api.git\ncd tracardi-api\ngit checkout 1.0.0\n</code></pre>"},{"location":"installation/commercial/docker/docker_compose/#run-docker-compose-dependencies","title":"Run docker compose (Dependencies)","text":"<p>Go to TRACARDI API folder, and run one line command:</p> <pre><code>docker-compose -f com-dep-docker-compose.yaml up\n</code></pre> <p>Note</p> <p>To run docker compose in the background add <code>-d</code> to the command above.</p> <p>Warning</p> <p>Installed dependencies with the above docker compose may not have properly set storages so restarting will cause DATA LOSS.</p>"},{"location":"installation/commercial/docker/docker_compose/#run-docker-compose-tracardi","title":"Run docker compose (Tracardi)","text":"<p>Go to TRACARDI API folder, and run one line command:</p> <pre><code>docker-compose -f com-app-docker-compose.yaml up\n</code></pre> <p>Note</p> <p>To run docker compose in the background add <code>-d</code> to the command above.</p> <p>Warning</p> <p>Tracardi, to operate with its full range of features, requires the presence of specific crontab jobs.  It's important to note that when using Docker Compose, these crontab jobs are not automatically included as  part of the setup. Therefore, to ensure that Tracardi functions as intended, it is essential to perform an  additional crontab installation.</p>"},{"location":"installation/commercial/docker/docker_compose/#upgrading-docker-compose","title":"Upgrading docker compose","text":"<ol> <li>Stopping Docker Compose</li> </ol> <p>Prior to upgrading, ensure that your Docker Compose configuration is not running. Execute the following command in your terminal:</p> <pre><code>docker compose down\n</code></pre> <ol> <li>Pulling New Images</li> </ol> <p>To upgrade to the latest version, fetch the latest Docker images for the components. Run the following commands in your terminal:</p> <pre><code>docker pull tracardi/tracardi-api:1.0.0\ndocker pull tracardi/tracardi-gui:1.0.0\ndocker pull tracardi/update-worker:1.0.0\ndocker pull tracardi/com-tracardi-api:1.0.0\ndocker pull tracardi/amp:1.0.0\ndocker pull tracardi/tms:1.0.0\ndocker pull tracardi/background-worker:1.0.0\ndocker pull tracardi/init:1.0.0\n</code></pre>"},{"location":"installation/commercial/docker/docker_compose/#handling-errors","title":"Handling Errors","text":"<p>If you encounter errors while bringing up the upgraded Docker Compose setup, it might be necessary to address these errors by deleting certain components. Follow the steps below:</p> <ul> <li>To stop all running containers (make sure that there are no other container running but the tracardi containers),   execute:</li> </ul> <pre><code>docker kill $(docker ps -q)\n</code></pre> <ul> <li>To delete unused containers, volumes, images, and networks, run:</li> </ul> <pre><code>docker container prune\ndocker volume prune\ndocker image prune\ndocker network prune\n</code></pre>"},{"location":"installation/commercial/helm/","title":"Helm-Based Production Installation","text":"<p>For commercial installation using helm charts, follow these steps:</p> <ul> <li>Installation via Helm Chart version 0.8.2 </li> <li>Installation via Helm Chart version 0.9.0</li> </ul>"},{"location":"installation/commercial/helm/helm_082/","title":"Installation with HelmChart version 0.8.2","text":"<p>This document provides comprehensive instructions for installing the commercial Tracardi application on a Kubernetes ( K8s) cluster using the Helm chart.</p>"},{"location":"installation/commercial/helm/helm_082/#prerequisites","title":"Prerequisites","text":"<p>Before initiating the installation process, ensure you have completed the following prerequisites:</p> <ol> <li> <p>Install K8S and Helm: Make sure that you have installed K8S and Helm.</p> </li> <li> <p>Obtain Helm Chart and License Information: Upon agreeing to the license agreement, you will receive a Helm chart    archive. Extract the contents of this archive into a folder named \"tracardi\". You will also receive a Docker Hub    login token, which is required to access the commercial Docker images. Additionally, make sure you have the Tracardi    license key.</p> </li> <li> <p>Install Dependant Services: Elasticsearch, redis, mysql and apache pulsar are required. </p> </li> <li> <p>Elasticsearch, Redis, Mysql, Apache Pulsar Credentials: Gather for all required services it will be necessary during the installation process.</p> </li> </ol>"},{"location":"installation/commercial/helm/helm_082/#namespace-creation","title":"Namespace Creation","text":"<p>Execute the following command to create a Kubernetes namespace named \"tracardi\":</p> <pre><code>kubectl create ns tracardi\n</code></pre>"},{"location":"installation/commercial/helm/helm_082/#docker-hub-access-configuration","title":"Docker Hub Access Configuration","text":"<p>Configure access to Docker Hub by creating a Kubernetes secret containing your Docker Hub login token. Use the following command:</p> <pre><code>kubectl create secret docker-registry tracardi-dockerhub \\\n    --docker-server=index.docker.io/v1/  \\\n    --docker-username=tracardi \\\n    --docker-password=&lt;docker-hub-token&gt; \\\n    -n tracardi\n</code></pre>"},{"location":"installation/commercial/helm/helm_082/#system-secrets-configuration","title":"System Secrets Configuration","text":"<p>To proceed with the installation, you need to set up essential system secrets including the license key, Elasticsearch password, and Redis password. Create a Kubernetes secret file, as illustrated in the example below:</p> <p>Save this content as \"tracardi-secrets.yaml\":</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: elastic-secret\ntype: Opaque\ndata:\n  elastic: &lt;base64-elastic-password&gt;\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: redis-secret\ntype: Opaque\ndata:\n  redis-password: &lt;base64-redis-password&gt;\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: tracardi-license\ntype: Opaque\ndata:\n  key: &lt;base64-license-key&gt;\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: tms\ntype: Opaque\ndata:\n  secret: &lt;base64-tms-secret&gt;\n  api-key: &lt;base64-tms-api-key&gt;\n</code></pre> <p>Apply this secret configuration using the following command:</p> <pre><code>kubectl apply -f tracardi-secrets.yaml -n tracardi\n</code></pre>"},{"location":"installation/commercial/helm/helm_082/#helm-chart-default-configuration","title":"Helm chart default configuration","text":"<p>The configuration details are defined in the file <code>tracardi/values.yaml</code> (look inside the helm-chart.zip). Please note that these settings may experience slight variations from one version to another. As of version 0.8.1, the default configuration is presented below:</p> <pre><code>secrets:\n  installationToken: \"SET-INSTALLATION-SECRET\"\n  dockerHub: \"tracardi-dockerhub\"\n  license:\n    secretName: \"tracardi-license\"\n    secretKey: \"license-key\"\n  tms:\n    secretName: \"tms\"\n    secret:\n      secretKey: \"secret\"\n    apiKey:\n      secretKey: \"api-key\"\n\nconfig:\n  multiTenant:\n    multi: \"no\"\n    tms_service: tms-svc\n  image:\n    tag: 0.8.1\n    api:\n      repository: tracardi/com-tracardi-api\n      pullPolicy: IfNotPresent\n    gui:\n      repository: tracardi/tracardi-gui\n      pullPolicy: IfNotPresent\n    tms:\n      repository: tracardi/tms\n      pullPolicy: IfNotPresent\n\ngui:\n  port: 8787\n  replicas: 1\n  ingress:\n    enabled: false\n    domain: gui.tracardi.example.com\n    ingressClassName: \"\"\n    tls:\n      enable: true\n      secretName: \"\"\n    annotations: { }\n\n# (More sections like 'tms', 'collector', 'staging', etc.)\n\n# Infrastructure\n\nelastic:\n  host: \"elastic-svc\"\n  schema: https\n  username: \"elastic\"\n  existingSecret: \"elastic-secret\"\n  existingSecretPasswordKey: \"elastic\"\n  verifyCerts: \"no\"\n  port: 9200\n\nredis:\n  existingSecret: \"redis-secret\"\n  existingSecretPasswordKey: \"redis-password\"\n  schema: \"redis://\"\n  host: redis-svc\n  port: \"6379\"\n  db: \"0\"\n</code></pre> <p>Please be aware that the above configuration is illustrative and may change across different versions of Tracardi.</p>"},{"location":"installation/commercial/helm/helm_082/#installing-helm-chart-with-default-values","title":"Installing helm chart with default values","text":"<p>Run the following command to install tracardi with default settings:</p> <pre><code>helm install tracardi tracardi -n tracardi\n</code></pre> <p>This will install tracardi in tracardi namespace.</p>"},{"location":"installation/commercial/helm/helm_082/#custom-configuration-overrides","title":"Custom Configuration Overrides","text":"<p>If you wish to tailor the default configuration to better suit your specific requirements, you have the flexibility to override default values. To achieve this, follow these steps:</p> <ol> <li> <p>Duplicate <code>values.yaml</code>: Copy the <code>tracardi/values.yaml</code> file to a new file, such as <code>settings.yaml</code>.</p> </li> <li> <p>Modify Settings: Within the newly created <code>settings.yaml</code>, remove any configuration entries that you wish to    retain as per the default settings. Keep only those settings that you intend to customize.</p> </li> </ol>"},{"location":"installation/commercial/helm/helm_082/#running-helm-with-custom-values","title":"Running helm with custom values","text":"<p>Run the following command to install tracardi with default settings</p> <pre><code>helm install --values settings.yaml tracardi tracardi -n tracardi\n</code></pre>"},{"location":"installation/commercial/helm/helm_082/#upgrading-the-helm-installation","title":"Upgrading the helm installation","text":"<pre><code>helm upgrade --wait --timeout=1200s --install --values settings.yaml tracardi tracardi -n tracardi\n</code></pre>"},{"location":"installation/commercial/helm/helm_082/#configuration-changes","title":"Configuration Changes","text":"<p>The YAML file contains distinct sections that configure various aspects of the Tracardi setup. Each section corresponds to a specific component or functionality within Tracardi.</p>"},{"location":"installation/commercial/helm/helm_082/#infrastructure-configuration","title":"Infrastructure Configuration","text":"<p>The \"Infrastructure\" section is dedicated to establishing connections with Elasticsearch and Redis, which are components of the Tracardi system. The configuration settings within this section enable communication with these backend services. Here is an example of how these connections are configured:</p> <pre><code># Infrastructure\n\nelastic:\n  host: \"elastic-svc\"\n  schema: https\n  username: \"elastic\"\n  existingSecret: \"elastic-secret\"\n  existingSecretPasswordKey: \"elastic\"\n  verifyCerts: \"no\"\n  port: 9200\n\nredis:\n  host: redis-svc\n  schema: \"redis://\"\n  existingSecret: \"redis-secret\"\n  existingSecretPasswordKey: \"redis-password\"\n  port: \"6379\"\n  db: \"0\"\n</code></pre> <ul> <li><code>elastic</code> section configures the connection to Elasticsearch with details such as the host, schema (using HTTPS),   username, and references an existing secret named \"elastic-secret\" that contains the necessary authentication   credentials.</li> <li><code>redis</code> section configures the connection to Redis with details including the host, schema, and an existing secret   named \"redis-secret\" that contains the required password for authentication.</li> </ul>"},{"location":"installation/commercial/helm/helm_082/#general-configuration","title":"General configuration","text":"<p>The \"General Configuration\" section encapsulates settings related to Docker images and their versions, as well as the configuration for enabling or disabling the multitenant mode of the system.</p> <pre><code>config:\n  multiTenant:\n    multi: \"no\"\n    tms_service: tms-svc  # The name of the tms service\n  image:\n    tag: 0.8.1  # Tag should be the same for GUI and backend\n    api:\n      repository: tracardi/com-tracardi-api\n      pullPolicy: IfNotPresent\n    gui:\n      repository: tracardi/tracardi-gui\n      pullPolicy: IfNotPresent\n    tms:\n      repository: tracardi/tms\n      pullPolicy: IfNotPresent\n</code></pre> <ul> <li><code>multiTenant</code>: This sub-section defines whether the system should operate in multitenant mode. By setting the value   to <code>\"no\"</code>, the system is configured for single-tenant operation. The <code>tms_service</code> specifies the name of the tms   service.</li> <li><code>image</code>: This sub-section details the Docker images and their corresponding versions for different components. The   specified Docker image repositories and tags determine which images to use for the GUI, API, and TMS services.   The <code>pullPolicy</code> specifies whether the system should pull the image if it's not present.</li> </ul>"},{"location":"installation/commercial/helm/helm_082/#api-installation","title":"API installation","text":"<p>Here's an example of how the Tracardi API collector is configured by default. This configuration example allows you to define the collector's port, the number of replicas if enabled, and several configuration settings.</p> <pre><code>collector:\n  enabled: true       # Whether the collector should be enabled\n  port: 8484          # Port the collector will be exposed on\n  replicas: 1         # Number of replicas if enabled\n  config:\n    saveLogs: \"no\"    # Whether to save logs\n    loggingLevel: \"WARNING\"  # Log verbosity level\n    apiDocs: \"no\"     # Whether to enable API documentation\n    enableWorkflow: \"yes\"    # Whether to enable workflow\n    enableEventDestinations: \"yes\"   # Whether to enable event destinations\n    enableProfileDestinations: \"yes\" # Whether to enable profile destinations\n</code></pre> <p>By modifying these settings, you can adapt Tracardi to your specific use case. The <code>enabled</code> flag determines whether the collector is active, the <code>port</code> specifies the port number it will listen on, and <code>replicas</code> allows you to define the desired number of replicas. The <code>config</code> section enables you to fine-tune various operational aspects such as logging behavior, API documentation availability, and the activation of different functionalities like workflow, event destinations, and profile destinations.</p> <p>Each section has similar settings.</p>"},{"location":"installation/commercial/helm/helm_082/#installing-helm-chart-with-custom-replicas-and-ports","title":"Installing Helm Chart with Custom Replicas and Ports","text":"<p>To install the Tracardi Helm chart with custom settings, you can create a custom configuration file and modify the desired parameters. Here's an example using a file named <code>settings.yaml</code> to adjust the number of replicas and expose services on different ports:</p>"},{"location":"installation/commercial/helm/helm_082/#example-settingsyaml","title":"Example <code>settings.yaml</code>","text":"<pre><code># Definition of defined secrets.\n\nsecrets:\n  installationToken: \"my-installation-token\"\n\n# General Tracardi configuration. Version, images, multi-tenancy, etc.\n\nconfig:\n  image:\n    tag: 0.8.1\n\n# Settings per service\n\ngui:\n  port: 80        # Custom port for the GUI service\n  replicas: 2     # Increase the number of GUI replicas to 2\n\ntms:\n  enabled: false  # Disable the TMS service\n\ncollector:\n  enabled: true   # Enable the collector service\n  port: 8080      # Custom port for the collector service\n  replicas: 10    # Increase the number of collector replicas to 10\n\nstaging:\n  enabled: true   # Enable the staging service\n  port: 8081      # Custom port for the staging service\n  replicas: 3     # Increase the number of staging replicas to 3\n</code></pre> <p>In this example, the <code>settings.yaml</code> file is tailored to modify the Tracardi installation according to your preferences. It increases the number of replicas for the GUI, collector, and staging services while also specifying custom ports for the GUI, collector, and staging services.</p> <p>To install Tracardi using these custom settings, you can run the following Helm command:</p> <pre><code>helm install tracardi ./tracardi -f settings.yaml -n tracardi\n</code></pre> <p>This approach allows you to easily adjust the deployment configuration to match your requirements while maintaining the core Helm chart intact.</p>"},{"location":"installation/commercial/helm/helm_090/","title":"Installation with HelmChart after version 0.9.0","text":"<p>This document provides comprehensive instructions for installing the commercial Tracardi application on a Kubernetes ( K8s) cluster using the Helm chart.</p>"},{"location":"installation/commercial/helm/helm_090/#prerequisites","title":"Prerequisites","text":"<p>Before initiating the installation process, ensure you have completed the following prerequisites:</p> <ol> <li> <p>Install K8S and Helm: Make sure that you have installed K8S and Helm.</p> </li> <li> <p>Obtain Helm Chart and License Information: Upon agreeing to the license agreement, you will receive a Helm chart    archive. Extract the contents of this archive into a folder named \"tracardi\". You will also receive a Docker Hub    login token, which is required to access the commercial Docker images. Additionally, make sure you have the Tracardi    license key.</p> </li> <li>Install dependencies (ElasticSearch, Redis, Apache Pulsar, Mysql)</li> </ol> <p>Advice</p> <p>We strongly recommend setting up the dependent services (Redis, Elasticsearch, MySQL, and Pulsar) in separate   namespaces. This strategy has several advantages:</p> <ol> <li>Upgrade Management: Each new version of Tracardi can be deployed in a new namespace, facilitating migration and      testing without disrupting the current setup.</li> <li>Isolation: Keeping dependencies isolated helps in managing and troubleshooting issues more effectively.</li> <li>Avoiding In-Place Upgrades: Placing everything in one namespace would necessitate an in-place upgrade for      Tracardi, which is not recommended due to the increased risk of disruptions and complications.</li> </ol>"},{"location":"installation/commercial/helm/helm_090/#overall-process-description","title":"Overall process description","text":"<p>The installation takes the following steps:</p> <ul> <li>Dependencies installation</li> <li>Init script for dependencies setup (it is part of the tracardi pod)</li> <li>API/GUI and workers installation</li> </ul>"},{"location":"installation/commercial/helm/helm_090/#installation-settings","title":"Installation settings","text":"<p>Installation will need setting that will connect tracardi with its database, cache, etc.</p> <p>You must customize the deployment by providing your own <code>values.yaml</code> file where you will set up the required credentials.</p>"},{"location":"installation/commercial/helm/helm_090/#using-custom-values-in-helm-charts","title":"Using Custom Values in Helm Charts","text":"<p>To use custom values when installing a Helm chart, you create a custom <code>values.yaml</code> file and pass it to the <code>helm install</code> command using the <code>-f</code> or <code>--values</code> flag. Here's the general syntax:</p> <pre><code>helm install [RELEASE_NAME] [CHART] -f [PATH_TO_YOUR_CUSTOM_VALUES_FILE]\n</code></pre> <p>For example:</p> <pre><code>helm install tracardi tracardi -f my-custom-values.yaml\n</code></pre> <p>How Custom Values Override Default Values</p> <ol> <li> <p>Default Values: Each Helm chart includes a <code>values.yaml</code> file that defines the default configuration. Description of    default custom values will be described below.</p> </li> <li> <p>Custom Values: When you provide a custom <code>values.yaml</code> file, the values specified in this file take precedence over    the corresponding default values.</p> </li> <li> <p>Merge Process: Helm doesn't completely replace the default values file. Instead, it performs a deep merge of your    custom values with the default values.</p> </li> <li> <p>Overriding: Only the values you specify in your custom file will override the defaults. All other values remain    unchanged.</p> </li> <li> <p>Nested Values: For nested structures, you can override specific nested values without affecting the entire structure.</p> </li> <li> <p>Arrays: When overriding array values, your custom values completely replace the default array.</p> </li> </ol>"},{"location":"installation/commercial/helm/helm_090/#minimal-values-file","title":"Minimal values file","text":"<p>Minimal configuration will require connection to all dependant services with credentials. </p> <p>```yaml tilte=\"Example of minimal custom values.yaml file\"</p>"},{"location":"installation/commercial/helm/helm_090/#infrastructure","title":"Infrastructure","text":"<p>elastic:   name: es1   host: cluster-es-http.elastic.svc.cluster.local  # Address of elastic-search installation   schema: https   authenticate: true   port: 9200   verifyCerts: \"no\"</p> <p>redis:   name: rd1   host: redis-master.redis.svc.cluster.local  # Address of redis installation   schema: \"redis://\"   authenticate: true   port: 6379   db: \"0\"</p> <p>pulsar:   name: ps1   host: pulsar-proxy.pulsar.svc.cluster.local:6650  # Address of apache pulsar installation   api: http://pulsar-broker.pulsar.svc.cluster.local:8080   schema: \"pulsar://\"   authenticate: true   port: 6650</p> <p>mysql:   name: ms1   host: percona-db-pxc-db-haproxy.percona.svc.cluster.local  # Address of mysql installation   schema: \"mysql+aiomysql://\"   database: \"tracardi\"   port: 3306</p> <p>secrets:   installation:     token: \"random-token\"   license:     licenseKey: \"license-key\"   redis:     password: \"redis-password\"   elastic:     username: \"elasticsearch-username\"     password: \"elasticsearch-password\"   pulsar:     token: \"pulsar-token\"   mysql:     username: \"mysql-username\"     password: \"mysql-password\"   tms:     secretKey: \"random-tms-secret-key\"     apiKey: \"random-tms-api-key\" <pre><code>### Detailed local installation settings\n\nTo customize your installation create local `values.yaml` file and define custom setting for your setup.\n\nYour custom `values.yaml` file will contain only the values you wish to change from the defaults. Any values not\nspecified in your custom file will use the defaults provided by the HelmChart. This approach keeps your configuration\nconcise and easy to manage.\n\n### Configuration of Services Used by Tracardi\n\nDependencies configuration is the part in helm configuration that defines all the services that Tracardi needs to connect to. \n\n#### Elasticsearch Configuration\n\nThe Elasticsearch configuration specifies the necessary settings to connect Tracardi to an Elasticsearch service. This\nincludes the host, port, schema, and authentication details. Here's a detailed breakdown:\n\n```yaml\nelastic:\n  name: es1  # The name identifier for the Elasticsearch service\n  host: elastic-std-svc.elastic-standalone.svc.cluster.local  # The hostname for the Elasticsearch service\n  schema: http  # The schema to use for connecting to Elasticsearch (http/https)\n  authenticate: false  # Whether to use authentication when connecting to Elasticsearch\n  port: 9200  # The port on which Elasticsearch is running\n  verifyCerts: \"no\"  # Whether to verify SSL certificates (yes/no)\n  index:\n    shards: 3  # Number of primary shards for the index\n    replicas: 1  # Number of replica shards for the index\n</code></pre></p> Field Description Needs change name Identifier for the Elasticsearch service host Hostname or IP address of the Elasticsearch service yes schema Protocol used to connect (http or https) yes authenticate Toggle for enabling authentication. See secrets part for authentication. yes port Port number on which Elasticsearch is running verifyCerts Indicates whether SSL certificates should be verified index.shards Number of primary shards for the index Use default or change index.replicas Number of replica shards for the index Use default or change"},{"location":"installation/commercial/helm/helm_090/#redis-configuration","title":"Redis Configuration","text":"<p>The Redis configuration sets up the connection details for the Redis service, including the host, port, and database number.</p> <pre><code>redis:\n  name: rd1  # The name identifier for the Redis service\n  host: redis-std-svc.redis-standalone.svc.cluster.local  # The hostname for the Redis service\n  schema: \"redis://\"  # The schema to use for connecting to Redis\n  authenticate: false  # Whether to use authentication when connecting to Redis\n  port: 6379  # The port on which Redis is running\n  db: \"0\"  # The database number to use in Redis\n</code></pre> Field Description Needs change name Identifier for the Redis service host Hostname or IP address of the Redis service yes schema Protocol used to connect (e.g., redis://) authenticate Toggle for enabling authentication yes port Port number on which Redis is running db Redis database number to use"},{"location":"installation/commercial/helm/helm_090/#apache-pulsar-configuration","title":"Apache Pulsar Configuration","text":"<p>The Apache Pulsar configuration includes settings for connecting to the Pulsar service, including the host, port, and whether to enable Pulsar.</p> <pre><code>pulsar:\n  name: ps1  # The name identifier for the Pulsar service\n  host: pulsar-std-svc.pulsar-standalone.svc.cluster.local  # The hostname for the Pulsar service\n  api: \"http://pulsar-std-svc.pulsar-standalone.svc.cluster.local:8080\"  # API endpoint for Pulsar\n  schema: \"pulsar://\"  # The schema to use for connecting to Pulsar\n  authenticate: false  # Whether to use authentication when connecting to Pulsar\n  port: 6650  # The port on which Pulsar is running\n  cluster_name: pulsar  # The cluster name for Pulsar\n  enabled: true  # Whether Pulsar is enabled\n</code></pre> Field Description needs change name Identifier for the Pulsar service host Hostname or IP address of the Pulsar service yes api API endpoint for Pulsar yes schema Protocol used to connect (e.g., pulsar://) authenticate Toggle for enabling authentication yes port Port number on which Pulsar is running cluster_name Name of the Pulsar cluster enabled Toggle to enable or disable Pulsar"},{"location":"installation/commercial/helm/helm_090/#mysql-configuration","title":"MySQL Configuration","text":"<p>The MySQL configuration details the settings for connecting to a MySQL service, including the host, port, and database name.</p> <pre><code>mysql:\n  name: ms1  # The name identifier for the MySQL service\n  host: percona-db-pxc-db-haproxy.percona.svc.cluster.local  # The hostname for the MySQL service\n  schema: \"mysql+aiomysql://\"  # The schema to use for connecting to MySQL\n  database: \"tracardi\"  # The database name to use in MySQL\n  port: 3306  # The port on which MySQL is running\n</code></pre> Field Description Needs change name Identifier for the MySQL service host Hostname or IP address of the MySQL service yes schema Protocol used to connect (e.g., mysql+aiomysql://) database Name of the database to use port Port number on which MySQL is running"},{"location":"installation/commercial/helm/helm_090/#tenant-management-service-tms-api-configuration","title":"Tenant Management Service (TMS) API Configuration","text":"<p>The TMS API configuration outlines the settings for the Tenant Management Service, a microservice responsible for managing tenants in a multi-tenant environment.</p> <pre><code>tmsApi:\n  host: be-fa-tms-svc.tracardi-com-090.svc.cluster.local  # The hostname for the TMS API service\n  database: \"tms\"  # The database name to use in TMS API\n</code></pre> Field Description Needs change host Hostname or IP address of the TMS API service yes database Name of the database to use in TMS API <p>Here's an example <code>values.yaml</code> file where only the required fields are changed. This is the example for resource configuration. See other parts below</p> <pre><code># Elasticsearch configuration. Set required values like elastic.host\nelastic:\n  host: elastic-std-svc.elastic-standalone.svc.cluster.local\n  authenticate: true\n\n# Redis configuration. \nredis:\n  host: redis-std-svc.redis-standalone.svc.cluster.local\n  authenticate: true\n\n# Apache Pulsar configuration. Set required fields like pulsar.host, pulsar.api\npulsar:\n  host: pulsar-std-svc.pulsar-standalone.svc.cluster.local\n  api: \"http://pulsar-std-svc.pulsar-standalone.svc.cluster.local:8080\"\n  enabled: true  # Enable Pulsar for this configuration\n  authenticate: true\n\n# MySQL configuration. Set mysql.host required.\nmysql:\n  host: percona-db-pxc-db-haproxy.percona.svc.cluster.local\n\n# TMS API configuration. Change tmsApi.host\ntmsApi:\n  host: be-fa-tms-svc.tracardi-com-090.svc.cluster.local \n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#telemetry-configuration","title":"Telemetry Configuration","text":""},{"location":"installation/commercial/helm/helm_090/#introduction","title":"Introduction","text":"<p>The telemetry configuration in Tracardi allows for monitoring and logging various metrics and logs related to the system's performance and operations. This feature is currently experimental and is disabled by default. You can safely remove this section from your custom <code>values.yaml</code> file.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields","title":"Configuration Fields","text":"<p>The <code>telemetry</code> section in the <code>values.yaml</code> file includes several fields to configure the telemetry settings. Here\u2019s a detailed breakdown of each field:</p> <pre><code>telemetry:\n  disabled: true  # Whether telemetry is disabled\n  name: \"tracardi\"  # The name for telemetry\n  log_level: \"info\"  # The logging level for telemetry\n  export:\n    endpoint: \"\"  # Endpoint for exporting telemetry data\n    headers: \"\"  # Headers to use when exporting telemetry data\n    metrics: \"\"  # Metrics configuration for telemetry\n    logs: \"\"  # Logs configuration for telemetry\n    attributes: \"\"  # Attributes for telemetry\n    time_out: 30000  # Timeout for telemetry export in milliseconds\n    delay: 5000  # Delay for telemetry export in milliseconds\n    batch_size: 512  # Batch size for telemetry export\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields","title":"Explanation of Fields","text":"Field Description disabled Indicates whether telemetry is disabled. name The name used for telemetry identification. log_level The logging level for telemetry. export Export configuration for telemetry data. endpoint The endpoint URL where telemetry data will be exported. headers Headers to include when exporting telemetry data. metrics Configuration for exporting metrics. logs Configuration for exporting logs. attributes Attributes to include in the telemetry data. time_out Timeout duration for exporting telemetry data. delay Delay between telemetry export operations. batch_size The number of telemetry entries to include in each export batch."},{"location":"installation/commercial/helm/helm_090/#load-balancer-configuration","title":"Load Balancer Configuration","text":""},{"location":"installation/commercial/helm/helm_090/#introduction_1","title":"Introduction","text":"<p>The load balancer configuration section in the <code>values.yaml</code> file is used to set up a load balancer for your Tracardi installation, particularly when deploying on DigitalOcean. This section includes options to enable or disable the load balancer and to specify a certificate ID for secure connections.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields_1","title":"Configuration Fields","text":"<p>The <code>digitalOcean</code> section includes the following fields:</p> <pre><code>digitalOcean:\n  loadBalancer: false  # Whether to use a DigitalOcean load balancer. Set this to true if you need a load balancer\n  certId: \"\"  # Certificate ID for DigitalOcean\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields_1","title":"Explanation of Fields","text":"Field Description loadBalancer Determines whether a load balancer will start. certId The certificate ID for securing connections through the DigitalOcean load balancer. <p>Set digitalOcean.loadBalancer to true if you need a load balancer</p> <p>Add this to your local <code>values.yaml</code></p> <pre><code>digitalOcean:\n  loadBalancer: true\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#general-tracardi-configuration","title":"General Tracardi Configuration","text":""},{"location":"installation/commercial/helm/helm_090/#overview","title":"Overview","text":"<p>The general configuration settings for Tracardi govern how the system operates, including multi-tenancy, ID prefixes, demo mode, system events, and visit handling. Below is a detailed breakdown of each configuration option.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields_2","title":"Configuration Fields","text":"<pre><code>config:\n  multiTenant:\n    multi: \"no\"  # Whether multi-tenancy is enabled\n  storage: # This part can be removed from the custom file.\n    failOver:\n      enabled: true  # Whether failover storage is enabled\n      size: 1Gi  # Size of the failover storage\n  primaryId: \"emm-\" \n  demo: \"no\"  # Whether demo mode is enabled. Disable on production\n  systemEvents: \"no\"  # Whether system events are enabled.\n  enableVisitEnded: \"no\"  # Whether to enable visit ended events. Will the system register when the visit ends.\n  visit:\n    close: 1200  # Time in seconds to close a visit after inactivity\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields_2","title":"Explanation of Fields","text":"Field Description multiTenant.multi Indicates whether multi-tenancy is enabled. primaryId Primary ID prefix for the system, set only once during installation. Emm prefix means use email.main to compute the primary key and use it as a merging key during automatic profile merging. This means tracardi will automatically merge profiles when there are 2 profiles with the same email. demo Indicates whether demo mode is enabled. systemEvents Indicates whether system events are enabled. enableVisitEnded Indicates whether visit ended events are enabled. visit.close The time in seconds to close a visit after inactivity."},{"location":"installation/commercial/helm/helm_090/#example","title":"Example","text":"<p>Here is an example <code>values.yaml</code> file with only the necessary fields modified:</p> <pre><code>config:\n  multiTenant:\n    multi: \"yes\"  # Enable multi-tenancy\n  primaryId: \"emm-\"  # Set the primary ID prefix\n  systemEvents: \"no\"  # Enable system events\n  enableVisitEnded: \"no\"  # Enable visit ended events\n  visit:\n    close: 1800  # Set visit close time to 1800 seconds (30 minutes)\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#definition-of-secrets","title":"Definition of Secrets","text":""},{"location":"installation/commercial/helm/helm_090/#overview_1","title":"Overview","text":"<p>This section of the configuration file contains all the necessary credentials and secrets required for Tracardi and its dependencies, including databases and external services. Proper management of these secrets is crucial for the security and functionality of the system.</p>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields_3","title":"Explanation of Fields","text":"Field Description Required dockerHub Name of the Docker Hub repository. yes installation.token Installation token. yes license.licenseKey License key for the application. no tms.secretKey Secret key for Tenant Management Service (TMS). if multi-tenant installation tms.apiKey API key for TMS. if multi-tenant installation redis.password Password for Redis. if authentication enabled elastic.username Username for Elasticsearch. yes elastic.password Password for Elasticsearch. if authentication enabled pulsar.token Token for Pulsar. if authentication enabled mysql.username Username for MySQL. if authentication enabled mysql.password Password for MySQL. if authentication enabled maxmind.licenseKey License key for MaxMind. no maxmind.accountId Account ID for MaxMind. no mergingToken Token used for hashing data during profile merging. This should be a random value and should not be changed after installation. It must remain permanent across all installations. yes"},{"location":"installation/commercial/helm/helm_090/#docker-image-settings","title":"Docker Image Settings","text":""},{"location":"installation/commercial/helm/helm_090/#overview_2","title":"Overview","text":"<p>The image settings section in the <code>values.yaml</code> file is used to configure the API component of Tracardi. This includes settings for both the private and public APIs, such as Docker image details, replica configurations, logging levels, and service ports. Proper configuration of these settings ensures the APIs operate efficiently and meet the deployment requirements.</p> <p>Private API is Used for communication with GUI while Public for collecting Data.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields_3","title":"Configuration Fields","text":"<pre><code># API configuration\napi:\n  image:\n    repository: tracardi/com-tracardi-api  # Docker repository for the API image\n    pullPolicy: IfNotPresent  # Image pull policy\n    tag: 1.0.0  # Image tag, should be the same for GUI and backend\n\n  private:\n    enabled: true  # Whether the private API is enabled\n    replicas: 1  # Number of replicas for the private API\n    config:\n      saveLogs: \"yes\"  # Whether to save logs\n      loggingLevel: \"INFO\"  # Logging level for the private API\n      apiDocs: \"yes\"  # Whether to enable API documentation\n      enableWorkflow: \"yes\"  # Whether to enable workflows\n      enableEventDestinations: \"yes\"  # Whether to enable event destinations\n      enableProfileDestinations: \"yes\"  # Whether to enable profile destinations\n      enableIdentification: \"yes\"  # Whether to enable identification\n      eventPartitioning: \"month\"  # Event partitioning strategy\n      profilePartitioning: \"quarter\"  # Profile partitioning strategy\n      sessionPartitioning: \"quarter\"  # Session partitioning strategy\n    service:\n      port: 8686  # Port for the private API service\n    ingress:\n      enabled: false\n      host: \"*.private-api.your-domain.com\"\n      path: /\n\n  public:\n    enabled: true  # Whether the public API is enabled\n    spread:\n      rules:\n        topologySpreadConstraints:\n          - maxSkew: 1  # Maximum skew for topology spread\n            topologyKey: kubernetes.io/hostname  # Topology key for spread constraints\n            whenUnsatisfiable: ScheduleAnyway  # Action to take when constraints are unsatisfiable\n            labelSelector:\n              matchLabels:\n                app.kubernetes.io/component: be-fa-public  # Label selector\n    replicas: 1  # Number of replicas for the public API\n    config:\n      saveLogs: \"no\"  # Whether to save logs\n      loggingLevel: \"WARNING\"  # Logging level for the public API\n      apiDocs: \"no\"  # Whether to enable API documentation\n      enableWorkflow: \"yes\"  # Whether to enable workflows\n      enableEventDestinations: \"yes\"  # Whether to enable event destinations\n      enableProfileDestinations: \"yes\"  # Whether to enable profile destinations\n      enableIdentification: \"yes\"  # Whether to enable identification\n      eventPartitioning: \"month\"  # Event partitioning strategy\n      profilePartitioning: \"quarter\"  # Profile partitioning strategy\n      sessionPartitioning: \"quarter\"  # Session partitioning strategy\n    service:\n      port: 8585  # Port for the public API service\n    ingress:\n      enabled: false\n      host: \"*.public-api.your-domain.com\"\n      path: /\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields_4","title":"Explanation of Fields","text":""},{"location":"installation/commercial/helm/helm_090/#api-image","title":"API Image","text":"Field Type Description Default repository String Docker repository for the API image. <code>tracardi/com-tracardi-api</code> pullPolicy String Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. <code>IfNotPresent</code> tag String Image tag, ensuring compatibility between GUI and backend. <code>1.0.0</code>"},{"location":"installation/commercial/helm/helm_090/#privatepublic-api-configuration","title":"Private/Public API Configuration","text":"Field Type Description Default enabled Boolean Enables or disables the private API. <code>true</code> replicas Integer Number of replicas for the private API. Use for scaling. <code>1</code> config.saveLogs String Indicates whether to save logs. <code>\"yes\"</code> config.loggingLevel String Logging level for the private API. Common values are <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>. <code>\"INFO\"</code> config.apiDocs String Indicates whether to enable API documentation. <code>\"yes\"</code> config.enableWorkflow String Indicates whether to enable workflows. <code>\"yes\"</code> config.enableEventDestinations String Indicates whether to enable event destinations. <code>\"yes\"</code> config.enableProfileDestinations String Indicates whether to enable profile destinations. <code>\"yes\"</code> config.enableIdentification String Indicates whether to enable identification. <code>\"yes\"</code> config.eventPartitioning String Strategy for event partitioning. Common values are <code>day</code>, <code>week</code>, <code>month</code>, <code>quarter</code>, <code>year</code>. <code>\"month\"</code> config.profilePartitioning String Strategy for profile partitioning. Common values are <code>day</code>, <code>week</code>, <code>month</code>, <code>quarter</code>, <code>year</code>. <code>\"quarter\"</code> config.sessionPartitioning String Strategy for session partitioning. Common values are <code>day</code>, <code>week</code>, <code>month</code>, <code>quarter</code>, <code>year</code>. <code>\"quarter\"</code> service.port Integer Port for the private API service. <code>8686</code> ingress.enabled Boolean Enable API ingress. <code>false</code> ingress.host String API ingress host. Wildcard is used for multitenant installation. <code>*.public.your-domain.com</code> ingress.path String Enable API path. <code>/</code>"},{"location":"installation/commercial/helm/helm_090/#differences-in-configuration-of-private-and-public-api","title":"Differences in Configuration of Private and Public API","text":"Configuration Field Private API Public API saveLogs yes no loggingLevel INFO WARNING apiDocs yes no service.port 8686 8585 topologySpreadConstraints Not applicable Configured"},{"location":"installation/commercial/helm/helm_090/#gui-configuration","title":"GUI Configuration","text":""},{"location":"installation/commercial/helm/helm_090/#overview_3","title":"Overview","text":"<p>The GUI configuration section in the <code>values.yaml</code> file specifies the settings for the graphical user interface (GUI) of Tracardi. This includes details about the Docker image, replica settings, service ports, and specific configuration options for the console.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields_4","title":"Configuration Fields","text":"<pre><code># GUI configuration\ngui:\n  image:\n    repository: tracardi/tracardi-gui  # Docker repository for the GUI image\n    pullPolicy: IfNotPresent  # Image pull policy\n    tag: 1.0.0  # Image tag, should be the same for GUI and backend\n\n  console:\n    enabled: true  # Whether the GUI is enabled\n    replicas: 1  # Number of replicas for the GUI\n    service:\n      port: 8787  # Port for the GUI service\n    ingress:\n      enabled: false\n      host: \"gui.your-domain.com\"\n      path: /\n    config:\n      mode: \"with-deployment\"  # Mode for the GUI\n      allowUpdatesOnProduction: \"no\"  # Whether to allow updates on production\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields_5","title":"Explanation of Fields","text":"Field Description image.repository Docker repository for the GUI image. image.pullPolicy Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. image.tag Image tag. console.enabled Indicates whether the GUI is enabled. console.replicas Number of replicas for the GUI. console.service.port Port for the GUI service. console.ingress.enabled Enable GUI ingress. console.ingress.host GUI ingress host. console.ingress.path Enable GUI path. config.mode Mode for the console operation. Available values \"with-deployment\" or \"no-deployment\" config.allowUpdatesOnProduction Indicates whether updates are allowed on production."},{"location":"installation/commercial/helm/helm_090/#tms-configuration","title":"TMS Configuration","text":""},{"location":"installation/commercial/helm/helm_090/#overview_4","title":"Overview","text":"<p>The Tenant Management Service (TMS) configuration section in the <code>values.yaml</code> file specifies the settings for TMS in Tracardi. This includes details about the Docker image, replica settings, logging levels, service ports, and the service name.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields_5","title":"Configuration Fields","text":"<pre><code># TMS configuration\ntms:\n  image:\n    repository: tracardi/tms  # Docker repository for the TMS image\n    pullPolicy: IfNotPresent  # Image pull policy\n    tag: 1.0.0  # Image tag, should be the same for GUI and backend\n  docker:\n    enabled: true  # Whether Docker is enabled\n    replicas: 1  # Number of replicas for TMS\n    config:\n      loggingLevel: \"INFO\"  # Logging level for TMS\n    service:\n      port: 8383  # Port for the TMS service\n      name: be-fa-tms-svc  # The name of the TMS service\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields_6","title":"Explanation of Fields","text":"Field Description image.repository Docker repository for the TMS image. image.pullPolicy Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. image.tag Image tag. docker.enabled Indicates whether Docker is enabled for TMS. docker.replicas Number of replicas for TMS. service.port Port on which the TMS service runs. service.name Name of the TMS service. loggingLevel Logging level for TMS.  Common values are <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, and <code>DEBUG</code>."},{"location":"installation/commercial/helm/helm_090/#worker-configuration","title":"Worker Configuration","text":""},{"location":"installation/commercial/helm/helm_090/#overview_5","title":"Overview","text":"<p>The worker configuration section in the <code>values.yaml</code> file specifies the settings for various worker components in Tracardi, including background workers, APM (Auto Profile Merging) profiles, and upgrade workers. This configuration includes Docker image details, replica settings, logging levels, and resource limits.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields_6","title":"Configuration Fields","text":"<pre><code># Worker configuration\nworker:\n  background:\n    image:\n      repository: tracardi/background-worker  # Docker repository for the background worker image\n      tag: 1.0.0  # Image tag for the background worker\n      pullPolicy: IfNotPresent  # Image pull policy\n    enabled: true  # Whether the background worker is enabled\n    replicas: 1  # Number of replicas for the background worker\n    spread:\n      rules:\n        topologySpreadConstraints:\n          - maxSkew: 1  # Maximum skew for topology spread\n            topologyKey: kubernetes.io/hostname  # Topology key for spread constraints\n            whenUnsatisfiable: ScheduleAnyway  # Action to take when constraints are unsatisfiable\n            labelSelector:\n              matchLabels:\n                app.kubernetes.io/component: wk-pl-background  # Label selector for spread constraints\n    config:\n      loggingLevel: \"INFO\"  # Logging level for the background worker\n      bulker:\n         # Data Bulker\n         # \n         # The Data Bulker Configuration are setting for message bulker that is responsible for collecting messages and \n         # managing them for background storage operations.\n         # \n         # It operates by enforcing two main constraints: a size limit, which is the maximum number of messages the queue can\n         # hold, and a time limit, which dictates how long messages can remain in the queue. If either of these limits is\n         # exceeded, the queued data is flushed to storage.\n         # \n         # Additionally, if no new data arrives within a specified period of inactivity, a timeout is triggered that\n         # automatically flushes any remaining data in the queue that has not yet been processed.\n         maxTimeInBuffer: 5  # TimeLimit: Flush data to storage every X sec\n         bufferInactivityTimeOut: 10000 # If there is no data in then flash remaining buffer to storage in X milliseconds\n         minBatchSize: 200  # SizeLimit: Min number of messages in the queue buffer\n         maxBatchSize: 1000  # SizeLimit: Max number of messages in the queue buffer\n\n  apm:\n    image:\n      repository: tracardi/apm  # Docker repository for the APM image\n      tag: 1.0.0  # Image tag for the APM\n      pullPolicy: IfNotPresent  # Image pull policy\n    profile:\n      enabled: true  # Whether the APM profile is enabled\n      replicas: 1  # Number of replicas for the APM profile\n      config:\n        loggingLevel: \"INFO\"  # Logging level for the APM profile\n\n  upgrade:\n    image:\n      repository: tracardi/update-worker  # Docker repository for the upgrade worker image\n      tag: 1.0.0  # Image tag for the upgrade worker\n      pullPolicy: IfNotPresent  # Image pull policy\n    docker:\n      enabled: true  # Whether Docker is enabled\n      replicas: 1  # Number of replicas for the upgrade worker\n      config:\n        saveLogs: \"no\"  # Whether to save logs\n        loggingLevel: \"INFO\"  # Logging level for the upgrade worker\n      resources:\n        limits:\n          memory: 500Mi  # Memory limit for the upgrade worker\n          cpu: 500m  # CPU limit for the upgrade worker\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#bridges-configuration","title":"Bridges Configuration","text":""},{"location":"installation/commercial/helm/helm_090/#overview_6","title":"Overview","text":"<p>The bridges configuration section in the <code>values.yaml</code> file specifies the settings for the services responsible for collecting data from different channels. This includes the queue bridge configuration, detailing Docker image settings, enabling or disabling the bridge, setting the number of replicas, and logging levels. By default none standard bridges are disabled. You can safely remove this configuration form you local <code>values.yaml</code> file.</p>"},{"location":"installation/commercial/helm/helm_090/#configuration-fields_7","title":"Configuration Fields","text":"<pre><code># Bridges configuration for services responsible for collecting data from different channels\nbridge:\n  queue:\n    image:\n      repository: tracardi/com-bridge-queue  # Docker repository for the queue bridge image\n      tag: 1.0.0  # Image tag for the queue bridge\n      pullPolicy: IfNotPresent  # Image pull policy\n    docker:\n      enabled: false  # Whether Docker is enabled for the queue bridge\n      replicas: 1  # Number of replicas for the queue bridge\n      config:\n        loggingLevel: \"INFO\"  # Logging level for the queue bridge\n</code></pre>"},{"location":"installation/commercial/helm/helm_090/#explanation-of-fields_7","title":"Explanation of Fields","text":""},{"location":"installation/commercial/helm/helm_090/#queue-bridge","title":"Queue Bridge","text":"Field Description image.repository Docker repository for the queue bridge image. image.tag Image tag for the queue bridge. image.pullPolicy Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. docker.enabled Indicates whether Docker is enabled for the queue bridge. docker.replicas Number of replicas for the queue bridge. docker.config.loggingLevel Logging level for the queue bridge. Common values are <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, and <code>DEBUG</code>."},{"location":"installation/commercial/helm/helm_090/#summary","title":"Summary","text":"<p>Please override only the fields that needs to change in you local environment. Here is an example of such local <code>'values.yaml</code> file.</p> <pre><code># Dependencies\n\nelastic:   \n  host: elastic-std-svc.elastic-standalone.svc.cluster.local\n  schema: http\n  authenticate: true\n\nredis:\n  host: redis-master.redis.svc.cluster.local\n  schema: \"redis://\"\n  authenticate: true\n\npulsar:\n  host: pulsar-proxy.pulsar.svc.cluster.local:6650\n  api: http://pulsar-proxy.pulsar.svc.cluster.local:80\n  schema: \"pulsar://\"\n  authenticate: true\n\nmysql:\n  host: percona-db-pxc-db-haproxy.percona.svc.cluster.local\n  schema: \"mysql+aiomysql://\"\n  database: \"tracardi\"\n\ntmsApi:\n  host: be-fa-tms-svc.tracardi-com-090.svc.cluster.local\n\n# Secrets\n\nsecrets:\n  installation:\n    token: \"XXXX\"\n  dockerHub: \"tracardi-dockerhub\"\n  license:\n    licenseKey: \"XXXX\"\n  tms:\n    secretKey: \"XXXX\"\n    apiKey: \"XXXX\"\n  redis:\n    password: \"XXXX\"\n  pulsar:\n    token: \"XXXX\"\n  mysql:\n    username: \"root\"\n    password: \"XXXX\"\n\n# Networking\n\ndigitalOcean:\n  loadBalancer: true\n\n# Configuration\n\nconfig:\n  multiTenant:\n    multi: \"yes\"\n  primaryId: \"phm-\"  # Use phone as primary ID key, This value should be set only once during installation and never changed\n\n# Images and Versions\n\napi:\n  image:\n    tag: 1.0.0\n\n  private:\n    replicas: 1\n    service:\n      port: 48686\n\n  public:\n    replicas: 1\n    service:\n      port: 48585\n\ngui:\n  image:\n    tag: 1.0.0\n  console:\n    service:\n      port: 48787\n    config:\n      mode: \"no-deployment\"\n      allowUpdatesOnProduction: \"true\"\n\ntms:\n  image:\n    tag: 1.0.0\n  docker:\n    replicas: 1\n    service:\n      port: 48383\n\n# Workers\n\nworker:\n\n  background:\n    enabled: true\n    image:\n      tag: 1.0.0\n    replicas: 1\n\n  apm:\n    image:\n      tag: 1.0.0\n    profile:\n      enabled: true\n      replicas: 1\n\n  upgrade:\n    image:\n      tag: 1.0.0\n    docker:\n      enabled: true\n      replicas: 1\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/","title":"Installation with HelmChart after version 0.9.0","text":"<p>This document provides comprehensive instructions for installing the commercial Tracardi application on a Kubernetes ( K8s) cluster using the Helm chart.</p>"},{"location":"installation/commercial/helm/helm_100/#prerequisites","title":"Prerequisites","text":"<p>Before initiating the installation process, ensure you have completed the following prerequisites:</p> <ol> <li> <p>Install K8S and Helm: Make sure that you have installed K8S and Helm.</p> </li> <li> <p>Obtain Helm Chart and License Information: Upon agreeing to the license agreement, you will receive a Helm chart    archive. Extract the contents of this archive into a folder named \"tracardi\". You will also receive a Docker Hub    login token, which is required to access the commercial Docker images. Additionally, make sure you have the Tracardi    license key.</p> </li> <li>Install dependencies (ElasticSearch, Redis, Apache Pulsar, Mysql)</li> </ol> <p>Advice</p> <p>We strongly recommend setting up the dependent services (Redis, Elasticsearch, MySQL, and Pulsar) in separate   namespaces. This strategy has several advantages:</p> <ol> <li>Upgrade Management: Each new version of Tracardi can be deployed in a new namespace, facilitating migration and      testing without disrupting the current setup.</li> <li>Isolation: Keeping dependencies isolated helps in managing and troubleshooting issues more effectively.</li> <li>Avoiding In-Place Upgrades: Placing everything in one namespace would necessitate an in-place upgrade for      Tracardi, which is not recommended due to the increased risk of disruptions and complications.</li> </ol>"},{"location":"installation/commercial/helm/helm_100/#overall-process-description","title":"Overall process description","text":"<p>The installation takes the following steps:</p> <ul> <li>Dependencies installation</li> <li>Init script for dependencies setup (it is part of the tracardi pod)</li> <li>API/GUI and workers installation</li> </ul>"},{"location":"installation/commercial/helm/helm_100/#installation-settings","title":"Installation settings","text":"<p>Installation will need setting that will connect tracardi with its database, cache, etc.</p> <p>You must customize the deployment by providing your own <code>values.yaml</code> file where you will set up the required credentials.</p>"},{"location":"installation/commercial/helm/helm_100/#using-custom-values-in-helm-charts","title":"Using Custom Values in Helm Charts","text":"<p>To use custom values when installing a Helm chart, you create a custom <code>values.yaml</code> file and pass it to the <code>helm install</code> command using the <code>-f</code> or <code>--values</code> flag. Here's the general syntax:</p> <pre><code>helm install [RELEASE_NAME] [CHART] -f [PATH_TO_YOUR_CUSTOM_VALUES_FILE]\n</code></pre> <p>For example:</p> <pre><code>helm install tracardi tracardi -f my-custom-values.yaml\n</code></pre> <p>How Custom Values Override Default Values</p> <ol> <li> <p>Default Values: Each Helm chart includes a <code>values.yaml</code> file that defines the default configuration. Description of    default custom values will be described below.</p> </li> <li> <p>Custom Values: When you provide a custom <code>values.yaml</code> file, the values specified in this file take precedence over    the corresponding default values.</p> </li> <li> <p>Merge Process: Helm doesn't completely replace the default values file. Instead, it performs a deep merge of your    custom values with the default values.</p> </li> <li> <p>Overriding: Only the values you specify in your custom file will override the defaults. All other values remain    unchanged.</p> </li> <li> <p>Nested Values: For nested structures, you can override specific nested values without affecting the entire structure.</p> </li> <li> <p>Arrays: When overriding array values, your custom values completely replace the default array.</p> </li> </ol>"},{"location":"installation/commercial/helm/helm_100/#minimal-values-file","title":"Minimal values file","text":"<p>Minimal configuration will require connection to all dependant services with credentials. </p> <p>```yaml tilte=\"Example of minimal custom values.yaml file\"</p>"},{"location":"installation/commercial/helm/helm_100/#infrastructure","title":"Infrastructure","text":"<p>elastic:   name: es1   host: cluster-es-http.elastic.svc.cluster.local  # Address of elastic-search installation   schema: https   authenticate: true   port: 9200   verifyCerts: \"no\"</p> <p>redis:   name: rd1   host: redis-master.redis.svc.cluster.local  # Address of redis installation   schema: \"redis://\"   authenticate: true   port: 6379   db: \"0\"</p> <p>pulsar:   name: ps1   host: pulsar-proxy.pulsar.svc.cluster.local:6650  # Address of apache pulsar installation   api: http://pulsar-broker.pulsar.svc.cluster.local:8080   schema: \"pulsar://\"   authenticate: true   port: 6650</p> <p>mysql:   name: ms1   host: percona-db-pxc-db-haproxy.percona.svc.cluster.local  # Address of mysql installation   schema: \"mysql+aiomysql://\"   database: \"tracardi\"   port: 3306</p> <p>secrets:   installation:     token: \"random-token\"   license:     licenseKey: \"license-key\"   redis:     password: \"redis-password\"   elastic:     username: \"elasticsearch-username\"     password: \"elasticsearch-password\"   pulsar:     token: \"pulsar-token\"   mysql:     username: \"mysql-username\"     password: \"mysql-password\"   tms:     secretKey: \"random-tms-secret-key\"     apiKey: \"random-tms-api-key\" <pre><code>### Detailed local installation settings\n\nTo customize your installation create local `values.yaml` file and define custom setting for your setup.\n\nYour custom `values.yaml` file will contain only the values you wish to change from the defaults. Any values not\nspecified in your custom file will use the defaults provided by the HelmChart. This approach keeps your configuration\nconcise and easy to manage.\n\n### Configuration of Services Used by Tracardi\n\nDependencies configuration is the part in helm configuration that defines all the services that Tracardi needs to connect to. \n\n#### Elasticsearch Configuration\n\nThe Elasticsearch configuration specifies the necessary settings to connect Tracardi to an Elasticsearch service. This\nincludes the host, port, schema, and authentication details. Here's a detailed breakdown:\n\n```yaml\nelastic:\n  name: es1  # The name identifier for the Elasticsearch service\n  host: elastic-std-svc.elastic-standalone.svc.cluster.local  # The hostname for the Elasticsearch service\n  schema: http  # The schema to use for connecting to Elasticsearch (http/https)\n  authenticate: false  # Whether to use authentication when connecting to Elasticsearch\n  port: 9200  # The port on which Elasticsearch is running\n  verifyCerts: \"no\"  # Whether to verify SSL certificates (yes/no)\n  index:\n    shards: 3  # Number of primary shards for the index\n    replicas: 1  # Number of replica shards for the index\n</code></pre></p> Field Description Needs change name Identifier for the Elasticsearch service host Hostname or IP address of the Elasticsearch service yes schema Protocol used to connect (http or https) yes authenticate Toggle for enabling authentication. See secrets part for authentication. yes port Port number on which Elasticsearch is running verifyCerts Indicates whether SSL certificates should be verified index.shards Number of primary shards for the index Use default or change index.replicas Number of replica shards for the index Use default or change"},{"location":"installation/commercial/helm/helm_100/#redis-configuration","title":"Redis Configuration","text":"<p>The Redis configuration sets up the connection details for the Redis service, including the host, port, and database number.</p> <pre><code>redis:\n  name: rd1  # The name identifier for the Redis service\n  host: redis-std-svc.redis-standalone.svc.cluster.local  # The hostname for the Redis service\n  schema: \"redis://\"  # The schema to use for connecting to Redis\n  authenticate: false  # Whether to use authentication when connecting to Redis\n  port: 6379  # The port on which Redis is running\n  db: \"0\"  # The database number to use in Redis\n</code></pre> Field Description Needs change name Identifier for the Redis service host Hostname or IP address of the Redis service yes schema Protocol used to connect (e.g., redis://) authenticate Toggle for enabling authentication yes port Port number on which Redis is running db Redis database number to use"},{"location":"installation/commercial/helm/helm_100/#apache-pulsar-configuration","title":"Apache Pulsar Configuration","text":"<p>The Apache Pulsar configuration includes settings for connecting to the Pulsar service, including the host, port, and whether to enable Pulsar.</p> <pre><code>pulsar:\n  name: ps1  # The name identifier for the Pulsar service\n  host: pulsar-std-svc.pulsar-standalone.svc.cluster.local  # The hostname for the Pulsar service\n  api: \"http://pulsar-std-svc.pulsar-standalone.svc.cluster.local:8080\"  # API endpoint for Pulsar\n  schema: \"pulsar://\"  # The schema to use for connecting to Pulsar\n  authenticate: false  # Whether to use authentication when connecting to Pulsar\n  port: 6650  # The port on which Pulsar is running\n  cluster_name: pulsar  # The cluster name for Pulsar\n  enabled: true  # Whether Pulsar is enabled\n</code></pre> Field Description needs change name Identifier for the Pulsar service host Hostname or IP address of the Pulsar service yes api API endpoint for Pulsar yes schema Protocol used to connect (e.g., pulsar://) authenticate Toggle for enabling authentication yes port Port number on which Pulsar is running cluster_name Name of the Pulsar cluster enabled Toggle to enable or disable Pulsar"},{"location":"installation/commercial/helm/helm_100/#mysql-configuration","title":"MySQL Configuration","text":"<p>The MySQL configuration details the settings for connecting to a MySQL service, including the host, port, and database name.</p> <pre><code>mysql:\n  name: ms1  # The name identifier for the MySQL service\n  host: percona-db-pxc-db-haproxy.percona.svc.cluster.local  # The hostname for the MySQL service\n  schema: \"mysql+aiomysql://\"  # The schema to use for connecting to MySQL\n  database: \"tracardi\"  # The database name to use in MySQL\n  port: 3306  # The port on which MySQL is running\n</code></pre> Field Description Needs change name Identifier for the MySQL service host Hostname or IP address of the MySQL service yes schema Protocol used to connect (e.g., mysql+aiomysql://) database Name of the database to use port Port number on which MySQL is running"},{"location":"installation/commercial/helm/helm_100/#tenant-management-service-tms-api-configuration","title":"Tenant Management Service (TMS) API Configuration","text":"<p>The TMS API configuration outlines the settings for the Tenant Management Service, a microservice responsible for managing tenants in a multi-tenant environment.</p> <pre><code>tmsApi:\n  host: be-fa-tms-svc.tracardi-com-090.svc.cluster.local  # The hostname for the TMS API service\n  database: \"tms\"  # The database name to use in TMS API\n</code></pre> Field Description Needs change host Hostname or IP address of the TMS API service yes database Name of the database to use in TMS API <p>Here's an example <code>values.yaml</code> file where only the required fields are changed. This is the example for resource configuration. See other parts below</p> <pre><code># Elasticsearch configuration. Set required values like elastic.host\nelastic:\n  host: elastic-std-svc.elastic-standalone.svc.cluster.local\n  authenticate: true\n\n# Redis configuration. \nredis:\n  host: redis-std-svc.redis-standalone.svc.cluster.local\n  authenticate: true\n\n# Apache Pulsar configuration. Set required fields like pulsar.host, pulsar.api\npulsar:\n  host: pulsar-std-svc.pulsar-standalone.svc.cluster.local\n  api: \"http://pulsar-std-svc.pulsar-standalone.svc.cluster.local:8080\"\n  enabled: true  # Enable Pulsar for this configuration\n  authenticate: true\n\n# MySQL configuration. Set mysql.host required.\nmysql:\n  host: percona-db-pxc-db-haproxy.percona.svc.cluster.local\n\n# TMS API configuration. Change tmsApi.host\ntmsApi:\n  host: be-fa-tms-svc.tracardi-com-090.svc.cluster.local \n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#telemetry-configuration","title":"Telemetry Configuration","text":""},{"location":"installation/commercial/helm/helm_100/#introduction","title":"Introduction","text":"<p>The telemetry configuration in Tracardi allows for monitoring and logging various metrics and logs related to the system's performance and operations. This feature is currently experimental and is disabled by default. You can safely remove this section from your custom <code>values.yaml</code> file.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields","title":"Configuration Fields","text":"<p>The <code>telemetry</code> section in the <code>values.yaml</code> file includes several fields to configure the telemetry settings. Here\u2019s a detailed breakdown of each field:</p> <pre><code>telemetry:\n  disabled: true  # Whether telemetry is disabled\n  name: \"tracardi\"  # The name for telemetry\n  log_level: \"info\"  # The logging level for telemetry\n  export:\n    endpoint: \"\"  # Endpoint for exporting telemetry data\n    headers: \"\"  # Headers to use when exporting telemetry data\n    metrics: \"\"  # Metrics configuration for telemetry\n    logs: \"\"  # Logs configuration for telemetry\n    attributes: \"\"  # Attributes for telemetry\n    time_out: 30000  # Timeout for telemetry export in milliseconds\n    delay: 5000  # Delay for telemetry export in milliseconds\n    batch_size: 512  # Batch size for telemetry export\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields","title":"Explanation of Fields","text":"Field Description disabled Indicates whether telemetry is disabled. name The name used for telemetry identification. log_level The logging level for telemetry. export Export configuration for telemetry data. endpoint The endpoint URL where telemetry data will be exported. headers Headers to include when exporting telemetry data. metrics Configuration for exporting metrics. logs Configuration for exporting logs. attributes Attributes to include in the telemetry data. time_out Timeout duration for exporting telemetry data. delay Delay between telemetry export operations. batch_size The number of telemetry entries to include in each export batch."},{"location":"installation/commercial/helm/helm_100/#load-balancer-configuration","title":"Load Balancer Configuration","text":""},{"location":"installation/commercial/helm/helm_100/#introduction_1","title":"Introduction","text":"<p>The load balancer configuration section in the <code>values.yaml</code> file is used to set up a load balancer for your Tracardi installation, particularly when deploying on DigitalOcean. This section includes options to enable or disable the load balancer and to specify a certificate ID for secure connections.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields_1","title":"Configuration Fields","text":"<p>The <code>digitalOcean</code> section includes the following fields:</p> <pre><code>digitalOcean:\n  loadBalancer: false  # Whether to use a DigitalOcean load balancer. Set this to true if you need a load balancer\n  certId: \"\"  # Certificate ID for DigitalOcean\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields_1","title":"Explanation of Fields","text":"Field Description loadBalancer Determines whether a load balancer will start. certId The certificate ID for securing connections through the DigitalOcean load balancer. <p>Set digitalOcean.loadBalancer to true if you need a load balancer</p> <p>Add this to your local <code>values.yaml</code></p> <pre><code>digitalOcean:\n  loadBalancer: true\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#general-tracardi-configuration","title":"General Tracardi Configuration","text":""},{"location":"installation/commercial/helm/helm_100/#overview","title":"Overview","text":"<p>The general configuration settings for Tracardi govern how the system operates, including multi-tenancy, ID prefixes, demo mode, system events, and visit handling. Below is a detailed breakdown of each configuration option.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields_2","title":"Configuration Fields","text":"<pre><code>config:\n  multiTenant:\n    multi: \"no\"  # Whether multi-tenancy is enabled\n  storage: # This part can be removed from the custom file.\n    failOver:\n      enabled: true  # Whether failover storage is enabled\n      size: 1Gi  # Size of the failover storage\n  primaryId: \"emm-\" \n  demo: \"no\"  # Whether demo mode is enabled. Disable on production\n  systemEvents: \"no\"  # Whether system events are enabled.\n  enableVisitEnded: \"no\"  # Whether to enable visit ended events. Will the system register when the visit ends.\n  visit:\n    close: 1200  # Time in seconds to close a visit after inactivity\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields_2","title":"Explanation of Fields","text":"Field Description multiTenant.multi Indicates whether multi-tenancy is enabled. primaryId Primary ID prefix for the system, set only once during installation. Emm prefix means use email.main to compute the primary key and use it as a merging key during automatic profile merging. This means tracardi will automatically merge profiles when there are 2 profiles with the same email. demo Indicates whether demo mode is enabled. systemEvents Indicates whether system events are enabled. enableVisitEnded Indicates whether visit ended events are enabled. visit.close The time in seconds to close a visit after inactivity."},{"location":"installation/commercial/helm/helm_100/#example","title":"Example","text":"<p>Here is an example <code>values.yaml</code> file with only the necessary fields modified:</p> <pre><code>config:\n  multiTenant:\n    multi: \"yes\"  # Enable multi-tenancy\n  primaryId: \"emm-\"  # Set the primary ID prefix\n  systemEvents: \"no\"  # Enable system events\n  enableVisitEnded: \"no\"  # Enable visit ended events\n  visit:\n    close: 1800  # Set visit close time to 1800 seconds (30 minutes)\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#definition-of-secrets","title":"Definition of Secrets","text":""},{"location":"installation/commercial/helm/helm_100/#overview_1","title":"Overview","text":"<p>This section of the configuration file contains all the necessary credentials and secrets required for Tracardi and its dependencies, including databases and external services. Proper management of these secrets is crucial for the security and functionality of the system.</p>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields_3","title":"Explanation of Fields","text":"Field Description Required dockerHub Name of the Docker Hub repository. yes installation.token Installation token. yes license.licenseKey License key for the application. no tms.secretKey Secret key for Tenant Management Service (TMS). if multi-tenant installation tms.apiKey API key for TMS. if multi-tenant installation redis.password Password for Redis. if authentication enabled elastic.username Username for Elasticsearch. yes elastic.password Password for Elasticsearch. if authentication enabled pulsar.token Token for Pulsar. if authentication enabled mysql.username Username for MySQL. if authentication enabled mysql.password Password for MySQL. if authentication enabled maxmind.licenseKey License key for MaxMind. no maxmind.accountId Account ID for MaxMind. no mergingToken Token used for hashing data during profile merging. This should be a random value and should not be changed after installation. It must remain permanent across all installations. yes"},{"location":"installation/commercial/helm/helm_100/#docker-image-settings","title":"Docker Image Settings","text":""},{"location":"installation/commercial/helm/helm_100/#overview_2","title":"Overview","text":"<p>The image settings section in the <code>values.yaml</code> file is used to configure the API component of Tracardi. This includes settings for both the private and public APIs, such as Docker image details, replica configurations, logging levels, and service ports. Proper configuration of these settings ensures the APIs operate efficiently and meet the deployment requirements.</p> <p>Private API is Used for communication with GUI while Public for collecting Data.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields_3","title":"Configuration Fields","text":"<pre><code># API configuration\napi:\n  image:\n    repository: tracardi/com-tracardi-api  # Docker repository for the API image\n    pullPolicy: IfNotPresent  # Image pull policy\n    tag: 1.0.0  # Image tag, should be the same for GUI and backend\n\n  private:\n    enabled: true  # Whether the private API is enabled\n    replicas: 1  # Number of replicas for the private API\n    config:\n      saveLogs: \"yes\"  # Whether to save logs\n      loggingLevel: \"INFO\"  # Logging level for the private API\n      apiDocs: \"yes\"  # Whether to enable API documentation\n      enableWorkflow: \"yes\"  # Whether to enable workflows\n      enableEventDestinations: \"yes\"  # Whether to enable event destinations\n      enableProfileDestinations: \"yes\"  # Whether to enable profile destinations\n      enableIdentification: \"yes\"  # Whether to enable identification\n      eventPartitioning: \"month\"  # Event partitioning strategy\n      profilePartitioning: \"quarter\"  # Profile partitioning strategy\n      sessionPartitioning: \"quarter\"  # Session partitioning strategy\n    service:\n      port: 8686  # Port for the private API service\n    ingress:\n      enabled: false\n      host: \"*.private-api.your-domain.com\"\n      path: /\n\n  public:\n    enabled: true  # Whether the public API is enabled\n    spread:\n      rules:\n        topologySpreadConstraints:\n          - maxSkew: 1  # Maximum skew for topology spread\n            topologyKey: kubernetes.io/hostname  # Topology key for spread constraints\n            whenUnsatisfiable: ScheduleAnyway  # Action to take when constraints are unsatisfiable\n            labelSelector:\n              matchLabels:\n                app.kubernetes.io/component: be-fa-public  # Label selector\n    replicas: 1  # Number of replicas for the public API\n    config:\n      saveLogs: \"no\"  # Whether to save logs\n      loggingLevel: \"WARNING\"  # Logging level for the public API\n      apiDocs: \"no\"  # Whether to enable API documentation\n      enableWorkflow: \"yes\"  # Whether to enable workflows\n      enableEventDestinations: \"yes\"  # Whether to enable event destinations\n      enableProfileDestinations: \"yes\"  # Whether to enable profile destinations\n      enableIdentification: \"yes\"  # Whether to enable identification\n      eventPartitioning: \"month\"  # Event partitioning strategy\n      profilePartitioning: \"quarter\"  # Profile partitioning strategy\n      sessionPartitioning: \"quarter\"  # Session partitioning strategy\n    service:\n      port: 8585  # Port for the public API service\n    ingress:\n      enabled: false\n      host: \"*.public-api.your-domain.com\"\n      path: /\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields_4","title":"Explanation of Fields","text":""},{"location":"installation/commercial/helm/helm_100/#api-image","title":"API Image","text":"Field Type Description Default repository String Docker repository for the API image. <code>tracardi/com-tracardi-api</code> pullPolicy String Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. <code>IfNotPresent</code> tag String Image tag, ensuring compatibility between GUI and backend. <code>1.0.0</code>"},{"location":"installation/commercial/helm/helm_100/#privatepublic-api-configuration","title":"Private/Public API Configuration","text":"Field Type Description Default enabled Boolean Enables or disables the private API. <code>true</code> replicas Integer Number of replicas for the private API. Use for scaling. <code>1</code> config.saveLogs String Indicates whether to save logs. <code>\"yes\"</code> config.loggingLevel String Logging level for the private API. Common values are <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>. <code>\"INFO\"</code> config.apiDocs String Indicates whether to enable API documentation. <code>\"yes\"</code> config.enableWorkflow String Indicates whether to enable workflows. <code>\"yes\"</code> config.enableEventDestinations String Indicates whether to enable event destinations. <code>\"yes\"</code> config.enableProfileDestinations String Indicates whether to enable profile destinations. <code>\"yes\"</code> config.enableIdentification String Indicates whether to enable identification. <code>\"yes\"</code> config.eventPartitioning String Strategy for event partitioning. Common values are <code>day</code>, <code>week</code>, <code>month</code>, <code>quarter</code>, <code>year</code>. <code>\"month\"</code> config.profilePartitioning String Strategy for profile partitioning. Common values are <code>day</code>, <code>week</code>, <code>month</code>, <code>quarter</code>, <code>year</code>. <code>\"quarter\"</code> config.sessionPartitioning String Strategy for session partitioning. Common values are <code>day</code>, <code>week</code>, <code>month</code>, <code>quarter</code>, <code>year</code>. <code>\"quarter\"</code> service.port Integer Port for the private API service. <code>8686</code> ingress.enabled Boolean Enable API ingress. <code>false</code> ingress.host String API ingress host. Wildcard is used for multitenant installation. <code>*.public.your-domain.com</code> ingress.path String Enable API path. <code>/</code>"},{"location":"installation/commercial/helm/helm_100/#differences-in-configuration-of-private-and-public-api","title":"Differences in Configuration of Private and Public API","text":"Configuration Field Private API Public API saveLogs yes no loggingLevel INFO WARNING apiDocs yes no service.port 8686 8585 topologySpreadConstraints Not applicable Configured"},{"location":"installation/commercial/helm/helm_100/#gui-configuration","title":"GUI Configuration","text":""},{"location":"installation/commercial/helm/helm_100/#overview_3","title":"Overview","text":"<p>The GUI configuration section in the <code>values.yaml</code> file specifies the settings for the graphical user interface (GUI) of Tracardi. This includes details about the Docker image, replica settings, service ports, and specific configuration options for the console.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields_4","title":"Configuration Fields","text":"<pre><code># GUI configuration\ngui:\n  image:\n    repository: tracardi/tracardi-gui  # Docker repository for the GUI image\n    pullPolicy: IfNotPresent  # Image pull policy\n    tag: 1.0.0  # Image tag, should be the same for GUI and backend\n\n  console:\n    enabled: true  # Whether the GUI is enabled\n    replicas: 1  # Number of replicas for the GUI\n    service:\n      port: 8787  # Port for the GUI service\n    ingress:\n      enabled: false\n      host: \"gui.your-domain.com\"\n      path: /\n    config:\n      mode: \"with-deployment\"  # Mode for the GUI\n      allowUpdatesOnProduction: \"no\"  # Whether to allow updates on production\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields_5","title":"Explanation of Fields","text":"Field Description image.repository Docker repository for the GUI image. image.pullPolicy Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. image.tag Image tag. console.enabled Indicates whether the GUI is enabled. console.replicas Number of replicas for the GUI. console.service.port Port for the GUI service. console.ingress.enabled Enable GUI ingress. console.ingress.host GUI ingress host. console.ingress.path Enable GUI path. config.mode Mode for the console operation. Available values \"with-deployment\" or \"no-deployment\" config.allowUpdatesOnProduction Indicates whether updates are allowed on production."},{"location":"installation/commercial/helm/helm_100/#tms-configuration","title":"TMS Configuration","text":""},{"location":"installation/commercial/helm/helm_100/#overview_4","title":"Overview","text":"<p>The Tenant Management Service (TMS) configuration section in the <code>values.yaml</code> file specifies the settings for TMS in Tracardi. This includes details about the Docker image, replica settings, logging levels, service ports, and the service name.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields_5","title":"Configuration Fields","text":"<pre><code># TMS configuration\ntms:\n  image:\n    repository: tracardi/tms  # Docker repository for the TMS image\n    pullPolicy: IfNotPresent  # Image pull policy\n    tag: 1.0.0  # Image tag, should be the same for GUI and backend\n  docker:\n    enabled: true  # Whether Docker is enabled\n    replicas: 1  # Number of replicas for TMS\n    config:\n      loggingLevel: \"INFO\"  # Logging level for TMS\n    service:\n      port: 8383  # Port for the TMS service\n      name: be-fa-tms-svc  # The name of the TMS service\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields_6","title":"Explanation of Fields","text":"Field Description image.repository Docker repository for the TMS image. image.pullPolicy Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. image.tag Image tag. docker.enabled Indicates whether Docker is enabled for TMS. docker.replicas Number of replicas for TMS. service.port Port on which the TMS service runs. service.name Name of the TMS service. loggingLevel Logging level for TMS.  Common values are <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, and <code>DEBUG</code>."},{"location":"installation/commercial/helm/helm_100/#worker-configuration","title":"Worker Configuration","text":""},{"location":"installation/commercial/helm/helm_100/#overview_5","title":"Overview","text":"<p>The worker configuration section in the <code>values.yaml</code> file specifies the settings for various worker components in Tracardi, including background workers, APM (Auto Profile Merging) profiles, and upgrade workers. This configuration includes Docker image details, replica settings, logging levels, and resource limits.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields_6","title":"Configuration Fields","text":"<pre><code># Worker configuration\nworker:\n  background:\n    image:\n      repository: tracardi/background-worker  # Docker repository for the background worker image\n      tag: 1.0.0  # Image tag for the background worker\n      pullPolicy: IfNotPresent  # Image pull policy\n    enabled: true  # Whether the background worker is enabled\n    replicas: 1  # Number of replicas for the background worker\n    spread:\n      rules:\n        topologySpreadConstraints:\n          - maxSkew: 1  # Maximum skew for topology spread\n            topologyKey: kubernetes.io/hostname  # Topology key for spread constraints\n            whenUnsatisfiable: ScheduleAnyway  # Action to take when constraints are unsatisfiable\n            labelSelector:\n              matchLabels:\n                app.kubernetes.io/component: wk-pl-background  # Label selector for spread constraints\n    config:\n      loggingLevel: \"INFO\"  # Logging level for the background worker\n      bulker:\n         # Data Bulker\n         # \n         # The Data Bulker Configuration are setting for message bulker that is responsible for collecting messages and \n         # managing them for background storage operations.\n         # \n         # It operates by enforcing two main constraints: a size limit, which is the maximum number of messages the queue can\n         # hold, and a time limit, which dictates how long messages can remain in the queue. If either of these limits is\n         # exceeded, the queued data is flushed to storage.\n         # \n         # Additionally, if no new data arrives within a specified period of inactivity, a timeout is triggered that\n         # automatically flushes any remaining data in the queue that has not yet been processed.\n         maxTimeInBuffer: 5  # TimeLimit: Flush data to storage every X sec\n         bufferInactivityTimeOut: 10000 # If there is no data in then flash remaining buffer to storage in X milliseconds\n         minBatchSize: 200  # SizeLimit: Min number of messages in the queue buffer\n         maxBatchSize: 1000  # SizeLimit: Max number of messages in the queue buffer\n\n  apm:\n    image:\n      repository: tracardi/apm  # Docker repository for the APM image\n      tag: 1.0.0  # Image tag for the APM\n      pullPolicy: IfNotPresent  # Image pull policy\n    profile:\n      enabled: true  # Whether the APM profile is enabled\n      replicas: 1  # Number of replicas for the APM profile\n      config:\n        loggingLevel: \"INFO\"  # Logging level for the APM profile\n\n  upgrade:\n    image:\n      repository: tracardi/update-worker  # Docker repository for the upgrade worker image\n      tag: 1.0.0  # Image tag for the upgrade worker\n      pullPolicy: IfNotPresent  # Image pull policy\n    docker:\n      enabled: true  # Whether Docker is enabled\n      replicas: 1  # Number of replicas for the upgrade worker\n      config:\n        saveLogs: \"no\"  # Whether to save logs\n        loggingLevel: \"INFO\"  # Logging level for the upgrade worker\n      resources:\n        limits:\n          memory: 500Mi  # Memory limit for the upgrade worker\n          cpu: 500m  # CPU limit for the upgrade worker\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#bridges-configuration","title":"Bridges Configuration","text":""},{"location":"installation/commercial/helm/helm_100/#overview_6","title":"Overview","text":"<p>The bridges configuration section in the <code>values.yaml</code> file specifies the settings for the services responsible for collecting data from different channels. This includes the queue bridge configuration, detailing Docker image settings, enabling or disabling the bridge, setting the number of replicas, and logging levels. By default none standard bridges are disabled. You can safely remove this configuration form you local <code>values.yaml</code> file.</p>"},{"location":"installation/commercial/helm/helm_100/#configuration-fields_7","title":"Configuration Fields","text":"<pre><code># Bridges configuration for services responsible for collecting data from different channels\nbridge:\n  queue:\n    image:\n      repository: tracardi/com-bridge-queue  # Docker repository for the queue bridge image\n      tag: 1.0.0  # Image tag for the queue bridge\n      pullPolicy: IfNotPresent  # Image pull policy\n    docker:\n      enabled: false  # Whether Docker is enabled for the queue bridge\n      replicas: 1  # Number of replicas for the queue bridge\n      config:\n        loggingLevel: \"INFO\"  # Logging level for the queue bridge\n</code></pre>"},{"location":"installation/commercial/helm/helm_100/#explanation-of-fields_7","title":"Explanation of Fields","text":""},{"location":"installation/commercial/helm/helm_100/#queue-bridge","title":"Queue Bridge","text":"Field Description image.repository Docker repository for the queue bridge image. image.tag Image tag for the queue bridge. image.pullPolicy Image pull policy. Common values are <code>Always</code>, <code>IfNotPresent</code>, and <code>Never</code>. docker.enabled Indicates whether Docker is enabled for the queue bridge. docker.replicas Number of replicas for the queue bridge. docker.config.loggingLevel Logging level for the queue bridge. Common values are <code>ERROR</code>, <code>WARNING</code>, <code>INFO</code>, and <code>DEBUG</code>."},{"location":"installation/commercial/helm/helm_100/#summary","title":"Summary","text":"<p>Please override only the fields that needs to change in you local environment. Here is an example of such local <code>'values.yaml</code> file.</p> <pre><code># Dependencies\n\nelastic:   \n  host: elastic-std-svc.elastic-standalone.svc.cluster.local\n  schema: http\n  authenticate: true\n\nredis:\n  host: redis-master.redis.svc.cluster.local\n  schema: \"redis://\"\n  authenticate: true\n\npulsar:\n  host: pulsar-proxy.pulsar.svc.cluster.local:6650\n  api: http://pulsar-proxy.pulsar.svc.cluster.local:80\n  schema: \"pulsar://\"\n  authenticate: true\n\nmysql:\n  host: percona-db-pxc-db-haproxy.percona.svc.cluster.local\n  schema: \"mysql+aiomysql://\"\n  database: \"tracardi\"\n\ntmsApi:\n  host: be-fa-tms-svc.tracardi-com-090.svc.cluster.local\n\n# Secrets\n\nsecrets:\n  installation:\n    token: \"XXXX\"\n  dockerHub: \"tracardi-dockerhub\"\n  license:\n    licenseKey: \"XXXX\"\n  tms:\n    secretKey: \"XXXX\"\n    apiKey: \"XXXX\"\n  redis:\n    password: \"XXXX\"\n  pulsar:\n    token: \"XXXX\"\n  mysql:\n    username: \"root\"\n    password: \"XXXX\"\n\n# Networking\n\ndigitalOcean:\n  loadBalancer: true\n\n# Configuration\n\nconfig:\n  multiTenant:\n    multi: \"yes\"\n  primaryId: \"phm-\"  # Use phone as primary ID key, This value should be set only once during installation and never changed\n\n# Images and Versions\n\napi:\n  image:\n    tag: 1.0.0\n\n  private:\n    replicas: 1\n    service:\n      port: 48686\n\n  public:\n    replicas: 1\n    service:\n      port: 48585\n\ngui:\n  image:\n    tag: 1.0.0\n  console:\n    service:\n      port: 48787\n    config:\n      mode: \"no-deployment\"\n      allowUpdatesOnProduction: \"true\"\n\ntms:\n  image:\n    tag: 1.0.0\n  docker:\n    replicas: 1\n    service:\n      port: 48383\n\n# Workers\n\nworker:\n\n  background:\n    enabled: true\n    image:\n      tag: 1.0.0\n    replicas: 1\n\n  apm:\n    image:\n      tag: 1.0.0\n    profile:\n      enabled: true\n      replicas: 1\n\n  upgrade:\n    image:\n      tag: 1.0.0\n    docker:\n      enabled: true\n      replicas: 1\n</code></pre>"},{"location":"installation/dependencies/","title":"Installing Dependencies","text":"<p>This guide explains how to install the necessary services for Tracardi to run properly. Please note that this setup is intended for testing purposes only and is not suitable for production use. For a production-ready setup, please refer to the Elasticsearch and Redis documentation.</p> <p>Notice</p> <p>Open source Tracardi requires only: Redis, ElasticSearch, and MySql to run. Prerequisites for Commercial Tracardi are installed clusters of: Redis, ElasticSearch, MySql, and Apache Pulsar.</p>"},{"location":"installation/dependencies/#dependencies-installation","title":"Dependencies installation","text":"<p>We have several options when installing dependencies. Use your preferred method.</p>"},{"location":"installation/dependencies/#docker-installation","title":"Docker installation","text":"<ul> <li>Elasticsearch docker installation - version up to 8.11.3 </li> <li>Redis docker installation - Tracardi should work with any version of Redis. Recently tested version (7.2.4)</li> <li>Apache Pulsar docker installation - version 3.1.0</li> <li>Mysql docker installation - version 8.3. Tracardi also works on percona version tested on 8.0.36.</li> </ul>"},{"location":"installation/dependencies/#installation-from-deb","title":"Installation from DEB","text":"<ul> <li>Elasticsearch DEB installation</li> </ul>"},{"location":"installation/dependencies/#installation-from-helm-chart","title":"Installation from Helm Chart","text":"<p>The preferred method for installing commercial Tracardi dependencies is through Helmchart. To use this method, you will need access to commercial scripts that automate the installation process.</p> <ul> <li>Elasticsearch K8S Helm Chart installation</li> <li>Redis K8S Helm Chart  installation</li> <li>Apache Pulsar doK8S Helm Chart cker installation</li> <li>Mysql K8S Helm Chart  installation</li> </ul>"},{"location":"installation/dependencies/deb/elasticsearch/","title":"Elasticsearch","text":"<p>Notice</p> <p>It's important to note that this document does not cover the installation of Elasticsearch intended for production use. For information on setting up Elasticsearch for production environments, please refer to the official Elasticsearch documentation dedicated to production-ready installations.</p>"},{"location":"installation/dependencies/deb/elasticsearch/#elasticsearch-as-a-service","title":"Elasticsearch as a service","text":"<p>The Elasticsearch components are not available in Ubuntu\u2019s default package repositories. They can, however, be installed with APT after adding Elastic\u2019s package source list.</p> <p>All of the packages are signed with the Elasticsearch signing key in order to protect your system from package spoofing. Packages which have been authenticated using the key will be considered trusted by your package manager. In this step, you will import the Elasticsearch public GPG key and add the Elastic package source list in order to install Elasticsearch.</p> <p>To begin, use cURL, the command line tool for transferring data with URLs, to import the Elasticsearch public GPG key into APT. Note that we are using the arguments -fsSL to silence all progress and possible errors (except for a server failure) and to allow cURL to make a request on a new location if redirected. Pipe the output of the cURL command into the apt-key program, which adds the public GPG key to APT.</p> <p>Open a terminal and enter:</p> <pre><code>curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\n</code></pre> <p>Next, add the Elastic source list to the sources.list.d directory, where APT will look for new sources:</p> <pre><code>echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list\n</code></pre> <p>Next, update your package lists so APT will read the new Elastic source:</p> <pre><code>sudo apt update\n</code></pre> <p>Then install Elasticsearch with this command:</p> <pre><code>sudo apt install elasticsearch\n</code></pre> <p>Elasticsearch is now installed and ready to be configured.</p>"},{"location":"installation/dependencies/deb/elasticsearch/#elasticsearch-configuration","title":"Elasticsearch configuration","text":"<p>To configure Elasticsearch, we will edit its main configuration file elasticsearch.yml where most of its configuration options are stored. This file is located in the /etc/elasticsearch directory.</p> <p>Use your preferred text editor to edit Elasticsearch\u2019s configuration file. Here, we\u2019ll use nano:</p> <pre><code>sudo nano /etc/elasticsearch/elasticsearch.yml\n</code></pre> <p>Note</p> <p>Elasticsearch\u2019s configuration file is in YAML format, which means that we need to maintain the indentation format.  Be sure that you do not add any extra spaces as you edit this file.</p> <p>The elasticsearch.yml file provides configuration options for your cluster, node, paths, memory, network, discovery, and gateway. Most of these options are preconfigured in the file but you can change them according to your needs. For the purposes of our demonstration of a single-server configuration, we will only adjust the settings for the network host.</p> <p>Elasticsearch listens for traffic from everywhere on port 9200. You will want to restrict outside access to your Elasticsearch instance to prevent outsiders from reading your data or shutting down your Elasticsearch cluster through its [REST API] (https://en.wikipedia.org/wiki/Representational_state_transfer). To restrict access and therefore increase security, find the line that specifies network.host, uncomment it, and replace its value with localhost, so it looks like this:</p> <pre><code># ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: localhost\n</code></pre> <p>We have specified localhost so that Elasticsearch listens on all interfaces and bound IPs. If you want it to listen only on a specific interface, you can specify its IP in place of localhost. Save and close elasticsearch.yml. If you\u2019re using nano, you can do so by pressing CTRL+X, followed by Y and then ENTER .</p> <p>These are the minimum settings you can start with in order to use Elasticsearch. Now you can start Elasticsearch for the first time.</p> <p>Start the Elasticsearch service with systemctl. Give Elasticsearch a few moments to start up. Otherwise, you may get errors about not being able to connect.</p> <pre><code>sudo systemctl start elasticsearch\n</code></pre>"},{"location":"installation/dependencies/deb/elasticsearch/#testing-elasticsearch","title":"Testing elasticsearch","text":"<p>By now, Elasticsearch should be running on port 9200. You can test it with cURL and a GET request.</p> <pre><code>curl -X GET 'http://localhost:9200'\n</code></pre> <p>You should see the following response:</p> <pre><code>{\n  \"name\" : \"localhost\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"XHATygZ4R1C59dEXDUs-og\",\n  \"version\" : {\n    \"number\" : \"7.17.0\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"deb\",\n    \"build_hash\" : \"bee86328705acaa9a6daede7140defd4d9ec56bd\",\n    \"build_date\" : \"2022-01-28T08:36:04.875279988Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.11.1\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n</code></pre> <p>If you see a response similar to the one above, Elasticsearch is working properly. If not, make sure that you have followed the installation instructions correctly and you have allowed some time for Elasticsearch to fully start.</p> <p>Questions answered by this document:</p> <ul> <li>What are the software prerequisites for installation from source?</li> <li>How do you install Elasticsearch as a service?</li> <li>How do you configure Elasticsearch?</li> </ul>"},{"location":"installation/dependencies/docker/elasticsearch/","title":"Elasticsearch","text":"<p>Notice</p> <p>It's important to note that this document does not cover the installation of Elasticsearch intended for production use. For information on setting up Elasticsearch for production environments, please refer to the official Elasticsearch documentation dedicated to production-ready installations.</p>"},{"location":"installation/dependencies/docker/elasticsearch/#elasticsearch-database-as-docker","title":"ElasticSearch database as docker","text":"<p>Tracardi need elasticsearch as its backend. Please pull and run elasticsearch single node docker before you start Tracardi.</p> <p>You can do it with this command.</p> <pre><code>docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:7.13.2\n</code></pre> <p>Warning</p> <p>The provided docker command lacks a persistent volume, which means that when you stop the Docker container,  all the data will be lost. If you wish to preserve the data between Docker container restarts, you can use the  following command: <code>docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /path/on/host:/usr/share/elasticsearch/data docker.elastic.co/elasticsearch/elasticsearch:7.13.2</code>.  To ensure data persistence, replace /path/on/host in the command with the directory path on your computer  where you would like to store the Elasticsearch data.</p> <p>Note</p> <p>Running one instance of elasticsaerch is not a production solution. For production purposes,  it is necessary to run the elasticearch cluster. Last tested version that is compatible with tracardi is: 8.11.3.  We suggest installing version 7.13.2 as this version we use for our internal testing.  </p> <p>Questions answered by this document:</p> <ul> <li>What are the software prerequisites for installation from source?</li> <li>How do you configure Elasticsearch?</li> <li>How do you install Elasticsearch as a docker container?</li> </ul>"},{"location":"installation/dependencies/docker/mysql/","title":"MySql","text":"<p>Notice</p> <p>It's important to note that this document does not cover the installation of MySql intended for production use. For information on setting up MySql for production environments, please refer to the official MySql documentation dedicated to production-ready installations.</p> <p>Start standalone version of mysql with root password set to <code>root</code>:</p> <pre><code>docker run -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 mysql\n</code></pre> <p>Warning</p> <p>This docker does not have any storage volume attached to it so when stopped all the data will be lost. </p> <p>Notice</p> <p>Last tested version of mysql is: version 8.3. Tracardi also works on percona version tested on 8.0.36.</p> <p>Please see the MySql Documentation for proper installation.</p>"},{"location":"installation/dependencies/docker/pulsar/","title":"Apache Pulsar","text":"<p>Notice</p> <p>It's important to note that this document does not cover the installation of Apache Pulsar intended for production use. For information on setting up Apache Pulsar for production environments, please refer to the official Apache Pulsar documentation dedicated to production-ready installations.</p> <p>Start standalone version of Apache Pulsar with:</p> <pre><code>docker run -it \\\n-p 6650:6650 \\\n-p 8080:8080 \\\napachepulsar/pulsar:3.1.0 \\\nbin/pulsar standalone\n</code></pre> <p>Warning</p> <p>This docker does not have any storage volume attached to it so when stopped all the data will be lost. </p> <p>Notice</p> <p>Last tested version of apache pulsar is: version 3.1.0.</p> <p>Please see the Apache Pulsar Documentation for proper installation.</p>"},{"location":"installation/dependencies/docker/redis/","title":"Redis","text":"<p>Notice</p> <p>It's important to note that this document does not cover the installation of Redis intended for production use. For information on setting up Redis for production environments, please refer to the official Redis documentation dedicated to production-ready installations.</p> <p>Start standalone version of redis with:</p> <pre><code>docker run -p 6379:6379 redis\n</code></pre> <p>Warning</p> <p>This docker does not have any storage volume attached to it so when stopped all the data will be lost. </p> <p>Please see the Apache Pulsar Documentation for proper installation.</p>"},{"location":"installation/dependencies/helm/elasticsearch/","title":"Elasticsearch","text":""},{"location":"installation/dependencies/helm/elasticsearch/#dependencies-installation-with-helm-chart-scripts","title":"Dependencies Installation with helm chart scripts","text":"<p>Tracardi dependencies can be installed using installation scripts. </p> <p>Notice</p> <p>Provided script may need changes for proper scaling.</p>"},{"location":"installation/dependencies/helm/elasticsearch/#prerequisites","title":"Prerequisites","text":"<ul> <li>kubectl 1.21 or higher, compatible with your cluster (+/- 1 minor release from your cluster)</li> <li>Helm v3 (3.10.0 or higher)</li> <li>A Kubernetes cluster, version 1.21 or higher.</li> <li>Access to tracardi scripts repo. This is where the scripts are stored.</li> </ul>"},{"location":"installation/dependencies/helm/elasticsearch/#install-elasticsearch","title":"Install Elasticsearch","text":"<pre><code>cd argocd\nbash ./elastic-install-operator.sh\nbash ./elastic-install-helm.sh\n</code></pre> <p>To customize installation values go to: elastic/local-values.yaml</p>"},{"location":"installation/dependencies/helm/mysql/","title":"Mysql","text":""},{"location":"installation/dependencies/helm/mysql/#dependencies-installation-with-helm-chart-scripts","title":"Dependencies Installation with helm chart scripts","text":"<p>Tracardi dependencies can be installed using installation scripts. </p> <p>Notice</p> <p>Provided script may need changes for proper scaling.</p>"},{"location":"installation/dependencies/helm/mysql/#prerequisites","title":"Prerequisites","text":"<ul> <li>kubectl 1.21 or higher, compatible with your cluster (+/- 1 minor release from your cluster)</li> <li>Helm v3 (3.10.0 or higher)</li> <li>A Kubernetes cluster, version 1.21 or higher.</li> <li>Access to tracardi scripts repo. This is where the scripts are stored.</li> </ul>"},{"location":"installation/dependencies/helm/mysql/#install-mysql-percona","title":"Install Mysql (Percona)","text":"<pre><code>cd argocd\nbash ./percona-install-repo.sh\nbash ./percona-install-helm.sh\n</code></pre> <p>To customize installation values go to: percona/local-values.yaml</p>"},{"location":"installation/dependencies/helm/pulsar/","title":"Pulsar","text":""},{"location":"installation/dependencies/helm/pulsar/#dependencies-installation-with-helm-chart-scripts","title":"Dependencies Installation with helm chart scripts","text":"<p>Tracardi dependencies can be installed using installation scripts. </p> <p>Notice</p> <p>Provided script may need changes for proper scaling.</p>"},{"location":"installation/dependencies/helm/pulsar/#prerequisites","title":"Prerequisites","text":"<ul> <li>kubectl 1.21 or higher, compatible with your cluster (+/- 1 minor release from your cluster)</li> <li>Helm v3 (3.10.0 or higher)</li> <li>A Kubernetes cluster, version 1.21 or higher.</li> <li>Access to tracardi scripts repo. This is where the scripts are stored.</li> </ul>"},{"location":"installation/dependencies/helm/pulsar/#install-apache-pulsar","title":"Install Apache Pulsar","text":"<pre><code>cd argocd\nbash ./pulsar-install-helm.sh\n</code></pre> <p>To customize installation values go to: pulsar/local-values.yaml</p>"},{"location":"installation/dependencies/helm/redis/","title":"Redis","text":""},{"location":"installation/dependencies/helm/redis/#dependencies-installation-with-helm-chart-scripts","title":"Dependencies Installation with helm chart scripts","text":"<p>Tracardi dependencies can be installed using installation scripts. </p> <p>Notice</p> <p>Provided script may need changes for proper scaling.</p>"},{"location":"installation/dependencies/helm/redis/#prerequisites","title":"Prerequisites","text":"<ul> <li>kubectl 1.21 or higher, compatible with your cluster (+/- 1 minor release from your cluster)</li> <li>Helm v3 (3.10.0 or higher)</li> <li>A Kubernetes cluster, version 1.21 or higher.</li> <li>Access to tracardi scripts repo. This is where the scripts are stored.</li> </ul>"},{"location":"installation/dependencies/helm/redis/#install-redis","title":"Install Redis","text":"<pre><code>cd argocd\nbash ./redis-install-repo.sh\nbash ./redis-install-helm.sh\n</code></pre> <p>To customize installation values go to: redis/local-values.yaml</p>"},{"location":"installation/opensource/","title":"Open-Source Installation","text":"<p>This guide will walk you through the process of installing Tracardi, which consists of four main components: API, GUI, Automatic Profile Merging Worker (APM), and Update Worker.</p>"},{"location":"installation/opensource/#docker-compose-installation","title":"Docker compose installation","text":"<p>The simplest approach to installing Tracardi is by using Docker Compose. It's important to note that this installation is intended for testing purposes only, as it doesn't configure all the required services properly.</p> <ol> <li>Installation via docker compose: One liner installation for testing purposes.</li> </ol>"},{"location":"installation/opensource/#docker-one-by-one-installation","title":"Docker one-by-one installation","text":"<p>The open-source version of Tracardi can be installed by starting each Docker container separately. You will need to configure each Docker container to connect to the dependent services accordingly:</p> <ol> <li>Docker one-by-one installation: Description of all open-source Tracardi dockers.</li> </ol>"},{"location":"installation/opensource/#settings","title":"Settings","text":"<ol> <li>Open-source version env variables: Detailed information of open-source version    environment variables.</li> </ol>"},{"location":"installation/opensource/env_variables/","title":"Open-source env variables","text":"Environment Variable Description <code>_DEBUG_VERSION</code> Application version. Default: <code>1.0.x</code>. <code>TENANT_NAME</code> Tenant name for the application. Default: <code>None</code>. <code>EVENT_TO_PROFILE_COPY_CACHE_TTL</code> Cache TTL for event-to-profile copy. Default: <code>5</code>. <code>SOURCE_CACHE_TTL</code> Cache TTL for source data. Default: <code>5</code>. <code>SESSION_CACHE_TTL</code> Cache TTL for session data. Default: <code>5</code>. <code>EVENT_VALIDATION_CACHE_TTL</code> Cache TTL for event validation data. Default: <code>15</code>. <code>EVENT_METADATA_CACHE_TTL</code> Cache TTL for event metadata. Default: <code>15</code>. <code>EVENT_DESTINATION_CACHE_TTL</code> Cache TTL for event destination. Default: <code>5</code>. <code>PROFILE_DESTINATION_CACHE_TTL</code> Cache TTL for profile destination. Default: <code>5</code>. <code>DATA_COMPLIANCE_CACHE_TTL</code> Cache TTL for data compliance. Default: <code>5</code>. <code>TRIGGER_RULE_CACHE_TTL</code> Cache TTL for trigger rules. Default: <code>15</code>. <code>MYSQL_HOST</code> MySQL host. Default: <code>localhost</code>. <code>MYSQL_USERNAME</code> MySQL username. Default: <code>root</code>. <code>MYSQL_PASSWORD</code> MySQL password. Default: <code>root</code>. <code>MYSQL_SCHEMA</code> MySQL schema for async driver. Default: <code>mysql+aiomysql://</code>. <code>MYSQL_PORT</code> MySQL port. Default: <code>3306</code>. <code>MYSQL_DATABASE</code> MySQL database name. Default: <code>tracardi</code>. <code>MYSQL_ECHO</code> Enable MySQL echo. Default: <code>no</code>. <code>UNSET_CREDENTIALS</code> Unset credentials after use. Default: <code>off</code>. <code>ELASTIC_INDEX_REPLICAS</code> Number of Elasticsearch index replicas. Default: <code>1</code>. <code>ELASTIC_INDEX_SHARDS</code> Number of Elasticsearch index shards. Default: <code>3</code>. <code>ELASTIC_CONF_INDEX_SHARDS</code> Number of Elasticsearch configuration index shards. Default: <code>1</code>. <code>ELASTIC_SNIFF_ON_START</code> Enable Elasticsearch sniffing on start. Default: <code>None</code>. <code>ELASTIC_SNIFF_ON_CONNECTION_FAIL</code> Enable Elasticsearch sniffing on connection fail. Default: <code>None</code>. <code>ELASTIC_SNIFFER_TIMEOUT</code> Timeout for Elasticsearch sniffing. Default: <code>None</code>. <code>ELASTIC_CA_FILE</code> Path to Elasticsearch CA file. Default: <code>None</code>. <code>ELASTIC_API_KEY_ID</code> Elasticsearch API key ID. Default: <code>None</code>. <code>ELASTIC_API_KEY</code> Elasticsearch API key. Default: <code>None</code>. <code>ELASTIC_CLOUD_ID</code> Elasticsearch cloud ID. Default: <code>None</code>. <code>ELASTIC_MAX_CONN</code> Maximum number of Elasticsearch connections. Default: <code>25</code>. <code>ELASTIC_HTTP_COMPRESS</code> Enable HTTP compression for Elasticsearch. Default: <code>None</code>. <code>ELASTIC_VERIFY_CERTS</code> Verify certificates for Elasticsearch. Default: <code>off</code>. <code>ELASTIC_HOST</code> Elasticsearch host. Default: <code>http://localhost:9200</code>. <code>ELASTIC_HTTP_AUTH_USERNAME</code> Elasticsearch HTTP authentication username. Default: <code>elastic</code>. <code>ELASTIC_HTTP_AUTH_PASSWORD</code> Elasticsearch HTTP authentication password. Default: <code>None</code>. <code>ELASTIC_SCHEME</code> Elasticsearch scheme. Default: <code>http</code>. <code>ELASTIC_QUERY_TIMEOUT</code> Elasticsearch query timeout. Default: <code>12</code>. <code>ELASTIC_LOGGING_LEVEL</code> Elasticsearch logging level. Default: <code>ERROR</code>. <code>REDIS_HOST</code> Redis host. Default: <code>localhost</code>. <code>REDIS_PORT</code> Redis port. Default: <code>6379</code>. <code>REDIS_PASSWORD</code> Redis password. Default: <code>None</code>. <code>PRODUCTION</code> Enable production mode. Default: <code>no</code>. <code>TRACK_DEBUG</code> Enable track debugging. Default: <code>no</code>. <code>SAVE_LOGS</code> Save logs. Default: <code>yes</code>. <code>ENABLE_EVENT_DESTINATIONS</code> Enable event destinations. Default: <code>no</code>. <code>ENABLE_PROFILE_DESTINATIONS</code> Enable profile destinations. Default: <code>no</code>. <code>ENABLE_WORKFLOW</code> Enable workflows. Default: <code>yes</code>. <code>ENABLE_EVENT_VALIDATION</code> Enable event validation. Default: <code>yes</code>. <code>ENABLE_EVENT_RESHAPING</code> Enable event reshaping. Default: <code>yes</code>. <code>ENABLE_EVENT_SOURCE_CHECK</code> Enable event source checking. Default: <code>yes</code>. <code>ENABLE_IDENTIFICATION_POINT</code> Enable identification points. Default: <code>yes</code>. <code>SYSTEM_EVENTS</code> Enable system events. Default: <code>no</code>. <code>ENABLE_ERRORS_ON_RESPONSE</code> Enable errors on responses. Default: <code>yes</code>. <code>ENABLE_FIELD_UPDATE_LOG</code> Enable field update logging. Default: <code>no</code>. <code>DISALLOW_BOT_TRAFFIC</code> Disallow bot traffic. Default: <code>yes</code>. <code>KEEP_PROFILE_IN_CACHE_FOR</code> Cache profile duration in seconds. Default: <code>3600</code>. <code>KEEP_SESSION_IN_CACHE_FOR</code> Cache session duration in seconds. Default: <code>1800</code>. <code>SKIP_ERRORS_ON_PROFILE_MAPPING</code> Skip errors on profile mapping. Default: <code>no</code>. <code>NEW_COLLECTOR</code> Use new event collector. Default: <code>yes</code>. <code>SYNC_PROFILE_TRACKS_MAX_REPEATS</code> Maximum number of profile track sync retries. Default: <code>10</code>. <code>SYNC_PROFILE_TRACKS_WAIT</code> Wait time between profile track sync retries (seconds). Default: <code>1</code>. <code>STORAGE_DRIVER</code> Storage driver. Default: <code>elastic</code>. <code>TRACARDI_PRO_HOST</code> Tracardi Pro host. Default: <code>pro.tracardi.com</code>. <code>TRACARDI_PRO_PORT</code> Tracardi Pro port. Default: <code>40000</code>. <code>LOGGING_LEVEL</code> Application logging level. Default: <code>WARNING</code>. <code>SERVER_LOGGING_LEVEL</code> Server logging level. Default: <code>WARNING</code>. <code>MULTI_TENANT</code> Enable multi-tenant mode. Default: <code>no</code>. <code>MULTI_TENANT_MANAGER_URL</code> URL for multi-tenant manager. Default: <code>None</code>. <code>MULTI_TENANT_MANAGER_API_KEY</code> API key for multi-tenant manager. Default: <code>None</code>. <code>EXPOSE_GUI_API</code> Expose GUI API. Default: <code>yes</code>. <code>IMAGE_TAG</code> Docker image tag. Default: <code>n/a</code>. <code>INSTALLATION_TOKEN</code> Installation token. Default: <code>tracardi</code>. <code>EVENT_PARTITIONING</code> Event data partitioning frequency. Default: <code>quarter</code>. <code>PROFILE_PARTITIONING</code> Profile data partitioning frequency. Default: <code>quarter</code>. <code>SESSION_PARTITIONING</code> Session data partitioning frequency. Default: <code>quarter</code>. <code>ENTITY_PARTITIONING</code> Entity data partitioning frequency. Default: <code>quarter</code>. <code>ITEM_PARTITIONING</code> Item data partitioning frequency. Default: <code>year</code>. <code>LOG_PARTITIONING</code> Log data partitioning frequency. Default: <code>month</code>. <code>DISPATCH_LOG_PARTITIONING</code> Dispatch log data partitioning frequency. Default: <code>month</code>. <code>CONSOLE_LOG_PARTITIONING</code> Console log data partitioning frequency. Default: <code>month</code>. <code>USER_LOG_PARTITIONING</code> User log data partitioning frequency. Default: <code>year</code>. <code>FIELD_CHANGE_LOG_PARTITIONING</code> Field change log data partitioning frequency. Default: <code>month</code>. <code>AUTO_PROFILE_MERGING</code> Auto profile merging token. Default: <code>s&gt;a.d-kljsa87^5adh</code>. <code>APM</code> Enable Application Performance Monitoring (APM). Default: <code>yes</code>. <code>AUTOLOAD_PAGE_SIZE</code> Page size for auto-load. Default: <code>25</code>. <code>USE_X_FORWARDED_IP</code> Use X-Forwarded-For header to get client IP. Default: <code>None</code>. <code>API_DOCS</code> Enable API docs. Default: <code>yes</code>. <code>PERFORMANCE_TRACKING</code> Enable performance tracking. Default: <code>None</code>. <code>CONFIG</code> Path to configuration file. Default: <code>config.yaml</code>. <code>INSTALLATION_TOKEN</code> Installation token. Default: <code>tracardi</code>."},{"location":"installation/opensource/docker/docker/","title":"Docker-based Tracardi Open-Source Installation","text":"<p>Notice</p> <p>Make sure you have docker installed on your system.</p> <p>Notice</p> <p>The following instalation description use the latest tracardi container version. If you would like to install stable version  of the system, what we strongly recommend, please add to <code>tracard/tracardi-api</code> a tag with version, e.g <code>tracardi/tracardi-api:0.8.1</code>.  The same applies to <code>tracardi/tracardi-gui</code>. Keep the version of API, GUI, and APM the same. </p>"},{"location":"installation/opensource/docker/docker/#start-tracardi-api","title":"Start Tracardi API","text":"<p>Pull and run Tracardi backend.</p> <pre><code>docker run -p 8686:80 \\\n-e ELASTIC_HOST=http://&lt;elasticsearch-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\ntracardi/tracardi-api:&lt;last-version&gt; #(1)\n</code></pre> <ol> <li>Replace &lt;...-ip&gt; with your local laptop IP if the service is installed locally or with server IP where the service is installed. Replace  with the latest version. Do not use latest. <p>Tracardi must connect to dependant services. To do that you have to set ELASTIC_HOST, REDIS_HOST, MYSQL_HOST variable to reference your laptop's or server IP.</p> <p>Please use the version tag</p> <p>Please use only docker with version tag. Do not use latest. See the version in docker hub. </p> <p>Waiting for application startup</p> <p>Notice that when type <code>http://localhost:9200</code> you try to connect to Elastic on localhost. This means that you're connecting to the docker itself as localhost means local in docker. Obviously elastic is not there, so Tracardi will never connect. Pass external ip for elastic. This may be your laptop IP if you are running Tracardi locally.</p>"},{"location":"installation/opensource/docker/docker/#api-documentation","title":"API Documentation","text":"<p>For API documentation visit http://127.0.0.1:8686/docs</p>"},{"location":"installation/opensource/docker/docker/#start-tracardi-gui","title":"Start Tracardi GUI","text":"<p>Pull and run Tracardi Graphical User Interface.</p> <pre><code>docker run -p 8787:80 tracardi/tracardi-gui:&lt;last-version&gt; #(1)\n</code></pre> <ol> <li>If you want a certain version of docker image add version tag, e.g. <code>tracardi/tracardi-gui:0.8.1</code></li> </ol> <p>Please use the version tag</p> <p>Please use only docker with version tag. See the latest version in docker hub. </p>"},{"location":"installation/opensource/docker/docker/#run-tracardi-graphical-user-interface","title":"Run Tracardi Graphical User Interface","text":"<p>Visit http://127.0.0.1:8787 and follow the instructions to finish up the Tracardi set-up.  When asked for Tracardi API type: http://127.0.0.1:8686. </p>"},{"location":"installation/opensource/docker/docker/#start-tracardi-apm-automatic-profile-merging","title":"Start Tracardi APM (Automatic Profile Merging)","text":"<p>Pull and run Tracardi APM.</p> <pre><code>docker run \\\n-e ELASTIC_HOST=http://&lt;elasticsearch-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\n-e MODE=worker \\\n-e PAUSE=5 \\\ntracardi/apm:&lt;last-version&gt;\n</code></pre>"},{"location":"installation/opensource/docker/docker_compose/","title":"Open-source Tracardi with docker compose","text":""},{"location":"installation/opensource/docker/docker_compose/#installation","title":"Installation","text":"<p>The easiest way to run TRACARDI is to run it as a  docker container. Please install docker and docker-compose on your local machine  then clone tracardi/tracardi-api</p> <pre><code>git clone https://github.com/Tracardi/tracardi-api.git:&lt;version&gt;\n</code></pre> <p>Go to TRACARDI API folder, and run one line command:</p> <pre><code>cd tracardi-api\ndocker-compose up\n</code></pre> <p>This command will install all required services along with tracardi API and required workers. To test if the installation is correct visit http://localhost:8686.</p>"},{"location":"installation/production/painpoints_in_hudge_mutitenant_setups/","title":"Pain-points in huge multi-tenant setups","text":"<p>When operating Tracardi in environments with a large number of tenants (over 100), several significant challenges arise:</p> <ol> <li> <p>Index Capacity in Elasticsearch: By its default settings, Elasticsearch (ES) can support up to 1000 indices.    However, given that Tracardi, version prior 0.9.0, allocates approximately 16 indices per tenant, this limit can be reached rapidly as the number    of tenants grows. It necessitates adjustments to Elasticsearch configurations to accommodate a greater number of    indices.</p> </li> <li> <p>Performance Verification: It's crucial to rigorously test the system to ascertain its efficiency and reliability    under the strain of a multi-tenant arrangement (with exceeded 1000 indices). This ensures that the introduction of    more tenants doesn\u2019t compromise the performance of the system.</p> </li> <li> <p>Anticipated Software Updates: The Tracardi development team is contemplating a migration of certain data types    from Elasticsearch to MySQL. This transition introduces a dependency on a MySQL database, which requires careful    integration and management alongside the existing Elasticsearch database. This should allow storing more tenant data    per one ES cluster.</p> </li> <li> <p>Cluster Grouping: To further support a growing number of tenants, it is necessary to establish multiple Tracardi    clusters. Each of these clusters should be accessible through its own unique URL. Furthermore, each cluster can    employ various data partitioning strategies, which allows for more tenants to be accommodated within one cluster. For    details on data partitioning, refer to Tracardi's documentation.</p> </li> </ol>"},{"location":"license/","title":"Tracardi licensing","text":"<p>Tracardi Licensing Options:</p> <p>Tracardi offers users two distinctive licensing options to cater to their specific needs:</p> <ol> <li> <p>Open Source License:    Under the Open Source license, Tracardi provides users with the liberty to access, modify, and distribute the    software's source code openly. This license is based on the MIT license with the inclusion of the Common Clause,    ensuring that the software remains accessible while still protecting its commercial use.</p> </li> <li> <p>Standard Commercial License:    In addition to the Open Source license, Tracardi also offers a Standard Commercial License, which is ideal for    businesses and organizations seeking enhanced features and greater freedom of use. With this license, commercial    entities can make full use of Tracardi's features and functionalities for their commercial projects.</p> </li> </ol> <p>It's important to note that both licenses are granted to a single customer, allowing them to choose the license that best suits their requirements and intended usage of the Tracardi software.</p>"},{"location":"license/com_license/","title":"Standard Commercial License","text":"<p>The Standard Commercial License enables commercial usage of Tracardi. It grants users access to exclusive commercial features that are not available in the open-source version of the system. Moreover, this license allows users to access the source code, preventing vendor lock-in.</p> <p>The Standard Commercial License is provided per one instance of the software, which means it is granted to one company. If you wish to use Tracardi with multiple customers or resell it to others, you'll need to purchase a separate license for each customer, regardless of how many instances of the software you have installed to serve them, or sign a Reseller  agreement with Tracardi. </p>"},{"location":"license/com_license/#license-restrictions","title":"License Restrictions","text":"<p>The Commercial License removes the restriction of using Tracardi solely for \"internal business purposes.\" This means you are allowed to sell the software license or permit your customers to use Tracardi. However, the license is granted per licensee, so it can't be shared with multiple unrelated customers.</p> <p>Within this license, there is no restriction on the amount of data you can store in the system. You can store an unlimited number of records, users, and more, as long as they belong to one company. Additionally, the license is not limited by territory, meaning you can use Tracardi anywhere globally. You also have the flexibility to replicate the software to accommodate your traffic needs.</p>"},{"location":"license/com_license/#bulk-licensing","title":"Bulk licensing","text":"<p>If you want to allow multiple customers to use Tracardi or resell it, you have two options. You can either sign a reseller contract or purchase a separate license for each customer. For larger bulk purchases, significant discounts are available.</p> <p>Q&amp;A:</p> <ul> <li>Can I make changes to commercial version of Tracardi?</li> <li>Do the license prevent vendor lock?</li> <li>What is in the standard commercial license?</li> <li>Can I resell Tracardi with Standard Commercial License?</li> </ul>"},{"location":"license/os_license/","title":"Open-source license","text":"<p>Tracardi is available under MIT with Common Clause.</p>"},{"location":"license/os_license/#mit-license","title":"MIT License","text":"<p>Copyright 2021 Risto Kowaczewski</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"license/os_license/#commons-clause-license-condition-v10","title":"\u201cCommons Clause\u201d License Condition v1.0","text":"<p>The Software is provided to you by the Licensor under the License, as defined below, subject to the following condition.</p> <p>Without limiting other conditions in the License, the grant of rights under the License will not include, and the License does not grant to you, the right to Sell the Software.</p> <p>For purposes of the foregoing, \u201cSell\u201d means practicing any or all of the rights granted to you under the License to provide to third parties, for a fee or other consideration (including without limitation fees for hosting or consulting/ support services related to the Software), a product or service whose value derives, entirely or substantially, from the functionality of the Software. Any license notice or attribution required by the License must also include this Commons Clause License Condition notice.</p> <p>Software: Tracardi</p> <p>License: MIT</p> <p>Licensor: Risto Kowaczewski</p>"},{"location":"license/os_license/#qa","title":"Q&amp;A:","text":"<ul> <li>Examples of allowed and not allowed usages under this license </li> <li>Can I use Tracardi for my own project for free?</li> <li>Do I need a commercial license to host Tracardi as SaaS?</li> </ul>"},{"location":"qa/are_events_connected_to_profiles_before_sent_to_destination/","title":"Are events linked to profiles before they are sent to the destination in the data integration process?","text":"<p>Yes, in the data integration process, events are linked to profiles before being sent to the destination. Each event is assigned a profile ID and session ID, ensuring that by the time the events reach the stream or warehouse destination, they are appropriately associated with the correct profiles. This pre-linkage of events to profiles is essential for keeping the data organized and relevant within the warehouse.</p>"},{"location":"qa/can_i_add_custom_event_timestamp/","title":"Can I add custom event timestamp?","text":"<p>Yes, you can add a custom event timestamp. In the Event Payload structure, there is a <code>time</code> attribute which includes the timestamp information for the event. You can set the <code>time.insert</code> attribute to the desired date and time to override the default insert time, which represents the time of event collection.</p> <p>Similarly, you can customize the <code>time.create</code> and <code>time.update</code> attributes to provide custom timestamps for event creation and update if needed. By leveraging these attributes, you have the flexibility to control the temporal aspects associated with the event and ensure accurate representation within your event tracking system.</p>"},{"location":"qa/can_i_make_changes_to_code_under_com_license/","title":"Can I make changes under commercial license?","text":"<p>Under the commercial license agreement, the customer is permitted to modify the source code of the software. This allows for customization and adaptation of the software to meet specific requirements or preferences.</p>"},{"location":"qa/can_i_only_process_the_event/","title":"Can I only process the event?","text":"<p>Yes, you have the option to only process an event without saving it permanently in the system. There are two approaches to achieve this:</p> <ol> <li> <p>Set the event source to be ephemeral: By designating the event source as ephemeral, the data received through this    type of event source is processed by the workflow without being saved in the system. Ephemeral event sources are    typically used for real-time processing and analysis, allowing for temporary data usage during the workflow without    the need for long-term storage.</p> </li> <li> <p>Adjust the event configuration: Within the event payload, there is an <code>options</code> attribute that provides additional    instructions for event processing. By setting the <code>saveEvent</code> option to <code>false</code>, the event will be processed but not    permanently saved in the system. This allows you to perform the necessary operations and derive insights from the    event without persisting it.</p> </li> </ol> <p>These options give you the flexibility to choose whether to save the event or solely focus on its processing based on your specific requirements and use case.</p>"},{"location":"qa/can_i_resell_com/","title":"Can I sell Tracardi under standard license agreement?","text":"<p>No. The standard agreement does state that the customer may not sell, lease, license, or sublicense the software or documentation. If you would like to sell Tracardi licenses you need a Reseller Agreement with Tracardi</p>"},{"location":"qa/can_i_send_marketing_campaigns/","title":"Can I send marketing campaigns from Tracardi? Is Tracardi a Marketing Automation Platform?","text":"<p>Tracardi supports marketing-related features and integrations, but it is not a dedicated marketing automation system. It is designed to enhance customer engagement and improve the overall consumer experience.</p> <p>That means that you can trigger campaigns but Tracardi is not designed for Marketing Automation tasks.</p> <p>Note</p> <p>That Tracardi can send one-to-one emails and SMSes.</p>"},{"location":"qa/can_i_use_my_own_profile_id/","title":"Can I use my own profile ID?","text":"<p>Yes, you can use your own ID as a profile ID in Tracardi. The platform allows for custom profile ID generation, as seen with the introduction of a static profile ID generator in version 0.8.1. This means you can set or pass your own unique identifier as the profile ID during the data ingestion or profile creation process, ensuring that the ID used aligns with your existing systems or requirements.</p> <p>Make sure that you define an event source that allows static profile ID.</p>"},{"location":"qa/can_i_use_my_own_profile_id/#security-issue-when-using-custom-profile-id","title":"Security issue when using custom profile ID","text":"<p>When using custom profile IDs in Tracardi, there is a security consideration you should be aware of to avoid potential vulnerabilities:</p> <p>Predictable IDs: If the custom profile IDs follow a predictable pattern (e.g., incremental numbers or easily guessable strings), it could lead to security risks like enumeration attacks. Attackers might be able to guess or iterate through possible IDs to gain unauthorized access to store events under not their profile. Use UUIDs or strong, unpredictable identifiers to reduce the risk of ID guessing or enumeration attacks.</p>"},{"location":"qa/can_i_use_system_for_my_own_project/","title":"Can I use Tracardi for my own project for free?","text":"<p>Yes, you can use Tracardi for your own project, as long as it is not intended for sale. In other words, if the project is for your personal use or for internal purposes within your organization and not meant for commercial distribution or sale, you are allowed to use Tracardi freely.</p>"},{"location":"qa/can_i_use_tracardi_for_free/","title":"Can I use Tracardi for free?","text":"<p>Yes, you can use Tracardi for free as an individual or a small company. Tracardi offers a free open-source version that provides comprehensive features and the ability to leverage AI-driven insights and automation.</p> <p>However, it's important to note that if you plan to create a software-as-a-service (SAAS) platform that sells Tracardi or if you intend to resell Tracardi to your customers, you would need to consider the commercial open-source version, which is designed for marketing agencies and larger corporations. The commercial open-source version may have additional features and support tailored to meet the needs of businesses operating at a larger scale.</p> <p>In summary, Tracardi offers a free open-source version for individuals and small companies, but if you plan to sell or resell Tracardi as a service, you would need to consider the commercial open-source version.</p> <p>This document also answers the questions: - Can I sell Tracardi?</p>"},{"location":"qa/can_kafka_be_an_event_source/","title":"Is it possible to use Kafka as the primary source of events for Tracardi, where events from various channels are initially published to Kafka?","text":"<p>In the commercial version of Tracardi, there is a Kafka bridge, and the payload format aligns with the API. If you have alternative strategies for event collection, it's possible to extend this bridge. However, it's important to note that when collecting events through Kafka, a synchronous connection is not available. This means that if you require a response or intend to use a widget, it may not be suitable.</p> <p>Regarding the organization of data, there isn't a prescribed method; you can simply subscribe to a topic, and Tracardi will consume the data. It's essential to ensure that the payload structure matches that of the API body.</p>"},{"location":"qa/can_tracardi_import_data_from_csv/","title":"Can Tracardi import data from CSV files and external sources using a secure API?","text":"<p>Tracardi supports data imports from external sources using its API. While there isn't a dedicated CSV import feature, a script can be used to import CSV data through regular Tracardi API endpoints. Importing data directly from the machine where the CSV is saved can often be more advantageous for large datasets, rather than uploading it to the server first.</p>"},{"location":"qa/can_tracardi_use_chatgpt/","title":"Can Tracadi use ChatGPT?","text":"<p>Yes, Tracardi can use ChatGPT. There are two options available to integrate ChatGPT with Tracardi.</p> <p>The first option is to make direct API calls to the OpenAI API, which allows you to interact with ChatGPT  programmatically. This means you can send user queries to the API and receive responses from ChatGPT,  which can then be utilized within the Tracardi workflow.</p> <p>The second option is to use the Tracardi Chat GPT plugin. This plugin is specifically designed to integrate ChatGPT  functionality into the Tracardi platform. </p> <p>Both options enable Tracardi to utilize ChatGPT for conversational purposes.</p>"},{"location":"qa/can_you_describe_tracardi_components/","title":"Can you describe Tracardi components?","text":"<p>This is technical documentation of source code and dockers.</p>"},{"location":"qa/can_you_describe_tracardi_components/#commercial-tracardi-api","title":"Commercial Tracardi API","text":"<ul> <li>Source: com-tracardi/com_tracardi, tracardi/tracardi</li> <li>Github: https://github.com/Tracardi/com-tracardi, https://github.com/Tracardi/tracardi</li> <li>Docker: tracardi/com-tracardi-api</li> <li>Description: This is commercial Tracardi API responsible for collecting and processing events.</li> </ul>"},{"location":"qa/can_you_describe_tracardi_components/#commercial-jobs","title":"Commercial Jobs","text":""},{"location":"qa/can_you_describe_tracardi_components/#heartbeats","title":"Heartbeats","text":"<ul> <li>Source: com-tracardi/com_job/heartbeat</li> <li>Github: https://github.com/Tracardi/com-tracardi</li> <li>Docker: tracardi/com-heartbeat-job</li> <li>Description: This job is responsible for running some defined event on all profiles. </li> </ul>"},{"location":"qa/can_you_describe_tracardi_components/#live-segmentation","title":"Live Segmentation","text":"<ul> <li>Source: com-tracardi/com_job/segmentation</li> <li>Github: https://github.com/Tracardi/com-tracardi</li> <li>Docker: tracardi/com-tracardi-segmentation-job</li> <li>Description: Iterate over live segmentation flows and push to the segmentation:live queue a job for worker that   segments the profile based on the live workflows.</li> </ul>"},{"location":"qa/can_you_describe_tracardi_components/#commercial-workers","title":"Commercial Workers","text":""},{"location":"qa/can_you_describe_tracardi_components/#scheduler","title":"Scheduler","text":"<ul> <li>Source: None</li> <li>Github: https://github.com/Tracardi/com-tracardi</li> <li>Docker: tracardi/com-tracardi-scheduler-worker, tracardi/com-tracardi-scheduler</li> <li>Description: background processes for Pause and Result actions. This is basically as rq worker and rqscheduler from RQ   library.</li> </ul>"},{"location":"qa/can_you_describe_tracardi_components/#segmentation-and-coping","title":"Segmentation and Coping","text":"<ul> <li>Source: com-tracardi/com_worker</li> <li>Github: https://github.com/Tracardi/com-tracardi</li> <li>Docker: tracardi/com-tracardi-segmentation-worker</li> <li>Redis Queue Worker that monitors the following queues:<ul> <li>segmentation:live,</li> <li>event_to_profile_coping:worker,</li> <li>event_props_to_event_traits:worker</li> </ul> </li> <li>Description:<ul> <li>event_props_to_event_traits:worker is responsible for background coping of historical event properties to traits.</li> <li>event_to_profile_coping:worker is responsible for background event to profile coping</li> <li>segmentation:live is responsible for warning live segmentations. It is triggered by segmentation job.</li> </ul> </li> </ul>"},{"location":"qa/can_you_describe_tracardi_components/#commercial-bridges","title":"Commercial bridges","text":"<ul> <li>Source: com-bridge-queue</li> <li>Github: https://github.com/Tracardi/com-bridge-queue</li> <li>Description: Queue bridges.</li> </ul>"},{"location":"qa/can_you_describe_tracardi_components/#open-source-tracardi-api","title":"Open-source Tracardi API","text":"<ul> <li>Source:tracardi</li> <li>Github: https://github.com/Tracardi/tracardi-api</li> <li>Description: This is open-source Tracardi API responsible for collecting and processing events.</li> </ul>"},{"location":"qa/can_you_describe_tracardi_components/#open-source-workers","title":"Open-source Workers","text":"<ul> <li>Source:tracardi/worker</li> <li>Github: https://github.com/Tracardi/tracardi-api</li> <li>Description: This is open-source Tracardi worker responsible for imports and system migration. </li> </ul> <p>This document also answers the questions.</p> <ul> <li>Provide an overview of the different components that comprise Tracardi ?</li> <li>What are the key building blocks or modules that constitute Tracardi ?</li> <li>What are the fundamental components or sections within Tracardi ?</li> <li>What are the main functions of Tracardi components ?</li> <li>What containers Tracardi needs?</li> </ul>"},{"location":"qa/com_basic_terms/","title":"What are the basic terms of Tracardi commercial agreement?","text":"<p>The basic terms of the standard Tracardi commercial license agreement are as follows:</p> <ol> <li> <p>Order: The agreement is formed based on the order that references these terms and identifies the software, developer,    and customer involved.</p> </li> <li> <p>Versions: The agreement covers the specific software version mentioned in the order, as well as any new versions    provided by the vendor during the agreement's duration.</p> </li> <li> <p>Modifications: The customer is allowed to make changes to the software's source code, compile those changes, and run    modified versions of the software.</p> </li> <li> <p>Billing: The vendor invoices the customer as per the order, and the customer agrees to pay the fees using the    specified payment method. There are provisions for addressing billing errors.</p> </li> <li> <p>Term and Termination: The agreement continues on a month-to-month basis after the trial period ends. Either party can    terminate the agreement immediately if the other party breaches the terms outlined in the agreement.</p> </li> <li> <p>Use: The customer may use the software for its own computing needs and those of its subsidiaries and corporate    affiliates. Specific usage restrictions and prohibited uses are mentioned.</p> </li> <li> <p>Licenses: The customer and authorized users are granted standard licenses for the software's copyrights and patents    mentioned in the agreement. There are separate licenses for the software and its documentation.</p> </li> <li> <p>Open Source: The agreement addresses the use of open source components and provides guidelines for compliance with    open source licenses.</p> </li> <li> <p>Delivery: The vendor agrees to deliver the software, its source code, relevant documentation, and license keys within    specified timeframes and using specified methods.</p> </li> <li> <p>Limited Technical Support: The vendor does not provide a technical support for the software within this license.</p> </li> <li> <p>Warranties: The vendor does not provide warranties related to the software.</p> </li> <li> <p>Prohibited Use: The customer agrees not to use the software for illegal or unauthorized purposes.</p> </li> <li> <p>Liability: The vendor disclaims certain warranties, and both parties agree on limitations and caps on liability,     except for certain uncapped liabilities.</p> </li> <li> <p>Responsibilities: The customer bears responsibility for the use, data storage, and data processing associated with     the software.</p> </li> <li> <p>Indemnities: The customer agrees to indemnify and hold the vendor harmless from any claims or damages arising from     the customer's use of the software.</p> </li> <li> <p>Tax: The customer is responsible for paying applicable taxes on the fees, except for the vendor's income tax.</p> </li> <li> <p>General Contract Terms: The terms cover notices, governing law, dispute resolution, enforcement, amendments,     waivers, assignment, and other general provisions related to the agreement.</p> </li> </ol> <p>Please note that this is a summary of the terms mentioned in the provided draft, and it is always advisable to review and seek legal advice on any specific agreement to ensure compliance with applicable laws and suitability for your particular situation.</p>"},{"location":"qa/com_license_vendor_lock/","title":"Will I be vendor locked if I use Tracardi?","text":"<p>Tracardi tries hard not to vendor lock its customers. They provide API integration, allowing you to create adapters and decouple from Tracardi in the future if needed. Tracardi does not host your data, so there is no risk of data loss when the agreement ends. Tracardi's flexibility allows you to add custom code to the code base, providing additional flexibility to meet your specific needs.</p>"},{"location":"qa/describe_some_of_the_merging_scenarios/","title":"Describe some of the merging scenarios.","text":"<p>When merging data fields in a system, the behavior and outcome depend significantly on the rules defined for the merging process. Here's a breakdown of some of the scenarios:</p> <ol> <li> <p>Merging two empty fields:</p> <ul> <li>If two empty fields are merged, typically, the merged field remains empty. This is because merging two   non-values (empty fields) generally results in no change.</li> </ul> </li> <li> <p>Merging one empty field with a non-empty field:</p> <ul> <li>Usually, the system will skip the empty field and retain the value of the non-empty field in the merged result.   This prevents overwriting meaningful data with an empty value.</li> </ul> </li> <li> <p>Merging two fields with different timestamps:</p> <ul> <li>When fields with different timestamps are merged, the system will select the field to retain based on the defined   merging strategy. Common strategies might include keeping the most recent data (based on timestamp) or the oldest,   depending on the requirements. Thus, the timestamp of the merged field will be that of the selected field,   preserving the context of when the retained data was last updated.</li> </ul> </li> <li> <p>Merging and summing fields with different timestamps:</p> <ul> <li>If the fields are summed (e.g., numerical data being aggregated), the timestamp of the resulting field is   typically set to the time of the summation. This indicates when the new value was computed, providing a current   timestamp reflecting the latest update.</li> </ul> </li> </ol>"},{"location":"qa/difference_between_major_and_minor_upgrades/","title":"What are the differences between major and minor upgrades","text":"<p>The main differences between minor and major upgrades can be summarized as follows:</p> <p>Minor Upgrades:</p> <ol> <li>Changes: Minor upgrades involve updates that do not require modifications to the underlying database structure.</li> <li>Version Number: Minor upgrades are indicated by a change in the last number of the version. For example, going from    version 1.2.0.1 to 1.2.0.1.</li> <li>Data Migration: Minor upgrades generally do not require data migration or schema updates.</li> <li>Compatibility: Minor upgrades are designed to ensure backward compatibility, meaning that the system will continue to    work as it did before the upgrade.</li> </ol> <p>Major Upgrades:</p> <ol> <li>Changes: Major upgrades involve substantial changes, including modifications to the underlying database structure.</li> <li>Version Number: Major upgrades are indicated by a change in a number other than the last one in the version. For    example, going from version 2.0.0 to 3.0.0 or 0.8.0 rto 0.8.1.</li> <li>Data Migration: Major upgrades often require data migration or schema updates to align the existing data with the new    version.</li> <li>Upgrade Process: Major upgrades typically involve a more involved process, including running two copies of the    system (old and new) and migrating the data from the old version to the new version.</li> <li>Compatibility: Major upgrades may introduce backward-incompatible changes, meaning that the system may require    additional steps and effort to ensure that existing functionalities and data work correctly with the new version.</li> </ol> <p>In summary, minor upgrades involve smaller updates that do not require significant changes to the system's database structure. Major upgrades, on the other hand, encompass substantial changes, including modifications to the database structure, and often require data migration and careful planning to ensure a smooth transition to the new version.</p>"},{"location":"qa/do_i_have_to_define_custom_properties_upfront/","title":"Do I have to define custom properties","text":"<p>No, you do not have to define custom profile properties upfront. The traits field, where custom profile attributes are stored, allows for dynamic storage of data without the need for predefined schema or attribute definitions. You can add custom attributes to a profile as needed without any prior definition or configuration. This flexibility enables you to adapt and extend the profile data based on your evolving requirements or specific use cases.</p>"},{"location":"qa/do_i_need_license_for_saas/","title":"Do I need a commercial license to host Tracardi as SaaS?","text":"<p>Yes, to host Tracardi as a Software-as-a-Service (SaaS) platform and offer it to customers for sale, you will require a commercial license. This license allows you to go beyond in-house use and use Tracardi for commercial purposes, such as offering it as a service to external customers.</p>"},{"location":"qa/does_system_store_update_timestamp_for_each_field_in_profile/","title":"Does the system store an update timestamp for each field in a profile?","text":"<p>Yes, if possible, Tracardi stores all field updates in <code>metadata.fields</code>. This data is utilized during profile merging. However, note that this feature is available only in the commercial version of Tracardi. Some merging strategies may not work in the open-source version.</p>"},{"location":"qa/does_tracarid_have_its_own_backup_system/","title":"Does tracardi has its own backup system?","text":"<p>No. Tracardi uses the built-in backup mechanism of Elasticsearch for data backups. Elasticsearch allows you to create backups of your data for disaster recovery and data protection. The backup process involves creating snapshot repositories to store the backup data, defining a snapshot lifecycle policy, and using the Snapshot and Restore API to manage the backup process. </p>"},{"location":"qa/empty_destination_drop_down/","title":"Could you please explain why there is no drop-down list or other options in the \u2018destination\u2019 field in the outbound traffic?","text":"<p>In Tracardi, a \"destination\" in the outbound traffic settings is a location or service where you can send or store processed data. However, to use the destination field, you first need to create a \"resource.\" A resource in Tracardi is an external entity or service that a plugin can interact with, such as databases, APIs, or other systems. These resources are crucial for storing the configuration data necessary for connecting and interacting with these external entities.</p> <p>As of version 0.8.2, Tracardi supports the following resources for sending data to:</p> <ol> <li>REST API endpoint</li> <li>RabbitMQ</li> <li>Mautic</li> </ol> <p>Without setting up one of these resources, the destination field won't offer any dropdown options or other choices.</p>"},{"location":"qa/event_collection_process/","title":"Event collection process","text":"<p>Here's a rewritten version of the explanation:</p> <ol> <li> <p>Event Initiation:</p> <ul> <li>The process begins when a user interacts with your digital platform, such as a website or app.</li> <li>The client-side system (like your website's JavaScript) detects this interaction and generates an event, a data   packet that captures what the user did.</li> </ul> </li> <li> <p>Event Transmission:</p> <ul> <li>This event data is then sent to Tracardi, typically in real-time.</li> <li>Transmission is usually handled by a JavaScript snippet embedded in your website or via an API call from your   application.</li> <li>The event includes key identifiers like profile ID and session ID, which allow Tracardi to recognize and track the   user across different interactions.</li> </ul> </li> <li> <p>Reception and Validation:</p> <ul> <li>Tracardi's API receives the incoming event data.</li> <li>The system checks whether the event follows the required format and includes all necessary information.</li> <li>It also verifies the event's source by checking the event source ID to ensure it comes from a valid origin.</li> </ul> </li> <li> <p>Profile Identification:</p> <ul> <li>Tracardi attempts to match the event with an existing user profile using the provided identifiers.</li> <li>If no match is found, a new profile may be created, or the system might try to link the event to an existing   profile using other available data.</li> </ul> </li> <li> <p>Data Enrichment:</p> <ul> <li>Tracardi may enhance the event data by adding additional information.</li> <li>This could include the user's geographic location (derived from the IP address) or marketing-related data such as   UTM parameters.</li> </ul> </li> <li> <p>Event Processing:</p> <ul> <li>The event can trigger specific workflows within Tracardi, such as starting an automated marketing sequence.</li> <li>It might also activate integrations with external systems.</li> <li>The event is processed according to the rules and actions you've configured within Tracardi.</li> </ul> </li> <li> <p>Profile Update:</p> <ul> <li>The event data is used to update the user's profile in Tracardi's database.</li> <li>If applicable, Tracardi may merge this profile with others if it determines they belong to the same user.</li> </ul> </li> <li> <p>Data Storage:</p> <ul> <li>The complete event data is stored in Tracardi's database for future analysis and reporting.</li> <li>The user's profile is also updated and saved, reflecting any new information from this event.</li> </ul> </li> <li> <p>Profile ID Response:</p> <ul> <li>Tracardi sends the profile ID back to the client (your website or app).</li> <li>This ID should be stored on the client-side and included with all future events for this user, ensuring consistent   tracking.</li> </ul> </li> </ol> <p>This process is executed in parallel in commercial Tracardi, some steps may be pushed as background processes, while open source version process all steps one after another. </p>"},{"location":"qa/event_not_firing/","title":"A have sent event form javascript using window.tracker.track but I do not see it in Tracardi. This is the code:","text":"<pre><code>window.tracker.track(\"purchase-order\", {\n  \"product\": \"Sun glasses - Badoo \" + index,\n  \"price\": 13.45\n}, {\n  async: false\n});\n</code></pre> <p>The issue seems to be that the event \"purchase-order\" is not being sent from the widget to Tracardi. This could be due to the fact that the event are waiting for the page to load before firing. To send event on demand additional option must be added. To resolve this issue, you can add the <code>fire: true</code> option to the <code>window.tracker.track</code> call. This will instruct the event to fire immediately, regardless of whether the page has loaded or not.</p> <p>Here's the corrected code:</p> <pre><code>window.tracker.track(\"purchase-order\", {\n  \"product\": \"Sun glasses - Badoo \" + index,\n  \"price\": 13.45\n}, {\n  async: false,\n  fire: true\n});\n</code></pre> <p>This should ensure that the \"purchase-order\" event is sent to Tracardi immediately when the purchase button is clicked.</p>"},{"location":"qa/event_type_on_start_node/","title":"In the Start plugin, you can only select a predefined event from the list. What if you need a custom one? For example, event \u201cmy-event\u201d? If I write it in the required field, it does not be save. How do I add new events?","text":"<p>The most likely issue is that you didn't hit enter after entering the event type. Please note that simply adding an event type to the start node does not automatically redirect traffic to this node. Instead, you must use a trigger to direct the traffic. The event type defined at the start node level simply indicates where the workflow should initiate for specific event types. This is helpful when multiple events are directed to a single workflow, but only a specific start node should activate it. If there is only one start node or a single event routed to the workflow, defining an event type at the node level is unnecessary.</p>"},{"location":"qa/example_of_not_allowed_usage_under_os/","title":"Examples of what is and isn't allowed under the Common Clause license ?","text":"<p>Allowed under the Common Clause License: The Common Clause license allows you to use Tracardi for your company's internal needs or business purposes. It means you can use Tracardi within your organization to manage data or for other internal tasks. However, you cannot use Tracardi to create and sell products, services, or modules that heavily rely on Tracardi's main features. In simple terms, you can use Tracardi for your own business, but you can't make money by selling Tracardi or products built mainly using Tracardi.</p> <p>Allowed under the Common Clause License: Some examples include:</p> <ul> <li>Using Tracardi within your organization to analyze and manage customer data.</li> <li>Implementing Tracardi for internal data tracking and analytics purposes.</li> <li>Customizing Tracardi for internal use without offering it as a commercial product.</li> </ul> <p>Not Allowed under the Common Clause License: The Common Clause license prohibits certain commercial uses where the value of a product, service, or module is derived entirely or significantly from Tracardi's functionality. Here are some examples of what is not allowed:</p> <ul> <li>White-labeling Tracardi (removing Tracardi's branding) and offering it to customers for monetary gain.</li> <li>Hosting Tracardi and charging users for accessing all or some of its features and services.</li> <li>Selling a product or service that heavily relies on Tracardi's core functionality to generate value for customers.</li> </ul>"},{"location":"qa/hot_to_get_started_with_data_collection/","title":"How to get started with data collection from the website.","text":"<p>To begin with event collection in Tracardi, follow these steps:</p> <p>1. Ensure Tracardi Installation:</p> <ul> <li>You must have Tracardi installed on your system.</li> </ul> <p>2. Understand Test and Production Modes:</p> <ul> <li>Tracardi GUI operates in two modes: test and production.</li> <li>The test mode collects data via API which can be configured to run as Test or Production. The default mode is tests.</li> <li>A separate instance of Tracardi can be opened with environment variable PRODUCTION set to 'yes' for production data   collection, typically on a different port.</li> </ul> <p>3. Switch Modes as Admin:</p> <ul> <li>As an admin, you can switch between test and production modes by clicking the 'test' label next to the Tracardi logo.</li> </ul> <p>4. Note Separation of Environments:</p> <ul> <li>Test and production modes are separate environments, meaning data collected in the test mode is not visible in   production, and all settings are specific to one environment.</li> </ul> <p>5. Workflow:</p> <ul> <li>The typical workflow is to set up the system in test mode, then deploy it to production by going to '   Maintenance/Deployment' and clicking 'Deploy to Production.' This action copies all the settings to the production   instance.</li> </ul> <p>Example for Test Environment:</p> <ul> <li>To confirm that your API is in test mode, click on the Tracardi logo and check for results like:<ul> <li>Frontend Version: 0.8.1</li> <li>Backend Version: 0.8.1.01506</li> <li>DB Version: 08x</li> <li>API context: staging</li> <li>GUI context: staging</li> <li>'API context: staging' indicates the API is in test mode.</li> <li>'GUI context: staging' indicates the GUI is fetching data from the test environment.</li> </ul> </li> </ul> <p>Event Collection in Test Mode:</p> <ul> <li>Click on 'test' near the Tracardi logo to change the mode (the GUI should turn red), indicating the GUI is fetching   data from production.</li> </ul> <p>Return to Test Mode:</p> <ul> <li>Click again to return to test mode.</li> </ul> <p>Create an Event Source:</p> <ul> <li>Go to 'Inbound Traffic/Event Source' and create a new event source. This source will be available only in the test   environment.</li> </ul> <p>JavaScript Integration:</p> <ul> <li>Select 'Use and JavaScript' and paste the script into your page.</li> <li>Don't forget to add this part to collect events:</li> </ul> <pre><code>&lt;script&gt;\n    window.tracker.track(\"event-type\", {\"property\": \"value\"});\n&lt;/script&gt;\n</code></pre> <p>Check Collected Events:</p> <ul> <li>After refreshing the page, you should see the events in 'Data/Events' in the test environment. Switching to production   mode should display no events since you did not collect them via the production API.</li> </ul>"},{"location":"qa/hot_to_get_started_with_data_collection/#debugging-event-collection","title":"Debugging Event Collection","text":"<ul> <li>To debug event collection, visit the page where you placed the script.</li> <li>Right-click on it and select 'Inspect.'</li> <li>Choose the 'Network' tab and refresh the page.</li> <li>You should see all the connections made by the page, including a connection to the Tracardi API. Check for any errors.</li> </ul>"},{"location":"qa/hot_to_use_reports/","title":"How can I use reports in Tracardi?","text":"<p>There are two ways to use reports in Tracardi:</p> <ol> <li>Attaching Reports to Workflows: You can attach reports to your workflows in Tracardi and download data while the    workflow is running. This allows you to gather information and make decisions based on the data generated by the    workflow. To enable this functionality, you need to use a commercial plugin called \"Load Report.\" With this plugin,    you can define the specific data you want to collect and analyze within your workflows.</li> <li>Downloading Data via Tracardi API: Another way to utilize reports in Tracardi is by downloading the data from the    report through the Tracardi API. This approach is particularly useful when you need to export the data to an external    system or integrate it with other tools. By accessing the Tracardi API (/report/{id}/run), you can retrieve the    desired report data and then use it in any way you require within your external system.</li> </ol>"},{"location":"qa/how_apm_watchdog_works/","title":"How APM (Automatic Profile Merging) Watchdog works?","text":"<p>Here's a detailed breakdown of what it does:</p> <ol> <li>Check if APM is on:</li> </ol> <p>The code first checks if the APM (Automatic Profile Merging) system is enabled using tracardi.is_apm_on().</p> <ol> <li>Try-Catch Block:</li> </ol> <p>The whole process is wrapped in a try-catch block to handle any exceptions that may occur during execution. If an exception occurs, it logs an error message.</p> <ol> <li>Find all predefined merging keys/fields:</li> </ol> <p>The code iterates through a dictionary FLAT_PROFILE_FIELD_MAPPING which contains fields of profiles and their respective prefixes.</p> <ol> <li>Find Duplicated Profiles by Field:</li> </ol> <p>For each field, it gets duplicated profiles with duplicated fields values across profiles. This function returns the count of duplicates. It logs the count of duplicated field values.</p> <p>5.Process Each Profile with Duplicated Field Values:</p> <p>For each duplicated field value, it retrieves the profiles that have that specific duplicated field value. Each profile is then converted to a Profile entity.</p> <ol> <li>Recreate Hash IDs:</li> </ol> <p>For each profile, the system computes a new hashed value for the duplicated field value. It checks if this hashed value is already in the profile\u2019s IDs. If not, it logs an information message and creates the missing hashed ID, then appends the new hashed value to the profile's IDs.</p> <ol> <li>Mark Profiles for Merging:</li> </ol> <p>The profile is marked for merging and sets the auto-merge fields in the profile\u2019s metadata. The profile is then saved back to the database.</p> <ol> <li>Logging and Error Handling:</li> </ol> <p>If any error occurs during the process, it catches the exception and logs an error message with details about the failure.</p>"},{"location":"qa/how_backups_are_made_in_tracardi/","title":"How backups are done in Tracardi.","text":"<p>Tracardi uses the built-in backup mechanism of Elasticsearch that allows you to create backups of your data for disaster recovery and data protection.</p> <p>Here's an overview of how backups work in Elasticsearch:</p> <ol> <li> <p>Snapshot Repositories: Elasticsearch backups are created and stored in snapshot repositories. A snapshot    repository is a location where Elasticsearch stores the backup data. It can be a shared file system, a cloud storage    service, or a network-attached storage (NAS).</p> </li> <li> <p>Snapshot Lifecycle: You define a snapshot lifecycle policy that specifies how often to take backups and how long    to retain them. This policy automates the backup process and ensures that backups are created at regular intervals.</p> </li> <li> <p>Snapshot Creation: When a snapshot is created, Elasticsearch takes a point-in-time copy of the data and metadata    in the cluster. This includes index data, index settings, mappings, and other relevant information. The snapshot is    stored in the designated repository.</p> </li> <li> <p>Incremental Backups: Elasticsearch uses incremental backups, which means that subsequent snapshots only include    the changes since the last snapshot. This reduces the backup time and storage requirements.</p> </li> <li> <p>Snapshot and Restore API: Elasticsearch provides a Snapshot and Restore API that allows you to manage the backup    process. You can create, list, restore, and delete snapshots using this API. You can also monitor the status of    snapshot operations and track the progress.</p> </li> <li> <p>Cluster Coordination: When taking snapshots, Elasticsearch coordinates the backup process across all nodes in the    cluster. It ensures that each shard of the data is captured and included in the backup, even in a distributed cluster    setup.</p> </li> <li> <p>Backup Verification: Elasticsearch allows you to verify the integrity of a snapshot by performing a verification    process. This ensures that the backup data is intact and can be restored successfully if needed.</p> </li> <li> <p>Disaster Recovery: In the event of a disaster or data loss, you can restore a snapshot to recover your data.    Elasticsearch provides options to restore the entire cluster, specific indices, or individual shards from a snapshot.</p> </li> </ol> <p>Please read more about Elasticsearch (ES) backups in documentation.  </p>"},{"location":"qa/how_can_I_authorize_and_get_API_KEY/","title":"How can I authorize and get API KEY","text":"<p>To authorize and obtain an API key for Tracardi, you can use OAuth2 authorization. Here's an outline of the process:</p> <ol> <li>Make a POST request to the <code>/user/token</code> endpoint.</li> <li> <p>Include the necessary parameters in the request body:</p> <ul> <li><code>username</code> (string): Provide the username associated with your Tracardi account.</li> <li><code>password</code> (string): Enter the password for your Tracardi account.</li> </ul> </li> <li> <p>Send the request and await the response.</p> </li> <li>If the authorization is successful, the API will return a 200 response along with an OAuth2 token. This token serves    as your API key.</li> <li>Store the API key securely, as it will be required for subsequent authenticated requests to the Tracardi API.</li> </ol> <p>Please note that the specific endpoint, request parameters, and response format may vary depending on the Tracardi API documentation or implementation. It's recommended to consult the Tracardi API documentation or contact their support for precise details on how to authorize and obtain an API key.</p>"},{"location":"qa/how_can_i_benefit_from_commercial_version/","title":"How can I benefit from commercial license?","text":"<p>By obtaining a commercial license, you can benefit in the following ways:</p> <ul> <li> <p>Access to Enhanced Features: The commercial version of Tracardi provides a range of advanced features that are not   available in the open-source version. These features, such as streamlined configuration, advanced time-based event   handling, expanded event collectors, and extensive action plugins, can significantly enhance your customer journey   automation capabilities. With these enhanced features, you can streamline workflows, personalize customer experiences,   and gain deeper insights into customer behavior.</p> </li> <li> <p>Simplified Setup and Maintenance: The commercial version of Tracardi offers a simplified configuration process, making   it effortless to set up and maintain the tool. The user-friendly interface allows you to adapt the tool to your   specific business requirements quickly. This saves time and effort in the long run, enabling you to focus on   optimizing your workflows and engaging with customers.</p> </li> <li> <p>Comprehensive Data Collection and Management: Tracardi's commercial version provides additional event collectors that   can gather data from various sources, expanding the scope of data collection. You can leverage insights from diverse   platforms and systems, enabling a more comprehensive understanding of your customers. Additionally, the commercial   version allows for validating, transforming, and copying events, ensuring accurate and consistent data for further   analysis and action.</p> </li> <li> <p>Intelligent Profile Merging and Segmentation: The commercial version of Tracardi offers intelligent profile merging   based on identification points, providing a comprehensive view of each customer's journey. This allows you to better   understand and engage with your customers. Moreover, the commercial version facilitates automated segmentation of   customer profiles, enabling you to move profiles between segments based on profile activity or inactivity. This helps   in targeting and personalizing your marketing efforts effectively.</p> </li> <li> <p>Retroactive Data Processing: Tracardi's commercial version allows you to process historical data and copy it to   profiles or index event data, even if the events were collected before the corresponding workflows were created. This   capability enables you to retroactively leverage previously collected data, enhancing your customer data analysis and   enabling personalized communication based on historical information.</p> </li> <li> <p>Enhanced User Experience and Engagement: Tracardi's commercial version offers UIX widgets that enable interactive   forms to be injected into the customer journey. These widgets, such as rating widgets, allow customers to provide   feedback at different stages of their journey, providing valuable data for improving customer satisfaction and   experience. By leveraging these UIX widgets, you can enhance customer engagement and better understand customer   sentiments.</p> </li> </ul>"},{"location":"qa/how_can_i_benefit_from_partnership_with_tracardi/","title":"How can I benefit from partnership with Tracardi?","text":"<p>Partnering with Tracardi, can provide several benefits for your business:</p> <ul> <li> <p>Flexibility and Customization: Tracardi offers the flexibility to tailor the platform to your specific needs. You   can customize and extend its capabilities to align perfectly with your clients' requirements. This flexibility   empowers you to create unique and innovative solutions that deliver exceptional results, giving you a competitive   edge.</p> </li> <li> <p>Cost-Effectiveness: Partnering with an open-source CDP provider like Tracardi brings significant cost advantages.   Unlike proprietary solutions that often come with high licensing fees and additional costs for upgrades and   maintenance, Tracardi eliminates these expenses. You can allocate your resources towards enhancing and optimizing the   platform instead of spending on expensive licenses.</p> </li> <li> <p>Collaboration and Community: Tracardi is part of a vibrant ecosystem of developers, contributors, and users. By   partnering with Tracardi, you become part of this collaborative environment, fostering knowledge sharing,   problem-solving, and continuous improvement. You can tap into the expertise of the community, gain valuable insights,   and contribute back, fostering innovation and growth.</p> </li> <li> <p>Continuous Innovation: Tracardi, as an open-source project, is committed to constant innovation. The community-driven   nature ensures a steady stream of updates, enhancements, and new features. By partnering with Tracardi, you gain   access to cutting-edge advancements, enabling you to provide your clients with state-of-the-art solutions that adapt   to the evolving marketing landscape.</p> </li> <li> <p>Data Privacy and Security: Tracardi takes data privacy and security seriously. As an open-source platform, it   undergoes rigorous security audits and benefits from community-driven reviews, ensuring a robust and secure   infrastructure. You have complete control over your data and can implement necessary security measures to protect   sensitive information, building trust and credibility with your clients.</p> </li> <li> <p>Scalability and Integration: Tracardi offers scalability options to accommodate increased data volumes and complex   data workflows as your business grows. Additionally, Tracardi is designed to integrate with various systems and tools,   allowing you to create a unified ecosystem that streamlines data management, analytics, and marketing automation. This   seamless integration enhances your overall operational efficiency.</p> </li> </ul> <p>By partnering with Tracardi, you can leverage the flexibility, cost-effectiveness, collaborative community, continuous innovation, data privacy, and scalability it offers. This empowers your digital agency to deliver exceptional results to your clients, harness the power of data-driven marketing, and gain a competitive edge in today's dynamic business landscape.</p>"},{"location":"qa/how_can_i_filter_data/","title":"How do I filter data? What query should I use to filer data?","text":"<p>To filter data in Tracardi prior version 0.8.2, you can use the query syntax provided by the platform. Here are some examples of how to construct queries to filter data:</p> <ol> <li> <p>Search by a specific field value:</p> </li> <li> <p>To find records where the status field contains \"active\": status:active To find records where the event type field   contains either \"page-view\" or \"purchase\": event.type:(page-view OR purchase)</p> </li> <li>To find records where the event properties product field contains the exact phrase \"Nike sneakers\":   event.properties.product:\"Nike sneakers\"</li> <li> <p>To find records where the profile first name field contains \"Alice\": profile.data.pii.firstname:Alice. Please note the need to   escape the space if in field name with a backslash.</p> </li> <li> <p>Wildcard searches:</p> </li> <li> <p>You can use wildcard characters to replace single or multiple characters in a term. For example, qu?ck will match \"   quick\" or \"quack\", and bro* will match \"brown\", \"brother\", etc.</p> </li> <li> <p>Regular expressions:</p> </li> <li> <p>Regular expression patterns can be embedded in the query string using forward-slashes (\"/\"). For example, name:   /joh?n(ath[oa]n)/ will match \"john\" or \"jonathan\".</p> </li> <li> <p>Fuzzy queries:</p> </li> <li> <p>Fuzzy queries allow for approximate matches. Use the tilde (~) operator with a numeric value to specify the maximum   number of changes allowed. For example, quikc~ brwn~ will match \"quick brown\" or \"quack brown\".</p> </li> <li> <p>Ranges:</p> </li> <li> <p>Ranges can be specified for date, numeric, or string fields. Inclusive ranges are specified with square   brackets [min TO max], and exclusive ranges with curly brackets {min TO max}. For example,   date:[2012-01-01 TO 2012-12-31] will match all days in 2012.</p> </li> <li> <p>Boolean operators:</p> </li> <li> <p>The boolean operators AND, OR, and NOT (also written as &amp;&amp;, ||, and !) can be used to combine multiple conditions.   Parentheses should be used to specify the desired precedence. For example, (quick AND fox) OR (brown AND fox) OR fox)   AND NOT news will match records that contain \"quick\" and \"fox\" or \"brown\" and \"fox\" or just \"fox\", but not \"news\".</p> </li> </ol> <p>For more information look for term <code>Data searching</code> in the documentation.</p> <p>This document also answers the questions: - How to search data in Tracardi? - How to find data in Tracardi?</p>"},{"location":"qa/how_can_i_get_telegram_bot/","title":"How can I get Telegram bot token and chat ID?","text":"<p>To create a Telegram bot and obtain the bot token and chat ID, you'll need to follow these steps:</p> <ol> <li> <p>Create a Telegram Bot:</p> <ul> <li>Open the Telegram app and search for the \"BotFather\" (username: @BotFather).</li> <li>Start a chat with BotFather and use the command \"/newbot\" to create a new bot.</li> <li>Follow the instructions provided by BotFather to choose a name and username for your bot. d. Once the bot is   created, BotFather will provide you with a unique API token. This token is your bot token, and you will need it to   authenticate and interact with the Telegram Bot API.</li> </ul> </li> <li> <p>Obtain your Chat ID:</p> <ul> <li>Add your newly created bot to the desired Telegram chat or group where you want to receive messages.</li> <li>Open a web browser and enter the following URL, replacing <code>&lt;YourBotToken&gt;</code> with the token you received from   BotFather:    <pre><code>https://api.telegram.org/bot&lt;YourBotToken&gt;/getUpdates\n</code></pre></li> <li>You should see a JSON response that contains information about the most recent messages received by your bot.</li> <li>Look for the \"chat\" object in the response, which contains details about the chat your bot is part of.</li> <li>The \"id\" field within the \"chat\" object corresponds to the chat ID of the group or channel. Make note of this chat   ID; you will need it to send messages to the chat.</li> </ul> </li> </ol> <p>Remember to keep your bot token and chat ID confidential and do not share them publicly or with unauthorized individuals. With this information, you can use the Telegram Bot API to program your bot to send and receive messages in your chat or group.</p>"},{"location":"qa/how_can_i_install_extensions/","title":"How to install extension?","text":"<p>To install extensions, follow these steps:</p> <ol> <li>Go to the \"Resource/Extensions\" section of the software or platform you are using.</li> <li>Sign in to your account if required.</li> <li>Select one of the available extensions from the list.</li> <li>Click on the \"Install\" button associated with the chosen extension.</li> <li>Fill out any required forms that appear. These forms may ask for credentials or additional information related to the    extension.</li> <li>Submit the form after filling out all the necessary details.</li> <li>Wait for the extension to install. The installation process may take a few moments, depending on the size and    complexity of the extension.</li> </ol> <p>Note that some extensions may install both resources and plugins. Additionally, certain extensions might also install destinations.</p> <p>This document also answers the questions: - Where can I find extensions? - How to extend system functionality?</p>"},{"location":"qa/how_can_i_load_profile/","title":"How can I load profile in workflow?","text":"<p>My question is \"I have a profile-less event. How can I load a profile using the data I have sent in event properties?\"</p> <p>The best way to load a profile in Tracardi system is by using the \"Load profile by...\" plugin. This plugin enables Tracardi to load and replace the current profile in the workflow. To load the profile using this plugin, the user can configure it by specifying profile id or e-mail.</p> <p>It is also possible to load the profile right in the webhook bridge. Go to your webhook event source and click edit and find \"Replace Profile ID\". This feature is available in webhook event source starting from version 0.8.1.</p> <p>This document also answers the questions:</p> <ul> <li>How can I replace profile inside workflow?</li> <li>Can a profile-less event have profile ID?</li> <li>How to load profile by event property?</li> </ul>"},{"location":"qa/how_can_i_load_session/","title":"How can I load session in workflow?","text":"<p>My question is \"I have a profile-less event. How can I load a session using the data I have sent in event properties?\"</p> <p>It is possible to load the session right in the webhook bridge. Go to your webhook event source and click edit and find \"Replace Session ID\". This feature is available in webhook event source starting from version 0.8.1.</p> <p>This document also answers the questions:</p> <ul> <li>How can I replace session in profile-less event?</li> <li>Can a profile-less event have session ID?</li> <li>How to load session by event property?</li> </ul>"},{"location":"qa/how_can_i_udata_event/","title":"How can I update event?","text":"<p>Events are typically considered immutable once they are created, as they represent a historical record of something that occurred at a specific time. This immutability ensures data integrity and consistency. However, there are certain scenarios where you might need to update event-related information, and the methods you mentioned are examples of how this can be achieved:</p> <ol> <li> <p>Elasticsearch Query: While events themselves are immutable, you can use Elasticsearch queries to update event    data.</p> </li> <li> <p>Change event during processing: In Tracardi, there is a plugin that allow you to perform transformations or    mappings on events in workflow. It is called <code>Copy data</code>. Confirm that you want to change event with <code>Update Event</code>    action.</p> </li> <li> <p>Post Collection Event to Event Mapping: Commercial Tracardi provides a feature called \"post collection event to    event mapping.\" This feature allows you copy values between event properties after its being collected.</p> </li> </ol>"},{"location":"qa/how_can_i_udata_event/#update-event-by-query","title":"Update event by query","text":"<p>To update an event using an Elasticsearch query with the <code>update_by_query</code> API, follow these steps:</p> <ol> <li> <p>Create the Query: First, you need to construct the Elasticsearch query that specifies the documents (events) you    want to update. This query should include the criteria to identify the events you want to modify and the changes you    want to apply.</p> </li> <li> <p>Use the <code>update_by_query</code> API: This API allows you to update documents in an index based on a query. It will find    all documents matching the query and apply the specified changes to them.</p> </li> </ol> <p>Here's a general outline of the process:</p> <ol> <li>Construct the Query: Your Elasticsearch query should be written in the JSON format and target the events you want    to update. For example, if you want to update events with a certain attribute value, your query might look like this:</li> </ol> <pre><code>{\n  \"query\": {\n    \"term\": {\n      \"attribute_name\": \"value_to_match\"\n    }\n  }\n}\n</code></pre> <ol> <li>Define the Updates: Within your query, you need to specify the changes you want to make to the selected events.    This is done using the <code>script</code> parameter, which contains the code that will be executed for each matching event. For    instance:</li> </ol> <pre><code>{\n  \"query\": {\n    \"term\": {\n      \"attribute_name\": \"value_to_match\"\n    }\n  },\n  \"script\": {\n    \"source\": \"ctx._source.new_attribute = 'new_value'\"\n  }\n}\n</code></pre> <ol> <li>Execute the <code>update_by_query</code>: Use the Elasticsearch API to execute the <code>update_by_query</code> operation. This can be    done through various means, such as a command-line tool, a programming language's Elasticsearch library, or an HTTP    client like cURL.</li> </ol> <p>For example, using cURL:</p> <pre><code>curl -X POST \"http://localhost:9200/your_event_index/_update_by_query\" -H \"Content-Type: application/json\" -d '{\n  \"query\": {\n    \"term\": {\n      \"attribute_name\": \"value_to_match\"\n    }\n  },\n  \"script\": {\n    \"source\": \"ctx._source.new_attribute = 'new_value'\"\n  }\n}'\n</code></pre> <p>Replace <code>your_event_index</code> with the name of your event index in Elasticsearch.</p> <p>Keep in mind:</p> <ul> <li>Always be cautious when updating data. Test your queries on a small subset of data before applying them to a larger   dataset.</li> <li>The Elasticsearch version you're using might have variations in the syntax or features of the <code>update_by_query</code> API.   Check the Elasticsearch documentation for the version you're working with.</li> </ul> <p>Lastly, ensure you have the necessary permissions and access to perform updates on your Elasticsearch index.</p>"},{"location":"qa/how_can_i_use_reports/","title":"How can I use reports?","text":"<p>Reports in Tracardi serve as a means to analyze and extract valuable insights from the collected data. While Tracardi itself is not an analytical tool, it can integrate with external platforms like Tableau, Amplitude, Matomo, Google Analytics, and others, allowing you to send data from Tracardi to these platforms for more sophisticated analysis and report generation. This can be done by utilizing queues or other mechanisms for data transfer.</p> <p>Kibana is another analytical tool that can be used with Tracardi. It is specifically designed to work with data stored in Elasticsearch, which is the underlying database technology used by Tracardi. Kibana provides powerful visualization and analysis capabilities, allowing you to explore and gain insights from the data stored in Elasticsearch.</p> <p>In addition to integrating with external analytical platforms, Tracardi also offers its own reporting functionality. You can use Reports in Tracardi to run Elasticsearch queries on the collected data. These queries can aggregate the data and provide aggregated values for events, such as sums, averages, medians, or event counts based on specific properties. For example, you could calculate the total sum of the \"amount\" property for purchase events associated with a particular profile.</p> <p>Once a report is created, it can be loaded into a workflow as an action. This means that you can use the report's results as input for making decisions within the workflow. By leveraging reports in Tracardi, you can extract relevant information from the data and incorporate it into your decision-making processes.</p> <p>In summary, reports in Tracardi serve the purpose of extracting aggregated data from the Tracardi database and utilizing it for decision-making within workflows. Additionally, Tracardi can integrate with external analytical platforms like Tableau, Amplitude, Matomo, and Google Analytics to enable more advanced analysis and reporting capabilities.</p>"},{"location":"qa/how_do_i_get_my_own_source_id/","title":"How do I get my own event source id?","text":"<ol> <li> <p>Access the Inbound Traffic / Event Source Section: Log in to the platform or service where you track inbound traffic.    Navigate to the section that manages event sources.</p> </li> <li> <p>Click on \"New Event Source\": Look for a button or option labeled \"New Event Source\" and click on it to create a new    event source.</p> </li> <li> <p>Select REST API Bridge: From the available options for event sources, choose \"REST API Bridge\" as the type of event    source you want to create.</p> </li> <li> <p>Fill in the Name: Provide a name for your new event source. This name is for your reference and will help you    identify the event source in the future.</p> </li> <li> <p>Create the Event Source: Complete the necessary information and configuration for the REST API Bridge event source.    Once you have filled in the required details, proceed to create the new event source.</p> </li> <li> <p>Copy the Event Source ID: After successfully creating the event source, you should be redirected to a page displaying    the details of the new event source. On this page, you should find an \"ID\" associated with the event source. Copy    this ID to your clipboard.</p> </li> <li> <p>Use the ID with Tracking Script: Now that you have the event source ID, you can use it with your tracking script.</p> </li> </ol>"},{"location":"qa/how_do_i_setup_multi_tenant/","title":"How to start Tracardi in multi-tenant mode?","text":"<p>To start Tracardi in multi-tenant mode, follow these steps:</p> <ol> <li> <p>Obtain a commercial Tracardi API Docker: Multi-tenancy is a commercial feature, so you will need to acquire a    commercial version of the Tracardi API Docker.</p> </li> <li> <p>In the Docker configuration, set the <code>MULTI_TENANT</code> environment variable to \"yes\". This enables the multi-tenant mode    in Tracardi.</p> </li> <li> <p>Configure the Tenant Management Service (TMS): Tracardi's multi-tenant setup relies on a dependent system called the    Tenant Management Service (TMS). You will need to provide the necessary configuration details for the TMS to    integrate it with Tracardi. Specifically, you need to provide the following to the tracardi-api docker:</p> <ul> <li> <p><code>MULTI_TENANT_MANAGER_URL</code>: This is the URL of the Tenant Management Service (TMS). Set it to the appropriate   endpoint where the TMS is running.</p> </li> <li> <p><code>MULTI_TENANT_MANAGER_API_KEY</code>: Provide the API key for the TMS. This is used for authentication and authorization   between Tracardi and the TMS.</p> </li> </ul> </li> </ol>"},{"location":"qa/how_get_mailchimp_api_key_for_transactional_emails/","title":"How to get API Key for one-to-one transactional e-mails","text":"<p>To obtain the API key for sending transactional emails with Mailchimp (specifically through the Mandrill service), follow these steps:</p> <ul> <li>Log in to your Mailchimp account.</li> <li>Click on your account icon in the top-right corner.</li> <li>Select \"Profile\".</li> <li>In the \"Profile\" section, choose \"Extras\" and then \"API keys\".</li> <li>Under the \"Your API keys\" section, click on \"Add a Mandrill API Key\" (not \"Create A Key\").</li> <li>You will be redirected to the Mandrill website.</li> <li>Follow the instructions on the Mandrill site to set up your sending domain and verify ownership.</li> <li>Once you have completed the domain verification, you will find the API key on the Mandrill site.</li> <li>Copy the API key and use it for sending transactional emails, such as with the Tracardi Form.</li> </ul> <p>Please note that verifying your domain and making changes to your DNS records may be required in order to send one-to-one emails successfully. Failure to complete the domain verification process may result in rejected emails with the error message \"unsigned\" when sending from Tracardi.</p>"},{"location":"qa/how_live_segmentation_works_from_technical_point_of_view/","title":"How live segmentation works from technical point of view?","text":"<p>From a technical point of view, live segmentation involves several components and processes working together. Here's an overview of how live segmentation works:</p> <ul> <li> <p>Workflow Definition: Live segmentation starts with defining workflows, which outline the steps and logic for   segmenting profiles. These workflows specify the conditions, actions, and filters required to classify profiles into   segments.</p> </li> <li> <p>Profile Retrieval: The live segmentation system fetches the defined workflows. It then retrieves the profiles that   need to be segmented. Profiles typically contain user data, such as demographics, preferences, behaviors, and   interactions.</p> </li> <li> <p>Iteration and Execution: The system iterates over each profile and executes the defined workflow for that profile.   This means that the segmentation logic is applied to each individual profile to determine its segment membership.</p> </li> <li> <p>Task Queuing: To efficiently manage the segmentation tasks, a pool of segmentations is created. Each segmentation task   is queued in a Redis queue, which acts as a job queue system. The queue holds the tasks until a worker is available to   process them.</p> </li> <li> <p>Segmentation Job Docker: The segmentation job docker container, named \"tracardi/com-tracardi-segmentation-job\", is   responsible for orchestrating the segmentation tasks. It picks up all workflows, batches profiles and schedules them   for processing.</p> </li> <li> <p>Segmentation Worker Docker: The segmentation worker docker container, named \"   tracardi/com-tracardi-segmentation-worker\" performs the actual segmentation computations. When a worker receives a   task from the job docker, it applies the workflow logic to the corresponding profile, determines the segment(s) the   profile belongs to, and stores the segmentation results in profile. This way segmentation can run in parallel.</p> </li> <li> <p>Result Storage: After a worker finishes segmenting a profile, it stores the segmentation results in profile in key segments. </p> </li> <li> <p>Cron Job: Live segmentation is often scheduled as a recurring task using a cron job. The cron job triggers the   segmentation process at specified intervals, ensuring that profiles are regularly segmented based on the defined   workflows. Docker tracardi/com-tracardi-segmentation-job is responsible for this.</p> </li> </ul> <p>In summary, live segmentation involves defining workflows, retrieving profiles, queuing segmentation tasks, and executing the tasks using dedicated job and worker docker containers. The segmentation process applies the workflow logic to each profile, determines the corresponding segment(s), and stores the results for further analysis.</p> <p>THis document answers the questions: - Which dockers are responsible for live segmentation - Is live segmentation scheduled? - Does live segmentation run in parallel?</p>"},{"location":"qa/how_many_events_can_handle_tracardi/","title":"How many events can handle Tracardi?","text":"<p>Tracardi can handle a high volume of events, with the exact number depending on your specific hardware configuration and network bandwidth. However, Tracardi is designed to be scalable, so you can easily add more resources to handle increasing event volumes.</p> <p>In general, Tracardi can handle millions of events per day without any issues. For example, one Tracardi user reported handling over 50 million events per day with a cluster of 10 Tracardi nodes.</p> <p>Tracardi is a very thin layer on top of elasticsearch, redis and Apache Pulsar.</p> <p>Here are some factors that can affect the number of events that Tracardi can handle:</p> <ul> <li>Hardware configuration: The more CPU cores, RAM, and disk space you have, the more events Tracardi can handle.</li> <li>Network bandwidth: The more bandwidth you have, the faster Tracardi can process and store events.</li> <li>Event size: The larger your events are, the fewer events Tracardi can handle per second.</li> <li>Event processing: The more complex your event processing rules are, the fewer events Tracardi can handle per second.</li> </ul> <p>If you are concerned about the number of events that Tracardi can handle, you can contact Tracardi support for a more specific assessment. They can help you determine the optimal hardware configuration and network bandwidth for your needs.</p>"},{"location":"qa/how_many_records_can_tracardi_store/","title":"How many records can tracardi store?","text":"<p>Tracardi can store a significant amount of data. The largest production instance currently holds 0.3 billion events collected in 3 months. The same amount can be stored as profiles. Tracardi uses Elasticsearch as its backend storage, which is capable of storing records in the billions. The data is split into monthly indices for easy management, data movement between cluster nodes, and automatic archiving if needed.</p>"},{"location":"qa/how_merging_strategies_are_matched/","title":"How Merging Strategies are Matched","text":"<p>The system determines which merge strategy to use when there is a conflict in profile data. Strategies can be matched either by exact field match or wildcard field match.</p>"},{"location":"qa/how_merging_strategies_are_matched/#exact-field-match","title":"Exact Field Match","text":"<p>For example, if a strategy is defined to be triggered for conflicts in the field <code>profile.ids</code>, this is considered a final match, and nothing can override this. This exact match ensures that conflicting fields are resolved using the specific set of strategies defined for them.</p>"},{"location":"qa/how_merging_strategies_are_matched/#wildcard-match","title":"Wildcard Match","text":"<p>If no strategy is defined for <code>profile.ids</code>, the system looks for wildcard strategies such as <code>profile.*</code> or <code>*</code>. The <code>profile.*</code> strategy can be applied to any missing strategy for fields that start with <code>profile.</code>. The <code>*</code> strategy matches all fields and serves as a general fallback.</p> <p>As of Tracardi 1.0.0, strategies are predefined in the system and cannot be changed. This may change in future versions.</p>"},{"location":"qa/how_pause_and_resume_works/","title":"Does the pause event impact the performance? Causing the workflow cannot complete in several days.","text":"<p>The pause event does not directly impact the performance of the current event process. When you pause an event, it is sent to a background scheduled task and placed in a queue for completion. This means that the current event process continues without being affected by the pause.</p> <p>Once the pause time is finished, the event either resumes as a separate event if it has been configured as such, or it resumes as an internal system event that is not recorded but processed. In either case, the response to the current event is returned immediately, allowing the process to continue uninterrupted.</p> <p>Overall, the pause event has minimal impact on the performance of the current event process, as it is handled separately in the background without interrupting the ongoing operations.</p>"},{"location":"qa/how_post_segmentation_works/","title":"How post event segmentation work?","text":"<p>Post event segmentation works differently from live segmentation as it is triggered by events that update the profile. Here's an explanation of how post event segmentation works:</p> <ul> <li> <p>Profile Update: Post event segmentation is initiated when an event occurs and updates the profile.</p> </li> <li> <p>Event Type: Post event segmentation is typically configured to run only on specific event types. This means that the   segmentation process is triggered only when the specified event type occurs. For example, if the event type is \"   purchase,\" segmentation will be performed only when a purchase event is received and updates the profile.</p> </li> <li> <p>Segment Evaluation: Once the event updates the profile, the system evaluates the segment conditions defined in the   segmentation condition. These conditions can be based on factors, such as profile attributes, traits, or properties.   The segment conditions define the criteria that profiles must meet to be assigned to a particular segment.</p> </li> <li> <p>Segment Assignment: If a profile satisfies the segment conditions, it is assigned to the defined segment.</p> </li> </ul> <p>Overall, post event segmentation is triggered when an event updates the profile. It evaluates the segment conditions and assigns the profile to the appropriate segment if the conditions are met.</p> <p>This documents answers the following questions:</p> <ul> <li>My post event segmentation does not work</li> <li>How the post event segmentation is different for live segmentation?</li> <li>Why my post event segmentation does not work?</li> </ul>"},{"location":"qa/how_profile_event_and_session_ids_are_tied_up_together/","title":"How profile, event and session ids are tied up together?","text":"<ul> <li>Events have references to both the profile ID and session ID.</li> <li>Sessions have references to the profile ID.</li> <li>This means that a profile can be associated with multiple events and sessions (session is basically a visit).</li> </ul> <p>To illustrate this relationship, consider the following example:</p> <p>Visit one:</p> <pre><code>Event 1, Event 2, and Event 3 are associated with Profile 1 and Session 1.\n</code></pre> <p>Visit two:</p> <pre><code>Event 4, Event 5, and Event 6 are associated with Profile 1 and Session 2.\n</code></pre> <p>This example demonstrates that the profile is connected to multiple events and multiple sessions. The session ID changes when the user opens a new browser or visits a new page, representing a new session or visit. However, the session ID remains the same between the visits or interactions within a session. In the context of web page the script that is placed on the wab page is responsible for changing the session ID when the browser is closed. </p> <p>It's important to note that the system automatically increments the visit counts in the profile when the session ID changes, reflecting the number of visits or sessions associated with that profile.</p>"},{"location":"qa/how_profile_event_and_session_ids_are_tied_up_together/#data-example","title":"Data Example","text":"<p>Visit one.</p> <p>Event tables</p> Event ID Profile ID Session ID 1 1 1 2 1 1 3 1 1 <p>Visit two</p> Event ID Profile ID Session ID 4 1 2 5 1 2 6 1 2 <p>Visit counts in profile are automatically incremented when the session id changes. </p>"},{"location":"qa/how_profile_event_and_session_ids_are_tied_up_together/#debugging-and-session-ids","title":"Debugging and Session IDs","text":"<p>When utilizing the debug mode in the workflow editor, it's important to note that the behavior of session IDs may differ from regular operation. In debug mode, the session ID remains the same for every simulated event, which can impact the expected functionality.</p> <p>During debugging, the workflow editor creates a fake event and session to simulate the execution of the workflow. The IDs assigned to these debug entities are constant, meaning they don't change with each iteration or interaction. This consistent session ID can affect the expected behavior of the system, as it deviates from the dynamic session ID changes that occur in regular user sessions.</p> <p>It's crucial to consider this discrepancy when debugging workflows that involve session-dependent logic or functionality. If the workflow relies on different session IDs for distinct visits or interactions, the debug mode's static session ID may not accurately reflect the intended behavior (it will not increase the visits in profile).</p> <p>To overcome this limitation, it's recommended to thoroughly test the workflow in a test mode (See test in the left-hand menu). By doing so, you can ensure that the workflow functions as expected under normal conditions, considering the dynamic nature of session IDs in actual user sessions.</p> <p>Keep in mind that the debug mode's static session ID serves the purpose of simplifying the debugging process by providing consistency and predictability. However, it's important to be aware of its impact on session-dependent logic when transitioning from debug mode to live deployment.</p>"},{"location":"qa/how_profile_is_loaded/","title":"How the profile is loaded?","text":"<p>To load a profile, two identifiers are used: session_id and profile_id. Both of them are optional, so we have four different loading scenarios:</p> <ol> <li>If the session exists and the profile exists in the Tracardi database, both the profile and the session are loaded    from the database.</li> <li>If the session exists but the profile does not exist in the database, a new profile is created and saved to the    database, and the existing session is loaded.</li> <li>If the session does not exist but the profile already exists in the database, the existing profile is loaded, and a    new session is created and saved in the database.</li> <li>If neither the session nor the profile exists, then both the session and the profile are created and saved in the    database.</li> </ol> <p>Error scenarios that may occur:</p> <ol> <li>Session and profile are defined, but the profile does not exist in the database. The result of this operation is that    the saved session in the database will reference the old profile, which will be restored.</li> <li>Session and profile are defined, but the session does not exist in the database. The result of this operation is that    a new session will be created.</li> <li>Session and profile are defined. The session does not exist in the database, and although the profile is defined, it    also does not exist in the database. Attempt to fake the profile ID. The result of this operation is that a new    session and a new profile will be created.</li> </ol> <p>Device Fingerprinting:</p> <p>Device Fingerprinting is activated when using the \"Javascript integration\" event source. This means that when integrating with JavaScript, actions related to Device Fingerprinting are performed to identify a unique device (e.g., computer, phone) used by the user. The identification is based on device characteristics and behaviors, such as the browser, screen resolution, operating system version, and more.</p> <p>Matching customers based on device fingerprint is restricted by the customer's IP address and the time they access the system. If the device, IP address, and time range match, the customer will be associated with the same profile, even if the new webpage does not have the customer's profile ID saved. This ensures that the system can still correctly recognize and link the customer's data based on the matching device fingerprint, IP address, and time range, even if the profile ID is not available.</p> <p>Moreover, if the customer visits a new page that already has a profile ID from their previous browsing session, the system will match the customer with the saved profile ID. The system will not merge the profiles unless the event source is configured to allow merging using the device fingerprint. In other words, if there is an existing profile ID associated with the customer, the system will prioritize using that ID instead of merging it with the device fingerprint, unless the event source specifically permits merging based on the device fingerprint. This approach ensures better control and accuracy in associating customer data and prevents unintended merging of profiles when it is not desired.</p>"},{"location":"qa/how_profile_is_restored/","title":"How profile is restored? Why my tracardi profile is restored even if I deleted it from the localStorage in browser.","text":"<p>The restoration of a profile in Tracardi, even after deleting it from localStorage, can occur due to a synchronization between the client-side and the server. If the tracker payload sent to Tracardi does not provide a profile ID, or if the profile ID provided does not exist in Tracardi's database, the system will create a new profile ID.</p> <p>Additionally, if a valid previous session is provided but the profile ID is not, Tracardi will attempt to search for the lost profile by matching the last valid session and return the correct profile ID (restore the profile). It's crucial to synchronize the profile ID returned in the response with the profile ID saved on the client side. If the profile ID in the response is different from the one sent, the client should update its profile ID and include the new one in the next call to Tracardi. Failing to synchronize these IDs may result in the profile ID being recreated with each call to the /track API, potentially causing issues with tracking and profiling of customer behavior.</p> <p>SO the answer to the question is:</p> <p>To completely delete a profile ID reference, it is necessary to delete not only the profile ID from local storage but also the session ID from cookies. Tracardi is capable of recreating a profile from the session ID, which explains why profiles are sometimes restored even after the profile ID is deleted from local storage.</p>"},{"location":"qa/how_profile_is_restored/#browser-fingerprint","title":"Browser fingerprint","text":"<p>Additionally, the commercial version of Tracardi might employ browser fingerprinting to identify profiles. This means that even removing cookies, session, and profile IDs from localStorage won't prevent Tracardi from restoring the correct profile ID. In such cases, changing your IP or browser may be necessary to completely evade profile restoration.</p>"},{"location":"qa/how_profile_resolution_works/","title":"How profile resolution works in tracardi?","text":"<p>The Tracardi profile resolution process is a mechanism used to ensure that the data associated with a user is correctly and consistently merged into a single profile. This process is crucial for creating unified customer profiles, even when data comes from various sources or channels. Here's how the profile resolution process works:</p> <ol> <li>Event Ingestion:</li> </ol> <p>When an event is sent to Tracardi, it typically contains some identifying information, such as a profile ID.    If an event contains a profile ID, Tracardi attempts to match this profile ID with an existing profile in its    database.</p> <ol> <li>Profile Identification:</li> </ol> <p>If a matching profile ID is found, the event data is linked to that existing profile.    If no profile ID is provided or if the profile ID does not match any existing profiles, Tracardi tries to identify    the profile using other identification points, such as an email address, phone number, or other unique identifiers    that might be part of the event data. This is only possible for some event types like \"profile-update\", etc. Not all    event will have PII data therefore including profile ID in event is so crucial.</p> <ol> <li>Profile Creation:</li> </ol> <p>If Tracardi cannot find a matching profile based on the provided identification points, it creates a new profile and    assigns it a unique profile ID. This profile ID is returned on the response of Tracardi API. System Expects that this    ID will be attached to each next event associated with this profile. This new profile will start accumulating data    from events associated with it.</p> <ol> <li>Profile Merging:</li> </ol> <p>Tracardi includes a profile merging mechanism that can automatically combine profiles that share common identifiers (    such as the same email address).    When the event type \"identification\" is send to the system two or more profiles represent the same individual (based    on matching identification points), it merges them into a single profile. The merged profile retains all relevant    data, and any old profile IDs    are added to the profile.ids field for historical reference.    This merging process ensures that the system maintains a single, unified profile for each individual, even if the    data comes from different sessions, devices, or channels.</p> <ol> <li>Profile Resolution and Updates:</li> </ol> <p>Each time an event is processed, Tracardi performs a resolution check to determine if the incoming event data should    update an existing profile or create a new one.</p> <ol> <li>Session Handling:</li> </ol> <p>Tracardi also manages sessions associated with each profile. A new session ID may be generated when a user interacts    with the system after a period of inactivity, but the session is still linked to the same profile.</p> <ol> <li>Historical Data and Profile Continuity:</li> </ol> <p>The system stores all historical profile IDs in the profile.ids field to ensure continuity and a complete history of    the user's interactions. When profiles are merged, IDs from all devices are preserved so that if an old profile ID    from another device is used to identify the profile, the system can correctly recognize it and return the new profile    ID. These old profile IDs remain in the system, allowing for accurate identification across devices even when older    IDs are used.</p>"},{"location":"qa/how_system_process_event_context/","title":"How tracardi process event context","text":"<p>This documentation describes in detail how Tracardi retrieves event context and profile geo location, utm parameters, etc.</p>"},{"location":"qa/how_system_process_event_context/#description","title":"Description","text":"<p>The code for retrieving the profile's geo location in Tracardi follows the following steps:</p> <ol> <li> <p>It first checks if the session is new by evaluating the <code>session.is_new()</code> condition. If the session is    new, it proceeds with the following steps. If not, it skips the subsequent steps and moves to the next part of the    code.</p> </li> <li> <p>When a new session is detected, the code adds a \"session-opened\" event to the list of registered events. This event    signifies the creation of a new session.</p> </li> <li> <p>The code then retrieves the user agent data from the session's context. The user agent data provides information    about the user's browser, device, and operating system. It extracts the user agent string from the session's context    and parses it using the <code>parse</code> function.</p> </li> <li> <p>From the parsed user agent data, the code extracts various device-related information such as the operating system    version, operating system name, and device type. The device type can be \"mobile,\" \"pc,\" \"tablet,\" or \"email\" based on    the user agent data.</p> </li> <li> <p>Next, the code checks if the session's context contains additional device information under the \"device\" key. If    present, it uses that information to populate the session's device properties such as device name, brand, model,    touch capability, and device type. If the session's context does not have device information, the code uses the    corresponding values from the parsed user agent data.</p> </li> <li> <p>The code then retrieves the spoken languages from the request headers and the geo country code from the device's geo    information. It looks for the \"accept-language\" header in the tracker payload's request headers and parses the    languages using the <code>parse_accept_language</code> function. It filters out languages with a length of 2 characters and maps    them to the corresponding spoken languages using a predefined dictionary. The code also checks if the device's geo    information includes a country code and maps it to spoken languages using the same dictionary. The resulting spoken    languages are set as the session's language context and stored in the profile's \"pii.language.spoken\" field.</p> </li> <li> <p>If the profile's auxiliary data does not contain a \"geo\" field, the code initializes it as an empty dictionary.</p> </li> <li> <p>The code determines the continent based on the timezone information present in the tracker payload's context. It    extracts the timezone value and checks if it is in UTC or a specific region. If it is in a specific region, the code    splits the timezone string and retrieves the continent. The continent is then stored in the profile's auxiliary data    under the \"geo.continent\" key.</p> </li> <li> <p>The code identifies the markets based on the language codes obtained earlier. It checks if the language codes exist    in a predefined dictionary that maps language codes to market values. If there are matching market values, they are    added to the profile's auxiliary data under the \"geo.markets\" key.</p> </li> <li> <p>The code tries to retrieve additional screen-related information from the tracker payload's context. It retrieves     the screen resolution, color depth, and orientation if available, and assigns them to the session's device     properties.</p> </li> <li> <p>The code determines if the session's device is a bot by checking the user agent data. If the user agent indicates     that it is a bot, the session's \"app.bot\" property is set to <code>True</code>.</p> </li> <li> <p>The code extracts the browser name from the user agent data and assigns it to the session's \"app.name\" property. It     also retrieves the browser version and assigns it to the session's \"app.version\" property. The session's \"app.type\"     property is set to \"browser\" to indicate that it is a browser application.</p> </li> <li> <p>If the tracker payload's context contains UTM parameters, the code creates a UTM object from the context data and     assigns it to the session's \"utm\" property. The UTM parameters are used for tracking the source of the incoming     traffic.</p> </li> <li> <p>The code attempts to retrieve the device's IP address from the request headers. It looks for the \"x-forwarded-for\"     header and assigns its value to the session's device IP property.</p> </li> <li> <p>Lastly, the code tries to retrieve the browser's language from the session's context and assigns it to the     session's \"app.language\" property.</p> </li> </ol> <p>After completing the above steps, the code checks if the location information is available in the tracker payload's context. If it is present, the code proceeds with the following steps. Otherwise, it skips to the next part of the code.</p> <ol> <li> <p>The code validates and parses the location information using the <code>Geo</code> class. If the validation succeeds, the code     removes the location data from the tracker payload's context.</p> </li> <li> <p>If the session's device geo information is empty, indicating that no geo information has been assigned yet, the code     updates it with the new location data. This ensures that the session's device geo information is populated with the     latest available location.</p> </li> <li> <p>The code updates the profile's last device geo information if the new location data is different from the existing     one. This ensures that the profile's last device geo information reflects the most recent geo location.</p> </li> </ol> <p>Finally, the code handles the scenario where there is no geo location available, but the session's device IP address is present. It checks if the necessary environment variables, namely <code>MAXMIND_LICENSE_KEY</code> and <code>MAXMIND_ACCOUNT_ID</code>, are set. If these variables are available, the code proceeds with the following steps. Otherwise, it skips the remaining part.</p> <ol> <li> <p>If the profile's last device geo information is empty, indicating that no geo location has been assigned yet, the     code fetches the geo location using the MaxMind API. It creates a <code>GeoLiteCredentials</code> object with the MaxMind     license key and account ID and calls the <code>get_geo_maxmind_location</code> function with the session's device IP address.</p> </li> <li> <p>The fetched geo location is assigned to the profile's last device geo information, ensuring that it reflects the     newly obtained geo location.</p> </li> <li> <p>If the session is new, indicating that the user has just initiated the session, the code fetches the geo location     using the MaxMind API. It assigns the obtained geo location to the session's device geo information and updates the     profile's last device geo information if it is empty or different from the new location.</p> </li> <li> <p>If there is an error while fetching the geo location using the MaxMind API, the code logs the error message.</p> </li> </ol> <p>The code for retrieving the profile's geo location in Tracardi follows the logic described above, enabling the system to determine and update the geo location information associated with the profile based on the available data from sessions, user agents, headers, and external APIs.</p>"},{"location":"qa/how_tenant_are_diffrenciated/","title":"How Tenants are differentiated in Tracardi multi-tenant environment?","text":"<p>In Tracardi's multi-tenant environment, tenants are distinguished based on their unique domains and associated API URLs. Each tenant receives a specific GUI and API URL, along with an installation key. It's important to understand that although the domains may differ, they all point to the same Tracardi instance.</p> <p>The tenant name is derived from the API domain by removing non-alphanumeric characters. For instance, if the API domain is \"company-x.tracardi.com,\" the corresponding tenant name would be \"companyx.\" This tenant name serves as a unique identifier and helps create separate storage namespaces, ensuring data isolation between tenants.</p> <p>To set up a new tenant, they access Tracardi using their dedicated GUI URL. During the initial access, they are guided through the installation process and asked to define an admin account. To ensure security, an installation token is provided, which must be copied into the installation form to authorize the setup.</p> <p>Tip</p> <p>Important: The installation token is a unique and hard-to-guess string provided to the tenant during the setup process. It acts as a verification mechanism, ensuring that only authorized individuals can install the Tracardi system for the respective tenant.</p> <p>Once the system is installed, the tenant gains access to their admin account and can use their GUI URL to access Tracardi. This approach allows multiple tenants to coexist within the same Tracardi instance while maintaining data separation and tenant-specific configurations.</p> <p>If multiple multi-tenant instances are needed, different domains can be used, such as \"tenant-name.instance1.domain.com\" and \"tenant-name.instance2.domain.com,\" connected to separate Elasticsearch instances. The number of tenants per instance depends on Elasticsearch capacity.</p> <p>It's essential to ensure that subdomains are directed to different IP addresses where Tracardi is installed, ensuring instance separation.</p> <p>This organization of domains and instances in Tracardi enables efficient management of multi-tenant environments, accommodating scalability and flexibility based on the needs of each instance.</p>"},{"location":"qa/how_the_profile_is_tracked/","title":"How the profile is tracked?","text":"<p>In Tracardi, customer tracking and identity resolution are done through a combination of profile IDs and session IDs. Here's a detailed explanation:</p> <ol> <li> <p>Profile ID and Session ID Storage:</p> </li> <li> <p>The Profile ID and Session ID are key components in tracking a customer's journey.</p> </li> <li>The Profile ID is stored in the local storage of a user's browser.</li> <li> <p>The Session ID, representing a visit, is stored in the browser's cookies.</p> </li> <li> <p>Session Creation and Management:</p> </li> <li> <p>A session is initiated when a browser is opened and is terminated when it's closed. A new session is created upon   reopening the browser.</p> </li> <li>The Session ID remains constant throughout a browser session.</li> <li> <p>In mobile applications, the session ID can be controlled more flexibly, for instance, by generating a new Session ID   each time the app is opened or when certain events (like logging out) occur.</p> </li> <li> <p>Profile Creation Across Different Browsers:</p> </li> <li> <p>Customers might use multiple browsers (e.g., one at home and another at work), leading to the creation of different   Profile IDs for each browser.</p> </li> <li> <p>Each action or click by the customer is tracked as an event and linked to the respective Profile ID and Session ID.</p> </li> <li> <p>Profile Merging and Identity Resolution:</p> </li> <li> <p>An important aspect of Tracardi's tracking system is the ability to merge profiles.</p> </li> <li>When a customer is identified (e.g., through an email address) across different browsers or devices, Tracardi merges   these profiles into a single profile.</li> <li>This merging process copies data from all detected profiles (say Profile A, B, and others) into one (say Profile B).</li> <li>After merging, while the Session IDs remain unique to each visit, the Profile ID becomes uniform across all browsers   and devices.</li> <li> <p>However, each profile still retains multiple IDs because these IDs cannot be replaced on devices not currently in use.</p> </li> <li> <p>Handling Multiple Profile IDs:</p> </li> <li> <p>Even after merging, the old Profile IDs are still relevant.</p> </li> <li> <p>When a customer accesses the service from a device using an old Profile ID, Tracardi uses this ID to find the current   profile and then updates the device with the new Profile ID.</p> </li> <li> <p>Simplified Overview:</p> </li> <li> <p>Sessions represent visits: Each browser session or app use is tracked with a unique Session ID.</p> </li> <li>Profiles represent the customer: Different Profile IDs created across devices or browsers are merged upon   identification, creating a unified view of the customer.</li> <li>Merged profiles have multiple IDs: Merged profiles retain their old IDs to ensure continuity in tracking across all   devices until they are updated with the new unified Profile ID.</li> </ol> <p>This system allows Tracardi to provide a comprehensive view of a customer's journey, accounting for their interactions across various browsers and devices, and enabling effective identity resolution.</p>"},{"location":"qa/how_to_add_data_to_api_call/","title":"How to insert variables into the request body in a Remote API call?","text":"<p>When inserting variables into the request body of a Remote API call in Tracardi, you can utilize the dot notation, which is represented as <code>data-source@field.path</code>. This notation allows you to access specific data fields within a data source. For instance, using <code>profile@id</code> would retrieve the <code>id</code> field from the <code>profile</code> data source, effectively yielding <code>profile.id</code>.</p> <p>You can apply this principle within JSON objects to reference data inside the object. For example, in a JSON request body, you can specify:</p> <pre><code>{\n  \"id\": \"profile@id\"\n}\n</code></pre> <p>This structure tells the system to replace <code>\"profile@id\"</code> with the actual value of <code>profile.id</code> from the current data context. So, if <code>profile.id</code> is <code>9c98443a-0637-42f2-a4e2-f7b750a0b650</code>, the processed JSON object would appear as:</p> <pre><code>{\n  \"id\": \"9c98443a-0637-42f2-a4e2-f7b750a0b650\"\n}\n</code></pre> <p>Here, <code>\"id\"</code> in the JSON object gets the value of the current <code>profile.id</code>, demonstrating how you can dynamically insert data from Tracardi sources into your API request bodies.</p>"},{"location":"qa/how_to_add_plugin_class_to_system/","title":"How to add action plugin class to the system?","text":"<p>To register a plugin in Tracardi, follow these steps:</p> <ol> <li>Create the Register Function: Define a <code>register</code> function in the same file where your plugin class is defined.    This function will return a <code>Plugin</code> object containing the specifications and metadata of your plugin.</li> </ol> <p>2 Specify Plugin Details in Register Function:</p> <ul> <li>Start: Set to <code>False</code> as most plugins do not start the workflow.</li> <li>Spec: Include details like the module, class name, inputs, outputs, version, license, and author. Example:</li> </ul> <pre><code>spec = Spec(\n    module=__name__,\n    className='MyPlugin',\n    inputs=[\"payload\"],\n    outputs=[\"MyEvent\", \"NotMyEvent\"],\n    version='0.1',\n    license=\"MIT\",\n    author=\"Your Name\"\n)\n</code></pre> <ul> <li>Metadata: Define the metadata of the plugin like its name, description, and the group it belongs to. Example:</li> </ul> <pre><code>metadata = MetaData(\n    name=\"My first plugin\",\n    desc='Descriptive text about what the plugin does.',\n    group=[\"Test plugin\"]\n)\n</code></pre> <ul> <li> <p>Please see some already implemented classes in the system to see all the options od register function.</p> </li> <li> <p>Automatic Plugin Loading:</p> <ul> <li>Navigate to the directory: <code>/tracardi/service/setup</code>.</li> <li>Locate the <code>setup_plugins.py</code> file. This file contains the list of all available plugins in the system.</li> <li>Add an entry for your plugin in the <code>installed_plugins</code> dictionary in the <code>setup_plugins.py</code> file. The key should   be the package of the register function, and the value should be an object of type <code>PluginMetadata</code>. Example:   <pre><code>\"tracardi.process_engine.action.v1.my_plugin_folder.my_plugin\": PluginMetadata(\n    test=PluginTest(init=None, resource=None)\n)\n</code></pre></li> </ul> </li> <li> <p>Reinstall Plugins: After adding your plugin to the <code>setup_plugins.py</code> file, restart the Tracardi API for the    changes to take effect. Then, go to <code>Processing/Workflows</code> in the Tracardi GUI, open any workflow, and click    the <code>Reinstall Plugins</code> button to load your new plugin. Alternatively, you can go to <code>Maintenance/Plug-ins</code> and click    the <code>Reinstall Plugins</code> button.</p> </li> </ul> <p>This process adds your plugin to the list of available plugins in Tracardi, allowing you to use it in workflows. Remember to test your plugin thoroughly to ensure it works as expected in the Tracardi environment.</p>"},{"location":"qa/how_to_add_plugin_class_to_system/#example","title":"Example","text":"<p>Below is an example of a <code>register</code> function for a hypothetical Tracardi plugin. This function is used to register the plugin in the Tracardi system, specifying its details, configuration, and capabilities.</p> <pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData\n\n\ndef register() -&gt; Plugin:\n    return Plugin(\n        start=False,  # Indicates that the workflow cannot start from this node\n        spec=Spec(\n            module=__name__,  # The module where the plugin is defined\n            className='MyApiPlugin',  # The name of your plugin class\n            init={  # Plugin configuration\n                \"api_url\": \"\",  # Default value for the API URL\n                \"api_key\": \"\"  # Default value for the API key\n            },\n            inputs=[\"payload\"],  # List of input ports\n            outputs=[\"output\"],  # List of output ports\n            version='0.1',  # Version of your plugin\n            license=\"MIT\",  # License type\n            author=\"Your Name\"  # Author of the plugin\n        ),\n        metadata=MetaData(\n            name=\"API Connector Plugin\",  # Name of the plugin to display in the workflow editor\n            desc='Connects to a specified API and retrieves data.',  # Short description of what the plugin does\n            group=[\"Data Processing\"]  # Group under which the plugin will be listed\n        )\n    )\n</code></pre> <p>In this example:</p> <ul> <li>The <code>Plugin</code> class is instantiated with specific properties.</li> <li>The <code>start</code> property is set to <code>False</code>, meaning this plugin cannot be used as a starting node in a workflow.</li> <li>The <code>Spec</code> class defines the technical details of the plugin, like its module location (<code>__name__</code>), class   name (<code>MyApiPlugin</code>), input and output ports, version, license, and author.</li> <li>The <code>MetaData</code> class provides descriptive information about the plugin, like its display   name (<code>API Connector Plugin</code>), a short description (<code>Connects to a specified API and retrieves data.</code>), and the group   in which it will be categorized (<code>Data Processing</code>).</li> </ul> <p>After defining this function, remember to add your plugin to the <code>setup_plugins.py</code> file in the Tracardi system to complete the registration process.</p>"},{"location":"qa/how_to_add_plugin_class_to_system/#plugin-forms","title":"Plugin forms","text":"<p>Action plugins may have forms that fill the plugin configuration.</p> <p>To add a form to the plugin registration, you'll need to include a <code>Form</code> object within the <code>Spec</code> class. This form will define the configuration interface for the plugin in the Tracardi GUI, allowing users to input necessary data, like API endpoints or other settings.</p> <p>Here's the updated example of the <code>register</code> function with a plugin form:</p> <pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData, Form, FormGroup, FormField, FormComponent\n\n\ndef register() -&gt; Plugin:\n    return Plugin(\n        start=False,\n        spec=Spec(\n            module=__name__,\n            className='MyApiPlugin',\n            init={\n                \"api_url\": \"\",  # Default value for the API URL\n                \"api_key\": \"\"  # Default value for the API key\n            },\n            form=Form(groups=[\n                FormGroup(\n                    name=\"API Configuration\",\n                    description=\"Configure the API connection details.\",\n                    fields=[\n                        FormField(\n                            id=\"api_url\",\n                            name=\"API URL\",\n                            description=\"Enter the API endpoint URL.\",\n                            component=FormComponent(type=\"text\", props={\"label\": \"API URL\"})\n                        ),\n                        FormField(\n                            id=\"api_key\",\n                            name=\"API Key\",\n                            description=\"Enter your API key.\",\n                            component=FormComponent(type=\"text\", props={\"label\": \"API Key\"})\n                        )\n                    ]\n                )\n            ]),\n            inputs=[\"payload\"],\n            outputs=[\"output\"],\n            version='0.1',\n            license=\"MIT\",\n            author=\"Your Name\"\n        ),\n        metadata=MetaData(\n            name=\"API Connector Plugin\",\n            desc='Connects to a specified API and retrieves data.',\n            group=[\"Data Processing\"]\n        )\n    )\n</code></pre> <p>In this updated version:</p> <ul> <li>The <code>init</code> property inside <code>Spec</code> is used to define the default configuration values. Here, it sets the default values   for <code>api_url</code> and <code>api_key</code> as empty strings.</li> <li>The <code>form</code> property is defined to create a user interface for configuring the plugin. It consists of a <code>Form</code> with   a <code>FormGroup</code> containing two <code>FormField</code> objects.<ul> <li>Each <code>FormField</code> represents a field in the form. In this example, there are two fields: one for the API URL and   another for the API key.</li> <li>The <code>id</code> of each <code>FormField</code> should match the keys defined in the <code>init</code> dictionary.</li> <li>The <code>FormComponent</code> defines the type of input control (in this case, <code>text</code>) and additional properties like   labels.</li> </ul> </li> </ul> <p>By defining this form, you create a user-friendly interface in the Tracardi workflow editor, allowing users to easily configure your plugin with the necessary API details.</p>"},{"location":"qa/how_to_add_segement_based_on_customer_visits/","title":"How to do simple segmentation with number of visits.","text":"<p>To add a segment based on the number of visits made to a profile, you can follow these steps:</p> <ul> <li>Start by setting up a workflow in your system or platform.</li> <li>Use an \"if\" condition to check the number of visits made to the profile.</li> <li>Within the \"if\" condition, port TRUE connect the \"add segment\" action to add the desired segment to the profile.</li> <li>After adding the segment, update the profile to save the changes.</li> </ul> <p>Here's an example of how the workflow could be structured:</p> <ul> <li><code>Start</code></li> <li><code>If</code> (profile@metadata.time.visit.count == 1)</li> <li>On port TRUE connect <code>Add Segment</code> (choose the segment you want to add)</li> <li><code>Update Profile</code> (save the changes)</li> </ul> <p>Regarding the syntax, the profile's visit count is stored in <code>metadata.time.visit.count</code>. It is automatically  increased with every visit.</p>"},{"location":"qa/how_to_aggregate_events_for_segmentation/","title":"How to aggregate events for segmentation?","text":"<p>To aggregate data for segmentation in Tracardi, you can follow these steps:</p> <ol> <li> <p>Ensure that events (certain event type) capture the relevant information you need for segmentation, such as transaction amounts and wallet    additions.</p> </li> <li> <p>Create reports that aggregate and summarize the event data, using Elasticsearch query.</p> </li> <li> <p>Design a segmentation workflow that utilizes these reports as a basis for segmenting the profiles. Use load report plugin.</p> </li> <li> <p>The aggregation happens at the profile level by grouping the events associated with each profile. This allows you to    calculate aggregated values per profile, such as the total transaction amount over a specified period.</p> </li> </ol> <p>Additionally, the segmentation workflow is executed on every profile within the tenant. The system efficiently filters profiles that need to be segmented, reducing unnecessary processing.</p> <p>If you have complex aggregation requirements or want to populate profiles with necessary data for segmentation, you can consider using custom jobs. These jobs can aggregate data and update profile stats with the aggregated information, enabling conditional segmentation based on the updated profile stats.</p>"},{"location":"qa/how_to_agregate_data/","title":"How can you calculate something under aggregation conditions? How to count the number of events that meet given conditions? For example, how do I calculate purchases over the last 7 days? Or how do I calculate all purchases over 100 dollars in the last 7 days?","text":"<p>To achieve this, you can utilize elastic queries and generate reports in Tracardi. Firstly, it's important to learn how to craft Elasticsearch queries. For detailed guidance on Elasticsearch aggregations, please visit Elasticsearch Aggregations Documentation.</p> <p>Here's how to create a report in Tracardi:</p> <ol> <li>Navigate to the 'Reporting' section.</li> <li>Complete the form and insert your Elasticsearch query.</li> <li>Test the query to see the results.</li> <li>Assign a name to your report and save it.</li> <li>Your report will now appear in the report listings.</li> <li>Open the report to find the endpoint (e.g., <code>POST /report/f48d0c9f-8d5c-41e9-a04f-28c934189327/run</code>), which will    fetch the query results.</li> <li>These reports can also be integrated into workflows.</li> </ol> <p>Alternatively, you can use metrics to execute an aggregation and store the results directly in the profile.</p>"},{"location":"qa/how_to_automate_new_tenant_creation_in_tms/","title":"How automate the installation process for a new tenant?","text":"<p>To automate the installation process for a new tenant in Tracardi, the following steps can be followed:</p> <ol> <li> <p>Call the Tenant Management Service (TMS) API: To add a new tenant, you need to make an API call to the TMS. This    call will create a new tenant and generate a corresponding URL for the Graphical User Interface (GUI) of Tracardi.</p> </li> <li> <p>Provide the GUI URL to the partner: If our partner wants their customer to directly access and install Tracardi,    then the partner can then share GUI URL with their customer, who can use it to access the GUI and perform the    installation process themselves. During installation, the customer will have the opportunity to set up the admin    account for Tracardi.</p> </li> <li> <p>Alternative approach - Create the account via Tracardi API: If the partner prefers not to have their customers    directly interact with Tracardi, they can use the Tracardi API instead. The partner can call the Tracardi API,    providing the installation token obtained from the TMS. This API call will create a new account specifically for that    tenant, ensuring the customer doesn't have to directly access Tracardi, but the account and corresponding instance is    created.</p> </li> </ol> <p>In summary, the automated installation process for a new tenant in Tracardi involves calling the TMS API to create the tenant and generate the GUI URL. Depending on the partner's preference, the customer can either install Tracardi themselves using the GUI URL or have the partner create the account on their behalf using the Tracardi API.</p>"},{"location":"qa/how_to_automate_obtaining_the_API_key/","title":"How to automate retrieval of the API KEY to Tracardi?","text":"<p>To authenticate with the Tracardi API, follow these steps:</p> <ol> <li> <p>Obtain an admin account: You will need to have an admin account in the Tracardi system. This account can either be    created during the installation process or by someone with administrative privileges.</p> </li> <li> <p>Authenticate with admin account credentials and obtain API key: Using the provided admin account credentials (    username and password), make an API request to the Tracardi API for authentication. Upon successful authentication,    the Tracardi API will respond with an API key, which serves as an authentication token for accessing the API    endpoints. Store the API KEY to access Tracardi API.</p> </li> <li> <p>Authenticate using the API key: Include the API key in the headers of your subsequent API requests to access    the Tracardi API. The API key allows Tracardi to identify and authorize your access to the desired API    endpoints.</p> </li> </ol>"},{"location":"qa/how_to_bind_event_to_a_click/","title":"How to send event when I click something?","text":"<p>To bind an event to a button click, you can use the JavaScript code provided in the Tracardi documentation. First, you need to add an onClick event to the button, like this: </p> <pre><code>&lt;button onClick=\"testClick()\"&gt;Test click&lt;/button&gt;\n</code></pre> <p>Then, you need to create a function that will send an event when the button is clicked. This function should be added to the JavaScript code, like this: </p> Example<pre><code>&lt;script&gt;\n  function testClick() {\n     window.tracker.track(\"page-view\", {\"view\": 1});\n  }\n&lt;/script&gt;\n</code></pre> <p>This code will record the event in the console, but it won't be sent to Tracardi by default. To trigger the event and send it to Tracardi immediately, you need to add the <code>fire</code> attribute with a value of <code>true</code> as a parameter to the window.tracker.track function, like this: </p> Example<pre><code>&lt;script&gt;\n  function testClick() {\n     window.tracker.track(\"page-view\", {\"view\": 1}, {\"fire\": true}); // (1)\n  }\n&lt;/script&gt;\n</code></pre> <p>This will send the event to Tracardi immediately.</p>"},{"location":"qa/how_to_check_registered_email_in_mailchimp/","title":"To check the verified domain registered in Mailchimp, you can follow these steps:","text":"<p>Follow those steps to see verified domains in Mailchimp:</p> <ol> <li>Click on \"Website\" in Mailchimp.</li> <li>Then click on \"Domains.\"</li> <li>Under the \"Email Domains\" section, you should see the domain name.</li> </ol> <p>To add verified domain follow those steps in Mailchimp:</p> <ol> <li>Click on \"Website\" in Mailchimp.</li> <li>Then click on \"Domains.\"</li> <li>In the \"Email Domains\" section, click on \"Add &amp; Verify Domain.\"</li> <li>Enter the email address associated with the domain you want to verify.</li> <li>Click on \"Send Verification Email.\"</li> <li>Check your email inbox for the verification email from Mailchimp.</li> <li>In the email, you can either click the \"Verify Domain Access\" button or enter the verification code provided.</li> <li>After verification, click \"Done\" to close the pop-up and return to the Domains Overview page.</li> </ol> <p>Following these steps should allow you to verify your email domain in Mailchimp. Remember that this process is specific to Mailchimp and may be subject to updates or changes by the platform, so it's always a good idea to consult Mailchimp's official documentation for the most accurate and up-to-date instructions.</p>"},{"location":"qa/how_to_configure_amp/","title":"How to enable ND configure AMP?","text":""},{"location":"qa/how_to_configure_amp/#enabling-auto-profile-merging","title":"Enabling Auto Profile Merging","text":"<ol> <li>Add Environment Parameter: Add the <code>AUTO_PROFILE_MERGING</code> environment parameter with a key of at least 20    characters when starting the Tracardi API. This key is used for hashing emails and phone numbers, etc. to aid in profile    identification. Keep this key confidential and note that changing it requires the system to recreate the merging    process, which can be time-consuming.</li> <li>Docker Command: Set the env variable when running docker.    <pre><code>docker run \\\n-e ELASTIC_HOST=http://&lt;elasticsearch-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\n-e AUTO_PROFILE_MERGING=&lt;your-hash-key&gt; \\\ntracardi/tracardi-api:&lt;last-version&gt;\n</code></pre>    Replace <code>&lt;elasticsearch-ip&gt;</code>, <code>&lt;redis-ip&gt;</code>, <code>&lt;mysql-ip&gt;</code>, and <code>&lt;last-version&gt;</code> with your respective values.</li> </ol>"},{"location":"qa/how_to_configure_amp/#running-apm-worker","title":"Running APM Worker","text":"<ol> <li>Start APM Worker: Execute the following Docker command to run the APM Worker.    <pre><code>docker run \\\n-e ELASTIC_HOST=http://&lt;elasticsearch-ip&gt;:9200 \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\n-e MYSQL_HOST=&lt;mysql-ip&gt; \\\n-e MODE=worker \\\n-e PAUSE=5 \\\ntracardi/apm:&lt;last-version&gt;\n</code></pre></li> </ol>"},{"location":"qa/how_to_configure_amp/#how-it-works","title":"How It Works","text":"<ol> <li>Merging Keys:<ul> <li>The following profile fields are used as merging keys:<ul> <li><code>data.contact.email.main</code></li> <li><code>data.contact.email.business</code></li> <li><code>data.contact.email.private</code></li> <li><code>data.contact.phone.main</code></li> <li><code>data.contact.phone.business</code></li> <li><code>data.contact.phone.whatsapp</code></li> <li><code>data.contact.phone.mobile</code></li> </ul> </li> </ul> </li> <li>Profile Monitoring:<ul> <li>Tracardi continuously monitors changes in the merging key fields and saves hashes of all changed fields (see above) in the <code>profile.ids</code>.</li> </ul> </li> <li>Profile IDs Management:<ul> <li>IDs are stored in the <code>profile IDs</code> field with specific   prefixes (<code>emm-</code>, <code>emb-</code>, <code>emp-</code>, <code>phm-</code>, <code>phw-</code>, <code>phb-</code>, <code>pho-</code>). E.g. <code>emm-</code> is a prefix for main email.</li> </ul> </li> <li>Merging Process:<ul> <li>Profiles flagged for merging are processed by a background worker, consolidating the profiles and updating   the <code>ids</code> field with the merged profile's ID.</li> </ul> </li> </ol>"},{"location":"qa/how_to_configure_number_of_shards/","title":"How to configure number of shards?","text":""},{"location":"qa/how_to_configure_number_of_shards/#helm-installation","title":"Helm installation.","text":"<p>To configure the number of shards in Tracardi, you'll need to adjust the settings in the <code>values.yaml</code> (In helm installation) file used for your Tracardi deployment. The number of shards is part of the Elasticsearch configuration, and you can define it within the <code>elastic</code> section of the configuration file. Here's how you can do it:</p>"},{"location":"qa/how_to_configure_number_of_shards/#step-by-step-guide-to-configure-number-of-shards","title":"Step-by-Step Guide to Configure Number of Shards","text":"<ol> <li> <p>Locate Your <code>values.yaml</code> File:</p> <ul> <li>This file contains the configuration settings for your Tracardi installation. It's typically used during   deployment with Helm or another orchestration tool.</li> </ul> </li> <li> <p>Edit the Elasticsearch Configuration Section:</p> <ul> <li>Open the <code>values.yaml</code> file in a text editor.</li> <li>Find the <code>elastic</code> section within the file.</li> </ul> </li> <li> <p>Set the Number of Shards and Replicas:</p> <ul> <li>Add or update the <code>index</code> configuration to specify the number of primary shards and replicas.</li> </ul> </li> </ol> <p>Here is an example of what the <code>elastic</code> section might look like after setting the number of shards:</p> <pre><code>elastic:\n  name: es1  # The name identifier for the Elasticsearch service\n  host: elastic-std-svc.elastic-standalone.svc.cluster.local  # The hostname for the Elasticsearch service\n  schema: http  # The schema to use for connecting to Elasticsearch (http/https)\n  authenticate: false  # Whether to use authentication when connecting to Elasticsearch\n  port: 9200  # The port on which Elasticsearch is running\n  verifyCerts: \"no\"  # Whether to verify SSL certificates (yes/no)\n  index:\n    shards: 5  # Number of primary shards for the index\n    replicas: 1  # Number of replica shards for the index\n</code></pre> <ol> <li>Apply the Configuration:<ul> <li>Save the changes to your <code>values.yaml</code> file.</li> <li>If you are using Helm, you can apply the configuration with the following command:   <pre><code>helm upgrade --install tracardi &lt;path_to_your_chart&gt; -f values.yaml\n</code></pre></li> <li>This command will apply the updated configuration to your Tracardi deployment.</li> </ul> </li> </ol>"},{"location":"qa/how_to_configure_number_of_shards/#key-considerations","title":"Key Considerations","text":"<ul> <li>Primary Shards (<code>shards</code>): This setting determines how many primary shards will be created for each index. More   shards can improve indexing and search performance, but it also means more resources will be required.</li> <li>Replica Shards (<code>replicas</code>): This setting determines how many replica shards will be created. Replicas are copies   of primary shards and help with fault tolerance and search performance.</li> <li>Performance Impact: Adjusting the number of shards can significantly impact performance. More shards can improve   parallelism, but too many shards can lead to overhead and reduced performance.</li> </ul>"},{"location":"qa/how_to_configure_number_of_shards/#docker-compose-installation","title":"Docker compose installation","text":"<p>To configure the number of shards in Tracardi using docker-compose use <code>ELASTIC_INDEX_SHARDS</code> environment variable in a Docker setup, follow these steps:</p>"},{"location":"qa/how_to_configure_number_of_shards/#step-by-step-guide","title":"Step-by-Step Guide","text":"<ol> <li>Edit Docker Compose File:</li> <li>You will add the <code>ELASTIC_INDEX_SHARDS</code> environment variable to your Tracardi service configuration in the <code>docker-compose.yml</code> file.</li> </ol> <p>Here\u2019s an example of how to configure your <code>docker-compose.yml</code> file to include the <code>ELASTIC_INDEX_SHARDS</code> environment variable:</p> <pre><code>version: '3'\nservices:\n  tracardi:\n    image: tracardi/tracardi-api:1.0.0\n    container_name: tracardi\n    environment:\n      - ELASTIC_HOST=http://elasticsearch:9200\n      - ELASTIC_INDEX_SHARDS=5  # Set number of shards\n      - ELASTIC_INDEX_REPLICAS=1  # Set number of replicas\n      # Other env settings\n    ports:\n      - \"8686:8686\"\n    depends_on:\n      - elasticsearch\n      - redis\n      - mysql\n\n  # The rest of the configuration\n</code></pre>"},{"location":"qa/how_to_configure_number_of_shards/#explanation","title":"Explanation","text":"<ul> <li>ELASTIC_INDEX_SHARDS: This environment variable sets the number of primary shards for Elasticsearch indices created by Tracardi.</li> <li>ELASTIC_INDEX_REPLICAS: This environment variable sets the number of replica shards for Elasticsearch indices created by Tracardi.</li> </ul>"},{"location":"qa/how_to_configure_number_of_shards/#apply-configuration","title":"Apply Configuration","text":"<ol> <li>Start Docker Compose:</li> <li>Navigate to the directory containing your <code>docker-compose.yml</code> file.</li> <li>Run the following command to start your services with the updated configuration:</li> </ol> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"qa/how_to_configure_number_of_shards/#with-docker-commands","title":"With docker commands","text":"<p>To set environment variables using the <code>docker run</code> command with the <code>-e</code> option, you can specify the environment variables directly in the command. Below is an example of how to run the Tracardi container with the <code>ELASTIC_INDEX_SHARDS</code> environment variable set.</p>"},{"location":"qa/how_to_configure_number_of_shards/#example-using-docker-run","title":"Example Using <code>docker run</code>","text":"<pre><code>docker run -d \\\n  --name tracardi \\\n  -e ELASTIC_HOST=http://localhost:9200 \\\n  -e REDIS_HOST=redis://localhost:6379 \\\n  -e MYSQL_HOST=localhost \\\n  -e MYSQL_USER=root \\\n  -e MYSQL_PASSWORD=root \\\n  -e MYSQL_DATABASE=tracardi \\\n  -e ELASTIC_INDEX_SHARDS=5 \\\n  -e ELASTIC_INDEX_REPLICAS=1 \\\n  -p 8686:8686 \\\n  tracardi/tracardi-api:1.0.0\n</code></pre>"},{"location":"qa/how_to_configure_number_of_shards/#explanation-of-the-command","title":"Explanation of the Command","text":"<ul> <li><code>docker run -d</code>: Runs the container in detached mode.</li> <li><code>--name tracardi</code>: Names the container \"tracardi\".</li> <li><code>-e ELASTIC_HOST=http://localhost:9200</code>: Sets the Elasticsearch host environment variable.</li> <li><code>-e REDIS_HOST=redis://localhost:6379</code>: Sets the Redis host environment variable.</li> <li><code>-e MYSQL_HOST=localhost</code>: Sets the MySQL host environment variable.</li> <li><code>-e MYSQL_USER=root</code>: Sets the MySQL user environment variable.</li> <li><code>-e MYSQL_PASSWORD=root</code>: Sets the MySQL password environment variable.</li> <li><code>-e MYSQL_DATABASE=tracardi</code>: Sets the MySQL database name environment variable.</li> <li><code>-e ELASTIC_INDEX_SHARDS=5</code>: Sets the number of primary shards for Elasticsearch indices.</li> <li><code>-e ELASTIC_INDEX_REPLICAS=1</code>: Sets the number of replica shards for Elasticsearch indices.</li> <li><code>-p 8686:8686</code>: Maps port 8686 of the host to port 8686 of the container.</li> <li><code>tracardi/tracardi-api:1.0.0</code>: Specifies the image to use.</li> </ul>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/","title":"How to configure Tracardi to be multi tenant?","text":"<p>To configure Tracardi as a multi-tenant system, you need to follow these steps:</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#understand-tracardis-multi-tenancy-concept","title":"Understand Tracardi's Multi-Tenancy Concept","text":"<p>In Tracardi, multi-tenancy means that a single Tracardi container can serve data for multiple separated tenants. Each tenant's data is stored in a separate namespace within the storage, ensuring data isolation and separation between tenants. This feature is available only in commercial Tracardi version.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#configure-tracardi-as-single-tenant-default","title":"Configure Tracardi as Single Tenant (Default)","text":"<p>By default, Tracardi operates as a single tenant system, connecting to the namespace of a single tenant. The name of the tenant can be configured using the environment variable TENANT_NAME. If this variable is not set, the system will generate a random name for the tenant.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#enable-multi-tenancy","title":"Enable Multi-Tenancy","text":"<p>To enable multi-tenancy in Tracardi, you need to set the environment variable MULTI_TENANT to \"yes\". This tells Tracardi container that it should serve multiple tenants. The tenant name will be defined based on your API domain. For example, if your API domain is company-x.tracardi.com, the tenant name will be set as \"companyx\" by removing all non-alphanumeric characters. All the data indices for each tenant will be prefixed with the tenant name, creating a namespace in the storage.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#prerequisites-for-tenant-name","title":"Prerequisites for Tenant Name","text":"<p>There are some prerequisites for the tenant name in Tracardi.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#length-requirement","title":"Length Requirement","text":"<p>The tenant name must be at least 5 letters long, excluding non-alphanumeric characters.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#non-numeric","title":"Non-Numeric","text":"<p>The tenant name cannot consist solely of numeric characters. It must include at least one non-numeric character.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#domain-structure","title":"Domain Structure","text":"<p>The tenant name must be part of a domain that has three parts. For example, a domain like \"mydomain.com\" will not create a valid tenant as it only has two parts (\"com\" and \"mydomain\"). However, a domain like \"xxx.mydomain.com\" will define a tenant with the name \"xxx\". Similarly, in the case of \"zzz.xxx.mydomain.com,\" the tenant name will be \"zzz\".</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#define-available-tenants","title":"Define Available Tenants","text":"<p>You can define the list of available tenants by setting the environment variable TENANT_API to the URL of the tenant manager microservice. This microservice will manage the list of tenants and provide the necessary functionality to create, update, and delete tenants.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#set-multi-tenant-gui","title":"Set Multi Tenant GUI","text":"<p>Set the environment variable called MULTI_TENANT to \"yes\". This setting will disable index management on the graphical user interface (GUI).</p> <p>In a multi-tenant installation, managing indices is not available. Multi-tenant installations are designed to have access to the entire Elasticsearch cluster, rather than tenant index management.</p>"},{"location":"qa/how_to_configure_tracardi_to_be_multi_tenant/#errors","title":"Errors","text":"<p>If you encounter an issue while trying to start a multi-tenant Tracardi server API, you can check the logs for a specific error message: \"Can not find tenant for this instance.\" This error indicates that the prerequisites for the tenant name have not been met. In other words, the tenant name provided does not meet the necessary criteria as discussed earlier. By reviewing the logs and ensuring that the tenant name meets the required prerequisites, you can resolve this issue and successfully start the multi-tenant Tracardi server API.</p> <p>This document answers the following questions: - How to set-up multitenacy in Tracardi? - How to set-up GUI to be multi tenant installation? - How multi tenant setup works in Tracardi? - How tenants are differentiated in Tracardi? - How to enable tenant in Tracardi? - Is multi tenancy available in open-source version?</p>"},{"location":"qa/how_to_copy_data_from_event_to_profile/","title":"How can you copy data from events to profiles?","text":"<p>To copy data from events to profiles, you will need to create a workflow with a start node and a node called \" copy data\". In the \"copy data\" node, you can select the destination and set it to the event property e.g. \"phone\", \" email\", etc. Another way to copy data is to use the \"Auto group merge event properties\" node, which will automatically merge all event properties to the profile traits.</p>"},{"location":"qa/how_to_copy_data_from_event_to_profile/#auto-coping","title":"Auto coping","text":"<p>Tracardi offers an easy way to copy data from events to profiles with its auto-coping feature, available in the commercial version. Users can define an event type and specify which properties to copy, and the system will handle the copying automatically.</p>"},{"location":"qa/how_to_copy_data_from_event_to_profile/#pre-build-event-types","title":"Pre-build event types","text":"<p>Starting from version 0.8.1, Tracardi includes build-in event types that can be used for auto-coping. These internal event types are designed to track the customer journey on websites or applications, and they come with default properties that eliminate the need for manual copying.</p> <p>Using these internal event types streamlines the use of Tracardi and simplifies the process of data collection and analysis. When an internal event type is utilized, the system automatically detects it and populates the profile and session with relevant data. To learn more about the available default event types, please refer to the provided list.</p>"},{"location":"qa/how_to_create_new_tenant/","title":"How to create new tenant","text":""},{"location":"qa/how_to_create_new_tenant/#creating-a-new-tenant","title":"Creating a New Tenant","text":"<p>This guide offers a comprehensive walkthrough for creating a new tenant within the Tenant Management Service (TMS) system. By following these steps, you can provide your customers with a link to complete the installation process. It's important to note that this approach is not a plug-and-play solution; rather, it's a pivotal step in the installation journey, enabling you to delegate the finalization of the installation to your customers.</p> <p>If you're seeking a more streamlined installation process accomplished through a single API call, you can explore the full installation guide available here. This resource outlines the steps for setting up a multi-tenant environment in a more automated manner.</p>"},{"location":"qa/how_to_create_new_tenant/#prerequisites","title":"Prerequisites","text":"<p>Before starting the tenant creation process, ensure you have access to the Tenant Management Service (TMS) and the required API key. To create a new tenant, you'll need a TMS API key generated during TMS installation.</p>"},{"location":"qa/how_to_create_new_tenant/#creating-a-new-tenant-with-an-api-call","title":"Creating a New Tenant with an API Call","text":"<p>Follow these instructions to create a new tenant using an API call:</p> <ol> <li>Authorize with API Key:</li> </ol> <p>To initiate the process, authorize yourself with the API key. Use the following CURL command to obtain a token that    will be used for authorization in the subsequent API call:</p> <pre><code>curl -X 'GET' \\\n  'http://TMS-server:8383/api-key/API-KEY' \\\n  -H 'accept: application/json'\n</code></pre> <p>The response will provide a token that must be included in the header of the next API call.</p> <ol> <li> <p>API Call Configuration:</p> <ul> <li>Utilize the HTTP POST method.</li> <li>Direct the API call to the endpoint <code>/tenant</code>.</li> <li>Construct the API call payload with the following details:</li> </ul> <pre><code>{\n  \"id\": \"uuid4-id\",\n  \"created\": \"2023-08-16T16:36:13.115Z\",\n  \"name\": \"tenant-name\",\n  \"install_token\": \"installation\",\n  \"email\": \"tenant@email\",\n  \"expire\": \"2023-08-16T16:36:13.115Z\"\n}\n</code></pre> <ul> <li>Example CURL:</li> </ul> <pre><code>curl -X POST \\\n  https://TMS-server/tenant \\\n  -H 'Content-Type: application/json' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer TOKEN' \\\n  -d '{\n    \"id\": \"uuid4-id\",\n    \"created\": \"2023-08-16T16:36:13.115Z\",\n    \"name\": \"tenant-name\",\n    \"install_token\": \"installation\",\n    \"email\": \"tenant@email\",\n    \"expire\": \"2023-08-16T16:36:13.115Z\"\n  }'\n</code></pre> </li> <li> <p>Result:</p> </li> </ol> <p>After successfully executing the API call, a new tenant with the specified name will be created. The provided name    will form the initial part of the tenant's URL, such as <code>tenant-name.mydomain.com</code>.</p> <p>Please note that successful execution of the API call requires proper authorization using the obtained token. Replace placeholders like <code>TOKEN</code>, <code>TMS-server</code>, <code>API-KEY</code>, and other relevant placeholders with actual values before making the API calls.</p>"},{"location":"qa/how_to_create_new_tenant/#can-i-use-account-id-as-a-tenant-identifier","title":"Can I use Account ID as a Tenant Identifier","text":"<p>Yes, you have the option to use your account ID as an identifier for the newly created tenant. This can be incorporated into the domain name that the tenant uses to access the system. For instance, if your account ID is \"xxx,\" the tenant's domain could be \"xxx.domain.com.\"</p> <p>By following these steps, you can seamlessly create a new tenant and establish the necessary components for their access to the system.</p>"},{"location":"qa/how_to_create_report/","title":"How to create report","text":"<p>To create a report, first navigate to the \"Reporting\" section and select \"Create Report.\" You'll need to provide a name for your report. Next, choose the index you wish to query from the available options: 'available', 'profile', 'event', or 'session entity'.</p> <p>For querying, you'll use an Elasticsearch query. Refer to the Elasticsearch documentation for guidance on how to construct these queries. Remember, your query will be run on the chosen index each time you execute the report.</p> <p>You can incorporate parameter placeholders in your query. For instance, use {\"profile.id\": \"{{profile_id}}\"}. Any placeholders set within {{ }} will be substituted with the actual parameters when the report runs. For example, you could use {\"profile_id\": \"\"}. Keep in mind that the entire string should be a parameter; partial placeholders like \"{{profile_id}}-some-other-data\" won't work. <p>Test the query and save the report.</p> <p>Reports are also available via API endpoint. Click on report to see the endpoint URL.</p>"},{"location":"qa/how_to_delete_a_node/","title":"How to delete a node in the workflow?","text":"<p>To delete a node in a workflow, follow these steps:</p> <ul> <li>Open the workflow you want to modify.</li> <li>Identify the node you want to delete. Nodes are located on the left side of the screen.</li> <li>Select the node by clicking on it.</li> <li>Press the \"Delete\" key on your keyboard or Fn + Delete on Mac.</li> <li>The node will be removed from the canvas, and any connections or edges associated with it will be removed as well.</li> </ul> <p>This document also answers:</p> <ul> <li>How to delete nodes on Apple Macintosh?</li> </ul>"},{"location":"qa/how_to_download_tracardi_helm_chart/","title":"How to download tracardi helm chart repo?","text":"<p>USe the following command to download tracardi helm chart 1.0.0.</p> <pre><code>curl -O http://tracardi.com/helm/1.0.0/tracardi-1.0.0.tgz\n</code></pre>"},{"location":"qa/how_to_enable_system_events/","title":"How to enable system events?","text":"<p>Enabling system events will depend on you installation?</p> <ul> <li>How to enable system events in heml chart installation?</li> <li>How to enable system events in docker compose installation?</li> <li>How to enable system events in docker installation?</li> </ul>"},{"location":"qa/how_to_enable_system_events_in_docker/","title":"How to enable/disable system events in docker?","text":"<p>To enable system events when running Tracardi with the <code>docker run</code> command, you need to set the <code>SYSTEM_EVENTS</code> environment variable to <code>yes</code> (<code>no</code> for disable). This can be done by using the <code>-e</code> flag to pass environment variables to the Docker container.</p> <p>Here is an example command to run the Tracardi API container with system events enabled:</p> docker command<pre><code>docker run -d \\\n  --name tracardi-api \\\n  -e ELASTIC_HOST=http://&lt;elasticsearch-host&gt;:9200 \\\n  -e REDIS_HOST=redis://&lt;redis-host&gt;:6379 \\\n  -e MYSQL_HOST=&lt;mysql-host&gt; \\\n  -e PULSAR_HOST=pulsar://&lt;pulsar-host&gt;:6650 \\\n  -e PULSAR_API=http://&lt;pulsar-host&gt;:8080 \\\n  -e LOGGING_LEVEL=info \\\n  -e SYSTEM_EVENTS=yes \\  # Enable system events\n  -p 8686:80 \\\n  tracardi/com-tracardi-api:&lt;version&gt;\n</code></pre> <p>Replace <code>&lt;elasticsearch-host&gt;</code>, <code>&lt;redis-host&gt;</code>, <code>&lt;mysql-host&gt;</code>, <code>&lt;pulsar-host&gt;</code>, and <code>&lt;version&gt;</code> with the appropriate values for your setup.</p>"},{"location":"qa/how_to_enable_system_events_in_docker_compose/","title":"How to enable system events in docker compose?","text":"<p>To enable system events in Tracardi when using Docker Compose, follow these steps:</p> <ol> <li> <p>Locate your Docker Compose file: This file is typically named <code>docker-compose.yml</code> and contains the configuration    for all the services you are running.</p> </li> <li> <p>Modify the environment variables: Add or modify the environment variables for the Tracardi service to    include <code>SYSTEM_EVENTS=yes</code>.</p> </li> </ol> <p>Here is an example of how you can adjust your <code>docker-compose.yml</code> file:</p> Part of docker-comose.yaml<pre><code>version: '3.7'\n\nservices:\n  tracardi:\n    image: tracardi/com-tracardi-api:1.0.0  # or use the specific version you are running\n    container_name: tracardi-api\n    environment:\n      - ELASTIC_HOST=http://elasticsearch:9200\n      - REDIS_HOST=redis://redis:6379\n      - MYSQL_HOST=mysql\n      - PULSAR_HOST=pulsar://pulsar:6650\n      - PULSAR_API=http://pulsar:8080\n      - LOGGING_LEVEL=info\n      - SYSTEM_EVENTS=yes  # Enable system events\n    ports:\n      - \"8686:80\"\n\n# The rest of your docker-compose file.\n</code></pre> <ol> <li>Deploy the updated configuration: After making these changes, you need to restart your Docker Compose setup to    apply the new configuration. You can do this by running:</li> </ol> <pre><code>docker-compose down\ndocker-compose up -d\n</code></pre> <p>By adding <code>SYSTEM_EVENTS=yes</code> to the environment variables of the Tracardi service, you enable system events within the Tracardi instance running in Docker Compose. This will allow Tracardi to generate and handle internal system events.</p>"},{"location":"qa/how_to_enable_system_events_in_helm_chart/","title":"How to enable system events in helm chart?","text":"<p>To enable system events in Tracardi, you need to adjust the configuration settings in the <code>values.yaml</code> file. Here\u2019s how you can do it:</p> <ol> <li> <p>Locate the <code>values.yaml</code> file: This file contains the configuration settings for Tracardi. If you don't already    have a custom <code>values.yaml</code> file, you will need to create one by copying the default settings and then making the    necessary modifications.</p> </li> <li> <p>Modify the configuration to enable system events: In the <code>values.yaml</code> file, find the <code>config</code> section and set    the <code>systemEvents</code> field to <code>\"yes\"</code>.</p> </li> </ol> <p>Here is an example of what the relevant part of your <code>values.yaml</code> file should look like:</p> Part of values.yaml file<pre><code>config:\n  multiTenant:\n    multi: \"yes\"  # Enable multi-tenancy if needed\n  primaryId: \"emm-\"  # Set the primary ID prefix if needed\n  systemEvents: \"yes\"  # Enable system events\n  enableVisitEnded: \"no\"  # Enable visit ended events if needed\n  visit:\n    close: 1800  # Set visit close time to 1800 seconds (30 minutes)\n</code></pre> <ol> <li>Deploy the changes: After modifying the <code>values.yaml</code> file, deploy the changes to your Tracardi instance. The    exact method of deployment will depend on your environment. For example, if you are using Helm, you can use the    following command to apply the changes:</li> </ol> <pre><code>helm upgrade --install tracardi ./tracardi -f values.yaml\n</code></pre> <p>By setting <code>systemEvents</code> to <code>\"yes\"</code>, you enable the system events in Tracardi, allowing the platform to generate and handle internal events that provide insights into various operations and activities within the system.</p>"},{"location":"qa/how_to_fix_import_pending/","title":"How import data and fix an error of import pending?","text":""},{"location":"qa/how_to_fix_import_pending/#introduction","title":"Introduction:","text":"<p>Tracardi utilizes import workers to process data imports in the background, and sometimes import workers may face errors that lead to import pending issues. In this documentation, we will guide you through the steps to start an import worker and resolve import pending errors.</p>"},{"location":"qa/how_to_fix_import_pending/#step-1-start-tracardi-worker","title":"Step 1: Start Tracardi Worker","text":"<p>To start importing data, you need to start the Tracardi worker that will import data in the background. You can use the following Docker command to start the worker:</p> <pre><code>docker run -e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 tracardi/worker-update\n</code></pre> <p>In this command, replace  with the IP address of the Redis server that Tracardi uses."},{"location":"qa/how_to_fix_import_pending/#step-2-verify-that-the-worker-is-running","title":"Step 2: Verify that the Worker is Running","text":"<p>After running the above command, the import worker will start processing defined data imports, and you can verify that the worker is running by checking the list of running Docker containers using the following command:</p> <pre><code>docker ps\n</code></pre> <p>If the worker is not running, check the logs for any errors.</p>"},{"location":"qa/how_to_fix_import_pending/#step-3-check-background-tasks","title":"Step 3: Check Background Tasks","text":"<p>After starting the worker, check the background tasks in Tracardi to ensure that the import worker has started processing the import task. If the import worker did not start processing the task, try creating a new background task.</p>"},{"location":"qa/how_to_fix_import_pending/#step-4-troubleshoot-errors","title":"Step 4: Troubleshoot Errors","text":"<p>If you encounter any errors during the import process, refer to the Tracardi documentation or seek help from the  Tracardi community. Common issues that you may encounter include connection errors, malformed data, or unsupported  file formats.</p>"},{"location":"qa/how_to_fix_webhook_validation_error/","title":"I have ValidationError when calling webhook","text":"<p>If you see: 1 validation error for EventPayload\\nproperties\\n  value is not a valid dict (type=type_error.dict) That means  that you did not send a post payload as dict. Dict in python is an JavaScript object. Please, send an empty object in  post body/payload e.g. {} or any object with data: {\u201ckey\u201d:\u201dvalue\u201d}.</p>"},{"location":"qa/how_to_get_javascript_to_put_on_page/","title":"How to get integration javascript that I put on my web page?","text":"<ol> <li> <p>Begin by creating an event source, which can be found in the \"Inbound Traffic Event Source\" tab. This tab is    specifically designed to handle incoming data to Tracardi.</p> </li> <li> <p>Locate the button to create a new event source and click on it. This will initiate the process of setting up a new    source for events.</p> </li> <li> <p>From the available options, choose the bridge type \"REST API Bridge.\"</p> </li> <li> <p>Provide a suitable name for your event source. Additionally, you have the option to specify a channel name such as \"    web,\" \"mobile,\" \"crm,\" or any other relevant identifier. This helps in organizing and categorizing the incoming    events based on their source.</p> </li> <li> <p>Once you have filled in the necessary details, save your settings. As a result, the newly created event source will    now be listed among the existing sources.</p> </li> <li> <p>Click on the newly created event source from the list. This action will open a detailed information about    that specific source. Select the \"Use and Javascript\" tab.</p> </li> <li> <p>Inside the \"Use and Javascript\" tab, you will find a detailed description guiding you on how to utilize the    JavaScript snippet for integration. This snippet is a piece of code that you will need to incorporate into your web    page to enable the desired integration functionality.</p> </li> <li> <p>In case you encounter any issues during the process, it is recommended to refer to the documentation provided. Simply    access the documentation and search for \"JavaScript integration.\" You should be able to find comprehensive resources    and support materials to assist you in resolving any problems you may encounter along the way.</p> </li> </ol> <p>This documentation answers the following questions:</p> <ul> <li>Where do I find JavaScript?</li> <li>How to create a REST event source?</li> </ul>"},{"location":"qa/how_to_get_user_consents/","title":"How to collect consents and use consent box widget to obtain customer consents.","text":"<ol> <li> <p>Defining Consent Types: Determine the various consents you need from your customers. These could include    permissions for marketing communications, data processing, cookie tracking, etc. Categorize these under '    Identification/Consent Types' in Tracardi.</p> </li> <li> <p>Creating a Consent Box: Develop a consent box widget that will be displayed to users, which should:</p> <ul> <li>Clearly articulate what the user is consenting to, using the consents defined in Tracardi.</li> <li>Offer options for users to accept or decline specific types of consents.</li> <li>Ensure compliance with relevant regulations, such as GDPR and CCPA.   You can leverage Tracardi's built-in Consent Bar Widget, which automatically utilizes defined consents.</li> </ul> </li> <li> <p>Integrating the Consent Box: Embed the consent box into the appropriate user interaction workflow on your    platform.</p> </li> <li> <p>Capturing Consent Responses: Monitor and record the user's interactions with the consent box, whether they accept    or decline. This can be done using Tracardi, which tracks these interactions as events. The built-in Consent Bar    Widget in Tracardi automates this process, eliminating the need for manual event setting.</p> </li> <li> <p>Storing Consent Information: Preserve the gathered consent information in the user's profile in Tracardi,    typically within the <code>consents</code> key. The built-in widget in Tracardi facilitates automatic storage of this data.</p> </li> <li> <p>Utilizing Consent Data in Workflows: Use the stored consent data in your Tracardi workflows to enhance user    experiences and personalize marketing efforts. For instance, send marketing emails only to users who have explicitly    consented to receive them.</p> </li> <li> <p>Anonymizing Data Using Consents: Employ the consents provided by users to anonymize data as necessary, ensuring    privacy and compliance with data protection regulations.</p> </li> </ol>"},{"location":"qa/how_to_import_data_to_tracardi/","title":"How to import data to Tracardi","text":"<p>This answer is the summary of the following video tutorial: https://www.youtube.com/watch?v=w_4gPOL0tvw</p> <p>To import data into Tracardi through event collection, follow these steps:</p> <ol> <li> <p>Open an Event Source: It's recommended to open an event for the import. This is the initial step where you set up    an event source in Tracardi.</p> </li> <li> <p>Allow Static Profile ID: Ensure that the option \"allow static profile ID\" is selected. This is crucial because    you'll be sending profile IDs from an external system, and this setting allows Tracardi to recognize and use these    IDs.</p> </li> <li> <p>Send a Regular Event to the Tracardi Endpoint: Simulate a regular event with some random session data. You can    keep the session the same during the import process.</p> </li> </ol> <p>During sending:</p> <pre><code>1. **Include a Profile ID in Track Paylaod**: This step involves sending a profile ID. This profile ID will be\n   persistent and won't be\n   replaced by Tracardi's internal ID.\n\n2. **Include Import Source in Track Payload**: Choose the appropriate import source for your data.\n\n3. **Set event type to profile-update**: Indicate that you're sending profile data that you want to update. If the\n   profile does not exist, it will be created with the specified ID, thanks to the option in the Event Source that\n   retains this ID.\n\n4. **Set Profile Data**: Send the data you want to be associated with the profile. This can include various types of\n   user or\n   event data.\n</code></pre> <p>This process essentially involves setting up an event source, ensuring the correct handling of profile IDs, sending data to Tracardi, and then verifying that the data has been correctly imported and the profiles have been updated or created as needed.</p>"},{"location":"qa/how_to_import_data_with_python/","title":"Importing Data to Tracardi Documentation","text":""},{"location":"qa/how_to_import_data_with_python/#introduction","title":"Introduction","text":"<p>This documentation outlines the steps to import data into Tracardi, a data management platform that stores data in Elasticsearch. </p>"},{"location":"qa/how_to_import_data_with_python/#methods-for-data-import-into-tracardi","title":"Methods for Data Import into Tracardi","text":"<p>There are multiple methods available for importing data into Tracardi:</p> <ol> <li> <p>Simple Import Script: The most flexible and recommended approach by Tracardi is to use a custom import script to    transfer your data. This method allows you to have full control over the import process.</p> </li> <li> <p>Tracardi's Built-in Import Feature: Tracardi also provides its own built-in import feature. This option is    user-friendly and can be utilized for importing data directly within the Tracardi platform.</p> </li> <li> <p>Elasticsearch and Kibana Integration: If preferred, you can leverage Elasticsearch's internal mechanisms and the    powerful data visualization capabilities of Kibana. Here is a resource guide on how to import data into Elasticsearch    using File Data    Visualizer: Elastic Blog - Importing CSV and Log Data into Elasticsearch with File Data Visualizer.</p> </li> </ol>"},{"location":"qa/how_to_import_data_with_python/#types-of-objects-in-tracardi","title":"Types of Objects in Tracardi","text":"<p>Tracardi allows you to work with three primary types of objects: profiles, sessions, and events. This guide will help you get started with the data import process.</p> <ol> <li> <p>Profiles: Profiles represent individual entities, such as customers or users. In most cases, you'll need to    import profile objects when you start working with Tracardi.</p> </li> <li> <p>Sessions: Sessions correspond to user sessions or interactions, capturing the behavior and engagement of your    users over time. You may choose to import session objects in addition to profiles if you want to track user    interactions.</p> </li> <li> <p>Events: Events are specific actions or occurrences, such as a user making a purchase or clicking on a link.    Importing events is necessary when you want to capture detailed user actions and their timestamps.</p> </li> </ol>"},{"location":"qa/how_to_import_data_with_python/#steps-to-start-importing-data","title":"Steps to Start Importing Data","text":"<p>Follow these steps to begin the process of importing data into Tracardi:</p> <ol> <li> <p>Find the Data: Locate the data that you intend to import into Tracardi. This data can be sourced from various    platforms or sources.</p> </li> <li> <p>Find the Data Schema in Tracardi: Understand the structure of the data you plan to import by finding the relevant    schema within Tracardi. You can do this by using a test section in Tracardi to register a single event, which will    automatically generate a profile, session, and event. You can access the schema for each object by following these    steps:</p> <ul> <li>Click on the \"3 dots\" icon near each object (profile, session, or event).</li> <li>Navigate to the JSON tab to access the schema for the respective object.</li> </ul> </li> <li> <p>Prepare Mapping: Before importing data, prepare a mapping that aligns the fields in your data source with the    schema in Tracardi. This mapping will help ensure that your data is accurately ingested.</p> </li> <li> <p>Write a Simple Script: Create a script in your preferred programming language that extracts data from your source    and imports it into Tracardi using the prepared mapping. This script should establish a connection to Tracardi's    Elasticsearch database for data insertion.</p> </li> <li> <p>Run the Script: Execute the script to begin the data import process. The script will transfer your data into    Tracardi, where it will be stored in Elasticsearch.</p> </li> </ol>"},{"location":"qa/how_to_import_data_with_python/#tracardi-data-structure","title":"Tracardi Data Structure","text":"<p>The structure for each object (profile, session, and event) in Tracardi can be found within the platform itself. To access the schema for each object, use the following steps:</p> <ol> <li>Create a test section in Tracardi to register a single event, which will generate a profile, session, and event.</li> <li>Click on the \"3 dots\" icon near the object you are interested in (profile, session, or event).</li> <li>Navigate to the JSON tab, where you will find the schema for the selected object.</li> </ol>"},{"location":"qa/how_to_import_data_with_python/#examples","title":"Examples","text":"<p>Here are examples of each object in Tracardi:</p> Profile Object Schema <pre><code>{\n  \"id\": \"cc89f945-5262-4859-b8f7-4eebe3d740ba\",\n  \"ids\": [\n    \"cc89f945-5262-4859-b8f7-4eebe3d740ba\"\n  ],\n  \"metadata\": {\n    \"time\": {\n      \"insert\": \"2023-10-16T09:25:14.336120\",\n      \"create\": null,\n      \"update\": \"2023-10-16T09:25:21.396452\",\n      \"segmentation\": null,\n      \"visit\": {\n        \"last\": null,\n        \"current\": \"2023-10-16T09:25:14.342063\",\n        \"count\": 1,\n        \"tz\": \"Europe/Sarajevo\"\n      }\n    },\n    \"aux\": {},\n    \"status\": null\n  },\n  \"stats\": {\n    \"visits\": 0,\n    \"views\": 0,\n    \"counters\": {}\n  },\n  \"traits\": {},\n  \"segments\": [],\n  \"interests\": {},\n  \"consents\": {\n    \"cookies\": {\n      \"revoke\": null\n    }\n  },\n  \"active\": true,\n  \"aux\": {\n    \"geo\": {\n      \"continent\": \"Europe\"\n    }\n  },\n  \"data\": {\n    \"pii\": {\n      \"firstname\": \"Maria\",\n      \"lastname\": \"White\",\n      \"name\": \"Maria White\",\n      \"birthday\": \"1986-01-22T04:51:59\",\n      \"language\": {\n        \"native\": null,\n        \"spoken\": null\n      },\n      \"gender\": \"female\",\n      \"education\": {\n        \"level\": \"Technical Education\"\n      },\n      \"civil\": {\n        \"status\": \"Married\"\n      },\n      \"attributes\": {\n        \"height\": 176,\n        \"weight\": 65,\n        \"shoe_number\": 44\n      }\n    },\n    \"contact\": {\n      \"email\": \"powen@example.org\",\n      \"phone\": null,\n      \"app\": {\n        \"whatsapp\": \"980-060-6463x2839\",\n        \"discord\": null,\n        \"slack\": \"@White\",\n        \"twitter\": \"@tracardi\",\n        \"telegram\": \"@Maria\",\n        \"wechat\": null,\n        \"viber\": null,\n        \"signal\": null,\n        \"other\": {}\n      },\n      \"address\": {\n        \"town\": \"Blakeberg\",\n        \"county\": null,\n        \"country\": \"Libyan Arab Jamahiriya\",\n        \"postcode\": \"61402\",\n        \"street\": \"417 Randy Mall\",\n        \"other\": null\n      },\n      \"confirmations\": []\n    },\n    \"identifier\": {\n      \"id\": null,\n      \"badge\": null,\n      \"passport\": null,\n      \"credit_card\": null,\n      \"token\": null,\n      \"coupons\": null\n    },\n    \"devices\": {\n      \"names\": [],\n      \"last\": {\n        \"geo\": {\n          \"country\": {\n            \"name\": \"Asia/Shanghai\",\n            \"code\": \"CN\"\n          },\n          \"city\": \"Sishui\",\n          \"county\": \"CN\",\n          \"postal\": null,\n          \"latitude\": 35.64889,\n          \"longitude\": 117.27583\n        }\n      }\n    },\n    \"media\": {\n      \"image\": \"http://tracardi.com/demo/image/female/profile_8.JPG\",\n      \"webpage\": \"http://www.tracardi.com\",\n      \"social\": {\n        \"twitter\": \"@tracardi\",\n        \"facebook\": \"tracardi\",\n        \"youtube\": \"@mytag\",\n        \"instagram\": null,\n        \"tiktok\": null,\n        \"linkedin\": null,\n        \"reddit\": null,\n        \"other\": {}\n      }\n    },\n    \"preferences\": {\n      \"purchases\": [],\n      \"colors\": [\n        \"gray\"\n      ],\n      \"sizes\": [\n        \"xxl\"\n      ],\n      \"devices\": [\n        \"tablet\"\n      ],\n      \"channels\": [\n        \"direct\"\n      ],\n      \"payments\": [\n        \"cash\"\n      ],\n      \"brands\": [\n        \"Maybelline\"\n      ],\n      \"fragrances\": [\n        \"Chanel No. 5\"\n      ],\n      \"services\": [\n        \"Insurance\"\n      ],\n      \"other\": []\n    },\n    \"job\": {\n      \"position\": \"Customer Service Representative\",\n      \"salary\": 3521,\n      \"type\": null,\n      \"company\": {\n        \"name\": \"Target\",\n        \"size\": 16,\n        \"segment\": \"Healthcare\",\n        \"country\": \"Switzerland\"\n      },\n      \"department\": \"Design\"\n    },\n    \"metrics\": {\n      \"ltv\": 0,\n      \"ltcosc\": 0,\n      \"ltcocc\": 0,\n      \"ltcop\": 0,\n      \"ltcosv\": 0,\n      \"ltcocv\": 0,\n      \"next\": null,\n      \"custom\": {}\n    },\n    \"loyalty\": {\n      \"codes\": [\n        \"but1get2\"\n      ],\n      \"card\": {\n        \"id\": null,\n        \"name\": null,\n        \"issuer\": \"Champion\",\n        \"expires\": \"2024-01-31T23:51:46\",\n        \"points\": 40\n      }\n    }\n  }\n}\n</code></pre> Session Object Schema <pre><code>{\n   \"id\": \"e4b1e0b0-d90d-4cd0-86c3-9c91ccab25af\",\n   \"metadata\": {\n      \"time\": {\n         \"insert\": \"2023-10-16T09:24:30.292701\",\n         \"update\": null,\n         \"timestamp\": 1697448270.292705,\n         \"duration\": 0,\n         \"weekday\": 0\n      },\n      \"channel\": \"Internal\",\n      \"aux\": {},\n      \"status\": \"active\"\n   },\n   \"profile\": {\n      \"id\": \"44f12a8c-bdc9-44a4-bf19-bbc1d0a4ccd8\"\n   },\n   \"device\": {\n      \"name\": \"Other\",\n      \"brand\": \"LG\",\n      \"model\": \"Degree\",\n      \"type\": null,\n      \"touch\": false,\n      \"ip\": null,\n      \"resolution\": null,\n      \"geo\": {\n         \"country\": {\n            \"name\": \"America/Havana\",\n            \"code\": \"CU\"\n         },\n         \"city\": \"Varadero\",\n         \"county\": \"CU\",\n         \"postal\": null,\n         \"latitude\": 23.15678,\n         \"longitude\": -81.24441\n      },\n      \"color_depth\": null,\n      \"orientation\": null\n   },\n   \"os\": {\n      \"name\": \"Android\",\n      \"version\": \"4.2.2\"\n   },\n   \"app\": {\n      \"type\": null,\n      \"name\": null,\n      \"version\": null,\n      \"language\": \"sc_IT\",\n      \"bot\": false,\n      \"resolution\": null\n   },\n   \"utm\": {\n      \"source\": null,\n      \"medium\": null,\n      \"campaign\": null,\n      \"term\": null,\n      \"content\": null\n   },\n   \"context\": {\n      \"time\": {\n         \"local\": \"8/26/2021, 9:36:13 PM\",\n         \"tz\": \"Asia/Katmandu\"\n      },\n      \"location\": {\n         \"country\": {\n            \"name\": \"America/Havana\",\n            \"code\": \"CU\"\n         },\n         \"city\": \"Varadero\",\n         \"county\": \"CU\",\n         \"postal\": null,\n         \"latitude\": \"23.15678\",\n         \"longitude\": \"-81.24441\"\n      },\n      \"device\": {\n         \"name\": \"Other\",\n         \"brand\": \"Werner-White\",\n         \"model\": \"degree company knowledge\",\n         \"type\": \"tablet\",\n         \"touch\": false,\n         \"ip\": null,\n         \"resolution\": \"1280x960\",\n         \"geo\": {\n            \"country\": {\n               \"name\": \"America/Havana\",\n               \"code\": \"CU\"\n            },\n            \"city\": \"Varadero\",\n            \"county\": \"CU\",\n            \"postal\": null,\n            \"latitude\": \"23.15678\",\n            \"longitude\": \"-81.24441\"\n         },\n         \"color_depth\": 8,\n         \"orientation\": \"landscape-primary\"\n      },\n      \"os\": {\n         \"name\": \"macOS\",\n         \"version\": \"21.04\"\n      },\n      \"app\": {\n         \"type\": \"mobile_browser\",\n         \"name\": \"Internet Explorer\",\n         \"version\": \"50.0\",\n         \"language\": \"ja-JP\",\n         \"bot\": false,\n         \"resolution\": \"3840x1080\"\n      },\n      \"page\": {\n         \"url\": \"https://dixon.com/wp-content/blog/wp-content/post.html\",\n         \"path\": \"/wp-content/blog/wp-content/post.html\",\n         \"hash\": \"\",\n         \"title\": \"Rubber Shirt\",\n         \"referer\": {\n            \"host\": \"https://dixon.com\",\n            \"query\": null\n         },\n         \"history\": {\n            \"length\": 6\n         }\n      },\n      \"browser\": {\n         \"local\": {\n            \"browser\": {\n               \"name\": \"Netscape\",\n               \"engine\": \"Gecko\",\n               \"appVersion\": \"5.0 (X11)\",\n               \"userAgent\": \"Mozilla/5.0 (Linux; Android 4.2.2) AppleWebKit/531.0 (KHTML, like Gecko) Chrome/49.0.842.0 Safari/531.0\",\n               \"language\": \"sc_IT\",\n               \"onLine\": true,\n               \"javaEnabled\": false,\n               \"cookieEnabled\": true\n            },\n            \"device\": {\n               \"platform\": \"Android 2.3.6\"\n            }\n         }\n      },\n      \"storage\": {\n         \"local\": {\n            \"__anon_id\": \"\\\"f30ee0a4-be4e-4571-97b2-80b32a18a77f\\\"\",\n            \"profileQuery\": \"\",\n            \"eventQuery\": \"\",\n            \"sessionQuery\": \"\"\n         },\n         \"cookie\": {\n            \"cookies1\": \"tracardi-session-id=fb151f11-e6f4-4cbf-9ad9-39414c1219f8; ajs_user_id=null; ajs_group_id=null; ajs_anonymous_id=%22f573ac77-2d68-41f1-b768-d2d4aa986382%22\",\n            \"cookies2\": \"tracardi-session-id=fb151f11-e6f4-4cbf-9ad9-39414c1219f8, ajs_user_id=null, ajs_group_id=null, ajs_anonymous_id=\\\"f573ac77-2d68-41f1-b768-d2d4aa986382\\\"\"\n         }\n      },\n      \"screen\": {\n         \"width\": 2379,\n         \"height\": 819,\n         \"innerWidth\": 1507,\n         \"innerHeight\": 964,\n         \"availWidth\": 1526,\n         \"availHeight\": 956,\n         \"colorDepth\": 24,\n         \"pixelDepth\": 24\n      },\n      \"ip\": \"0.0.0.0\"\n   },\n   \"properties\": {},\n   \"traits\": {},\n   \"aux\": {}\n}\n</code></pre> Event Object Schema <pre><code> {\n   \"id\": \"053a1536-167d-4f1f-b066-2d556274a261\",\n   \"name\": \"Test Event\",\n   \"type\": \"test-event\",\n   \"metadata\": {\n      \"aux\": {},\n      \"time\": {\n         \"insert\": \"2023-08-16T08:55:00.055083\",\n         \"create\": null,\n         \"update\": null,\n         \"process_time\": 0.02,\n         \"total_time\": 0\n      },\n      \"ip\": null,\n      \"status\": \"collected\",\n      \"channel\": null,\n      \"processed_by\": {\n         \"rules\": [],\n         \"flows\": [],\n         \"third_party\": []\n      },\n      \"profile_less\": false,\n      \"debug\": false,\n      \"valid\": true,\n      \"error\": false,\n      \"warning\": false,\n      \"merge\": false,\n      \"instance\": null\n   },\n   \"utm\": {\n      \"source\": null,\n      \"medium\": null,\n      \"campaign\": null,\n      \"term\": null,\n      \"content\": null\n   },\n   \"properties\": {},\n   \"traits\": {},\n   \"source\": {\n      \"id\": \"1\"\n   },\n   \"session\": {\n      \"id\": \"1\",\n      \"start\": \"2023-10-16T08:54:59.956772\",\n      \"duration\": 0,\n      \"tz\": \"utc\"\n   },\n   \"profile\": null,\n   \"context\": {},\n   \"request\": {},\n   \"config\": {},\n   \"tags\": {\n      \"values\": [],\n      \"count\": 0\n   },\n   \"aux\": {},\n   \"device\": {},\n   \"os\": {},\n   \"app\": {},\n   \"hit\": {},\n   \"data\": {},\n   \"journey\": {\n      \"state\": null\n   }\n}\n ```\n\n## Mapping Your Data\n\nThe most crucial step is mapping your data to fit Tracardi's structure. Make sure all the necessary data properties\nmatch the right parts of Tracardi. Once this is done, send it to Elasticsearch using your preferred programming\nlanguage.\n\n## Importing CSV Data to Elasticsearch using Python\n\nIn this chapter we explain how to use Python to iterate through a CSV file containing fields such\nas `first name`, `last name`, and `gender` and import this data into an Elasticsearch index. The Elasticsearch index\nshould follow the provided schema structure.\n\n## Prerequisites\n\nBefore you begin, ensure you have the following:\n\n- Elasticsearch server up and running.\n- Python installed on your system.\n- Elasticsearch Python client library (`elasticsearch-py`) installed.\n\n\n## Necessary Information\n\nTo perform the data import to Tracardi, please ensure you have the following essential details:\n\n1. **Elasticsearch Login and Password:**\n   You will require the login credentials (username and password) for the Elasticsearch instance that is connected to\n   Tracardi. If necessary, make modifications to the script provided below to include these login credentials.\n\n2. **Last Event Index Name:**\n   You will need to know the name of the most recent monthly event index created by Tracardi in Elasticsearch. Please\n   check your Elasticsearch environment to determine the name of this index.\n\n3. **Import Sequence:**\n   The data import should follow a specific sequence to ensure proper data handling. Start by importing profiles, and\n   subsequently, if required, import events and sessions. This order ensures that the essential profile data is in place\n   before related events and sessions are imported.\n\n## Steps\n\n1. **Install the Elasticsearch Python Client**\n\n   If you haven't already installed the Elasticsearch Python client, you can do so using pip:\n\n   ```bash\n   pip install elasticsearch\n   ```\n\n2. **Python Script for Data Import**\n\n   Create a Python script that reads the CSV file, maps its data to the Elasticsearch schema, and sends the data to the\n   Elasticsearch index. Here's a sample Python script to achieve this:\n\n   ```python\n   from elasticsearch import Elasticsearch\n   import csv\n   import uuid\n   from datetime import datetime\n\n   # Elasticsearch client setup\n   es = Elasticsearch([{'host': 'your_elasticsearch_host', 'port': 9200}])\n\n   # Open the CSV file\n   with open('your_data.csv', mode='r') as csv_file:\n       csv_reader = csv.DictReader(csv_file)\n\n       # Iterate through each row in the CSV\n       for row in csv_reader:\n           # Create a unique identifier for each record\n           unique_id = str(uuid.uuid4())\n\n           # Prepare the data in the Elasticsearch schema\n           data = {\n               \"id\": unique_id,\n               \"ids\": [unique_id],\n               \"metadata\": {\n                   \"time\": {\n                       \"insert\": datetime.now().isoformat(),\n                       \"create\": None,\n                       \"update\": datetime.now().isoformat(),\n                       \"segmentation\": None,\n                       \"visit\": {\n                           \"last\": None,\n                           \"current\": datetime.now().isoformat(),\n                           \"count\": 1,\n                           \"tz\": \"Your_Timezone\"\n                       }\n                   },\n                   \"aux\": {},\n                   \"status\": None\n               },\n               \"stats\": {\n                   \"visits\": 0,\n                   \"views\": 0,\n                   \"counters\": {}\n               },\n               \"traits\": {\n                   \"gender\": row['gender']\n               },\n               \"segments\": [],\n               \"interests\": {},\n               \"consents\": {\n                   \"cookies\": {\n                       \"revoke\": None\n                   }\n               },\n               \"active\": True,\n               \"aux\": {\n                   \"geo\": {\n                       \"continent\": \"Your_Continent\"\n                   }\n               },\n               \"data\": {\n                   \"pii\": {\n                       \"firstname\": row['first name'],\n                       \"lastname\": row['last name'],\n                       \"name\": row['first name'] + \" \" + row['last name']\n                   },\n                   # Add other data fields as needed\n               }\n           }\n\n           # Send the data to Elasticsearch\n           print(es.index(index='vendor.tracardi-event-2023-10', doc_type='_doc', body=data))\n\n   print(\"Data import completed.\")\n   ```\n\n   Replace placeholders like `'your_elasticsearch_host'`, `'your_data.csv'`, `'Your_Timezone'`, and other values with\n   your specific details. Notice that the import is to the monthly index of the tracardi event `vendor.tracardi-event-2023-10`. Please check elasticsearch for the last monthly index that is created by tracardi. \n\n3. **Run the Python Script**\n\n   Execute the Python script to import the data from the CSV file into your Elasticsearch index. You should see the \"\n   Data import completed\" message upon successful execution.\n\nNow, your CSV data is successfully imported into Elasticsearch with the specified schema.\n\n### How to import event data through Tracardi endpoint?\n\nYou can use `/track` endpoint to import event data from CSV and map them with session and profile.\n\nExample:\n\n```python\nimport csv\nimport requests\n\n\ndef read_csv(filename):\n    with open(filename, 'r') as file:\n        reader = csv.reader(file)\n        headers = next(reader)  # Read the header row\n        for row in reader:  # Iterate over the remaining rows\n            yield dict(zip(headers, row))  # spit out column name and data\n\n\n# Provide the path to your CSV file\nconfig = ('file1.csv', 'phone-call', 'session-id', 'profile-id')\n\nsource_id = \"c437d599-5d38-43e2-84b9-c6267dce6410\"\n\nfor row in read_csv(config[0]):\n\n    mapped_properties = {\n       \"from\": config[0]\n       # Add the properties you need. Include them in the CSV to be able to \n       # map them here\n    }\n\n    payload = {\n        \"source\": {\n            \"id\": source_id\n        },\n        \"session\": {\n            \"id\": row[config[2]]  # If the session id does not exist system will create it for you\n        },\n        \"profile\": {\n            \"id\": row[config[3]]\n        },\n        \"events\": [\n            {\n                \"type\": config[1],\n                \"properties\": row\n            }\n        ]\n    }\n\n    response = requests.post(url=\"http://localhost:8686/track\", json=payload)\n\n    # Display response\n    print(response.content)\n</code></pre> <p>This document also answers the questions: - How to programmatically import data to Tracardi? - Is there a way to use code to import data to Tracardi? - How to use API to import data?</p>"},{"location":"qa/how_to_import_initial_data/","title":"How to make the initial loading of the data and how to update it constantly? We want to add user data to the profile from an external resource (Database). And how to upload a new profile if we have nothing on the user in Tracardi?","text":"<p>The simplest method is to execute a script that retrieves data from your database and uses the <code>/track</code> endpoint to insert the data. Importing is quite similar to collecting data. You will need to convert your database records into the Tracardi profile format.</p> <p>Here are the steps:</p> <ol> <li>Create an event source in Tracardi for the import.</li> <li>Note down the event source ID, as you will need it later.</li> <li>Develop a basic script that connects to your database and fetches the profiles you wish to import.</li> <li>Process each data record and adapt it to the following schema. If your profile IDs are numbers, convert them to an MD5 hash with some added 'salt' for security reasons, as using plain numbers can be risky. Not all fields must ne filled. Remove unnecessary ones: <pre><code>{\n \"pii\": {\n  \"firstname\": \"string\",\n  \"lastname\": \"string\",\n  \"name\": \"string\",\n  \"birthday\": \"2010-01-01 00:00:00\",\n  \"language\": {\n   \"native\": \"string\",\n   \"spoken\": [\n    \"string\"\n   ]\n  },\n  \"gender\": \"string\",\n  \"education\": {\n   \"level\": \"string\"\n  },\n  \"civil\": {\n   \"status\": \"string\"\n  },\n  \"attributes\": {\n   \"height\": 0,\n   \"weight\": 0,\n   \"shoe_number\": 0\n  }\n },\n \"identifier\": {\n  \"id\": \"string\",\n  \"token\": \"string\",\n  \"passport\": \"string\",\n  \"credit_card\": \"string\",\n  \"coupons\": [\n   \"string\"\n  ],\n  \"badge\": \"string\"\n },\n \"contact\": {\n  \"email\": \"string\",\n  \"phone\": \"string\",\n  \"app\": {\n   \"whatsapp\": \"string\",\n   \"discord\": \"string\",\n   \"slack\": \"string\",\n   \"twitter\": \"string\",\n   \"telegram\": \"string\",\n   \"wechat\": \"string\",\n   \"viber\": \"string\",\n   \"signal\": \"string\"\n  },\n  \"address\": {\n   \"town\": \"string\",\n   \"county\": \"string\",\n   \"country\": \"string\",\n   \"postcode\": \"string\",\n   \"street\": \"string\",\n   \"other\": \"string\"\n  }\n },\n \"media\": {\n  \"image\": \"string\",\n  \"webpage\": \"string\",\n  \"social\": {\n   \"twitter\": \"string\",\n   \"facebook\": \"string\",\n   \"youtube\": \"string\",\n   \"instagram\": \"string\",\n   \"tiktok\": \"string\",\n   \"linkedin\": \"string\",\n   \"reddit\": \"string\"\n  }\n },\n \"job\": {\n  \"position\": \"string\",\n  \"salary\": 10,\n  \"type\": \"string\",\n  \"company\": {\n   \"name\": \"string\",\n   \"size\": 100,\n   \"segment\": \"string\",\n   \"country\": \"string\"\n  },\n  \"department\": \"string\"\n },\n \"preferences\": {\n  \"purchases\": [\n   \"string\"\n  ],\n  \"colors\": [\n   \"string\"\n  ],\n  \"sizes\": [\n   \"string\"\n  ],\n  \"devices\": [\n   \"string\"\n  ],\n  \"channels\": [\n   \"string\"\n  ],\n  \"payments\": [\n   \"string\"\n  ],\n  \"brands\": [\n   \"string\"\n  ],\n  \"fragrances\": [\n   \"string\"\n  ],\n  \"services\": [\n   \"string\"\n  ],\n  \"other\": [\n   \"string\"\n  ]\n },\n \"loyalty\": {\n  \"codes\": [\n   \"string\"\n  ],\n  \"card\": {\n   \"id\": \"string\",\n   \"name\": \"string\",\n   \"issuer\": \"string\",\n   \"expires\": \"2022-01-01 00:00:00\",\n   \"points\": 0\n  }\n }\n}\n</code></pre></li> <li>Use the <code>/track</code> endpoint on your Tracardi API to send the following data payload: <pre><code>{\n    \"source\": {\n        \"id\": \"&lt;source_id&gt;\"\n    },\n    \"profile\": {\n        \"id\": \"&lt;profile-id-from-your-system&gt;\"\n    },\n    \"events\": [\n        {\n            \"type\": 'profile-update',\n            \"properties\": &lt;mapped-profile&gt;\n        }\n    ]\n}\n</code></pre></li> </ol> <p>The 'profile-update' event will transfer the provided properties to your Tracardi profile. The same way you can update the profile data. </p>"},{"location":"qa/how_to_install_elastic_on_k3s/","title":"How to Install ElasticSearch Cluster on K3s/K8s?","text":"<p>This post outlines the process of installing ElasticSearch (ES) on K3s, a lightweight Kubernetes distribution designed for edge and IoT environments. Before proceeding with the installation, it is crucial to ensure that you have a prerequisite setup, which includes a working K3s or Kubernetes (K8s) cluster with <code>kubectl</code> connected and configured. This setup will allow you to effectively manage your cluster's resources and deploy ES using the methodologies described here. The following steps will guide you through the installation of the ElasticSearch cluster, leveraging the Kubernetes operator and Helm charts for a simplified and efficient deployment.</p> <p>Note</p> <p>Kubernetes uses namespaces to separate different projects. We will use separate namespaces for each Tracardi dependency.</p> <p>The best way to install ElasticSearch (ES) on Kubernetes is to use the ES operator. A Kubernetes operator is a method of packaging, deploying, and managing a Kubernetes application. To install it, type:</p> <pre><code>kubectl apply -f https://download.elastic.co/downloads/eck/2.10.0/crds.yaml\nkubectl apply -f https://download.elastic.co/downloads/eck/2.10.0/operator.yaml\n</code></pre> <p>It will automatically install the ElasticSearch Kubernetes Operator, which configures and manages ES clusters in your K8s environment.</p>"},{"location":"qa/how_to_install_elastic_on_k3s/#helm-chart-download","title":"Helm Chart Download","text":"<p>Then we will use a helm chart prepared by Tracardi to simplify the whole installation. First, download the helm chart file:</p> <pre><code>curl -O http://tracardi.com/helm/1.0.0/elastic-1.0.0.tgz\n</code></pre> <p>This command saves the helm chart as a file named <code>elastic-1.0.0.tgz</code>.</p>"},{"location":"qa/how_to_install_elastic_on_k3s/#configuration","title":"Configuration","text":"<p>Next, you need to prepare a simple file called <code>values.yaml</code> that defines how many nodes your Elastic cluster should have:</p> Example of a values.yaml file<pre><code>version: 8.11.3  # Version of ElasticSearch\n\nservice:\n  type: LoadBalancer  # LoadBalancer for ES\n  port: 9200\n\nmaster:\n  replicas: 1  # Number of master nodes\n  storage:\n    size: 5Gi  # Storage size for the master node\n\ndata:\n  replicas: 3 # Number of worker nodes\n  storage:\n    size: 10Gi # Storage size for each worker node\n</code></pre> <p>This is a very simplified installation but will install a production-ready ElasticSearch cluster. It will create storage volumes and the defined number of nodes.</p>"},{"location":"qa/how_to_install_elastic_on_k3s/#installation","title":"Installation","text":"This command will create elastic namespace<pre><code>kubectl create ns elastic\n</code></pre> <p>Let's install ElasticSearch. We will use the previously defined <code>values.yaml</code> file and the downloaded helm chart:</p> <pre><code>helm install elastic elastic-1.0.0.tgz --values values.yaml -n elastic\n</code></pre> <p>This command installs the ElasticSearch cluster using the helm chart <code>elastic-1.0.0.tgz</code> within the namespace <code>elastic</code>, applying your configuration specified in <code>values.yaml</code>. This automates the setup of your ES cluster with specified versions, node configurations, and storage settings.</p> <p>If later you would like to upgrade your installation after editing <code>values.yaml</code>, please use the following command. Note that you will not be able to decrease the storage; you can only increase it.</p> <pre><code>helm upgrade --install elastic elastic-1.0.0.tgz --values values.yaml -n elastic\n</code></pre>"},{"location":"qa/how_to_install_elastic_on_k3s/#wrap-up","title":"Wrap Up","text":"<p>After a minute or two, you should be able to see the pods in the <code>elastic</code> namespace. A pod in Kubernetes is the smallest deployable unit that can be created, scheduled, and managed. It's essentially a group of one or more docker containers, with shared storage/network, and a specification for how to run the containers.</p> <p>To check if everything is OK, run this command:</p> <pre><code>kubectl get pods -n elastic\n</code></pre> Expected output<pre><code>NAME                                  READY   STATUS    RESTARTS       AGE\nelastic-cluster-es-master-node-0      1/1     Running   0              72d\nelastic-cluster-es-data-node-1        1/1     Running   0              72d\nelastic-cluster-es-data-node-2        1/1     Running   0              72d\nelastic-cluster-es-data-node-0        1/1     Running   0              72d\n</code></pre>"},{"location":"qa/how_to_install_k3s/","title":"How to install kubernetes for Tracardi","text":"<p>We advice to use k3s as a simple K8s cluster. </p> <p>To do so you will need at lease 3 machines or VPSes.</p> <p>To install a k3s cluster with at least 3 nodes, follow these steps:</p> <ol> <li> <p>Install k3s on the First Node:    On your main server node (Master), run the following command to install k3s:    <pre><code>curl -sfL https://get.k3s.io | sh -\n</code></pre>    This will install k3s and start it as a service. To get the token required for adding agent nodes, run:    <pre><code>sudo cat /var/lib/rancher/k3s/server/node-token\n</code></pre></p> </li> <li> <p>Install k3s on Agent Nodes:    On each of the remaining nodes (agent nodes), run the following command, replacing <code>&lt;SERVER_IP&gt;</code> with the IP address    of your server node and <code>&lt;NODE_TOKEN&gt;</code> with the token retrieved from the server node:    <pre><code>curl -sfL https://get.k3s.io | K3S_URL=https://&lt;SERVER_IP&gt;:6443 K3S_TOKEN=&lt;NODE_TOKEN&gt; sh -\n</code></pre></p> </li> <li> <p>Verify the Cluster:    After installing k3s on all nodes, verify the cluster status on the server node by running:    <pre><code>kubectl get nodes\n</code></pre>    This command should list all nodes in the cluster, including the master and agent nodes, showing their status as \"    Ready\".</p> </li> </ol>"},{"location":"qa/how_to_install_k3s/#how-to-manage-k3s-from-outside-the-cluster","title":"How to manage k3s from outside the cluster","text":"<p>Managing a K3s (Lightweight Kubernetes) cluster from outside the cluster involves configuring <code>kubectl</code> to access the cluster remotely. Here's a step-by-step guide on how to do this:</p>"},{"location":"qa/how_to_install_k3s/#1-set-up-k3s-cluster","title":"1. Set Up K3s Cluster","text":"<p>Make sure your K3s cluster is running and you have access to the <code>kubeconfig</code> file, which is usually located at <code>/etc/rancher/k3s/k3s.yaml</code> on the master node.</p>"},{"location":"qa/how_to_install_k3s/#2-expose-the-k3s-api-server","title":"2. Expose the K3s API Server","text":"<p>Ensure that port 6443 (default port for the Kubernetes API server) is open on your firewall and accessible from your remote location.</p>"},{"location":"qa/how_to_install_k3s/#3-copy-and-modify-etcrancherk3sk3syaml-file","title":"3. Copy and modify /etc/rancher/k3s/k3s.yaml` file","text":"<p>Copy the remote file <code>/etc/rancher/k3s/k3s.yaml</code> (from server master node) to you local computer (best location on your local computer is: <code>~/.kube/config</code>). Modify the file (<code>~/.kube/config</code>). Update the <code>server</code> field to use the external IP or DNS name of the master node:</p> <pre><code>server: https://YOUR_EXTERNAL_IP:6443\n</code></pre> <p>This will tell you computer where the k3s cluster is located.</p>"},{"location":"qa/how_to_install_k3s/#4-configure-kubectl","title":"4. Configure <code>kubectl</code>","text":"<ol> <li>Set the <code>KUBECONFIG</code> Environment Variable:</li> </ol> <pre><code>export KUBECONFIG=~/.kube/config\n</code></pre> <ol> <li>Test the Connection: Verify that you can connect to the K3s cluster from your local computer.</li> </ol> <pre><code>kubectl get nodes\n</code></pre>"},{"location":"qa/how_to_install_k3s/#4-secure-the-connection","title":"4. Secure the Connection","text":"<p>For production environments, it is important to secure the API server:</p> <ul> <li>Use a VPN: Set up a VPN to securely connect to your internal network.</li> <li>TLS Certificates: Ensure that TLS certificates are properly configured and trusted.</li> <li>Firewall Rules: Restrict access to the API server to specific IP addresses.</li> </ul>"},{"location":"qa/how_to_install_k3s/#example-commands","title":"Example Commands","text":"<ol> <li>Copy <code>k3s.yaml</code> to Local Machine:</li> </ol> <pre><code>scp user@master-node:/etc/rancher/k3s/k3s.yaml ~/.kube/config\n</code></pre> <ol> <li>Edit <code>k3s.yaml</code>:</li> </ol> <p>Update the <code>server</code> field to use the external IP or DNS name:</p> <pre><code>server: https://YOUR_EXTERNAL_IP:6443\n</code></pre> <ol> <li>Set <code>KUBECONFIG</code>:</li> </ol> <pre><code>export KUBECONFIG=~/.kube/config\n</code></pre> <ol> <li>Test Connection:</li> </ol> <pre><code>kubectl get nodes\n</code></pre> Example output for 3 node cluster<pre><code>NAME      STATUS   ROLES                  AGE   VERSION\nnode-02   Ready    &lt;none&gt;                 1s   v1.29.4+k3s1\nnode-03   Ready    &lt;none&gt;                 1s   v1.29.4+k3s1\nnode-01   Ready    control-plane,master   1s   v1.29.4+k3s1\n</code></pre> <ol> <li>Your K3s cluster is ready: Now you can use kubectl to manage the kluster from you machine.</li> </ol>"},{"location":"qa/how_to_install_k3s/#other-k8s-clients","title":"Other K8s Clients","text":"<p>We recommend OpenLens which is the open-source version of Lens, a popular Kubernetes IDE. Installing OpenLens involves downloading the appropriate package for your operating system and setting it up. Here are the steps to install OpenLens on different operating systems:</p>"},{"location":"qa/how_to_install_k3s/#for-windows","title":"For Windows","text":"<ol> <li> <p>Download the Installer:</p> <ul> <li>Go to the OpenLens GitHub Releases page.</li> <li>Download the <code>.exe</code> installer for the latest version of OpenLens.</li> </ul> </li> <li> <p>Run the Installer:</p> <ul> <li>Double-click the downloaded <code>.exe</code> file.</li> <li>Follow the installation prompts to complete the setup.</li> </ul> </li> </ol>"},{"location":"qa/how_to_install_k3s/#for-macos","title":"For macOS","text":"<ol> <li> <p>Download the Installer:</p> <ul> <li>Go to the OpenLens GitHub Releases page.</li> <li>Download the <code>.dmg</code> file for the latest version of OpenLens.</li> </ul> </li> <li> <p>Install OpenLens:</p> <ul> <li>Open the downloaded <code>.dmg</code> file.</li> <li>Drag the OpenLens application to the Applications folder.</li> </ul> </li> </ol>"},{"location":"qa/how_to_install_k3s/#for-linux","title":"For Linux","text":"<ol> <li> <p>Download the Installer:</p> <ul> <li>Go to the OpenLens GitHub Releases page.</li> <li>Download the appropriate package for your distribution (e.g., <code>.AppImage</code>, <code>.deb</code>, or <code>.rpm</code>).</li> </ul> </li> <li> <p>Install OpenLens:</p> <ul> <li>For <code>.AppImage</code>:   <pre><code>chmod +x OpenLens-x.y.z.AppImage\n./OpenLens-x.y.z.AppImage\n</code></pre></li> <li>For <code>.deb</code> (Debian/Ubuntu):   <pre><code>sudo dpkg -i OpenLens-x.y.z.deb\n</code></pre></li> <li>For <code>.rpm</code> (Fedora/CentOS/RHEL):   <pre><code>sudo rpm -i OpenLens-x.y.z.rpm\n</code></pre></li> </ul> </li> </ol>"},{"location":"qa/how_to_install_k3s/#launch-openlens","title":"Launch OpenLens","text":"<p>After installation, you can launch OpenLens from your application launcher or by running <code>openlens</code> from the terminal, depending on your operating system.</p>"},{"location":"qa/how_to_install_k3s/#connecting-to-a-kubernetes-cluster","title":"Connecting to a Kubernetes Cluster","text":"<ol> <li> <p>Open OpenLens:</p> <ul> <li>Launch OpenLens from your installed applications.</li> </ul> </li> <li> <p>Add Cluster:</p> <ul> <li>Click on \"Add Cluster\" and follow the prompts to connect to your Kubernetes cluster. You will need   the <code>kubeconfig</code> file for your cluster.</li> </ul> </li> <li> <p>Manage Clusters:</p> <ul> <li>Once connected, you can manage and monitor your Kubernetes clusters using the OpenLens interface.</li> </ul> </li> </ol>"},{"location":"qa/how_to_install_percons_on_k8s/","title":"How to Install MySQL Using Percona on Kubernetes","text":"<p>This article guides you through the installation of Percona XtraDB Cluster (PXC), a robust and scalable SQL database solution, on a Kubernetes (K8s) environment. Percona enhances MySQL's capabilities by providing high availability, more consistent backups, enhanced performance, and better scalability.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, you'll need a functioning Kubernetes cluster with <code>kubectl</code> installed and configured. Helm package manager installed on your local machine. This setup is essential for managing the resources and deploying the Percona database using the steps described below.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#setting-up-the-environment","title":"Setting Up the Environment","text":"<p>Note: Kubernetes namespaces allow for the isolation of cluster resources. We will deploy Percona in its own namespace to maintain a tidy environment and facilitate resource management.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#step-1-add-the-percona-helm-repository","title":"Step 1: Add the Percona Helm Repository","text":"<p>Helm charts simplify the deployment and management of applications on Kubernetes. Start by adding the Percona Helm repository:</p> <pre><code>helm repo add percona https://percona.github.io/percona-helm-charts/\n</code></pre> <p>This command adds the Percona repository, which contains the Helm charts necessary for deploying Percona XtraDB Cluster.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#step-2-update-the-helm-repository","title":"Step 2: Update the Helm Repository","text":"<p>To ensure you have the latest Helm charts and updates, refresh your repository:</p> <pre><code>helm repo update\n</code></pre> <p>This syncs your Helm repository with the remote Percona charts, ensuring the latest versions are ready for installation.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#configuration","title":"Configuration","text":""},{"location":"qa/how_to_install_percons_on_k8s/#prepare-the-valuesyaml-file","title":"Prepare the <code>values.yaml</code> File","text":"<p>To tailor the Percona deployment to your needs, configure your settings in a <code>values.yaml</code> file. This file will dictate the cluster configuration, resource allocation, and more. Here\u2019s an example configuration:</p> <pre><code>allowUnsafeConfigurations: true\n\nsharding:\n  enabled: false\n\nbackup:\n  enabled: true\n\npxc:\n  size: 1\n  volumeSpec:\n    pvc:\n      resources:\n        requests:\n          storage: 2Gi\n\nhaproxy:\n  enabled: true\n  size: 1\n  resources:\n    requests:\n      memory: 100Mi\n\nproxysql:\n  size: 1\n</code></pre> <p>This configuration sets up a single-node Percona cluster with HAProxy and ProxySQL for load balancing and routing. Backups are enabled, ensuring data durability and recovery capabilities.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#installation","title":"Installation","text":""},{"location":"qa/how_to_install_percons_on_k8s/#create-a-namespace-for-percona","title":"Create a Namespace for Percona","text":"<p>Organize your deployment by creating a namespace specifically for Percona:</p> <pre><code>kubectl create namespace percona\n</code></pre>"},{"location":"qa/how_to_install_percons_on_k8s/#install-percona-operator-and-database","title":"Install Percona Operator and Database","text":"<p>Deploy the Percona Operator, which manages the lifecycle of the Percona cluster:</p> <pre><code>helm install percona-op percona/pxc-operator --namespace percona\n</code></pre> <p>Next, deploy the Percona database cluster using the previously prepared <code>values.yaml</code> file:</p> <pre><code>helm install percona-db percona/pxc-db --values values.yaml --namespace percona\n</code></pre> <p>These commands deploy the Percona Operator and the Percona database itself, configuring them according to the specifications in your <code>values.yaml</code> file.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#uninstalling-percona","title":"Uninstalling Percona","text":"<p>Should you need to remove the Percona cluster, you can do so cleanly using the following commands:</p> <pre><code>NS=\"percona\"\n\nkubectl delete pxc percona-db-pxc-db -n $NS\n\nhelm delete percona-db --namespace $NS\nhelm delete percona-op --namespace $NS\n\nkubectl delete namespace $NS\n</code></pre> <p>These commands will delete the Percona database and operator, as well as the namespace, effectively cleaning up all resources associated with the installation.</p>"},{"location":"qa/how_to_install_percons_on_k8s/#wrap-up","title":"Wrap Up","text":"<p>After installation, verify the status of the Percona pods:</p> <pre><code>kubectl get pods -n percona\n</code></pre> <p>Expect output showing that your Percona cluster pods are running correctly:</p> Expected output<pre><code>NAME                                     READY   STATUS    RESTARTS   AGE\npercona-db-pxc-db-0                      1/1     Running   0          10m\npercona-db-pxc-haproxy-0                 1/1     Running   0          10m\npercona-db-pxc-proxysql-0                1/1     Running   0          10m\n</code></pre> <p>By following these steps, you have successfully deployed a Percona XtraDB Cluster on your Kubernetes environment, equipped with high availability and automatic backups, ready to handle your application\u2019s data needs.</p>"},{"location":"qa/how_to_install_redis_on_k3s/","title":"How to Install Redis on Kubernetes?","text":"<p>This article will guide you through the process of installing Redis, a popular in-memory data structure store, on a Kubernetes (K8s) environment. Kubernetes, with its robust orchestration capabilities, is ideal for managing Redis instances that require high availability and quick scalability.</p> <p>Before you begin, ensure you have a working Kubernetes cluster with <code>kubectl</code> installed and properly configured. This initial setup is crucial for successfully deploying and managing Redis within your Kubernetes infrastructure.</p>"},{"location":"qa/how_to_install_redis_on_k3s/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Kubernetes cluster up and running.</li> <li><code>kubectl</code> tool installed and configured to interact with your cluster.</li> <li>Helm package manager installed on your local machine</li> </ul>"},{"location":"qa/how_to_install_redis_on_k3s/#setting-up-the-environment","title":"Setting Up the Environment","text":"<p>Note: Kubernetes uses namespaces to organize and isolate cluster resources by team, application, or environment. In this guide, we will deploy Redis in its own namespace to keep it separate from other applications.</p>"},{"location":"qa/how_to_install_redis_on_k3s/#step-1-add-the-helm-repository","title":"Step 1: Add the Helm Repository","text":"<p>Helm is a package manager for Kubernetes that simplifies the deployment and management of applications. The first step in installing Redis is to add the Bitnami repository, which contains a pre-configured Helm chart for Redis:</p> <pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\n</code></pre> <p>This command registers the Bitnami repository with Helm, making the Redis chart available for installation.</p>"},{"location":"qa/how_to_install_redis_on_k3s/#step-2-update-the-helm-repository","title":"Step 2: Update the Helm Repository","text":"<p>After adding the new repository, update your Helm chart repository to ensure you have the latest list of charts and updates:</p> <pre><code>helm repo update\n</code></pre> <p>This command synchronizes your local Helm chart repository with the remote one, ensuring you have access to the latest charts provided by Bitnami.</p>"},{"location":"qa/how_to_install_redis_on_k3s/#configuration","title":"Configuration","text":""},{"location":"qa/how_to_install_redis_on_k3s/#prepare-the-valuesyaml-file","title":"Prepare the <code>values.yaml</code> File","text":"<p>To customize the Redis deployment to your specific needs, you will need to create and modify a <code>values.yaml</code> file. This file contains configuration settings like resource limits and storage options. Here is an example <code>values.yaml</code>:</p> <pre><code>master:\n  persistence:\n    size: 2Gi\n  resources:\n    limits:\n      memory: 2Gi\n    requests:\n      memory: 1Gi\nreplica:\n  persistence:\n    size: 5Gi\n  replicaCount: 1\n  resources:\n    limits:\n      memory: 2Gi\n    requests:\n      memory: 1Gi\n</code></pre> <p>This configuration defines the resource allocation and storage requirements for both the Redis master and replica instances. It ensures that Redis has enough memory and disk space to perform effectively while managing cost and resource usage within your cluster.</p>"},{"location":"qa/how_to_install_redis_on_k3s/#installation","title":"Installation","text":""},{"location":"qa/how_to_install_redis_on_k3s/#create-a-namespace-for-redis","title":"Create a Namespace for Redis","text":"<p>Before deploying Redis, create a dedicated namespace for it:</p> <pre><code>kubectl create namespace redis\n</code></pre> <p>This command creates a new namespace named <code>redis</code>, providing an isolated environment for running your Redis instances.</p>"},{"location":"qa/how_to_install_redis_on_k3s/#install-redis-using-helm","title":"Install Redis Using Helm","text":"<p>Now, install Redis into the newly created namespace using the Helm chart:</p> <pre><code>helm upgrade --install redis bitnami/redis --values values.yaml --namespace redis --create-namespace\n</code></pre> <p>This command tells Helm to install the Redis chart from the Bitnami repository. If Redis is not already installed, Helm will install it (<code>--install</code>). The <code>upgrade</code> option allows you to update an existing installation or configure additional parameters without affecting existing data. It uses the configurations specified in <code>values.yaml</code> and deploys Redis in the <code>redis</code> namespace.</p>"},{"location":"qa/how_to_install_redis_on_k3s/#wrap-up","title":"Wrap Up","text":"<p>After deployment, you can monitor the status of the Redis pods to ensure they are running correctly:</p> <pre><code>kubectl get pods -n redis\n</code></pre> <p>You should expect output similar to this, confirming that the Redis instances are up and operational:</p> Expected output<pre><code>NAME                       READY   STATUS    RESTARTS   AGE\nredis-master-0             1/1     Running   0          10m\nredis-replica-0            1/1     Running   0          10m\n</code></pre> <p>By following these steps, you will have successfully deployed a scalable and robust Redis instance on your Kubernetes cluster, ready to handle your application's caching and data structure management needs effectively.</p>"},{"location":"qa/how_to_integrate_TMS_with_Tracardi/","title":"How to integrate TMS with Tracardi?","text":"<p>To integrate TMS (Tenant Management Service) with Tracardi, follow these steps:</p> <ol> <li> <p>Set up Multi-tenancy: In Tracardi, multi-tenancy allows multiple tenants (clients) to use the system independently.    To enable multi-tenancy, set the <code>MULTI_TENANT</code> environment variable to \"yes\" in the Tracardi API Docker    configuration.</p> </li> <li> <p>Configure the Tenant Management Service (TMS): The TMS is responsible for managing various aspects related to tenants    within Tracardi. Provide the following configuration details for the TMS integration to the tracardi-api docker:</p> <ul> <li><code>MULTI_TENANT_MANAGER_URL</code>: Set this variable to the URL of the Tenant Management Service. It should point to the   endpoint where the TMS is running.</li> <li><code>MULTI_TENANT_MANAGER_API_KEY</code>: Provide the API key for the TMS. This key is used for authentication and   authorization between Tracardi and the TMS.</li> </ul> </li> <li> <p>Onboard new tenants: To automate the onboarding process for new tenants, you can use the TMS API. You can make API    calls to the TMS to create new tenants, retrieve their information, and manage tenant-specific data.</p> </li> <li> <p>Obtain API Key for Tracardi: To authenticate with the Tracardi API, follow the OAuth2 authorization process. Make a    POST request to the <code>/user/token</code> endpoint with your admin account credentials. If the authorization is successful,    you will receive an API key as an OAuth2 token, which will be used for subsequent authenticated requests to the    Tracardi API.</p> </li> </ol> <p>By following these steps, you can integrate TMS with Tracardi, enable multi-tenancy, automate tenant onboarding, and authenticate API requests using the obtained API key.</p>"},{"location":"qa/how_to_integrate_with_webhook/","title":"How to integrate external systems using webhooks","text":"<p>Integrating a system using JavaScript is easy, but using webhooks is more challenging. A webhook sends an API call when an event occurs in an external system, such as Slack notifying when someone joins a channel or writes a message. Intercepting a webhook is simple - create a URL webhook in Tracardi and add it to the external system as the URL to send data when an event occurs. However, the difficulty lies in the fact that the external system lacks information about the user who raised the event. Each external system has its own method of user identification, which means the profile ID in the external system is different from Tracardi's.</p> <p>This discrepancy means that when data is sent, the external system may not send it in any globally defined way. As a result, it is not possible to create a Tracardi event associated with any profile. Such events are profile-less, and unfortunately, do not contain information useful for tracking customer journeys. We must process these events and attempt to connect them with the existing Tracardi profile.</p> <p>First, we must ensure that all events collected by the webhook are grouped into one profile, even if it is not connected to an existing Tracardi profile. Tracardi can store multiple profiles belonging to one person, so if there is a technical possibility to connect them, it will do so. The collected data should be consistent and grouped per user.</p> <p>To keep the data within one profile, the webhook needs to transmit an identifier assigned to the user, such as a user ID from an external system. If such data is not sent, we will not be able to use it, and it is best not to collect it unless it is needed for other purposes and can remain anonymous.</p> <p>To identify the transmitted data and keep it within one profile, the event source in Tracardi has a <code>Replace profile ID</code> field in which we specify where the ID that identifies the profiles is located in the webhook data/payload.  This identifier is used to group events and connect each event to one profile.</p> <p>Once we have grouped events, we can consider whether there is any data that allows us to merge the profile from the external system with the profile from Tracardi. For this purpose, we use identification points and some data that  identifies the profile across all systems. We can use email for example, which is a common part between  Tracardi and the external system.</p>"},{"location":"qa/how_to_move_events_to_warehouse.md/","title":"How to move events to warehouse.md","text":""},{"location":"qa/how_to_move_events_to_warehouse.md/#how-can-processed-events-from-all-tenants-be-set-up-to-be-stored-and-assigned-to-profiles-in-a-data-warehouse-by-default","title":"How can processed events from all tenants be set up to be stored and assigned to profiles in a data warehouse by default?","text":"<p>There are two main approaches to storing and assigning processed events from all tenant accounts to profiles in a data warehouse.</p> <p>One method is to use an API that collects all the events and then connects this data to the warehouse. Then a destination can be used to send data to that API.</p> <p>Alternatively, a more direct approach involves using an internal Tracardi stream to write data directly to the warehouse. with this approach you would need to write your own code that connects to the internal tracardi stream.</p>"},{"location":"qa/how_to_pass_profile_id_from_domain_to_domain/","title":"Passing Profile ID in the URL Between Owned Domains (Cross Domain Event / Cross Domain Identification)","text":"<p>This feature is beneficial if you want to ensure that the same profile ID is created within owned domains. For example, if you own two domains that are linked and you click and redirect user from one domain to another domain, the same profile ID should be used. The JavaScript code can be used to rewrite links on the page to contain the current profile and pass it to destination domain. However, the profile must first exist in the system.</p> <p>System then will recognize that the profile already exists and is redirected from other domain and will connect profiles.</p>"},{"location":"qa/how_to_pass_profile_id_from_domain_to_domain/#default-behavior-without-cross-domain-events","title":"Default Behavior (without Cross-Domain Events):","text":"<ol> <li>First Visit: A random profile ID is created for a new visitor.</li> <li>Subsequent Visits: The existing profile ID is reused.</li> <li>Merging Profiles:<ul> <li>Only occurs when the user provides identifiable data (e.g., email during sign-in).</li> <li>Without such data, profiles remain separate.</li> </ul> </li> </ol>"},{"location":"qa/how_to_pass_profile_id_from_domain_to_domain/#cross-domain-events-advantage","title":"Cross-Domain Events Advantage:","text":"<ol> <li>Prevents Multiple Profiles: Avoids creating separate profiles for the same user across different domains.</li> <li>Automatic Merging: The system connects profiles based on the sequence of events, even without explicit merging keys    like email.</li> <li>Improved Tracking: Maintains a single user profile across all your owned domains.</li> </ol> <p>This feature is particularly useful when you can't rely on traditional merging methods (like email sign-ins) to connect user profiles across your different websites.</p> <p>Note</p> <pre><code>This is commercial feature\n</code></pre>"},{"location":"qa/how_to_pass_profile_id_from_domain_to_domain/#javascript-configuration","title":"Javascript Configuration","text":"<p>To enable the \"passing of profile ID\" feature:</p> <ol> <li>Add <code>trackExternalLinks</code> to the <code>settings</code> object in your Tracardi configuration:</li> </ol> Example<pre><code>const options = {\n  tracker: {\n    url: {\n      script: '//mydomain.com/tracker',\n      api: '//mydomain.com'\n    },\n    source: {\n      id: \"some-source-id\"\n    },\n    settings: {\n      trackExternalLinks: ['example.com', 'tracardi.com']\n    }\n  }\n}\n</code></pre> <ol> <li> <p>This configuration automatically modifies <code>&lt;a&gt;</code> tags on your page, adding <code>__tr_pid</code> (profile ID) and <code>__tr_src</code> (    source ID) parameters to links ending with the specified domains.</p> </li> <li> <p>When a user navigates between your domains, Tracardi processes the profile data as follows:</p> </li> </ol> <p>a. Checks for valid referrer data (profile ID and source ID).    b. If valid, marks for merging the referred profile with the existing local profile.    c. Logs warnings for invalid profile or source IDs.</p> <ol> <li>Destination website must have tracardi javascript snippet connected and be configured to accept the passed parameters.</li> </ol> <p>Here is the example of the configuration.</p> Example configuration of destination web site, e.g example.com<pre><code>var options = {\n     tracker: {\n         url: {\n             script: '//mydomain.com/tracker',\n             api: '//mydomain.com'\n         },\n         source: {\n             id: \"some-source-id\"\n         },\n         context: {\n             tracardiPass: true\n            }\n     }\n}\n</code></pre>"},{"location":"qa/how_to_personalize_messages/","title":"How to personalize messages?","text":"<p>Tracardi offers a Template Plugin that simplifies the process of creating templates and referencing data within them. The plugin allows you to generate dynamic text content that can be utilized in various plugins, such as SMS77, SMTP email, Mailchimp messages, and more.</p> <p>To leverage the Template Plugin in Tracardi, follow these steps:</p> <ul> <li>Create a Template: Start by creating a template using the Template Plugin. This plugin provides an interface where   you can design your template and use placeholders for the dynamic data.</li> <li>Use Data Placeholders: Within the template, you can define data placeholders using {{ }}. Place a referenced data   inside, for example {{ event@properties.name }}. These placeholders will represent the dynamic information that will be   replaced when the template is processed.</li> <li>Use Template: After creating the template, you can use it as a data source in various plugins within   Tracardi. For example, you can reference the template in the SMS77 plugin to generate personalized SMS messages, or in   the SMTP email plugin to create customized email content.</li> </ul> <p>This document also answers the questions: - How to personalize SMS77 messages? - How to send personalized emails? - How to use templates? - How to use data placeholders in text? - How to customize the messages? - Can messages be dynamic?</p>"},{"location":"qa/how_to_prioritize_events/","title":"Is it possible to give some events a higher priority for processing and others a lower priority?","text":"<p>Unfortunately, no. In the commercial version, all events are processed in parallel, with a slight delay due to bulking. If you want the workflow to be executed during the API call, you need to pass async: false in the parameters of the event.</p>"},{"location":"qa/how_to_prioritize_events/#what-happens-when-async-false-is-used","title":"What happens when async: false is used?","text":"<p>When async: false is used in the options of event collector, then there is no bulking, but the API call will take longer since the workflow must be completed before the response is returned.</p>"},{"location":"qa/how_to_purge_events_sessions_profiles/","title":"How to purge events, sessions, and profiles?","text":"<p>To purge events, you can follow these steps:</p> <ol> <li>Go to the maintenance/indices section.</li> <li>Locate the profile, event, and session indices.</li> <li>Delete these indices by clicking on the trash icon located on the right side.</li> <li>Refresh the page, and the system will reinstall those indices automatically.</li> </ol> <p>For example, if you find indices like \"080.fa73a.tracardi-event-2023-1,\" \"080.fa73a.tracardi-event-2023-2,\" and so on, deleting them will remove all the events collected in that respective month (e.g., January 2023).</p> <p>The same process can be applied to purge profiles and sessions. Once you have deleted the data, refresh the page. In most cases, you will be redirected to the installation page. The system detects any inconsistencies in the indices and recreates the missing ones if needed. However, if you haven't deleted all event indices, the system may not require a reinstallation.</p> <p>It's important to note that this operation is only available for single tenant installations, such as open-source installations. Multi-tenant installations of Tracardi do not have the option to delete indices.</p> <p>Please be aware that as of version 0.8.1, there is no function to delete events, profiles, or sessions individually.</p> <p>This document answers also questions: - How to delete events, profiles, sessions? - How to delete all data? - How to delete an index? - How to manage elasticsearch indices in Tracardi?</p>"},{"location":"qa/how_to_quickly_copy_data_from_node_to_node_in_wf/","title":"How to quickly copy node configuration from node to node (action to action)?","text":"<p>Creating a New Node by Copying an Existing Node</p> <p>To create a new node that replicates the configuration of an existing node, follow these steps:</p> <ul> <li>Identify the node you wish to copy.</li> <li>Access the advanced configuration options for the new node. Look for the JSON icon, typically located in the toolbar.</li> <li>Click on the JSON icon to open the advanced configuration panel. This panel allows you to view and edit the JSON   representation of the node's configuration.</li> <li>This JSON contains all the necessary information to recreate the node.</li> <li>Select the entire JSON code and copy it to the clipboard. You can usually do this by right-clicking and choosing the \"   Copy\" option, or by using the keyboard shortcut (e.g., Ctrl+C or Command+C).</li> <li>Create a new node in your desired location. Ensure that the new node you create is the same type as this existing   node.</li> <li>Once the new node is created, access its advanced configuration options as before and open the JSON panel.</li> <li>In the JSON panel, paste the previously copied JSON code into the text field. To do this, right-click inside the field   and choose the \"Paste\" option, or use the keyboard shortcut (e.g., Ctrl+V or Command+V).</li> <li>After pasting the JSON code, click Save.</li> <li>Review the configuration of the new node to ensure that everything has been copied correctly. Make any necessary   adjustments or modifications if needed.</li> <li>Save the changes and exit the advanced configuration mode.</li> </ul>"},{"location":"qa/how_to_replace_a_profile_in_workflow/","title":"How to Replace a Profile in Workflow?","text":"<p>Sometimes, it may be necessary to replace a profile with a different profile based on certain data from the event properties. This documentation will walk through how to do this using a workflow and looking for a profile based on a specific identifier, such as an email address. By following the instructions below, you can easily replace a profile and ensure that the correct information is being used in the workflow.</p> <ul> <li>Create a workflow with a start and end node</li> <li>Add a \"Load Profile by\" node and connect it to the start node</li> <li>Select the field (e.g., email) that you would like to use to identify the profile</li> <li>Send the email in the event properties</li> <li>Add an \"Event Properties\" node and connect it to the \"Load Profile by\" node for debugging purposes</li> <li>Run the workflow</li> <li>Check the state of the profile to ensure it was successfully loaded</li> <li>If the email is misspelled, there will be an error indicating that no record was found</li> <li>Consider what to do with events that do not have a profile (e.g., discard the event or keep it for further analysis)</li> </ul>"},{"location":"qa/how_to_scale_tracardi/","title":"Scaling Commercial Tracardi","text":"<p>Scaling Tracardi involves three main aspects: Data Bulking, Tracardi Scaling, and Infrastructure Scaling. Understanding how Tracardi is built is essential for effectively scaling it. Tracardi ingests data through API calls, so the more data you send, the more it can process in one run.</p>"},{"location":"qa/how_to_scale_tracardi/#data-bulking","title":"Data Bulking","text":"<p>Tracardi allows multiple events to be sent per profile in one API call. This helps in optimizing the data ingestion process. If you gather events for one profile, you can send them in one API call. Tracardi's JavaScript library, by default, bulks the events registered on one page.</p>"},{"location":"qa/how_to_scale_tracardi/#how-to-send-bulk-events","title":"How to Send Bulk Events","text":"<p>Tracardi's API schema supports sending multiple events for one profile. Here is an example of an API bulk payload:</p> <pre><code>{\n  \"source\": {\n    \"id\": \"Source ID\"\n  },\n  \"session\": {\n    \"id\": \"Session ID\"\n  },\n  \"profile\": {\n    \"id\": \"Profile ID\"\n  },\n  \"events\": [\n    {\n      \"type\": \"event-type\",\n      \"properties\": {\n        // Event properties\n      },\n      \"options\": {\n        // Event options\n      }\n    }\n    // Multiple events for one profile\n  ]\n}\n</code></pre>"},{"location":"qa/how_to_scale_tracardi/#tracardi-scaling","title":"Tracardi Scaling","text":""},{"location":"qa/how_to_scale_tracardi/#api-scaling","title":"API Scaling","text":"<p>Each API call takes time to process, so a single API instance has a limited number of calls it can handle. To handle more API calls, replicate the <code>tracardi-api</code> Docker container. Starting with at least 10 replicas is a good approach. The API sends data to Apache Pulsar, which is then consumed by background workers.</p>"},{"location":"qa/how_to_scale_tracardi/#scaling-background-workers","title":"Scaling Background Workers","text":"<p>To process data quickly, scale the number of background workers. Ensure there are enough workers to process data so that no data is left in the Apache Pulsar topic. Depending on the number of bulked events, you may need different numbers of background worker replicas.</p> <p>Monitor the backlog of Apache Pulsar via the Tracardi API using the <code>/queue/{namespace}/{topic}/backlog</code> endpoint. The namespace and topic you want to monitor are <code>system</code> and <code>functions</code>, respectively. The response will look something like this:</p> <pre><code>{\n  \"total\": 0,\n  \"backlog\": [\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-0\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-2\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-1\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-4\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-3\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-6\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-5\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-8\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-7\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    },\n    {\n      \"partition\": \"persistent://tracardi/system/functions-partition-9\",\n      \"subscription\": \"tracardi-function-subscription\",\n      \"count\": 0\n    }\n  ]\n}\n</code></pre> <p>Ensure the <code>count</code> on each partition is low or equal to 0. This number tells how many messages are not consumer. Near realtime consumption will keep this number low.</p>"},{"location":"qa/how_to_scale_tracardi/#infrastructure-scaling","title":"Infrastructure Scaling","text":""},{"location":"qa/how_to_scale_tracardi/#apache-pulsar","title":"Apache Pulsar","text":"<p>Begin by scaling Pulsar. Refer to Apache Pulsar documentation for detailed scaling instructions.</p> <p>To scale Apache Pulsar, you need to focus on scaling its main components: brokers, bookies, and ZooKeeper nodes. Brokers handle client connections and manage topic partitions, so increasing the number of brokers improves load distribution and fault tolerance. Bookies store message data, so adding more bookies enhances storage capacity and write/read throughput. ZooKeeper nodes manage metadata and coordination; scaling them ensures higher availability and resilience of the cluster. Properly balancing and scaling these components ensures Apache Pulsar can efficiently handle increased traffic and data loads.</p>"},{"location":"qa/how_to_scale_tracardi/#elasticsearch","title":"Elasticsearch","text":"<p>By default, Tracardi saves events in bulks to Elasticsearch with a bulk size of 500 events. Monitor if the background workers are filling the predefined bulk size or if they trigger saving due to buffer timeout. Tracardi will save 500 events at once if they arrive within a specific timeframe (e.g., 30 seconds). If not, the buffer will be emptied, and only the collected events will be saved.</p> <p>To ensure Elasticsearch can handle the data, define the number of nodes and the number of shards for the event index. Changing the number of shards post-setup is not possible. When installing Tracardi use environment variables to configure at least one data replica and set up shards for each index. Look for <code>ELASTIC_INDEX_REPLICAS</code> and <code>ELASTIC_INDEX_SHARDS</code>.</p> <p>Proper scaling ensures that Tracardi can efficiently handle large volumes of data, providing a robust solution for commercial needs.</p>"},{"location":"qa/how_to_scale_tracardi/#wrap-up","title":"Wrap-up","text":"<p>Scaling may require several rounds of system adjustments. Please thoroughly test the configurations before going live. </p>"},{"location":"qa/how_to_send_event_on_a_click_that_goes_to_external_page/","title":"How to collect event on the external click","text":"<p>To send an event on a click that goes to an external page, you need to add an onClick event to the button, create a function that will send an event when the button is clicked, and add the <code>fire</code> attribute with a value of <code>true</code> as a parameter to the window.tracker.track function. Moreover, you also need to set beacon to True. A beacon is an event that is sent even if the customer leaves the page. It allows you to track user interactions that may occur after a user has navigated away from a page, providing valuable insights into user behavior.</p> Example<pre><code>window.tracker.track(\"page-view\", {}, {\"fire\": true, asBeacon: true});\n</code></pre>"},{"location":"qa/how_to_send_event_when_customer_leaves_page/","title":"How can I send the event of a customer leaving the page?","text":"<p>To detect and handle the event of a customer leaving a webpage in Tracardi, you can use JavaScript to listen for events that typically signify a user's intent to exit. These events include beforeunload and unload. Here\u2019s a general approach on how to capture these events and send them to Tracardi:</p> <p>First, add an event listener to the window object for beforeunload or unload. The beforeunload event can ask the user for confirmation before leaving the page and can be used to trigger a send to Tracardi.</p> <p>Here's an example of how you might write the JavaScript to capture these events:</p> <pre><code>window.addEventListener(\"beforeunload\", function(event) {\n    // Optionally, you can prompt the user to confirm the page exit\n    event.preventDefault(); // Chrome requires returnValue to be set\n    event.returnValue = '';\n\n    // Data you might want to send to Tracardi\n    const eventData = {\n            \"timestamp\": new Date().toISOString(),\n            \"message\": \"User is leaving the page\"\n        };\n\n    // Track event with Tracardi\n    window.tracker.track(\"page-exit\", eventData, {fire: true});\n});\n</code></pre> <p>Other way is to use the beacon event on the click of the external link.</p> <p>Example</p> <pre><code>&lt;a href=\"http://external-page.com\" onClick=\"window.tracker.track('page-exit', {}, {fire: true, asBeacon: true});\n</code></pre> <p>More on beacon events can be found here</p>"},{"location":"qa/how_to_send_mails_with_mailchimp/","title":"How to send mails with mailchimp","text":"<p>To send emails with Mailchimp in Tracardi, follow these steps:</p> <ul> <li> <p>Obtain the API key: Log in to your Mailchimp account, click on your account icon in the top-right corner,   select \"Profile,\" then choose \"Extras &gt; API keys.\" Click on \"Create A Key\" to generate an API key. Copy this key to   the Token field in the Tracardi form.</p> </li> <li> <p>Verify the API key: If you encounter an error stating that the API key is invalid, double-check that you have set the   correct API key from Mailchimp.</p> </li> <li> <p>Check API key configuration: Make sure you have followed the tutorial for finding and setting the API key correctly.   The API key should match the one generated in your Mailchimp account.</p> </li> <li> <p>Save API key: If you are unable to change the API key and it does not get saved, try disabling the resource and then   enabling it again. This may help in saving the updated API key.</p> </li> <li> <p>Troubleshooting: If the issue persists, reach out to the plugin developer or support team to investigate the error and   find a solution.</p> </li> </ul> <p>Additionally, as an alternative solution, you can consider using the SMTP mailer in Tracardi to send emails. This can be helpful if you continue to encounter difficulties with the Mailchimp integration.</p>"},{"location":"qa/how_to_send_mails_with_mailchimp/#how-to-send-email-only-once","title":"How to send email only once","text":"<p>Regarding triggering emails only once for the same event and user, you can achieve this by saving information about the sent email in the user's profile. For example, after sending an email, use the \"Copy Data\" action in Tracardi to set a flag in the profile (e.g., profile@aux.sent_email = 1). Before triggering the email, you can check this flag to determine if the email has already been sent for a specific event.</p> <p>Remember, it's important to save and utilize the necessary information in the profile to conditionally send emails and avoid duplicate sends based on specific events or user actions.</p> <p>If you need further assistance, don't hesitate to seek help from Tracardi support or consult with the Tracardi community.</p>"},{"location":"qa/how_to_send_my_own_profile_id/","title":"How to send my own profile ID and disable profile ID regeneration?","text":"<p>To make Tracardi create a profile with a specific ID that you send, you need to enable static profile ID handling in your event source configuration and ensure that the profile ID is included in your event data. Here's a step-by-step guide on how to achieve this:</p>"},{"location":"qa/how_to_send_my_own_profile_id/#step-1-enable-static-profile-id-in-event-source","title":"Step 1: Enable Static Profile ID in Event Source","text":"<p>First, you need to configure the event source to allow static profile IDs. This setting ensures that Tracardi will use the profile ID you provide rather than generating a new one.</p> <ol> <li> <p>Go to Event Sources:</p> <ul> <li>In the Tracardi dashboard, navigate to the \"Inbound Traffic\" section and select \"Event Sources.\"</li> </ul> </li> <li> <p>Edit Event Source:</p> <ul> <li>Find and edit the event source you are using to collect the data.</li> </ul> </li> <li> <p>Enable Static Profile ID:</p> <ul> <li>In the event source configuration, ensure there is an option for allowing static profile IDs. This might be a   checkbox or a specific setting in the configuration JSON. Enable this option.</li> </ul> </li> </ol>"},{"location":"qa/how_to_send_my_own_profile_id/#step-2-include-profile-id-in-the-event-data","title":"Step 2: Include Profile ID in the Event Data","text":"<p>When sending events to Tracardi, include the profile ID in your tracker payload. </p> <pre><code>POST /track HTTP/1.1\nHost: your-tracardi-url\nContent-Type: application/json\n{\n\"source\": {\n  \"id\": \"&lt;your-event-source-id&gt;\"\n},\n\"profile\": {\n  \"id\": \"specific-profile-id\"\n},\n\"events\": [\n    {\n    \"type\": \"purchase-order\",\n    \"properties\": {\n        \"product\": \"Sun glasses\",\n        \"price\": 13.45\n        }\n    }\n]\n}\n</code></pre> <p>Replace <code>&lt;your-event-source-id&gt;</code> and <code>\"specific-profile-id\"</code> with your actual event source ID and desired profile ID. This ensures Tracardi uses the specified profile ID when processing the event.</p>"},{"location":"qa/how_to_set_custom_event_time/","title":"How to set custom event time in API payload?","text":"<p>To set a custom date for an event sent to Tracardi, you need to populate the <code>time</code> field within the event payload. The <code>time</code> field can include attributes such as <code>insert</code>, <code>create</code>, and <code>update</code> to provide specific timestamps for the event. Here's a step-by-step guide on how to set these custom timestamps.</p>"},{"location":"qa/how_to_set_custom_event_time/#event-payload-structure","title":"Event Payload Structure","text":"<p>The event payload consists of the following attributes:</p> <ul> <li>type: The type or category of the event (e.g., \"page-view\").</li> <li>time: Timestamp information for the event, which includes <code>insert</code>, <code>create</code>, and <code>update</code> attributes.</li> <li>properties: A dictionary of properties associated with the event.</li> <li>options: Additional options for the event.</li> <li>context: Additional context data for the event.</li> <li>tags: Tags associated with the event.</li> </ul>"},{"location":"qa/how_to_set_custom_event_time/#time-attribute-structure","title":"Time Attribute Structure","text":"<p>The <code>time</code> attribute provides timestamp information and can include the following attributes:</p> <ul> <li>insert: The timestamp of the event insertion (default is the current UTC datetime).</li> <li>create: The timestamp of the event creation.</li> <li>update: The timestamp of the event update.</li> </ul>"},{"location":"qa/how_to_set_custom_event_time/#example-setting-custom-dates-in-event-payload","title":"Example: Setting Custom Dates in Event Payload","text":"<p>Here's an example of how to set custom dates in the event payload using the Tracardi JavaScript tracker:</p> <pre><code>// Tracardi tracker initialization\nconst options = {\n    tracker: {\n        url: {\n            script: 'http://your-tracardi-url/tracker',\n            api: 'http://your-tracardi-url'\n        },\n        source: {\n            id: \"&lt;your-event-source-id&gt;\"\n        }\n    }\n};\n\n// Define your custom event payload with custom dates\nconst customEventPayload = {\n    \"type\": \"custom-event-type\",\n    \"time\": {\n        \"insert\": \"2024-05-01T12:00:00Z\",  // Custom insert time in ISO 8601 format\n        \"create\": \"2024-05-01T10:00:00Z\",  // Custom create time in ISO 8601 format\n        \"update\": \"2024-05-01T11:00:00Z\"   // Custom update time in ISO 8601 format\n    },\n    \"properties\": {\n        \"customProperty\": \"customValue\"\n    }\n};\n\n// Send the custom event with the custom dates\nwindow.tracker.track(\"custom-event\", customEventPayload);\n</code></pre>"},{"location":"qa/how_to_set_custom_event_time/#explanation","title":"Explanation","text":"<ol> <li> <p>Tracker Initialization:    Initialize the Tracardi tracker with the correct script and API URLs, and your event source ID.</p> </li> <li> <p>Custom Event Payload:    Create an object for your custom event payload. The <code>time</code> field includes the <code>insert</code>, <code>create</code>, and <code>update</code>    attributes with custom dates in ISO 8601 format. The <code>properties</code>, <code>options</code>, <code>context</code>, and <code>tags</code> fields provide    additional event details.</p> </li> <li> <p>Send the Event:    Use <code>window.tracker.track</code> to send the event to Tracardi. The first parameter is the event type, and the second    parameter is the payload that includes the custom dates.</p> </li> </ol> <p>This approach ensures that the event sent to Tracardi includes the custom timestamps you specified, allowing for accurate temporal representation within your event tracking system. Make sure to replace placeholders like <code>&lt;your-event-source-id&gt;</code> and <code>http://your-tracardi-url</code> with actual values relevant to your Tracardi instance.</p>"},{"location":"qa/how_to_store_interests/","title":"How to store interests in Tracardi","text":"<p>The \"Add Interest\" plugin in Tracardi is designed for adding and updating interests in a user's profile during workflow processing.</p> <p>In Tracardi, the \"Add Interest\" plugin can simplify the process of storing interests in user profiles. Here's how you can use it within a workflow:</p> <ol> <li> <p>Setup the Workflow: Create a new workflow or edit an existing one where you want to incorporate the interest    tracking. This workflow would typically be triggered by user actions that indicate their interests, such as viewing    specific content or interacting with certain elements on your site.</p> </li> <li> <p>Add the Add Interest Plugin to Workflow: Drag and drop the <code>Add Interest</code> plugin into your workflow. Connect this    plugin to the appropriate part of your workflow, ensuring it's triggered by the relevant user actions.</p> </li> <li> <p>Configure the Plugin: In the plugin configuration, specify the key under which the interest will be stored. This    key will reside under the interests field in the profile. Assign a weight to the interest. This weight can quantify    the level of interest, allowing for a more nuanced understanding of the user's preferences.</p> </li> <li> <p>Use Profile Update to store the interest: Confirm the change to profile with <code>Profile Update</code> plugin.</p> </li> </ol> <p>You can use <code>Increase Interest</code> and <code>Decrease Interest</code> to update the interest weight.</p>"},{"location":"qa/how_to_store_utms/","title":"How to Tracardi stores UTMs?","text":"<p>Tracardi utilizes UTM to help track website traffic and better understand where it is coming from. UTM, which stands for Urchin Tracking Module, is parameter that is added to the end of a URL, allowing website owners to track various pieces of information about the source of the traffic, such as the campaign name, the medium used, and the source of the traffic.</p> <p>To store UTM information, Tracardi stores the first URL that contains the UTM code in a session. Subsequent clicks by the customer will retrieve this information from the session, allowing Tracardi to continue tracking the customer's activity and providing connection with campaign that brought the customer to the page.</p> <p>In order to ensure that all UTMs are passed through to Tracardi, it is necessary to include them in the URL. This means that any campaign-specific parameters should be included at the end of the URL, following a question mark (?), with each parameter separated by an ampersand (&amp;). By doing so, Tracardi will be able to track the source and success of each campaign, providing valuable data that can be used to optimize future marketing efforts.</p>"},{"location":"qa/how_to_store_utms/#example","title":"Example","text":"<p>Example URL that could redirect customer from marketing banner to the page.</p> <pre><code>https://www.example.com/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=spring_sale&amp;utm_content=text_ad\n</code></pre> <p>In this example, the UTM parameters are:</p> <ul> <li>utm_source=google: This indicates that the source of the traffic is Google.</li> <li>utm_medium=cpc: This indicates that the medium of the traffic is cost-per-click advertising.</li> <li>utm_campaign=spring_sale: This indicates that the traffic is part of a campaign called \"Spring Sale.\"</li> <li>utm_content=text_ad: This indicates that the traffic is coming from a text ad.</li> </ul>"},{"location":"qa/how_to_track_clicked_links/","title":"How to Track Links and Viewed Images?","text":""},{"location":"qa/how_to_track_clicked_links/#two-methods","title":"Two Methods","text":"<p>There are two ways to track user activity in the system.</p> <ul> <li> <p>Redirected Links: This method involves creating   special links that, when clicked, send information to Tracardi about the user and then redirect them to a specific page. The information is stored within the link itself.</p> </li> <li> <p>Parameterized Links: The second method involves adding   a parameter <code>__tr_pid</code> to an existing link. This parameter contains user information. When user visits the target   page, the tracking script, that must exist on the target page, sends an event to Tracardi and use the   parameter <code>__tr_pid</code> to identify the customer. </p> </li> </ul> <p>Both methods are similar, but they differ in who sends the event to the system. In Redirected Links, Tracardi handles the event since the link is within the system. In the second method, the script located at the destination address is responsible for sending the event.</p>"},{"location":"qa/how_to_track_clicked_links/#pros-and-cons","title":"Pros and Cons","text":"<p>The first method requires creating artificial links, which can be a bit cumbersome to manage when there are many of them.</p> <p>The second method avoids this problem since it uses existing links and only requires appending a parameter, like a profile ID. However, the Tracardi system script must be present on the page.</p> <p>These two techniques serve different purposes. The first one is useful for tracking if a client has viewed specific images. Since images cannot have a tracking script directly, the first method utilizes artificial links that redirect to the desired image. When the image is downloaded, Tracardi automatically sends an event. This is often used to track email openings (email tracking). If an email contains images and they are downloaded, it indicates that the user has seen the email.</p> <p>The second technique is handy for checking if a user accessed our website from a specific email. By adding parameters with the user's ID or session to the URL, we can track this information.</p> <p>Keep in mind that if a session number is provided, the event will be attached to the corresponding profile. If only a profile ID is given, a new session will be created for that profile.</p> <p>Both techniques have a wide range of applications, primarily tracking page transitions, image views, file downloads, and more.</p>"},{"location":"qa/how_to_upgrade_tracardi/","title":"How to upgrade Tracardi in GUI?","text":"<p>To upgrade Tracardi, you need to navigate to the maintenance/migration page and locate the migration script from the old version. Follow the instructions provided in the script to complete the data migration. This feature is only available in Tracardi version 0.7.2 and higher. If you are using an older version, you will need to upgrade to at least 0.7.2 in order to access this functionality.</p> <p>When performing multiple upgrades of Tracardi, the system will create a large number of new indices, which may cause you to reach the Elasticsearch limit of 1000 indices. To resolve this issue, you can either increase the limit in the Elasticsearch configuration or delete the indices used by old Tracardi versions. Tracardi version 0.8.0 includes a feature in the GUI to delete old indices. If you are using an older version, you can use the API to delete old indices, such as issuing a HTTP DELETE call to /indices/version/0.7.2 to delete the 0.7.2 version indices. However, be cautious when deleting old data, as there is no way to revert the system to a previous version.</p>"},{"location":"qa/how_to_upgrade_tracardi/#how-to-upgrade-tracardi-core","title":"How to upgrade tracardi core?","text":"<p>To upgrade Tracardi, you can follow the following steps:</p> <ol> <li> <p>Minor Upgrades: For minor upgrades that do not involve changes in the underlying database structure, you can    simply upgrade the Docker tag to the new version. This can be done by changing the version number in the Docker tag.</p> </li> <li> <p>Major Upgrades: Major upgrades involve changes in the database structure. In Tracardi, data migration is    performed using Elasticsearch's reindexing process. To perform a major upgrade, you would need to run two copies of    the system with separate sets of indices: one with the old version and one with the new version. Once the migration    is complete, you can upgrade the Docker tag to the new version, and the system will switch to the new version    automatically.</p> </li> </ol> <p>It's important to note that Tracardi provides migration scripts for all major versions, allowing for smooth upgrades. However, these scripts are only available from one version to the next, so it's recommended to follow the upgrade path version by version for proper data migration and system stability. Skipping versions is not supported, and custom scripts may require additional effort and commercial services.</p> <p>In a multi-tenant instance of Tracardi, the upgrade process is applied uniformly to all tenants. This means that when performing an upgrade, the changes will be applied to all the tenants in the system. In the case of a major upgrade involving data structure changes, the data migration process needs to be performed for all tenants to ensure their data aligns with the updated database structure.</p> <p>To upgrade Tracardi in the GUI, you can navigate to the maintenance/migration page and locate the migration script for the old version. Follow the instructions provided in the script to complete the data migration. This feature is available in Tracardi version 0.7.2 and higher. If you're using an older version, you will need to upgrade to at least version 0.7.2 to access this functionality.</p> <p>Please note that Tracardi does not manage or install Kubernetes (K8s). Tracardi can help with the installation of Tracardi itself, but the installation of Elasticsearch and Redis needs to be performed by you.</p> <p>Regarding data backups, Tracardi uses Elasticsearch's built-in backup mechanism. Backups are created and stored in snapshot repositories, which can be a shared file system, a cloud storage service, or a network-attached storage (NAS). You can define a snapshot lifecycle policy to specify backup frequency and retention. Elasticsearch performs incremental backups, reducing backup time and storage requirements. The Snapshot and Restore API allows you to manage backups, including creating, listing, restoring, and deleting snapshots. Elasticsearch also provides options for disaster recovery, allowing you to restore snapshots in case of data loss.</p> <p>Regarding the infra dependencies, Tracardi requires a commercial version of the Tracardi API Docker for multi-tenant mode. To start Tracardi in multi-tenant mode, you need to set the MULTI_TENANT environment variable to \"yes\" in the Docker configuration. Additionally, you need to configure the Tenant Management Service (TMS) by providing the MULTI_TENANT_MANAGER_URL (the URL of the TMS) and MULTI_TENANT_MANAGER_API_KEY (API key for authentication and authorization between Tracardi and the TMS).</p> <p>For specific details and instructions, it's recommended to consult the Tracardi documentation or contact their support for accurate and up-to-date information on upgrading Tracardi and managing the multi-tenant environment.</p>"},{"location":"qa/how_to_use_api/","title":"Can I use API to create profile not tracking script?","text":"<p>Sure. Tracardi is an API first solution so you can find all the APIs at http://localhsot:8686/docs. Here is the docs on how to use /track API.</p> <p>Tracardi is designed to gather data from multiple sources using various methods. While the default method is through a REST API, its capabilities can be expanded by adding bridges to collect data from queues such as RabbitMQ, Kafka, MQTT, Pulsar, as well as from email accounts, databases, and more.</p>"},{"location":"qa/how_to_use_own_profile_id/","title":"How to use own profile id?","text":"<p>Setting up your own profile ID in Tracardi involves the following steps:</p> <ol> <li>Navigate to the 'Inbound Traffic' section.</li> <li>Select the source from which you are collecting data.</li> <li>Click on the 'Edit' option for that source.</li> <li>Toggle the switch labeled 'Allow static, remotely defined profile ID.'</li> </ol> <p>Enabling this feature allows you to utilize profile IDs that were not generated by Tracardi. The provided profile ID will be used to create a profile that does not already exist. It's important to be aware that using this feature can introduce security risks. Therefore, ensure that your custom profile ID is not numeric but rather a UUID4, making it difficult to guess.</p>"},{"location":"qa/how_to_use_workflow_editor/","title":"How to use workflow editor?","text":"<p>Here is a step-by-step guide on how to use the Workflow Editor in Tracardi:</p> <p>Open the Workflow Editor: When you start processing data in Tracardi, open the Workflow Editor. You will see a screen with all the nodes that you can put on the canvas.</p> <p>Search for nodes: On the left side of the screen, you can search for nodes by typing their names, such as \"start node.\" Then, you can drag and drop the node onto the canvas.</p> <p>Connect nodes: To connect nodes, select the node you want to connect and drag an edge to the next node. You can double-click on a node to rename it and configure how it works.</p> <p>Configure nodes: Nodes have forms that you can fill out to configure how they work. For example, the start node may only accept a certain event type, such as a page view. You can also see a short description of each node by hovering over it.</p> <p>Save the workflow: After configuring the nodes, save the workflow. You can have multiple start nodes on one canvas to process different event types.</p> <p>Deploy the workflow: Remember that the workflow is a draft until you click \"deploy.\" Once deployed, the workflow will be visible and functional on production.</p> <p>Check node documentation: Some nodes have additional documentation that you can access by clicking on them. The documentation may contain information on configuring the node with advanced JSON setup.</p> <p>Use ports: Nodes have input and output ports that you can click on to see additional documentation. You can use these ports to pass data between nodes.</p> <p>Use advanced runtime settings: You can access advanced runtime settings by double-clicking on a node. This includes options to skip a node, stop the flow on a node, and stop the workflow if a value does not change.</p>"},{"location":"qa/how_to_use_workflow_editor/#how-to-delete-a-node-in-workflow","title":"How to delete a node in workflow?","text":"<p>To delete a node in the workflow editor, follow these steps:</p> <ul> <li>Select the node you want to delete by clicking on it.</li> <li>Press the Delete key on your keyboard.</li> </ul>"},{"location":"qa/how_to_use_workflow_editor/#how-to-select-multiple-nodes","title":"How to select multiple nodes?","text":"<p>To select multiple nodes in the workflow editor, follow these steps:</p> <ul> <li>Hold SHIFT key and click and hold the left mouse button anywhere in the canvas area.</li> <li>While holding the left mouse button, drag the cursor to create a selection box that encloses all the nodes you want to select.</li> <li>All the nodes within the selection box will be highlighted and selected.</li> </ul>"},{"location":"qa/how_to_use_workflow_editor/#how-to-delete-a-connection","title":"How to delete a connection?","text":"<p>To delete a connection in the workflow editor, follow these steps:</p> <ul> <li>Select the connection you want to delete by clicking on it.</li> <li>Press the DELETE key on your keyboard (On Mac Fn+Delete).</li> </ul>"},{"location":"qa/how_tracadi_use_javascript_sinppet_to_collect_events/","title":"How Tracardi use javascript snippet to collect events?","text":"<p>Tracardi employs a JavaScript snippet to gather events, which is embedded within the web page. This snippet captures user interactions and subsequently transmits them to Tracardi's server. Importantly, these events are not fired in a specific order or sequence.</p> <p>Here is a breakdown of the process by which Tracardi acquires events through the JavaScript snippet:</p> <ol> <li> <p>The JavaScript snippet is loaded onto the web page, typically incorporated into the HTML of the page.</p> </li> <li> <p>The snippet initializes the Tracardi tracker, responsible for capturing and dispatching events to Tracardi's server.</p> </li> <li> <p>The tracker aggregates events and transmits them to Tracardi's server. All events on the page are batched and sent    when the page completes loading. This approach helps reduce the number of network requests and enhances performance.    However, there is a drawback: if you wish to dynamically send an event when, for example, someone clicks on an image    or hovers the mouse, you must use on-demand event collection. This necessitates adding the \"fire: true\" option to    the \"window.tracker.track\" function.</p> </li> </ol> <p>This answers also questions: - How does Tracardi utilize a JavaScript snippet for event collection?</p>"},{"location":"qa/how_tracard_bot_works/","title":"How does Tracardi Bot work?","text":"<p>Tracardi Bot operates by searching through the Tracardi documentation to locate the answer to your question. It leverages advanced AI technology to process your inquiry. However, please note that it is specifically designed to handle queries related to Tracardi only.</p> <p>Tracardi Bot serves as a useful tool for swiftly accessing information found on the Tracardi documentation page at http://manual.tracardi.com. It can filter and rephrase the responses to better align with your specific question. It's important to mention that our community covers the expenses associated with maintaining this bot, as it relies on OpenAI resources. To ensure the bot remains available to everyone, we kindly request your consideration in making a small donation to our project at https://opencollective.com/tracardi-cdp.</p> <p>Please note that since Tracardi Bot relies on AI technology, the answers it provides may not always be entirely accurate. Sometimes, AI systems can generate responses that are incorrect or inaccurate, which is known as \" hallucination\" in the context of AI. Therefore, it is advisable to cross-reference the information provided by Tracardi Bot with the official documentation if the answer seems questionable or incorrect. Checking the documentation will help ensure the accuracy and reliability of the information you receive.</p> <p>This document answers also questions:</p> <ul> <li>How do you work?</li> <li>How Tracardi bot can help me?</li> <li>What is Tracardi bot?</li> </ul>"},{"location":"qa/how_tracardi_can_track_marketing_campaigns/","title":"How can I track marketing campaigns with tracardi?","text":"<p>You can use UTMs.</p> <p>Tracardi can use UTM (Urchin Tracking Module) parameters to track marketing campaigns. UTM parameters are a standard way of tagging URLs to track the source, medium, and campaign of traffic. When a user clicks on a URL with UTM parameters, the parameters are appended to the URL and can be captured by Tracardi.</p> <p>Here are some of the ways Tracardi can use UTM parameters:</p> <ul> <li>Identify the source of traffic: Tracardi can use the <code>utm_source</code> parameter to identify the source of traffic,   such as a social media platform, email newsletter, or paid advertising campaign.</li> <li>Identify the medium of traffic: Tracardi can use the <code>utm_medium</code> parameter to identify the medium of traffic,   such as a website, email, or social media post.</li> <li>Identify the campaign: Tracardi can use the <code>utm_campaign</code> parameter to identify the specific marketing campaign   that generated the traffic.</li> <li>Track campaign performance: Tracardi can use UTM parameters to track the performance of marketing campaigns by   measuring metrics such as click-through rates, conversion rates, and revenue generated.</li> </ul> <p>To use UTM parameters with Tracardi, you can simply add them to the URLs that you are using to track your marketing campaigns. For example, the following URL includes UTM parameters for a Facebook ad campaign:</p> <pre><code>https://www.example.com/product?utm_source=facebook&amp;utm_medium=cpc&amp;utm_campaign=summer-sale\n</code></pre> <p>When a user clicks on a URL with UTM parameters, Tracardi captures those parameters and associates them with the user's session. This means that even if the user subsequently clicks on URLs without UTM parameters, their interactions will still be attributed to the original UTM source. This is because Tracardi maintains the UTM parameters throughout the user's session.</p> <p>Overall, UTM parameters are a powerful tool that can be used to track marketing campaigns and gain valuable insights into their performance. Tracardi can effectively use UTM parameters to track traffic, identify sources and mediums, measure campaign performance, and optimize marketing efforts.</p>"},{"location":"qa/how_tracardi_creates_session_id/","title":"How Tracardi creates session ID?","text":"<p>Tracardi does not create a session ID by default; it is the responsibility of the client to generate the session ID. Tracardi assumes that the session remains the same as long as the session ID does not change. However, if Tracardi detects that the session ID is insecure\u2014such as being too short or easily guessable\u2014the system may intervene by generating a secure session ID server-side or by refusing to collect the event associated with the insecure ID.</p>"},{"location":"qa/how_tracardi_is_upgraded/","title":"How Tracardi is upgraded?","text":"<p>Tracardi upgrades are categorized into two types: minor upgrades and major upgrades.</p> <p>Minor Upgrades: Minor upgrades do not involve any changes in the underlying database structure. These upgrades are indicated by a change in the last number of the version. For example, upgrading from version 0.8.1.x to version 0.8.1.y would be considered a minor upgrade. Minor upgrades do not require data migration and can be performed simply by upgrading the Docker tag to the new version. The system will continue to work as it did before the upgrade.</p> <p>Major Upgrades: Major upgrades, on the other hand, involve changes in the database structure. These upgrades are indicated by a change in a number other than the last one in the version. For example, upgrading from version 0.8.0 to version 0.8.1 would be considered a major upgrade. Major upgrades typically require data migration or data schema updates. In Tracardi, data migration is performed using Elasticsearch's reindexing process. This involves running two copies of the system with separate sets of indices: one with the old version and one with the new version. Once the migration is complete, the Docker tag can be upgraded, and the system will automatically switch to the new version. After a period of time, the old version's data can be safely deleted.</p> <p>Tracardi provides migration scripts for all major versions, allowing for smooth upgrades. However, it's important to note that these scripts are only available from one version to the next. Skipping versions is not supported, and custom scripts may require additional effort and commercial services. It is recommended to follow the upgrade path version by version to ensure proper data migration and system stability.</p> <p>If you are running a multi-tenant instance of Tracardi, the upgrade process will be applied to all tenants simultaneously. This means that when performing an upgrade, the changes will be applied uniformly across all the tenants in the system.</p> <p>In the case of a major upgrade, where data structure changes are involved, it is important to note that the migration process will require migrating the data for all tenants. This ensures that the entire system is up-to-date and consistent with the new version. The data migration process, must be performed for all tenants to ensure that their data aligns with the updated database structure.</p> <p>By applying the major upgrade to all tenants and performing the necessary data migration, the system can maintain data integrity.</p>"},{"location":"qa/how_tracardi_loads_profile/","title":"How tracardi loads profile","text":"<p>Tracardi utilizes ID to identify profiles, with each profile having a unique identifier. When there is only one profile per user, loading is performed through a simple query that matches the ID to the given ID. However, since Tracardi gathers data from multiple sources and channels, passing the product ID to each of them may not always be feasible. Hence, during the initial data collection phase when the user is anonymous, multiple profiles belonging to the same user are stored in Tracardi. When linking profiles, all profile IDs are copied to the <code>IDS</code> field, and loading is executed by checking whether the given ID corresponds to any of the IDs stored in the <code>ids</code> field. Despite having an <code>ID</code> field, the possibility of outdated IDs on certain devices necessitates the use of the <code>ids</code> field during loading. This approach enables Tracardi to merge profiles from external systems by simply adding the external system's profile ID to the <code>ids</code> field, which can then be used to load the profile.</p> Example of profile data<pre><code>{\n  \"id\": \"22082393-4b65-4add-a2e1-7a6982a79d0d\",\n  \"ids\": [\n    \"22082393-4b65-4add-a2e1-7a6982a79d0d\",\n    \"79d07a66-a2e1-4a44-5b65-22082393a2e1\"\n  ],\n  ...\n}\n</code></pre>"},{"location":"qa/how_tracardi_records_vistits/","title":"How tracardi calculate the visits","text":"<p>Tracardi calculates visits based on the concept of a session. A session is identified by a session ID, which is typically a randomly generated number such as a UUID4. The session ID is used to track a user's activity and determine the duration of their visit.</p> <p>Tracardi calculates visits based on the continuity of the session ID. As long as the session ID remains the same, Tracardi considers it to be part of the same visit.</p> <p>Let's consider an example with 10 events. The first three events have a session ID of 1, the next five events have a session ID of 2, and the remaining events have a session ID of 3. In this case, Tracardi would interpret this as three separate visits because there are three distinct session IDs.</p> <p>However, it is also possible to append events to a previous visit by sending them with the same session ID as before. This allows for the extension of a visit beyond the initial set of events.</p> <p>In the case of web data collection, Tracardi relies on the session ID stored in a cookie. When a user opens a web page, Tracardi's JavaScript code creates a session and saves the session ID in a cookie. As long as the user continues browsing the website without closing their browser, the same session ID is used and associated with each event generated by the user's actions. Tracardi considers this continuous stream of events with the same session ID as a single visit. If the user closes their browser, the cookie is deleted, indicating the end of the session. When the user visits the website again, a new session ID is generated, and a new visit begins.</p> <p>For data collected from other sources, such as mobile apps, the definition of a visit may vary. In the mobile app context, a visit can start when the user opens the app and ends when the user closes it. To track visits in this scenario, the mobile app needs to generate a session ID when the app starts and include the same session ID in every event sent to Tracardi. Tracardi monitors session changes and increments the visit counter accordingly.</p> <p>In cases where data is collected from an external system or data source where we are not so sure when session starts or ends, developers can define a session based on the data that exists in the external system. For example, they can use a visit ID or device ID as a session identifier. If no specific identifier is available, developers can define a session as a fixed time period, such as 15 minutes, 10 events, etc. or choose to include all events in one session. Then generate one UUID4 session ID and keep it the same for all events.</p> <p>Overall, Tracardi allows developers to define how long a visit lasts by controlling the session ID and determining when to start and end a session based on the specific data source, whether it's a web page or a mobile app.</p>"},{"location":"qa/how_tracardi_segments_profiles/","title":"How tracardi segments profiles","text":"<p>Tracardi retrieves profiles for segmentation depends on the type of segmentation being executed. For time-based segmentations, such as identifying profiles that have engaged more than a month ago, Tracardi must check every profile because the qualifying criteria (time in this case) are continually changing. There's no way to pre-filter profiles for this kind of segmentation. Workflow segmentation is this kind of segmentation type.</p> <p>For property-based segmentations, Tracardi fetches only those profiles that have had recent changes, as these changes might cause a profile to shift from one segment to another. Additionally, Tracardi can perform on-event segmentation within automation workflows, where segments can be added dynamically based on events such as a purchase, which might change a profile\u2019s segment categorization. For this use-case use \"add segment\" action within tracardi automation workflow. </p>"},{"location":"qa/how_tracardi_tracks_customers/","title":"How tracardi tracks customers?","text":"<p>Tracardi tracks customers by collecting and unifying data from various sources, including:</p> <ul> <li>Websites: Tracardi can track customer behavior on websites using cookies and other tracking technologies. This   data can include the pages a customer visited, the products they viewed, and the actions they took.</li> <li>Mobile apps: Tracardi can track customer behavior in mobile apps using SDKs. This data can include the screens a   customer viewed, the actions they took, and their location.</li> <li>Social media: Tracardi can track customer interactions on social media platforms using APIs. This data can include   the posts a customer liked, the comments they made, and the groups they joined.</li> <li>Email: Tracardi can track customer interactions with email campaigns using email tracking pixels. This data can   include whether a customer opened an email, clicked on a link, or unsubscribed from a list.</li> </ul> <p>Once Tracardi has collected data from these sources, it unifies the data into a single customer profile. This profile includes all of the information that Tracardi knows about a particular customer, such as their name, email address, phone number, purchase history, and interests.</p> <p>Tracardi uses this customer data to track customers in several ways:</p> <ul> <li>Customer journey tracking: Tracardi can track the customer journey across different channels, such as websites,   mobile apps, and social media. This allows businesses to see how customers interact with their brand and identify   opportunities to improve the customer experience.</li> <li>Customer segmentation: Tracardi can segment customers into groups based on their demographics, interests, and   behavior. This allows businesses to target their marketing campaigns more effectively.</li> <li>Customer attribution: Tracardi can attribute sales to different marketing channels, such as email, social media,   and paid advertising. This allows businesses to see which marketing channels are most effective and allocate their   marketing budget accordingly.</li> </ul> <p>Tracardi can also be used to track customers offline, such as when they visit a physical store or make a purchase over the phone. This can be done by linking customer IDs to offline data, such as purchase receipts or loyalty card numbers.</p> <p>By tracking customers, businesses can gain a deeper understanding of their customers' needs and wants. This information can be used to improve customer service, develop new products and services, and create more effective marketing campaigns.</p>"},{"location":"qa/how_tracardi_uses_entities/","title":"What are entities and how can I use them.","text":"<p>In Tracardi, entity is concept used for storing and managing data. Tracardi maintains a separate index, which can be considered as a store or table, specifically designed to hold information about entities. Each entity has a unique type and associated data.</p> <p>The entity index in Tracardi allows you to store various types of data, depending on your requirements. For example, you can store information about email, products, or any other relevant data related to your business or application.</p> <p>Tracardi provides plugins called \"Save Entity\" and \"Load Entity\" that enable you to interact with the entity index within your workflows. These plugins are available in the commercial version of Tracardi. With the \"Save Entity\" plugin, you can save or update data for a specific entity in the entity index. The \"Load Entity\" plugin allows you to retrieve the stored data of an entity from the index.</p> <p>Each entity is related to profile.</p> <p>It's worth mentioning that if you are using the open-source version of Tracardi and require similar functionality, you can utilize the \"profile@aux\" attribute to store data. While it may not provide the same dedicated entity index as in the commercial version, the \"profile@aux\" attribute serves as a convenient way to store additional information within a user's profile. You can leverage this attribute to store and retrieve data similar to how entities work in the commercial version.</p>"},{"location":"qa/how_tracardi_uses_entities/#difference-between-entities-and-aux-property","title":"Difference between Entities and Aux Property","text":"<p>Entities and aux properties in Tracardi have distinct characteristics in terms of their relationship and usage:</p> <ul> <li>Relationship: Entities in Tracardi can be associated with a one-to-many relationship. This means that a single   profile can have multiple entities associated with it. For instance, you can have an entity called \"Purchase\"   associated with a specific user profile, and that user profile can have multiple purchase entities linked to it. This   allows for storing and managing collections of related data under a single profile.</li> </ul> <p>On the other hand, the aux property in Tracardi has a one-to-one relationship. Each profile can have its own aux   property, which serves as an additional attribute associated with that specific profile. The aux property allows you   to store supplementary information related to the profile, but it is limited to a single set of data per profile.</p> <ul> <li>Usage: Entities are commonly used when dealing with data that has a common theme or relationship but varies in   quantity. For example, entities can be utilized to store various actions, or interactions related to a customer, where   each entity represents a specific instance of that action (e.g. Purchase, Sent email).</li> </ul> <p>Conversely, aux properties are typically employed to store specific details or metadata about a profile that are   unique to that individual. This can include preferences, additional user information, or any other supplementary data   that is directly associated with the profile itself.</p> <p>In summary, the key distinction between entities and aux properties lies in their relationship and usage. Entities can establish a one-to-many relationship between profiles and associated data, while aux properties maintain a one-to-one relationship, providing an additional attribute specific to each profile. Understanding this difference allows for better organization and management of data within Tracardi based on your specific needs.</p>"},{"location":"qa/how_tracardi_uses_entities/#entities-as-an-extension-of-events","title":"Entities as an Extension of Events","text":"<p>It's important to note that the profile is also in a one-to-many relationship with events. This means that a single profile can have multiple events associated with it. Each event represents a specific action or occurrence related to the profile, such as a user interaction, a purchase, or any other significant event that you want to track.</p> <p>Since events capture a wide range of activities, entities can be seen as an extension of events. Entities provide a way to store additional data that may not be directly tied to a specific event but is still relevant to the profile. In other words, entities offer a mechanism to store information that doesn't fit neatly into the event structure or you do not want to keep this information in the event itself.</p> <p>For example, let's consider a scenario where you want to track purchases made by users. Each purchase can be represented as an event, and the associated data, such as the item purchased, the price, and the transaction details, can be stored within the event itself.</p> <p>However, there might be additional information related to the purchase that doesn't fit well within the event structure. This could include details like: if the confirmation email was sent by the workflow, or additional notes specific to that purchase. Instead of trying to raise another event, you can utilize entities to store these supplementary details and retrieve them when needed. </p>"},{"location":"qa/how_workflow_is_initated/","title":"How workflow works. What are the steps during workflow execution?","text":"<p>In the context of Tracardi, the event processing within a workflow follows a structured sequence and involves several key steps:</p> <p>Workflow Internal State:</p> <ul> <li>Event: Events serve as triggers for workflow actions. An event carries crucial information, including a \" profile_id\" or a \"session_id,\" the event type, and its properties.</li> <li>Event Loading: Upon receiving an event, the system retrieves the current profile using the provided identifier (profile_id or session_id), ensuring the system recognizes which profile is associated with the event.</li> <li>Assignment to Nodes: The retrieved profile, along with session and event data, is assigned to relevant nodes within the workflow. This establishes an internal state for the workflow, referenced in each action node. As the workflow progresses, this internal state can evolve.</li> <li>Dynamic State: During the execution of the workflow, the state of the event, profile, and session can change as various actions are performed. This reflects the dynamic nature of workflows, where information associated with the profile, session, and event can be modified based on the sequence of actions.</li> <li>Persistent Storage: Notably, when the workflow concludes, any modifications made to the profile, session, and event are saved back into the system. This ensures that the updated information is retained for future use or processing.</li> </ul>"},{"location":"qa/i_can_not_see_my_widget/","title":"I use commercial version and I do not see my widget","text":"<p>If you're using the commercial version of Tracardi and don't see your widget, it's important to understand how it handles event processing. Commercial Tracardi typically processes events asynchronously, which means workflows run in the background and the initial server response doesn't include workflow-defined details like widgets. This differs from the open-source version, which processes events synchronously and requires the server to complete event processing before sending a response.</p> <p>To see your widget, you may need to adjust the processing mode from asynchronous to synchronous. This change is necessary if you need immediate feedback, such as data or a widget display. To switch to synchronous processing, set the <code>async</code> option to <code>false</code> in your tracking configuration:</p> <pre><code>window.tracker.track(&lt;event-type&gt;, &lt;properties&gt;, { \"async\": false });\n</code></pre> <p>Add this in the options parameter of your tracking call to modify how events are handled.</p>"},{"location":"qa/i_get_error_api_invaild_from_mailchimp/","title":"I get error API Invalid from Mailchimp","text":"<p>If you are receiving an \"API Invalid\" error from Mailchimp, it usually indicates that the API key you provided is incorrect or invalid. Here is a step-by-step guide to obtaining the correct API keys for Mailchimp:</p> <ul> <li>Log in to your Mailchimp account.</li> <li>Click on your account icon in the top-right corner.</li> <li>Select \"Profile\".</li> <li>In the \"Profile\" section, choose \"Extras\" and then \"API keys\".</li> <li>To add email addresses to a Mailchimp audience, you need the Mailchimp API key. Click on \"Create A Key\" under the \"Your API keys\" section and generate a new API key.</li> <li>To send one-to-one transactional emails, you need the Mandrill API key. Click on \"Add a Mandrill API Key\" and follow the instructions. Note that you will need to verify your domain with Mandrill to send one-to-one emails.</li> <li>Once you have generated the API keys, copy the respective key (Mailchimp API or Mandrill API) and paste it into the Token field in the Tracardi Form or your Mailchimp integration settings in Tracardi.</li> </ul> <p>For more information on generating, disabling, and deleting API keys in Mailchimp, you can refer to the official Mailchimp documentation at https://mailchimp.com/help/about-api-keys/.</p> <p>Please keep in mind that sending one-to-one emails using Mandrill requires domain verification. You can find additional guidance on domain verification and configuring your DNS in the following Mailchimp documentation links:</p> <ul> <li>Mandrill Authentication and Delivery - Authentication</li> <li>Mandrill Authentication and Delivery - Configure Your DNS</li> </ul> <p>By following these instructions and ensuring the correct API key is used, you should be able to resolve the \"API Invalid\" error and successfully connect Tracardi with Mailchimp.</p>"},{"location":"qa/is_there_a_way_to_disable_pulsar_in_commercial_tracardi/","title":"Is there a way to disable Pulsar in Commercial Tracardi?","text":"<p>Yes, but it is not advisable. Disabling Pulsar will make Tracardi significantly less scalable, and all save operations will be performed in the foreground rather than being pushed to the background worker.</p>"},{"location":"qa/is_there_a_way_to_disable_pulsar_in_commercial_tracardi/#how-to-disable-pulsar","title":"How to Disable Pulsar","text":"<p>To disable Pulsar, set <code>PULSAR_DISABLE</code> to <code>\"yes\"</code> or <code>\"true\"</code>. Using a Helm chart with this setting will stop the background worker and execute all tasks with the current API event loop. This change will slow down all track requests.</p>"},{"location":"qa/is_there_a_way_to_disable_pulsar_in_commercial_tracardi/#when-to-disable-pulsar","title":"When to Disable Pulsar","text":"<p>It may be beneficial to disable Pulsar while debugging Tracardi or when there is minimal traffic on your website. In such cases, to avoid maintaining the Pulsar instance, you can opt for a less performant Tracardi collector.</p>"},{"location":"qa/live_segmentation_does_not_change_profile/","title":"My live segmentation does not change profile traits?","text":"<p>Live segmentation process does not update profile segments, traits, etc. unless there is a profile update in the workflow. In other words, if the segment of a particular profile is changed during the live segmentation run, the profile will not be updated unless you use update profile action.</p> <p>Live segmentation process is designed to periodically evaluate and categorize profiles based on certain criteria defined in segmentation workflow. </p>"},{"location":"qa/major_os_competitors/","title":"What are major open-source  competitors to Tracardi?","text":"<p>When it comes to open-source competitors in the customer data platform (CDP) space, there are a few notable options that provide similar functionality to Tracardi. Here are some major open-source competitors to Tracardi:</p> <ol> <li> <p>Apache Unomi: Apache Unomi is an open-source CDP that allows businesses to collect, store, and manage customer data.    It provides personalization and segmentation capabilities to deliver tailored customer experiences.</p> </li> <li> <p>RudderStack: RudderStack is an open-source customer data pipeline platform that helps businesses collect, route, and    process customer event data. It enables data integration and synchronization with various third-party tools and data    warehouses.</p> </li> <li> <p>CDP4j: CDP4j is an open-source CDP library written in Java. It provides a set of tools and APIs to build a custom CDP    solution, allowing businesses to manage and utilize customer data according to their specific requirements.</p> </li> <li> <p>Snowplow: Snowplow is an open-source event analytics platform that can be used as a foundation for building a CDP. It    allows businesses to capture, process, and analyze customer event data in real-time, enabling personalized marketing    efforts.</p> </li> </ol> <p>These open-source alternatives provide businesses with flexibility and customization options. However, it's important to note that open-source solutions may require more technical expertise and effort for setup, customization, and maintenance compared to commercial options like Tracardi. It's advisable to evaluate these alternatives based on your specific requirements and the level of support and community activity available for each project.</p>"},{"location":"qa/miggration_issues/","title":"My data was not migrated how can I debug what happened?","text":"<p>If you use docker on you local machine check the log of upgrade worker..</p> <p>To do that, you can follow these steps:</p> <ol> <li> <p>Identify the Container ID or Name:    First, you need to find out the ID or the name of the Docker container running the upgrade worker. You can list all    running containers by executing:    <pre><code>docker container ls\n</code></pre>    This command will show you a list of all active containers, including their IDs, names, and other details.</p> </li> <li> <p>View Logs:    Once you have identified the container ID or name of the upgrade worker, you can view its logs using the following    command:    <pre><code>docker logs [CONTAINER_ID_OR_NAME]\n</code></pre>    Replace <code>[CONTAINER_ID_OR_NAME]</code> with the actual ID or name of your upgrade worker container.</p> </li> </ol> <p>For example, if the container ID is <code>abc123def456</code>, the command would be:    <pre><code>docker logs abc123def456\n</code></pre></p> <ol> <li> <p>Tail Logs in Real-Time:    If you want to continuously monitor the logs as new log entries are created, you can use the <code>-f</code> flag to \"follow\"    the log output:    <pre><code>docker logs -f [CONTAINER_ID_OR_NAME]\n</code></pre></p> </li> <li> <p>Filter Logs:    If you're looking for specific log entries or want to filter the logs, you might need to use additional command-line    tools like <code>grep</code>. For example:    <pre><code>docker logs [CONTAINER_ID_OR_NAME] | grep \"some specific log text\"\n</code></pre></p> </li> <li> <p>Checking Past Logs:    Docker logs show the output from the container since it was started. If the container has been restarted, you might    not see older logs. In such cases, it's important to have a logging solution in place that archives logs for future    analysis.</p> </li> </ol> <p>These steps should help you access and analyze the logs of your upgrade worker in Docker, providing insights into its operation and any issues it might be encountering.</p>"},{"location":"qa/miggration_issues/#why-my-data-was-not-migrated","title":"Why my data was not migrated?","text":"<p>We conduct tests on various data sets during migration, but there might be instances where your profiles and events are structured in ways we didn't anticipate. In such cases, the migration mappings might not function as expected. To identify any discrepancies, please review the upgrade worker logs to determine which fields are not aligning correctly. After identifying these issues, kindly report them to us for further assistance.</p>"},{"location":"qa/multiple_profile_ids/","title":"I have multiple profile IDs in the profile.ids field. What could be the reason for this?","text":"<p>The presence of multiple profile IDs in the profile.ids field typically occurs when the \"identification\" event is triggered multiple times without including the previously assigned profile ID. Each time the system receives an  \"identification\" event without a specified profile ID, it generates a new one. The newly generated profile ID is then added to the list of profile IDs within the profile.ids field during merging. </p> <p>This behavior is intentional and designed to track all previous profile IDs associated with a user, ensuring a complete history of the user's profile as it evolves. It's a safeguard to maintain the continuity of the user's data, even if the profile ID changes over time.</p> <p>To prevent the accumulation of multiple profile IDs in the profile.ids field, ensure that every event you send to Tracardi includes the current profile ID. By consistently passing the correct profile ID with each event, you help Tracardi recognize and maintain a single, consistent profile ID, avoiding the creation of additional profile IDs.</p> <p>This is the correct and expected behavior, and adhering to this practice will help maintain the integrity of your profile data.</p>"},{"location":"qa/my_javascript_is_not_sending_events/","title":"My javascript is not sending events","text":""},{"location":"qa/my_javascript_is_not_sending_events/#my-javascript-is-not-sending-events","title":"My javascript is not sending events","text":"<p>If your JavaScript is not sending events, there could be several reasons for this issue:</p> <ul> <li> <p>Placement of the JavaScript: Ensure that the JavaScript code is placed correctly on the page. The configuration   part should be placed first, followed by the script for event sending. Check if the code is properly integrated within   the HTML structure of the page.</p> </li> <li> <p>Incorrect API address: Verify that the API address in your JavaScript code is correct and points to your Tracardi   server. If the API address is incorrect, the events will be sent to the wrong destination.</p> </li> <li> <p>Incorrect source ID: Make sure that the source ID specified in the JavaScript code is correct and matches the   registered event sources in Tracardi. If the source ID is incorrect, Tracardi will not recognize the events coming   from your JavaScript code.</p> </li> <li> <p>Disabled event source: Check if the event source specified in your script is enabled in Tracardi. If the event source   is disabled, the events will not be processed or stored by Tracardi.</p> </li> <li> <p>Transitional event source: If the events are being sent but not saved, it is possible that the event source is set to   be transitional. This means that the events are considered ephemeral and are processed without being permanently   stored. Review the settings of the event source to determine if this is the case.</p> </li> </ul>"},{"location":"qa/my_workflow_is_not_working/","title":"My workflow is not working","text":"<p>If your workflow is not working, there may be several reasons for it:</p> <ol> <li> <p>There might be an error in the workflow itself. To address this, it is recommended to debug the workflow. You can    start by selecting an event that is not working and trace its path through the workflow. Events that fail to process    often have tags like \"error\" or \"warning\" associated with them.</p> </li> <li> <p>Ensure that your workflow is connected to the correct event type. For instance, if you are collecting page view    events, you should route these events to the appropriate workflow. You can configure this in the routing section,    which can usually be found in the workflow editor under buttons like \"rules\" or \"routing.\"</p> </li> <li> <p>Check if you have placed the necessary JavaScript code correctly on your webpage, or if the source ID of the    JavaScript is incorrect. If the JavaScript code is not properly implemented or the source ID is incorrect, events    will not be visible in the system and consequently won't be processed.</p> </li> </ol>"},{"location":"qa/on_which_fields.can_i_merge/","title":"Which fields can be used to merge profile?","text":"<p>In the 'Merge Profiles' processing node, you can use any profile field for merging in version 0.8.1 of the software. In commercial version merging should be done with Identification Points. Usually fields that are used for merging as of version 0.8.2 are:</p> <ul> <li>profile@data.contact.email.main</li> <li>profile@data.contact.phone.main</li> <li>profile@data.contact.identifier.id</li> <li>profile@data.contact.identifier.passport</li> <li>etc.</li> </ul>"},{"location":"qa/pricing_comparation/","title":"How tracardi compares to other platforms in terms of pricing schemas","text":"<p>In terms of pricing schemas, here's a comparison of Tracardi with the other platforms:</p> <ol> <li> <p>Tracardi:</p> <ul> <li>Pricing: Tracardi has an open-source version that is free to use on-premises. The commercial version follows a   fixed monthly payment regardless of the number of events processed or stored data. This pricing structure offers   predictable costs without dependencies on data volume.</li> </ul> </li> <li> <p>Zapier:</p> <ul> <li>Pricing: Zapier offers a tiered pricing model based on usage and features. They have a free plan with limited   tasks per month. Paid plans start at around $20 per month and increase based on the number of zaps (automations)   and frequency of execution. The pricing scales with the level of usage and functionality needed.</li> </ul> </li> <li> <p>Segment.com:</p> <ul> <li>Pricing: Segment.com's pricing is based on factors such as data volume, integrations used, and additional features   required. They provide a free tier for low data volumes. Paid plans typically start at several hundred dollars per   month and can increase based on usage and specific requirements. The pricing aligns with the level of data   tracking and integrations needed.</li> </ul> </li> <li> <p>Adobe Experience Cloud:</p> <ul> <li>Pricing: Adobe Experience Cloud offers enterprise-level marketing and customer experience solutions. Pricing is   customized and tailored to the specific needs of each enterprise. The pricing structure varies depending on the   scope of implementation, modules used, data volume, and level of support required. Contacting Adobe directly is   recommended for detailed pricing information.</li> </ul> </li> <li> <p>Rudderstack:</p> <ul> <li>Pricing: Rudderstack is an open-source customer data platform (CDP) with commercial support and additional   features. Pricing is based on factors such as data volume processed, the number of sources and destinations, and   the level of support required. They offer both self-hosted and cloud-hosted options, with pricing plans starting   at a few hundred dollars per month.</li> </ul> </li> </ol> <p>These platforms have different pricing models, ranging from open-source, fixed monthly payments, usage-based tiers, and customized enterprise-level pricing. It's important to evaluate your specific requirements and consider the pricing structure that aligns best with your needs and budget.</p>"},{"location":"qa/production_configuration/","title":"What parameters should I tweak for production environment","text":""},{"location":"qa/production_configuration/#optimizing-tracardi-for-production-environments","title":"Optimizing Tracardi for Production Environments","text":"<p>Tracardi is a powerful data platform capable of handling large volumes of event data and providing valuable insights into user behavior. However, to ensure optimal performance and scalability in production environments, it's crucial to carefully configure and tweak various parameters. This guide outlines the key considerations for optimizing Tracardi in production settings.</p>"},{"location":"qa/production_configuration/#event-volume-and-traffic-spikes","title":"Event Volume and Traffic Spikes","text":"<p>Queueing:</p> <p>In scenarios with high event volume or unpredictable traffic patterns, implementing a queueing system like Apache Kafka or RabbitMQ is essential. This prevents Tracardi from being overwhelmed during traffic surges, ensuring smooth event processing and system stability.</p> <p>Batching:</p> <p>Consider batching events before sending them to Tracardi. Tracardi can efficiently process events in batches when they are grouped by profile. This reduces the number of individual event transmissions, improving overall throughput.</p>"},{"location":"qa/production_configuration/#event-size-and-efficiency","title":"Event Size and Efficiency","text":"<p>Payload Optimization:</p> <p>Minimize event payloads by removing unnecessary or redundant data. Smaller payloads reduce resource consumption, enhance processing speed, and minimize storage requirements.</p>"},{"location":"qa/production_configuration/#data-storage-and-retention","title":"Data Storage and Retention","text":"<p>Retention Policy:</p> <p>Establish a data retention policy aligned with your specific needs. Longer retention periods increase query complexity, storage requirements, and data management overhead.</p> <p>Elasticsearch Configuration:</p> <p>Configure Elasticsearch to utilize hot and cold nodes for data storage. Hot nodes should store frequently accessed data, while cold nodes retain older, less frequently accessed data. Minimize querying cold nodes unless absolutely necessary.</p> <p>Index Granularity:</p> <p>Balance index granularity between performance and flexibility. Monthly indices offer more granular data storage but may impact query performance. Tracardi's configuration options allow you to fine-tune index granularity based on your specific requirements.</p>"},{"location":"qa/production_configuration/#resource-allocation-and-scalability","title":"Resource Allocation and Scalability","text":"<p>Hardware Resources:</p> <p>Allocate sufficient CPU cores, RAM, and disk space to handle expected event volumes and processing demands. Pay particular attention to Elasticsearch's shard and replica configuration, as these settings cannot be dynamically changed.</p> <p>Distributed Deployment:</p> <p>Consider deploying Tracardi in a distributed manner to scale horizontally and handle increasing workloads. Tracardi is a distributed system that relies on Elasticsearch, Redis, Apache Pulsar, and MySQL. Scale these components proportionally to your traffic volume.</p> <p>Logging:</p> <p>Minimize unnecessary logging. Tracardi can generate extensive logs, including performance logs, profile field history, debugging logs, and system login logs. Configure logging to capture only essential information. For instance, when logging profile field changes, consider retaining them for a shorter duration.</p>"},{"location":"qa/production_configuration/#caching","title":"Caching","text":"<p>In-Memory Caching:</p> <p>Each Tracardi worker maintains in-memory caches to store frequently accessed data, reducing the need for repeated queries.</p>"},{"location":"qa/production_configuration/#monitoring-and-performance-optimization","title":"Monitoring and Performance Optimization","text":"<p>Continuous Monitoring:</p> <p>Continuously monitor Tracardi's performance metrics, including event throughput, resource utilization, and query latency. Identify and address any performance bottlenecks promptly.</p> <p>Performance Tuning:</p> <p>Implement performance tuning techniques, such as caching, batch processing, and code optimization, to enhance efficiency and reduce processing overhead.</p>"},{"location":"qa/profile_event_structure/","title":"Current version has a different profile structure than the previous version. Who sets this structure? Does it come out of the box, or can it be administered?","text":"<p>Structure of profile comes predefined in the system. All the custom fields are kept in profile traits, or event properties and traits. Elasticsearch can dynamically add new fields to traits and properties. </p>"},{"location":"qa/profile_merging_qa/","title":"Do I need to keep copy data and merge profile actions in one workflow?","text":"<p>If you are using the \"Event to profile mapping\" feature, you typically wouldn't need the \"Copy data\" action in your workflow, as all the necessary data should already be available (mapping happens before workflow). This implies that  \"Copy data\" is more suitable for situations where you need conditional copying of data.</p> <p>We advise that if you opt to use \"Copy data,\" it should be kept in the same workflow as the \"Merge profile\" action. This recommendation is based on the lack of a guaranteed sequence in which separate workflows might run, which could lead to profiles being merged before the data is copied to them. Mapping data to a profile from an event is a preferable option, as this happens before the workflow starts.</p> <p>The best practice would be to:</p> <ol> <li>Use \"Event to profile mapping\" wherever possible to avoid the need for a separate \"Copy data\" action.</li> <li>If \"Copy data\" is necessary, include it in the same workflow as the \"Merge profile\" action to ensure proper    sequencing and avoid potential issues with data not being present at the time of merging.</li> </ol>"},{"location":"qa/resource_as_destination/","title":"Which resources in tracardi can be used to send data and be treated as data destinations.","text":"<p>As of version 0.8.2 you can use only the following resources to send dat to:</p> <ol> <li>REST API endpoint</li> <li>RabbitMQ</li> <li>Mautic</li> </ol> <p>In the context of Tracardi, a \"destination\" refers to a target location or service where processed data is sent or stored. </p>"},{"location":"qa/tenant_management_service_api/","title":"How to use tenant management service API.","text":""},{"location":"qa/tenant_management_service_api/#tenant-management-service-api-create-tenant","title":"Tenant Management Service API - Create Tenant","text":""},{"location":"qa/tenant_management_service_api/#endpoint-tenant","title":"Endpoint: /tenant","text":""},{"location":"qa/tenant_management_service_api/#description","title":"Description:","text":"<p>This API endpoint is used to create a new tenant in the tenant management service.</p>"},{"location":"qa/tenant_management_service_api/#parameters","title":"Parameters:","text":"<p>No parameters are required for this API.</p>"},{"location":"qa/tenant_management_service_api/#request-body","title":"Request Body:","text":"<p>The request body should contain the following JSON payload:</p> <pre><code>{\n  \"id\": \"string\",\n  \"created\": \"2023-07-07T10:45:39.793Z\",\n  \"name\": \"string\",\n  \"install_key\": \"string\",\n  \"email\": \"string\",\n  \"license_id\": \"string\"\n}\n</code></pre> <ul> <li>id (string): The unique identifier for the tenant.</li> <li>created (string): The timestamp indicating the creation time of the tenant.</li> <li>name (string): The name of the tenant.</li> <li>install_key (string): The installation token for the tenant.</li> <li>email (string): The email associated with the tenant.</li> <li>license_id (string): The license ID for the tenant.</li> </ul>"},{"location":"qa/tenant_management_service_api/#responses","title":"Responses:","text":""},{"location":"qa/tenant_management_service_api/#200-successful-response","title":"200 - Successful Response","text":"<p>The API call is successful.</p>"},{"location":"qa/tenant_management_service_api/#422-validation-error","title":"422 - Validation Error","text":"<p>Occurs when there is a validation error in the request payload.</p> <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\n        \"string\",\n        0\n      ],\n      \"msg\": \"string\",\n      \"type\": \"string\"\n    }\n  ]\n}\n</code></pre>"},{"location":"qa/two_users_on_one_computer/","title":"If my wife and I access a website from our home (same PC) and I create an account, how will the profile identification be managed? And if my wife creates an account shortly after, how will the separation of accesses and clicks between the different profiles be handled?","text":"<p>When two users share the same computer and access the same website, the management of profiles in Tracardi depends largely on how the client-side (browser and website) handles profile identification. Tracardi, being a server-side system, relies on the information provided by the client to distinguish between users. Here's a detailed explanation of how profile identification is managed in this scenario, along with the factors that influence the separation of accesses and clicks between different profiles.</p>"},{"location":"qa/two_users_on_one_computer/#understanding-client-side-profile-identification","title":"Understanding Client-Side Profile Identification","text":"<p>Profile identification begins on the client side, which includes the browser and the website's integration with Tracardi. The browser is responsible for maintaining a consistent Profile ID for each user. This Profile ID is stored in the browser's local storage or cookies and is sent to Tracardi with each interaction. Tracardi uses this ID to associate events with the correct user profile.</p>"},{"location":"qa/two_users_on_one_computer/#scenario-1-separate-user-accounts-on-the-computer","title":"Scenario 1: Separate User Accounts on the Computer","text":"<p>Description:</p> <ul> <li>You and your wife use separate user accounts (workspaces) on the same computer.</li> <li>Each user account has its own browser data, including cookies and local storage.</li> </ul> <p>Profile Management:</p> <ul> <li>Distinct Profile IDs: Since each user account maintains its own browser storage, the Profile IDs generated and   stored are separate.</li> <li>Accurate Tracking: Tracardi assigns unique profiles to each of you based on the distinct Profile IDs.</li> <li>Data Separation: All activities, accesses, clicks, and account information are correctly attributed to the   respective profiles.</li> </ul> <p>Outcome:</p> <ul> <li>Full Separation: This scenario ensures complete separation of user data. Tracardi can accurately distinguish   between you and your wife because the client-side Profile IDs are not shared.</li> <li>Reliable Analytics: Any analysis or personalization based on user behavior will be accurate and specific to each   individual.</li> </ul>"},{"location":"qa/two_users_on_one_computer/#scenario-2-shared-user-account-and-browser","title":"Scenario 2: Shared User Account and Browser","text":"<p>Description:</p> <ul> <li>You and your wife use the same user account on the computer and the same browser.</li> <li>The browser maintains a single set of cookies and local storage for both users.</li> </ul> <p>Profile Management Before Logging In:</p> <ul> <li>Shared Anonymous Profile: Initially, both of you share the same anonymous browsing profile since the browser uses   the same Profile ID for all users.</li> <li>Mixed Browsing History: All pre-login activities are recorded under this shared anonymous profile. Tracardi cannot   distinguish between users at this stage.</li> </ul> <p>When You Create an Account:</p> <ul> <li>Profile Association: Upon creating and logging into your account, the shared anonymous Profile ID becomes   associated with your user profile.</li> <li>Inherited Browsing History: All prior anonymous activities (which may include your wife's actions) are now linked   to your profile.</li> <li>Profile Enrichment: Your profile is enriched with the browsing history accumulated before login.</li> </ul> <p>When Your Wife Creates an Account Shortly After:</p> <p>There are two possible outcomes based on how the website handles Profile IDs during the login process.</p>"},{"location":"qa/two_users_on_one_computer/#outcome-1-profile-id-is-reset-upon-new-login","title":"Outcome 1: Profile ID is Reset Upon New Login","text":"<p>Client-Side Actions:</p> <ul> <li>Profile ID Reset: The website or browser resets the Profile ID when your wife logs into her account. This can be   achieved by clearing the existing Profile ID from local storage and generating a new one.</li> <li>New Session Initiation: A new Session ID should also be generated to track activities within the new session.</li> </ul> <p>Tracardi's Response:</p> <ul> <li>New Profile Creation: Tracardi creates a new profile for your wife based on the new Profile ID.</li> <li>Data Separation: Her activities moving forward are associated exclusively with her profile.</li> <li>No Inherited History: Since the Profile ID was reset, she does not inherit the anonymous browsing history that was   previously linked to your profile.</li> </ul> <p>Outcome:</p> <ul> <li>Effective Separation: This approach ensures that both profiles remain distinct, and each user's activities are   accurately tracked.</li> <li>Accurate Attribution: Accesses, clicks, and other interactions are correctly attributed to the respective profiles   from the point of login onwards.</li> </ul>"},{"location":"qa/two_users_on_one_computer/#outcome-2-profile-id-is-retained","title":"Outcome 2: Profile ID is Retained","text":"<p>Client-Side Actions:</p> <ul> <li>Profile ID Unchanged: The browser retains the existing Profile ID when your wife logs into her account.</li> <li>Shared Profile Continuation: Both your activities and your wife's continue to be associated with the same Profile   ID.</li> </ul> <p>Tracardi's Response:</p> <ul> <li>Merged Profiles: Tracardi does not create a new profile since the Profile ID hasn't changed. Instead, it   associates your wife's account information with the existing profile.</li> <li>Combined Data: All subsequent activities from both users are merged into a single profile.</li> <li>Household Representation: The profile effectively represents a household rather than individual users.</li> </ul> <p>Outcome:</p> <ul> <li>Data Mixing: This results in a mixed dataset where activities from both users are combined.</li> <li>Less Accurate Tracking: Personalization and analytics become less accurate, as Tracardi cannot distinguish between   the two users' behaviors.</li> </ul>"},{"location":"qa/two_users_on_one_computer/#challenges-and-considerations","title":"Challenges and Considerations","text":"<ul> <li>Client-Side Responsibility: The management of Profile IDs is primarily the responsibility of the client (browser   and website). Tracardi cannot independently generate separate profiles without distinct Profile IDs.</li> <li>Anonymous Browsing History: Before any user logs in, all activities are anonymous and associated with the same   Profile ID in a shared browser. Separating this history is technically challenging without individual identifiers.</li> <li>User Behavior: In practice, users may not log out after using a shared computer, leading to data mixing. Automatic   sign-outs or enforced logins can mitigate this issue.</li> </ul>"},{"location":"qa/two_users_on_one_computer/#strategies-for-managing-profile-separation","title":"Strategies for Managing Profile Separation","text":"<p>To ensure accurate separation of accesses and clicks between different profiles on a shared computer, consider the following strategies:</p>"},{"location":"qa/two_users_on_one_computer/#1-implement-client-side-profile-id-resetting","title":"1. Implement Client-Side Profile ID Resetting","text":"<ul> <li> <p>On Logout:</p> <ul> <li>Clear the Profile ID from the browser's local storage when a user logs out.</li> <li>Ensure that the next user will receive a new Profile ID upon accessing the website. This mimics system account behaviour.</li> </ul> </li> <li> <p>On Login:</p> <ul> <li>Assign correct Profile ID whenever a user logs in. If User profile ID is unknown generate new one and send user   e-mail in payload. Tracardi will use it to merge the profile ID with previous profile history.</li> <li>Send this new Profile ID to Tracardi with each event.</li> </ul> </li> </ul>"},{"location":"qa/two_users_on_one_computer/#2-enforce-user-authentication","title":"2. Enforce User Authentication","text":"<ul> <li> <p>Require Login:</p> <ul> <li>Design the website to require users to log in before accessing personalized content.</li> <li>This ensures that each session is associated with a specific user from the start.</li> </ul> </li> <li> <p>Automatic Sign-Out:</p> <ul> <li>Implement session timeouts that automatically log users out after a period of inactivity.</li> <li>This prevents subsequent users from inadvertently using the same session and Profile ID.</li> </ul> </li> </ul>"},{"location":"qa/two_users_on_one_computer/#3-educate-users","title":"3. Educate Users","text":"<ul> <li>User Awareness:<ul> <li>Inform users about the importance of logging out on shared devices.</li> <li>Provide prompts or reminders to log out after completing their activities.</li> </ul> </li> </ul>"},{"location":"qa/two_users_on_one_computer/#4-integration-considerations","title":"4. Integration Considerations","text":"<ul> <li> <p>Synchronous vs. Asynchronous Tracking:</p> <ul> <li>Synchronous Tracking: Allows immediate communication between the client and Tracardi, facilitating Profile ID   updates.</li> <li>Asynchronous Tracking: Uses intermediaries like message queues (e.g., Kafka), which may delay or prevent   Profile ID updates in real-time.</li> </ul> </li> <li> <p>Recommendation:</p> <ul> <li>Opt for synchronous tracking when accurate profile separation is critical.</li> <li>Ensure that the integration method supports two-way communication for Profile ID management.</li> </ul> </li> </ul>"},{"location":"qa/two_users_on_one_computer/#conclusion","title":"Conclusion","text":"<p>In a shared computer environment, the accurate management of profiles in Tracardi hinges on the client-side handling of Profile IDs. To prevent data mixing and ensure that accesses and clicks are correctly attributed to the right user:</p> <ul> <li>Website Integration: The website should be designed to reset the Profile ID upon user logout or new login.</li> <li>User Practices: Users should be encouraged to log out after each session, especially on shared devices.</li> <li>Session Management: Implement automatic logout features and require authentication for access to personalized   content.</li> <li>Technical Integration: Choose synchronous tracking methods that allow real-time Profile ID updates between the   client and Tracardi.</li> </ul> <p>By implementing these strategies, Tracardi can more effectively distinguish between you and your wife when accessing the same website from the same PC, ensuring that each of your profiles is managed separately and accurately reflects your individual interactions.</p>"},{"location":"qa/unomi_vs_tracardi/","title":"What are the main differences between Apache Unomi and Tracardi?","text":"<p>Tracardi and Apache Unomi are both customer data platforms (CDPs) but have some key differences in terms of features and focus. Here are the main differences between Tracardi and Unomi:</p> <ol> <li> <p>Data Collection and Integration: Tracardi provides a wide range of data collection options, including API    integrations, webhook support, and data import/export capabilities. It offers flexible data integration capabilities    to gather data from various sources. Unomi, on the other hand, focuses on real-time data collection and offers    integration via API calls.</p> </li> <li> <p>AI-Driven Insights and Automation: Tracardi emphasizes AI-driven insights and automation. It leverages machine    learning algorithms through integration with external systems like ChatGPT, etc., providing advanced automation    capabilities for personalizing customer experiences and optimizing marketing campaigns. Unomi, on the other hand,    supports basic personalization and segmentation but does not have built-in AI capabilities.</p> </li> <li> <p>Workflow and Journey Orchestration: Tracardi provides a visual workflow editor and journey orchestration    capabilities, allowing users to design complex customer journeys and automate marketing workflows. Unomi, on the    other hand, focuses more on customer profile management and segmentation, with less emphasis on workflow    orchestration.</p> </li> <li> <p>User Interface and Ease of Use: Tracardi aims to provide a user-friendly interface and a low-code/no-code    environment, making it accessible to marketers and non-technical users. Unomi, being an Apache project, does not have    a graphical user interface (GUI) and requires more technical expertise for configuration and customization.</p> </li> <li> <p>Commercial Support: Tracardi offers commercial support and enterprise-grade features through its commercial    open-source version. Unomi, being an Apache project, primarily relies on community support, although some companies    may offer commercial support for Unomi as well.</p> </li> <li> <p>Licensing: Tracardi is licensed under the MIT License with the additional Common Clause. This licensing allows users    to freely use, modify, and distribute Tracardi while also imposing some restrictions on the commercial use of the    software. On the other hand, Apache Unomi is licensed under the Apache License 2.0. This license allows users to    freely use, modify, and distribute Unomi without imposing any additional restrictions on its use, including    commercial use.</p> </li> <li> <p>Maturity: Tracardi is a younger product compared to Unomi but offers a more extensive set of features. Tracardi    provides a user-friendly graphical user interface (GUI). It also offers built-in automation capabilities, integration    bridges to connect with various systems, and destinations for data export. In contrast, Apache Unomi requires more    programming and customization work to add similar features. It provides a solid foundation for customer data    management and segmentation but may require additional development effort to achieve the same level of automation,    integration, and user interface capabilities as Tracardi.</p> </li> </ol>"},{"location":"qa/what_are_available_installation_types/","title":"What are available types of installation. Can Tracardi be installed in kubernetes?","text":"<p>Yes. Tracardi can be installed on Kubernetes. </p> <p>The available types of installation for Tracardi system are:</p> <ul> <li>From docker image</li> <li>From source</li> </ul>"},{"location":"qa/what_are_available_merge_strategies/","title":"What are available merge strategies?","text":"<p>Below is a table that describes all available merge strategies in Tracardi as of version 0.9.0.7:</p> Strategy ID Name Description <code>LAST_UPDATE</code> Last updated value This merge strategy uses the update date of a field to find the most recent value that will prevail. <code>FIRST_UPDATE</code> First inserted value This merge strategy uses the update date of a fieldto find the first inserted value that will prevail. <code>MIN</code> Minimal value This merge strategy will select the minimal value as the merged value. <code>MAX</code> Maximal value This merge strategy will select the maximal value as the merged value. <code>SUM</code> Sum of values This merge strategy will sum all values and return it as the merged value. <code>AVG</code> Average of values This merge strategy will average all values and return it as the merged value. <code>LAST_DATETIME</code> Last date This merge strategy works only on date values and will select the last date as the merged value. <code>FIRST_DATETIME</code> First date This merge strategy works only on date values and will select the first date as the merged value. <code>ALWAYS_TRUE</code> Always TRUE This merge strategy always returns TRUE as the merged value. <code>ALWAYS_FALSE</code> Always FALSE This merge strategy always returns FALSE as the merged value. <code>AND</code> AND Operator This merge strategy will use the AND operator on all boolean values and return it as the merged value. <code>OR</code> OR Operator This merge strategy will use the OR operator on all boolean values and return it as the merged value. <code>MERGE_LISTS</code> Merge Values From Lists This merge strategy is used on lists and will concatenate all values and return them as the merged value. <code>MERGE_LISTS_DISTINCT</code> Merge Unique Values From Lists This merge strategy is used on lists and will concatenate all values and return unique values as the merged value. <code>MERGE_LISTS_AND_VALUES_DISTINCT</code> Merge Values and List of Values to Unique Lists This merge strategy is used on lists and values and will concatenate all values and return unique values as a list. <code>MERGE_LISTS_AND_VALUES</code> Merge Values and List of Values to Unique Lists This merge strategy is used on lists and values and will concatenate all values and return all values as a list. <code>CONCAT_VALUES_TO_LIST</code> Concatenates Values To A List This merge strategy concatenates all values and returns unique values as a list. <code>CONCAT_DISTINCT_VALUES_TO_LIST</code> Concatenates Distinct Values To A List This merge strategy concatenates all values and returns unique values as a list. <code>FIRST_PROFILE_INSERT_TIME</code> First Profile Insert Time This merge strategy will select the first inserted profile and get the value for the merged field from this profile. <code>FIRST_PROFILE_UPDATE_TIME</code> First Profile Update Time This merge strategy will select the first updated profile and get the value for the merged field from this profile. <code>FIRST_PROFILE_CREATE_TIME</code> First Profile Create Time This merge strategy will select the first created profile and get the value for the merged field from this profile. <code>LAST_PROFILE_CREATE_TIME</code> Last Profile Create Time This merge strategy will select the last created profile and get the value for the merged field from this profile. <code>LAST_PROFILE_UPDATE_TIME</code> Last Profile Update Time This merge strategy will select the last updated profile and get the value for the merged field from this profile. <code>LAST_PROFILE_INSERT_TIME</code> Last Profile Insert Time This merge strategy will select the last inserted profile and get the value for the merged field from this profile. <code>FIRST_ITEM</code> No Merging This merge strategy will not merge anything."},{"location":"qa/what_are_available_merge_strategies/#examples","title":"Examples","text":""},{"location":"qa/what_are_available_merge_strategies/#last-update-strategy","title":"Last Update Strategy","text":"<p>The Last Update Strategy prioritizes the most recent information when merging profiles. It uses the update date of a field to select the latest value among conflicting data.</p> <p>Example Scenario:</p> <p>Consider two profiles with conflicting email information:</p> <ul> <li> <p>Profile A:</p> <ul> <li>Email: john.doe@example.com</li> <li>Field was Updated: 2024-01-01</li> </ul> </li> <li> <p>Profile B:</p> <ul> <li>Email: johnny.doe@example.com</li> <li>Field was Updated: 2024-03-01</li> </ul> </li> </ul> <p>Using the Last Update Strategy:</p> <ol> <li>Compare Timestamps of Fields:<ul> <li>Profile A: 2024-01-01</li> <li>Profile B: 2024-03-01</li> </ul> </li> <li>Select Most Recent Data:<ul> <li>Email: johnny.doe@example.com (Profile B)</li> </ul> </li> </ol> <p>The unified profile will have the email \"johnny.doe@example.com\" as it is the most recently updated value.</p>"},{"location":"qa/what_are_available_merge_strategies/#last-profile-update-time-strategy","title":"Last Profile Update Time Strategy","text":"<p>The Last Profile Update Time Strategy selects the value from the profile that was last updated. This is particularly useful when merging data from profiles that have been updated at different times.</p> <p>Example Scenario:</p> <p>Consider three profiles with different names and update times:</p> <ul> <li> <p>Profile A:</p> <ul> <li>Name: John Doe</li> <li>Profile Update Time: 2024-01-10</li> </ul> </li> <li> <p>Profile B:</p> <ul> <li>Name: Jonathan Doe</li> <li>Profile Update Time: 2024-02-15</li> </ul> </li> <li> <p>Profile C:</p> <ul> <li>Name: Johnny Doe</li> <li>Profile Update Time: 2024-03-05</li> </ul> </li> </ul> <p>Using the Last Profile Update Time Strategy:</p> <ol> <li>Compare Profile Update Times:<ul> <li>Profile A: 2024-01-10</li> <li>Profile B: 2024-02-15</li> <li>Profile C: 2024-03-05</li> </ul> </li> <li>Select Most Recently Updated Profile:<ul> <li>Name: Johnny Doe (Profile C)</li> </ul> </li> </ol> <p>The unified profile will have the name \"Johnny Doe\" as it is from the profile that was last updated.</p>"},{"location":"qa/what_are_available_merge_strategies/#last-datetime-strategy","title":"Last DateTime Strategy","text":"<p>The Last DateTime Strategy is used for date values and selects the most recent date.</p> <p>Example Scenario:</p> <p>Consider three profiles with different last login dates:</p> <ul> <li> <p>Profile A:</p> <ul> <li>Last Login: 2024-01-01</li> </ul> </li> <li> <p>Profile B:</p> <ul> <li>Last Login: 2024-02-01</li> </ul> </li> <li> <p>Profile C:</p> <ul> <li>Last Login: 2024-03-01</li> </ul> </li> </ul> <p>Using the Last DateTime Strategy:</p> <ol> <li>Compare Dates:<ul> <li>Profile A: 2024-01-01</li> <li>Profile B: 2024-02-01</li> <li>Profile C: 2024-03-01</li> </ul> </li> <li>Select Most Recent Date:<ul> <li>Last Login: 2024-03-01 (Profile C)</li> </ul> </li> </ol> <p>The unified profile will have the last login date \"2024-03-01\" as it is the most recent date.</p>"},{"location":"qa/what_are_differences_between_session_and_profile_id/","title":"What are the differences between profile and session ID:","text":"<ul> <li>Session IDs:</li> <li>Generated on the client side when a user opens a browser or app.</li> <li>Used to track a user's visit or session.</li> <li>Stored in a cookie in the user's browser.</li> <li>Erased when the browser or app is closed.</li> <li>New session ID generated on each new visit.</li> <li> <p>Controlled by client-side scripts.</p> </li> <li> <p>Profile IDs:</p> </li> <li>Generated by Tracardi when a user interacts with the website or app.</li> <li>Used to create a user profile and store user data.</li> <li>Stored in the local storage of the browser.</li> <li>Remains constant across multiple visits and devices.</li> <li>Bound to the browser but can be merged into a single profile.</li> <li>Managed by Tracardi and used for identity resolution.</li> </ul>"},{"location":"qa/what_are_examples_of_real_time_or_time_based_segmentations/","title":"Give me examples of real time segmentation?","text":"<ol> <li> <p>Real-time Email Engagement Segmentation:    Trigger: \"Email Open\" event.     Condition: Check if the customer has opened a specific email or a series of    emails.    Action: Add the profile to the \"Engaged Email Subscribers\" segment.</p> </li> <li> <p>Time-triggered Inactive Customer Segmentation:    Trigger: Periodic time-based trigger (e.g., every week).     Condition: Check if the customer has not made a purchase or visited the website within a specified timeframe.     Action: Add the profile to the \"Inactive Customers\"    segment.</p> </li> <li> <p>Real-time Purchase Behavior Segmentation:    Trigger: \"Purchase\" event.     Condition: Check if the customer has made a certain number of purchases within a       given period.     Action: Add the profile to the \"Frequent Buyers\" segment.</p> </li> <li> <p>Real-time Weather-based Segmentation:    Trigger: \"Purchase\" event.     Condition: Check if the customer has purchased ice cream.    Action: Connect to a weather provider to retrieve the weather information for the customer's location at the time    of purchase. If it is raining, add the profile to the \"Ice Cream Lovers\" segment.</p> </li> <li> <p>Real-time Abandoned Cart Segmentation:    Trigger: \"Add to Cart\" event.     Condition: Check if the customer has not completed the purchase within a    specified timeframe.     Action: Add the profile to the \"Abandoned Cart\" segment.</p> </li> <li> <p>Real-time Event Pattern Segmentation:    Trigger: \"Session Closed\" event.     Condition: Detect if the customer has added products to their basket but did    not make a purchase during the session.     Action: Add the profile to the \"Browsing Shoppers\" segment.</p> </li> </ol> <p>Remember, these workflows are just examples, and you can customize them based on your specific segmentation goals and requirements. Tracardi provides the flexibility to design workflows that suit your business needs and perform segmentation effectively.</p>"},{"location":"qa/what_are_extension_points/","title":"What are extension points?","text":"<p>Tracardi is a modular customer data platform that allows for easy extension of various parts of its system to enhance functionality and customization. The main extension points in Tracardi include:</p> <ol> <li> <p>Inbound Traffic Extension Point: This feature enables the creation of new event sources using different types of    data bridges. Users can develop custom data bridges to gather information from a variety of sources or to generate    data in unique ways. This includes the implementation of API bridges, such as a RabbitMQ API bridge, and redirect    bridges for collecting data from link clicks.</p> </li> <li> <p>Resources Extensions: These extensions facilitate the connection to external systems, comprising both resources    and plugins. An example is the Airtable extension, which includes one resource and two plugins. Tracardi also allows    the integration of microservices as extensions, providing new functionalities without the need for system updates.    These microservices are configurable within Tracardi and can interact with various external systems or platforms,    such as Trello.</p> </li> <li> <p>Outbound Traffic Extension Point: This point is concerned with transmitting data from user profiles to external    systems. It involves installing various destinations within the system, like Maori and RabbitMQ, thereby broadening    Tracardi's capabilities to interact with external platforms.</p> </li> <li> <p>Workflow Actions Extensions: This extension point is related to the addition of process-related actions within    the Tracardi system, specifically focusing on action plugins used in workflows. These plugins are crucial for    integrating external systems and services into the Tracardi workflow, allowing for a seamless blend of internal    processes with external functionalities.</p> </li> </ol> <p>Additionally, the commercial version of Tracardi uses Apache Pulsar Queues, which serve as another extension point. These queues can be utilized to consume events and profiles, as well as to trigger actions in external systems. This functionality further enhances Tracardi's ability to interact dynamically with a range of systems and services, making it a versatile tool for managing customer data and automating marketing processes.</p>"},{"location":"qa/what_are_main_differences_between_os_and_com/","title":"What are the differences between open-source and commercial Tracardi","text":"<p>The main differences between the open-source and commercial versions of Tracardi are as follows:</p> <ul> <li> <p>License: Commercial Tracardi is sold with license that allows to resell the system to your customers.  </p> </li> <li> <p>Configuration: The commercial version of Tracardi offers a simplified configuration process, making it easier to set   up and maintain compared to the open-source version. It provides a user-friendly interface that allows businesses to   quickly adapt the tool to their specific requirements, saving time and effort in the long run.</p> </li> <li> <p>Advanced Time-Based Event Handling: The commercial version enhances time-based event handling capabilities. Users can   execute processes triggered by specific time intervals, enabling automation of tasks such as sending personalized   follow-up messages to customers after a certain time has elapsed. This feature is not available in the open-source   version.</p> </li> <li> <p>Expanded Event Collectors: The commercial version of Tracardi provides additional event collectors that can gather   data from various sources like Kafka, RabbitMQ, IMAP, MQTT, and more. This broadens the scope of data collection,   allowing businesses to leverage insights from diverse platforms and systems. The open-source version may have   limitations in terms of supported event collectors.</p> </li> <li> <p>Validating, Transforming, and Copying Events: Tracardi's commercial version allows events collected through the tool   to undergo validation, transformation, and automatic copying to customer profiles. This ensures that the data is   accurate, consistent, and readily accessible for further analysis and action. These features may be limited or not   available in the open-source version.</p> </li> <li> <p>Intelligent Profile Merging: The commercial version of Tracardi automatically merges profiles based on identification   points. This consolidation of relevant profile data happens even before an event reaches the workflow, providing a   comprehensive view of each customer's journey. Intelligent profile merging is a feature exclusive to the commercial   version.</p> </li> <li> <p>Extensive Action Plugins: Tracardi's commercial version offers an array of action plugins that enhance workflow   functionality. These plugins include features like pause and resume, limiter, load data report, geo distance or geo   fencing, event aggregator, event counter, multiple segmentation plugins, and event sequencing matching. These plugins   may not be available or as extensive in the open-source version.</p> </li> <li> <p>Enhanced Data Management: The commercial version of Tracardi allows for saving and loading of additional data into the   entity's database. This feature enables businesses to store supplementary information such as email records and   product purchases, enhancing data-driven decision-making. Enhanced data management capabilities may not be present in   the open-source version.</p> </li> <li> <p>Intelligent Session Handling: Tracardi's commercial version automatically closes a customer's session or visit upon   leaving the website, enabling the binding of workflows triggered by a customer's exit. This feature opens up new   possibilities for time-based workflows, allowing businesses to deliver targeted messages or offers based on customer   behavior and interaction. The intelligent session handling feature is not available in the open-source version.</p> </li> <li> <p>Automated Segmentation and Profile Management: The commercial version of Tracardi facilitates automated segmentation   of customer profiles, allowing users to schedule segmentation processes to run at specified intervals. This enables   businesses to move profiles from one segment to another based on profile activity or inactivity. Automated   segmentation and profile management features may not be as robust in the open-source version.</p> </li> <li> <p>Retroactive Data Processing: Tracardi's commercial version allows businesses to process historical data and copy it to   profiles or index event data, even if the events were collected before the corresponding workflows were created. This   capability enables businesses to retroactively leverage previously collected data, ensuring comprehensive customer   data analysis and personalized communication based on historical information. Retroactive data processing is not   available in the open-source version.</p> </li> <li> <p>Enhanced User Experience with UIX Widgets: Tracardi's commercial version offers UIX widgets that enable businesses to   inject interactive forms into their customer journey. These widgets can measure customer satisfaction at specific   event touchpoints, allowing customers to provide feedback on their experience. These UIX widgets are not available</p> </li> </ul>"},{"location":"qa/what_are_parts_of_tracardi/","title":"What are the main components or modules that make up Tracardi?","text":"<p>Tracardi consist of the following docker images. </p> <p>Note</p> <p>Docker image name is given in the brackets.</p>"},{"location":"qa/what_are_parts_of_tracardi/#backend","title":"Backend","text":"<ul> <li> <p>Database: Elasticsearch (docker.elastic.co/elasticsearch/elasticsearch)</p> </li> <li> <p>Redis: Cache (redis)</p> </li> <li> <p>Open-source Tracardi API (tracardi/tracardi-api)</p> </li> <li> <p>Open-source Tracardi Workers (tracardi/tracardi-api)</p> </li> <li>Various Import Workers</li> <li> <p>Migration Worker</p> </li> <li> <p>Commercial Tracardi API (tracardi/com-tracardi-api)</p> </li> <li> <p>Tenant Manager API</p> </li> <li> <p>Commercial Tracardi brides (tracardi/com-bridge-queue)</p> </li> <li>MQTT,</li> <li>Kafka</li> <li>IMAP</li> <li> <p>RabbitMq</p> </li> <li> <p>Commercial REST Bridge + Worker (tracardi/com-bridge-rest-worker, tracardi/com-bridge-rest)</p> </li> <li> <p>Commercial Workers</p> </li> <li> <p>Scheduler (tracardi/com-tracardi-scheduler + tracardi/com-tracardi-scheduler-worker)</p> </li> <li> <p>Commercial Jobs</p> </li> <li>Heartbeat (tracardi/com-heartbeat-job)</li> <li>Session closer</li> <li> <p>Segmentation (tracardi/com-tracardi-segmentation-job + tracardi/com-tracardi-segmentation-worker)</p> </li> <li> <p>Sponsored GraphQl (tracardi/com-graphql)</p> </li> <li> <p>Tracardi PRO</p> </li> <li> <p>Misc (most obsolete):</p> </li> <li>Deduplication (tracardi/com-job-deduplication)</li> <li>Merging (tracardi/com-job-merging)</li> <li>Segmentation (tracardi/com-job-segmentation)</li> </ul>"},{"location":"qa/what_are_parts_of_tracardi/#frontend","title":"Frontend","text":"<ul> <li>Tracardi Graphical User Interface</li> </ul>"},{"location":"qa/what_are_parts_of_tracardi/#optional","title":"Optional","text":"<ul> <li>Kibana as analytical tool</li> </ul>"},{"location":"qa/what_are_parts_of_tracardi/#programming","title":"Programming","text":"<ul> <li>Tracardi Library (http://www.github.com/tracardi/tracardi)</li> </ul> <p>This document also answers the questions.</p> <ul> <li>Provide an overview of the different components that comprise Tracardi?</li> <li>What are the key building blocks or modules that constitute Tracardi?</li> <li>Break down the various parts or elements that make up Tracardi?</li> <li>What are the fundamental components or sections within Tracardi?</li> <li>What are the primary constituent parts or components?</li> <li>What are the main sections or building elements that constitute Tracardi?</li> </ul>"},{"location":"qa/what_are_predefined_event_types/","title":"What are build-in event types?","text":"<p>Predefined event types in Tracardi are built-in event types that come with default properties. These event types are designed to track the customer journey on websites or applications. When these internal event types are used, Tracardi automatically detects them and populates the profile and session with relevant data.</p> <p>Using predefined event types streamlines the use of Tracardi and simplifies the process of data collection and analysis. The default properties of these event types eliminate the need for manual copying. They include information such as the event type, event properties (characteristics or attributes of the event), and contextual data that provides additional details about the event.</p> <p>Some examples of predefined event types in Tracardi include:</p> <ul> <li>Page View: Triggered when a customer visits a new page on the website or application. It captures the URL of the page and the time of the visit.</li> <li>Search: Triggered when a customer performs a search on the website or application. It captures the search query and the category of the search.</li> <li>Signup: Triggered when a customer signs up for an account. It captures the customer's first name, last name, email address, and login information.</li> <li>Identification: Triggered when a customer logs into their account. It captures the customer's login information.</li> <li>Purchase Order: Triggered when a customer makes a purchase. It captures the details of the purchase, such as the product ID, name, price, and quantity.</li> <li>Cart Update: Triggered when a customer adds or removes items from their shopping cart. It captures the details of the update, including the product ID, name, price, and quantity.</li> </ul> <p>Using these predefined event types helps in understanding customer behavior and preferences, allowing for better website or application optimization for improved engagement and conversions.</p>"},{"location":"qa/what_are_session-open_and_visit-open_meant_for/","title":"What are session opened and visit opened meant for?","text":"<p>In Tracardi, the \"session-opened\" and \"visit-opened\" events serve as triggers to capture the beginning of user interactions on the platform.</p> <ol> <li> <p>Session Opened:    The \"session-opened\" event is raised when a user's session starts, indicating the beginning of their continuous    activity on the platform. A session represents a period of time during which a user engages with the platform,    typically starting from the moment the first event is collected from the user. The session will end when the user's    session ID changes. This event allows you to initiate additional workflows or actions that should occur at the start    of a user's session, providing valuable insights into user activity over a specific timeframe.</p> </li> <li> <p>Visit Opened:    The \"visit-opened\" event is triggered when a user starts a new visit to the platform within a specific time frame    during one session. Usually, a session has only one visit, but there are cases where a session may have several    visits. For instance, if a customer keeps their browser open for multiple days and visits your page several times,    with 1h intervals of inactivity between clicks. When a user visits the platform and there is no existing visit    associated with them, Tracardi creates a new visit and raises the \"visit-opened\" event. This event helps you keep    track of and manage user visits, enabling you to analyze user behavior during specific visits and better understand    how users interact with your platform.</p> </li> </ol>"},{"location":"qa/what_are_the_differences_in_data_flow_in_os_and_com/","title":"What are the differences in Data Flow for Open-source and Commercial Version of Tracardi","text":"<p>Here is the outline the differences between an open-source Tracardi and a Commercial Tracardi, especially focusing on the differences in data flow, specifically regarding the new version 0.8.2. </p> <p>In an open-source Tracardi, we have the following data flow:</p> <ol> <li> <p>A request is made to the API, where we collect the tracker payload. The tracker payload basically consists of data in    the form of profile, session, and event payloads. There may be multiple event payloads for a single profile, with    potentially as many as 100 events per profile. This illustrates how data is bulked together.</p> </li> <li> <p>The data is then preprocessed and split into events, profiles, and sessions within the system. It is subsequently    sent to the workflow for processing.</p> </li> <li> <p>Within the workflow, an internal state is maintained, including the event, profile, and session data. The result of    the workflow, along with any modifications to the event, profile, and session, is saved into the database.</p> </li> <li> <p>Finally, the event or profile is sent to a destination via outbound traffic, and a response is generated. This    process operates as a single work unit, requiring completion before a response is issued. Consequently, if a workflow    takes a long time to process, it can result in extended processing times.</p> </li> </ol> <p>Pros of this approach:</p> <ul> <li>Easy setup with just one Docker installation.</li> <li>Ability to add personalized content and await responses within the workflow.</li> <li>Simplified maintenance of both the system and the code.</li> </ul> <p>Cons of this approach:</p> <ul> <li>Limited scalability as everything must be scaled together.</li> <li>Limited data access as data can only be fetched from the database.</li> <li>Lack of easy extensibility for specific components, as extensions often pollute the code.</li> <li>Lower performance due to increased processing time as more elements are added to the workflow or outbound traffic.</li> </ul> <p>There is also a commercial version with a different approach:</p> <ol> <li> <p>In the commercial version, there is a foreground process in the server and a background process. The request and    tracker payload, including profile and event payloads, are processed similarly.</p> </li> <li> <p>However, in this version, the user does not need to wait for everything to complete. The preprocessed data is    provided quickly as a response.</p> </li> <li> <p>The result of preprocessing includes event, profile, and session data. Deltas are used to describe how the profile is    updated.</p> </li> <li> <p>In the background, event, profile, and session data are created and sent to a workflow stream. This stream, which    utilizes Apache Pulsar, stores the data and connects to a worker for processing. Additional workers can be added as    needed, allowing for scalable processing.</p> </li> <li> <p>The output of this processing goes to a collector, which aggregates and outputs profile and session information at    regular intervals.</p> </li> <li> <p>Computed profiles and sessions are sent to their respective streams, where they can be connected to additional code    for further processing.</p> </li> <li> <p>Events, which are immutable, are sent directly to the event stream and then to the database.</p> </li> <li> <p>Another important component is responsible for determining when it's appropriate to process data, ensuring that    metrics are computed efficiently, and sending profile data to external systems.</p> </li> <li> <p>This approach optimizes data processing, reducing stress on both the database and external systems.</p> </li> </ol> <p>In summary, the commercial version offers faster responses by separating foreground and background processing, as well as improved scalability and flexibility in handling data streams. It provides better performance and reduces stress on the database and external systems. Additionally, failures in various components can be handled more effectively.</p>"},{"location":"qa/what_are_the_main_featuress_of_commercial_version/","title":"What are the main features of commercial vs open-source version?","text":"Feature Open source Commercial Data collection * API bridge x x * Redirect bridge x * Maintaining the profile id between domains x * Kafka bridge x * MQTT Bridge x Data mapping * Event to profile mappings x x * Event validation x * Event reshaping x * Event remapping x Profile identification * Profile merging x x * Profile identification points x * Data compliance x * Profile consents x x Data storage * Events x x * Sessions x x * Profiles x x * Entities x Destinations * Event destinations x * Profile destinations x Workflow triggers * Workflow triggered by event x x * Workflow triggered by time x * Workflow triggered by segmentation x * Workflow skipped if no consent x Segmentation * Simple segmentation based on profile data x x * Segmentation based on event data x * Segmentation by workflow x Profile data enhancement * Profile metrics x * Auto profile geo location x Automation * Workflow automation x x * Standard automation actions x x * Time based automation x * AI features, vector stores x * Geo location features x * Automation based on event aggregations x * UIX widgets x * Interactions with Twilio, varius databases, etc x Other * Multi-tenancy x * Performance improvements x * Automatic profile visits closing x * Post collection data indexing x"},{"location":"qa/what_are_the_plugins/","title":"What are plugins","text":"<p>Plugins in Tracardi are modular components that extend the functionality of the platform. They are essentially Python classes that can be integrated into Tracardi workflows to perform specific actions or processes. </p>"},{"location":"qa/what_are_the_pros_and_cons_of_multi-tenant_setup/","title":"What are the pros and cons of multi-tenant setup of Tracardi?","text":"<p>Pros of Multi-tenant Setup:</p> <ol> <li>Simplified Maintenance: Shared application instances across all tenants simplify maintenance and upgrade rollouts,    reducing maintenance overhead.</li> <li>Scalability: Multi-tenant setups allow for efficient resource utilization and scalability by sharing infrastructure    and resources among multiple tenants.</li> <li>Cost-effectiveness: By sharing resources, a multi-tenant setup can reduce infrastructure and operational costs    compared to maintaining separate instances for each tenant.</li> <li>One-click Onboarding: Multi-tenant setups can enable one-click onboarding of new clients, streamlining the process of    provisioning necessary infrastructure and mappings.</li> <li>Data Backup and Disaster Recovery: Multi-tenant setups can utilize backup mechanisms like Elasticsearch's snapshot    repositories to ensure data backups, disaster recovery, and data protection for all tenants.</li> </ol> <p>Cons of Multi-tenant Setup:</p> <ol> <li>Limited Customization: In a multi-tenant setup, it may be challenging to provide extensive customization options for    individual tenants since upgrades and modifications affect all tenants simultaneously.</li> <li>Upgrades and Patches: Upgrades and patches need to be applied uniformly across all tenants, making it challenging to    cherry-pick upgrades for specific tenants. This can result in more maintenance work compared to single-tenant setups.</li> <li>Dependency on Tenant Management Service (TMS): Multi-tenant setups rely on a Tenant Management Service (TMS) for    tenant management, which introduces an additional dependency that needs to be properly configured and maintained.</li> <li>Data Security and Isolation: Ensuring data security and isolation among tenants can be more complex in a multi-tenant    environment compared to separate instances.</li> <li>Increased Complexity: Multi-tenant setups introduce additional complexity in terms of architecture, infrastructure    management, and data segregation, requiring careful planning and implementation.</li> </ol> <p>It's important to note that the pros and cons may vary depending on the specific implementation and requirements of the multi-tenant setup.</p>"},{"location":"qa/what_are_the_steps_of_collector/","title":"How data is collected and what stages there are before the event is saved.","text":"<p>To understand the journey of an event in Tracardi before it gets saved, let's break down each step you've mentioned:</p> <ol> <li> <p>Data Validation:</p> <ul> <li>Purpose: To ensure that the incoming event data conforms to predefined standards and formats.</li> <li>How It Works: When an event is received, Tracardi checks it against a set of validation rules defined as   JSONSchema validation.</li> </ul> </li> <li> <p>Event Reshaping:</p> <ul> <li>Purpose: To transform or reformat the event data into a structure that is consistent and suitable for further   processing and storage.</li> <li>How It Works: This involves modifying the event data, if necessary, to align with the expected schema or format.   It might include operations like renaming fields, or restructuring nested data.</li> </ul> </li> <li> <p>Event Mapping:</p> <ul> <li>Purpose: To ensure that the data from the event is correctly indexed.</li> <li>How It Works: This step involves mapping the event data to the event traits. It ensures   that each piece of data is stored in the right place. Each part of event has different properties. For example   traits are indexed while properties are not. Please search the documentation for more information.</li> </ul> </li> <li> <p>Profile Identification Checkpoint:</p> <ul> <li>Purpose: To determine if the event data can be linked to/merged with an existing customer profile.</li> <li>How It Works: Tracardi examines the event to see if it contains identifiers that can link it to an existing   customer profile (like email, customer ID, etc.). If such identifiers are found, Tracardi associates the event   with the corresponding profile.</li> </ul> </li> <li> <p>Event to Profile Mapping:</p> <ul> <li>Purpose: To transfer relevant data from the event to the customer's profile.</li> <li>How It Works: Once an event is identified as belonging to a specific customer, certain data from the event may be   used to update or augment the customer\u2019s profile. This could include updating contact information, adding new   preferences, tracking recent interactions, etc.</li> </ul> </li> </ol>"},{"location":"qa/what_database_use_tracardi/","title":"What are the prerequisites, requirements for Tracardi to install","text":"<p>Tracardi needs Elasticsearch and Redis</p>"},{"location":"qa/what_database_use_tracardi/#what-database-use-tracardi-to-store-events-profiles-and-sessions","title":"What database use Tracardi to store events, profiles, and sessions.","text":"<p>Tracardi uses Elasticsearch as its backend storage for storing data.</p>"},{"location":"qa/what_dockers_are_used_by_tracardi/","title":"What dockers are used by tracardi?","text":"<p>The Docker images used by Tracardi are as follows:</p> <ol> <li> <p>Tracardi API:</p> <ul> <li>Repository: <code>tracardi/com-tracardi-api</code></li> <li>This image is used for both the private and public APIs of Tracardi.</li> <li>Private API interacts with the GUI, while the public API handles data collection.</li> </ul> </li> <li> <p>Tracardi GUI:</p> <ul> <li>Repository: <code>tracardi/tracardi-gui</code></li> <li>This image provides the graphical user interface (GUI) for interacting with Tracardi.</li> </ul> </li> <li> <p>Tracardi TMS (Tenant Management Service):</p> <ul> <li>Repository: <code>tracardi/tms</code></li> <li>This Docker image manages multi-tenancy within the system.</li> </ul> </li> <li> <p>Workers:</p> <ul> <li> <p>Background Worker:</p> <ul> <li>Repository: <code>tracardi/background-worker</code></li> <li>Responsible for collecting data in parallel. THis is the main background process.</li> </ul> </li> <li> <p>APM (Auto Profile Merging):</p> <ul> <li>Repository: <code>tracardi/apm</code></li> <li>Responsible for merging profiles</li> </ul> </li> <li> <p>Upgrade Worker:</p> <ul> <li>Repository: <code>tracardi/update-worker</code></li> <li>Responsible for updating tracardi</li> </ul> </li> </ul> </li> <li> <p>Bridge (Optional):</p> <ul> <li>Repository: <code>tracardi/com-bridge-queue</code></li> <li>This is used for collecting data from different channels via a queue bridge, but it is disabled by default.</li> </ul> </li> </ol> <p>These Docker images are pulled from Docker Hub, with specific configurations for each service, depending on whether it is enabled and how many replicas are required.</p>"},{"location":"qa/what_happens_if_two_workflow_return_responses/","title":"What Happens When Two Workflows Generate Responses","text":"<p>In a situation where a single event triggers two workflows, both workflows execute and produce responses as their output. The system consolidates these responses, and if there are no key name conflicts, it will return all the data. In case of conflicts, the last value will take precedence and override the first value.</p>"},{"location":"qa/what_happens_if_two_workflow_return_widgets/","title":"What occurs when two workflows yield widgets","text":"<p>In a scenario where a single event triggers two workflows, both of them execute and may produce widgets as their output. The system combines these widgets, and all of them are subsequently displayed.</p>"},{"location":"qa/what_is_a_set_of_strategies/","title":"What is a set of strategies","text":""},{"location":"qa/what_is_a_set_of_strategies/#what-is-a-set-of-merging-strategies","title":"What is a Set of Merging Strategies?","text":"<p>A set of merging strategies in Tracardi defines the sequence in which the system should attempt to resolve conflicts in profile data. For example, a default merging strategy set might be: <code>[LAST_UPDATE, LAST_PROFILE_UPDATE_TIME, LAST_PROFILE_INSERT_TIME]</code>.</p> <p>This set tells the system to:</p> <ol> <li>First, try to merge fields based on the <code>LAST_UPDATE</code> strategy, selecting the field that was last updated.</li> <li>If this is not possible (e.g., if field update dates are not available), then use the <code>LAST_PROFILE_UPDATE_TIME</code>    strategy, selecting the value from the last updated profile.</li> <li>As a final fallback, use the <code>LAST_PROFILE_INSERT_TIME</code> strategy, selecting the value from the last inserted profile.</li> </ol> <p>This mechanism is known as a merge strategy fallback in Tracardi, ensuring that there is always a method available to resolve conflicts in data merging.</p>"},{"location":"qa/what_is_aux_data/","title":"What is Auxiliary data?","text":"<p>Auxiliary data refers to additional or supplemental data that is associated with an event. It provides extra information or context related to the event but may not be directly essential for its core purpose. Auxiliary data can include various details, such as additional metadata, supporting information, temporary storage for obsolete or migrating data, or any other relevant data that does not fit into the predefined event schema. It allows for the flexibility of storing miscellaneous or non-standardized data related to the event without altering the predefined structure or losing any important information.</p>"},{"location":"qa/what_is_bridge/","title":"What is bridge?","text":"<p>A bridge is a piece of software that serves as a communication link between two separate systems or applications. Its primary function is to facilitate the exchange of data between these systems, allowing them to interact seamlessly.</p> <p>Specifically, in Tracardi, a bridge is responsible for collecting data from a particular source, such as a queue, email, social media, or any other external system, and then transferring that data to an event source within Tracardi. The event source, in turn, processes and handles the incoming data as part of Tracardi's workflows and data processing capabilities.</p> <p>For example, Tracardi may come with an open-source API bridge that enables the collection of data from an API's <code>/track</code> endpoint. This data can then be seamlessly transferred to the Tracardi system for further processing and analysis.</p> <p>Different types of bridges may be available based on the version of Tracardi being used. For instance, commercial versions of Tracardi might include bridges for integrating with various data sources, such as a Kafka bridge that allows the collection of data from a Kafka message broker.</p> <p>In summary, a bridge in Tracardi acts as a conduit, connecting external data sources to the Tracardi system, enabling smooth data transfer and integration.</p>"},{"location":"qa/what_is_cross_domain_click/","title":"What is cross domain click?","text":"<p>A cross-domain click refers to a user interaction where a click on one website leads to navigation to a different domain. This typically occurs when a user clicks a link on Site A that directs them to Site B.</p> <p>Cross-domain clicks are important in web analytics, advertising, and user experience design. They can present challenges for tracking user behavior, as browsers implement various restrictions on cross-domain interactions to protect user privacy.</p>"},{"location":"qa/what_is_cross_domain_click/#what-is-cross-domain-event","title":"What is cross domain event?","text":"<p>A cross-domain event in Tracardi is a mechanism that allows the transfer of a customer's profile ID from one domain to another, maintaining continuity of customer identification across different owned websites. Here's how it works:</p> <ol> <li> <p>Configuration: Enable the feature by adding <code>trackExternalLinks</code> to the tracker settings, specifying the domains you    own.</p> </li> <li> <p>Link Rewriting: The JavaScript code automatically rewrites links on the page, adding <code>__tr_pid</code> (profile ID)    and <code>__tr_src</code> (source ID) parameters to URLs that match the specified domains.</p> </li> <li> <p>Profile Transfer: When a user clicks a modified link, these parameters are passed to the destination domain.</p> </li> <li> <p>Profile Recognition: On the new domain, Tracardi checks for these parameters. If found and valid profile is available    then it merges the referred profile with an existing local profile</p> </li> <li> <p>Session Management: Tracardi invalidates the session if the profile ID is incorrect and creates a new one if    necessary.</p> </li> </ol> <p>Tip</p> <p>The destination web site musts have tracardi connected and tracker.context.tracardiPass set to true.</p> <p>This approach ensures consistent customer identification across your owned domains, improving user tracking and analytics capabilities.</p>"},{"location":"qa/what_is_customer_journey/","title":"What is customer journey?","text":"<p>The customer journey refers to the complete process that a person or buyer persona goes through from the moment they identify a need to the point of acquiring a product or service to fulfill that need. It involves multiple stages and interactions with a brand. Here is a summary of the steps in the customer journey:</p> <ul> <li> <p>Awareness: This is the stage where customers become aware of their needs and start searching for solutions. They   encounter multiple brands and products during this phase, and it's an opportunity for brands to make a good first   impression by providing valuable resources and educational content.</p> </li> <li> <p>Consideration: In the consideration stage, customers are actively researching and evaluating different brands and   products. They compare features, specifications, and customer support policies. Brands need to focus on promoting   their offerings and optimizing the user experience across touchpoints to stand out from competitors.</p> </li> <li> <p>Conversion/Purchase: The conversion stage is where customers make a specific action, such as making a purchase,   subscribing to a mailing list, or signing up for services. Brands need to convince potential customers that their   product is the best solution to their problem. Factors like price, value, customer service, and trustworthiness play a   role in the decision-making process.</p> </li> <li> <p>Retention: Once a customer has made a purchase, the goal is to retain them and build customer loyalty. This stage   involves keeping customers happy and satisfied with the product or service. Providing excellent customer support,   optimizing the transaction experience, and offering incentives can help retain customers and encourage them to become   repeat buyers.</p> </li> <li> <p>Advocacy: The final stage is advocacy, where satisfied customers become brand advocates and recommend the brand and   its products or services to others. Word-of-mouth recommendations and positive reviews are powerful in influencing   potential customers. Brands can encourage advocacy by engaging with customers, seeking their feedback, and   implementing loyalty programs.</p> </li> </ul> <p>Understanding the customer journey has several benefits for businesses, including:</p> <ol> <li>Improved customer experience: By mapping and analyzing the customer journey, businesses can identify pain points and    areas for improvement, leading to a better overall customer experience.</li> <li>Enhanced customer satisfaction: Meeting customer needs and expectations at each stage of the journey increases    customer satisfaction and loyalty.</li> <li>Increased customer retention: By focusing on customer retention strategies, businesses can retain existing customers,    leading to higher customer lifetime value and reduced acquisition costs.</li> <li>Better marketing and communication: Understanding the customer journey helps businesses deliver targeted and relevant    marketing messages across different communication channels, ensuring consistency and effectiveness.</li> <li>Competitive advantage: By providing a seamless and delightful customer journey, businesses can differentiate    themselves from competitors and attract more customers.</li> </ol> <p>Overall, the customer journey provides valuable insights into customer behavior, preferences, and interactions, enabling businesses to optimize their strategies and ultimately improve their bottom line.</p>"},{"location":"qa/what_is_data_partitioning/","title":"Understanding Data Partitioning in Tracardi","text":"<p>Data partitioning is a database management technique where a large dataset is divided into discrete segments, or partitions, which can be managed and accessed independently. This strategy is particularly useful for improving performance and managing data at scale.</p> <p>Tracardi, leverages data partitioning to handle its indices efficiently. Indices, which are essentially the databases for storing various types of data, can grow to be very large in volume. When such large indices are divided into smaller, time-based indices, it improves data manageability significantly. This approach facilitates:</p> <ul> <li>Improved Performance: Smaller indices are faster to read and write to, which enhances the overall system   performance.</li> <li>Easier Data Management: It's simpler to manage and archive data based on time-based criteria. For example, older   data that is less frequently accessed can be moved to cheaper, slower storage.</li> <li>Efficient Deletion: Purging old data becomes more straightforward and less resource-intensive when it's contained   within specific time-based partitions.</li> </ul> <p>In Tracardi, this partitioning method is applied to:</p> <ul> <li>Events: User actions and interactions that are recorded by the system.</li> <li>Profiles: Information about users, such as demographic data and preferences.</li> <li>Sessions: Data pertaining to a user's specific interaction session with a platform.</li> <li>Logs: System logs that record various events and transactions for monitoring and debugging purposes.</li> </ul>"},{"location":"qa/what_is_dot_notation/","title":"What is dot notation?","text":"<p>In short, dot notation is a way of referencing data in Tracardi. It is used to access data from the internal state of the workflow, such as the event, profile, payload, flow, session, and memory. It is written in the form of <code>&lt;source&gt;@&lt;path.to.data&gt;</code>, where the source is the type of data you are referencing and the path is a string of keys that indicate where the data is located.</p> <p>For example, if you wanted to access the data from the profile with the key <code>key.data</code>, the full dot notation would be <code>profile@key.data</code>. You can also use dot notation to access parts of data, such as everything below a certain key, or items in an array. In some cases, you may need to use dot notation to access data with keys that contain spaces, in which case you would use <code>profile@key[\"My key with spaces\"]</code>.</p> <p>For more information look for dot notation in the documentation.</p> <p>This document answers the following questions: - How to get profile, event, or session data? - How to reference profile, event, or session data? - How to get data from profile, event, session, memory, workflow.</p>"},{"location":"qa/what_is_ephemeral_event_source/","title":"What is ephemeral transactional event source?","text":"<p>An ephemeral transactional event source refers to a type of event source where the data received is not stored permanently in the system. Instead, it is processed and used only during the workflow. This approach allows for real-time processing and analysis of data without the requirement of long-term storage. The data is utilized within the workflow or system for immediate operations and insights, but it is not retained for the long term in the database.</p>"},{"location":"qa/what_is_ephemeral_event_source/#how-to-set-up-ephemeral-transactional-event-source","title":"How to set-up ephemeral transactional event source?","text":"<p>To set up an ephemeral transactional event source, follow these steps:</p> <ol> <li>Navigate to the <code>inbound traffic</code> / <code>event source</code> configuration settings.</li> <li>Locate the specific event source that you want to configure as ephemeral and access its settings.</li> <li>Look for the <code>advanced options</code> or advanced settings section within the event source configuration.</li> <li>Within the advanced options, you should find an option related to the transactional event type.</li> <li>Adjust the settings to enable the ephemeral mode for the event source. </li> <li>Save the changes to apply the ephemeral transactional settings to the event source.</li> </ol> <p>By following these steps, you can configure the event source as ephemeral, ensuring that the data received through this source is not stored permanently but is processed and used only for the duration of the workflow or a limited period of time.</p>"},{"location":"qa/what_is_event/","title":"What is event?","text":"<p>In the context of Tracardi, an event refers to a piece of data that represents an action, occurrence, or happening within a system. Events are fundamental units of data collected and processed by Tracardi to analyze user behavior, system interactions, and other activities. Each event contains specific characteristics or attributes, known as event properties, which provide valuable information about the event, such as its timestamp, source, and relevant details.</p> <p>Tracardi uses events to track and understand user interactions, record system activities, and trigger specific workflows based on event data. Events play a crucial role in data processing and analysis, enabling businesses to gain insights into user journeys, detect patterns, and make informed decisions based on the data collected from various sources.</p> <p>Event consist of:</p> <ol> <li> <p>Event Properties:</p> <ul> <li>Characteristics or attributes of an event that can be recorded and analyzed.</li> <li>Provide valuable information about the event, such as time, location, participants, and relevant context.</li> </ul> </li> <li> <p>Event Traits:</p> <ul> <li>Characteristics of an event that are indexed in the system for analysis and aggregation.</li> <li>Structured in a way that allows effective searching, analysis, and aggregation.</li> <li>Event data is moved from properties to traits for better analysis.</li> <li>Provide insights into user behavior, patterns, and correlations in the data.</li> </ul> </li> <li> <p>Profile-less Event:</p> <ul> <li>An event that cannot be assigned to any specific profile or user.</li> <li>Lacks sufficient information to identify a particular user associated with the event.</li> <li>Still useful for understanding the user journey but may not provide as much context as profiled events.</li> </ul> </li> <li> <p>Event Context:</p> <ul> <li>Data not directly connected to event properties or traits but provides additional context.</li> <li>Offers background information relevant to understanding the event's circumstances.</li> </ul> </li> <li> <p>Event States:</p> <ul> <li>Events can have different states based on their processing status.</li> <li>States include: \"collected\" (event was collected), \"processed\" (event was processed), \"warning\" (workflow logged   warnings), \"error\" (workflow returned errors), and \"ok\" (event was processed without errors).</li> </ul> </li> </ol>"},{"location":"qa/what_is_event/#event-processes","title":"Event processes","text":"<ol> <li> <p>Event Routing:</p> <ul> <li>Process of directing events to specific workflows or processes based on their type and source.</li> <li>Allows businesses to handle different types of events differently and route them to appropriate workflows.</li> </ul> </li> <li> <p>Events Synchronization:</p> <ul> <li>Process of managing the order in which events are processed in Tracardi.</li> <li>Ensures events for a specific profile are processed sequentially, while events for different profiles are   processed sequentially but in parallel to each other.</li> </ul> </li> </ol> <p>In summary, events in Tracardi carry various properties and traits, and they can be routed and synchronized to undergo different workflows for analysis and processing. The information gathered from events helps businesses gain valuable insights into user behavior and make informed decisions based on the data collected.</p>"},{"location":"qa/what_is_event_context/","title":"What is event context?","text":"<p>Event context refers to additional information or data that provides a broader context for an event. It includes pertinent details that help to better understand the circumstances surrounding the event. The specific content of event context can vary depending on the nature of the event and the requirements of the system or application.</p> <p>Event context serves to enrich the event data with supplementary metadata that offers a wider perspective on the event's occurrence. This additional data can take the form of contextual tags, event categories, or any custom contextual information specific to the application or system. It allows for a more comprehensive understanding of the event's significance and its relationship to other events or processes within the system.</p> <p>In essence, event context provides background information that gives meaning and relevance to the event, facilitating better analysis, tracking, and decision-making within the system or application.</p>"},{"location":"qa/what_is_event_property/","title":"What is event property?","text":"<p>An event property refers to a specific attribute or characteristic that provides relevant details about an event. It contains the actual data associated with the event and can vary depending on the nature of the event and the specific requirements of the system or application. Event properties play a crucial role in enriching the event data, allowing for a more detailed and meaningful representation of the event within the system or application.</p> <p>For example, event properties can include information about the user involved in the event, such as user ID, username, email address, or any other relevant user identifiers. They can also capture specific aspects of the event, such as quantity, price, duration, location, or any other measurable or meaningful attributes. Additionally, event properties may include flags or indicators that reflect the status or outcome of the event, such as success, failure, pending, or in-progress. Furthermore, they can contain additional contextual information or metadata that provides further insights into the event, such as event source, event category, or any custom-defined metadata specific to the application or system.</p>"},{"location":"qa/what_is_event_redirect/","title":"What is event redirect","text":"<p>Event Redirects</p> <p>Overview: Event redirects are a type of event source that enables you to create a clickable link. When this link is clicked, it triggers a specific event in Tracardi and redirects the user to a designated URL.</p> <p>How It Works:</p> <p>You can generate an event redirect link in the following format:</p> <pre><code>http://api.tracardi.com/redirect/{redirect-identifier}/{optional-session-id}\n</code></pre> <ul> <li><code>{redirect-identifier}</code>: A unique identifier for the redirect you want to trigger.</li> <li><code>{optional-session-id}</code>: An optional session identifier that can be attached to the link.</li> </ul> <p>Example:</p> <p>Let's break down an example to illustrate how event redirects work:</p> <ul> <li> <p>You create a link like this:   <pre><code>http://api.tracardi.com/redirect/d81c184a-eb5d-4f9e-b0f0-4b62bf7066dd/{optional-session-id}\n</code></pre></p> </li> <li> <p>When a customer clicks the above link, they will be redirected to (this is defined by user):   <pre><code>https://join.slack.com/t/tracardi/shared_invite/abcd\n</code></pre></p> </li> <li> <p>Simultaneously, a \"slack-invite-link\" event will be registered in Tracardi, including the specified properties.</p> </li> </ul> <p>Session-ID Attachment:</p> <p>You have the option to attach a session identifier to the link. Here's why you might want to do that:</p> <ul> <li> <p>If you're working with a specific user profile and have their session ID, attaching it to the link ensures that the   event triggered by the link is automatically associated with that profile and its current session.</p> </li> <li> <p>Tracardi profiles can be loaded using either their profile ID or one of their session ID. So, if you're running a workflow for a   particular profile and want to send an email with a link that, when clicked, registers an event in Tracardi, attach   the session ID. This way, the click event will be seamlessly linked to the profile and its ongoing session.</p> </li> </ul> <p>In essence, event redirects offer a straightforward way to capture user interactions, trigger events, and maintain associations with user profiles and sessions in Tracardi.</p>"},{"location":"qa/what_is_event_source/","title":"What is event source?","text":"<p>Event source refers to incoming traffic, which consists of systems that are capable of sending data to Tracardi. These systems can include websites, internal systems, and various services. Tracardi identifies and logs this inbound traffic, assigning it a unique identifier to track its origin and behavior.</p> <p>An event source serves as a bridge between the external system and Tracardi. It collects data from a specific source, such as a queue, email, or social media, and transfers it to Tracardi for further processing. For instance, Tracardi can use an API bridge to collect data from an API's \"/track\" endpoint and bring it into the system. Depending on the version of Tracardi being used, there may be different types of bridges, such as a Kafka bridge, designed to collect data from a Kafka message broker.</p> <p>When setting up a new project with Tracardi, it is essential to create a new event source. This event source provides an identifier that can be attached to track calls, enabling the collection of data about users. However, it's worth noting that an event source can be configured as ephemeral, meaning the data received through this type of event source is not stored permanently in the system. Instead, it is used and processed by the workflow in real-time, without the need for long-term storage.</p> <p>Important to consider is that certain sources may require user consent before collecting and storing their data. For example, a web page might need user consent to gather and retain their data for processing.</p>"},{"location":"qa/what_is_event_tag/","title":"What is event tag?","text":"<p>An event tag is a label or identifier that is associated with a specific event to categorize and organize it based on certain attributes or characteristics. Event tags serve as metadata that provides additional information about the event, making it easier to search, filter, and analyze events with similar tags.</p> <p>Event tags are customizable and can be used to represent various aspects of the event, such as its type, status, location, or any other relevant attribute. They offer a way to group events together based on common properties, facilitating better organization and management of event data.</p> <p>For example, in Tracardi, events related to product purchases could be tagged with labels like \" purchase,\" \"transaction,\" or \"completed order.\" Some events in Tracardi are automatically tagged to create a customer journey map, providing a visual representation of how customers engage over time.</p>"},{"location":"qa/what_is_event_traits_schema/","title":"What schema has event traits?","text":"<p>Event traits may have any schema. You bild the schema when you copy data from event properties.</p>"},{"location":"qa/what_is_major_version_upgrade/","title":"What is major version upgrade?","text":"<p>A major version upgrade refers to a significant update or release of a software system that introduces substantial changes, including modifications to the underlying database structure.</p> <p>In the context of Tracardi, a major version upgrade is indicated by a change in a number other than the last one in the version. For example, upgrading from version 0.8.0 to version 0.8.1 would be considered a major upgrade.</p> <p>During a major version upgrade of Tracardi, there may be changes to the database schema or data structure. These changes often require data migration or data schema updates to ensure that the system functions properly with the new version. Tracardi handles data migration during major upgrades using Elasticsearch's reindexing process.</p> <p>The upgrade process typically involves running two copies of the system: one with the old version and one with the new version. The migration process moves the data from the old version to the new version while ensuring data integrity and consistency. Once the migration is complete, the Docker tag can be upgraded, and the system will automatically switch to the new version.</p> <p>It's important to note that major upgrades may require additional effort and planning compared to minor upgrades. Tracardi provides migration scripts for all major versions, which help facilitate the upgrade process and ensure proper data migration. However, skipping versions during major upgrades is not supported, and it's recommended to follow the upgrade path version by version for data integrity and system stability.</p>"},{"location":"qa/what_is_merge_strategy_fallback/","title":"What is Merge Strategy Fallback?","text":"<p>A merge strategy fallback is a method used when the primary merge strategy cannot be applied due to missing or incomplete data. For instance, if the update time of a field is missing, the Last Update Strategy cannot be used, and an alternative strategy must be selected. Priorities for fallback strategies can be set within the system for each field in the profile, ensuring that there is always a method available to resolve conflicts in data merging.</p>"},{"location":"qa/what_is_merging_strategy/","title":"What is merging strategy?","text":"<p>The merging strategy in Tracardi is the method or algorithm used for combining different profiles or events to form a single cohesive profile. It is one of the predefined methods that the system will use in case there is conflicting data in the set of profiles that need to be merged into a single profile. An example of a strategy is an algorithm that prioritizes the last update made to a profile, regardless of the channel from which the data was collected.</p>"},{"location":"qa/what_is_merging_strategy/#example-of-merging-strategy","title":"Example of Merging Strategy","text":"<p>One of the strategies is Last Profile Update Wins.This strategy ensures that the most recent information is retained when merging profiles. It prioritizes the last update made to a profile, regardless of the channel that the data was collected from. This approach is useful when you want to ensure that the most current data is always reflected in the unified profile.</p>"},{"location":"qa/what_is_merging_strategy/#example-scenario","title":"Example Scenario","text":"<p>Consider three profiles with the following attributes:</p> <ul> <li> <p>Profile A:</p> <ul> <li>Name: John Doe</li> <li>Email: john.doe@example.com</li> <li>Last Profile Updated: 2024-01-01</li> </ul> </li> <li> <p>Profile B:</p> <ul> <li>Name: Jonathan Doe</li> <li>Email: jon.doe@example.com</li> <li>Last Profile Updated: 2024-02-01</li> </ul> </li> <li> <p>Profile C:</p> <ul> <li>Name: John Doe</li> <li>Email: johnny.doe@example.com</li> <li>Last Profile Updated: 2024-03-01</li> </ul> </li> </ul> <p>Using the Last Profile Update Wins Strategy:</p> <ol> <li>Identify Profiles to Merge: Profiles A, B, and C.</li> <li>Compare Timestamps:<ul> <li>Profile A: 2024-01-01</li> <li>Profile B: 2024-02-01</li> <li>Profile C: 2024-03-01</li> </ul> </li> <li>Prioritize Recent Data:<ul> <li>Name: John Doe (Profile C)</li> <li>Email: johnny.doe@example.com (Profile C)</li> </ul> </li> <li>Merge Data:<ul> <li>Name: John Doe</li> <li>Email: johnny.doe@example.com</li> </ul> </li> <li>Update Unified Profile:<ul> <li>The unified profile will now have the name \"John Doe\" and the email \"johnny.doe@example.com,\" reflecting the most   recent updates.</li> </ul> </li> </ol> <p>By following this strategy, Tracardi ensures that the most up-to-date information is always present in the unified profile, providing a reliable and current view of the user.</p>"},{"location":"qa/what_is_minor_version_upgrade/","title":"What is minor version upgrade?","text":"<p>A minor version upgrade refers to an update or release that introduces new features, improvements, and bug fixes to a software system, but does not involve any changes in the underlying database structure.</p> <p>In the context of Tracardi, a minor version upgrade is indicated by a change in the last number of the version. For example, upgrading from version 0.8.1.x to version 0.8.1.y would be considered a minor upgrade.</p> <p>During a minor version upgrade of Tracardi, the system can be updated simply by upgrading the Docker tag to the new version. This means that you can change the version number in the Docker tag to the desired minor version, and the system will continue to work as it did before the upgrade.</p> <p>Since there are no changes in the database structure, data migration is not required during a minor upgrade. The upgrade process mainly involves updating the software and taking advantage of the new features and bug fixes introduced in the new version.</p> <p>It's important to regularly perform minor version upgrades to ensure that your Tracardi system stays up-to-date with the latest improvements and enhancements provided by the software.</p>"},{"location":"qa/what_is_misc_data/","title":"What is Miscellaneous data in profile.","text":"<p>Miscellaneous data, often referred to as \"misc data,\" is a term used to describe data that does not have a specific category or purpose and does not need to be searched or indexed. It is typically used to store information that is not critical for the functioning or analysis of the system but may still be relevant for certain operations or processes.</p> <p>Misc data can include various types of information, such as operational flags, temporary variables, non-critical settings, or any other data that does not require specific grouping, indexing, or structured storage. It provides a flexible storage option for data that doesn't fit into predefined schemas or established data models.</p> <p>While misc data may not have a predefined structure or standardized format, it can still be useful for storing transient or context-specific information that is needed for specific tasks or operations within an application or system.</p>"},{"location":"qa/what_is_multi_tenant_setup/","title":"What is multi-tenant set up?","text":""},{"location":"qa/what_is_multi_tenant_setup/#multi-tenant-setup-in-tracardi","title":"Multi-Tenant Setup in Tracardi","text":"<p>In the context of Tracardi, a multi-tenancy setup refers to a system configuration where a single instance of the software serves multiple customers or \"tenants.\" Each tenant's data is isolated and kept separate from other tenants, ensuring privacy and security. However, the software instance and underlying resources, such as CPU, memory, and storage, are shared between all tenants.</p> <p>A multi-tenancy setup allows multiple different users to utilize a single Tracardi system while ensuring that each user has their own dedicated space for data storage and operations. This segregation of data and operations ensures that tenants' activities and information remain independent and inaccessible to others, maintaining a high level of data privacy and security.</p>"},{"location":"qa/what_is_post_collection_remapping/","title":"Difference between 'Assign data to profile from event' and a workflow to map data from event to profile","text":"<p>The key difference is when the data is processed. A workflow maps data from events to profiles in real-time as the events arrive. This ensures that profiles are immediately updated with the latest information. On the other hand, ' Assign data to profile from event' allows you to perform this mapping on already collected events. It's useful when you haven't set up the mappings initially and want to retrospectively update profiles with historical data.</p>"},{"location":"qa/what_is_post_collection_remapping/#does-reindexing-simply-mean-mapping-event-properties-to-event-traits-if-yes-how-does-it-differ-from-a-workflow-too","title":"Does reindexing simply mean mapping event properties to event traits? If yes, how does it differ from a workflow too","text":"<p>Yes, reindexing involves mapping event properties to event traits, but it is typically done after the data has already been collected. For instance, if you forgot to index the \"purchase order value\" and now want to be able to search for it, you would need to reindex the data. Reindexing updates the data in a batch process, converting properties to traits for older, already collected data.</p> <p>In contrast, a workflow maps event data to profiles in real-time as new events arrive. So, while both reindexing and workflows involve mapping data, the key distinction is that reindexing is a batch process for historical data, whereas workflows process data as it comes in, keeping profiles updated in real-time.</p>"},{"location":"qa/what_is_profile/","title":"What is profile?","text":"<p>In the context of Tracardi, a profile refers to a detailed record or representation of a person. It contains information about characteristics, interests, and activities. The profile is updated based on incoming events and data from external systems, and it includes both public and private data.</p> <p>Tracardi collects data from customer journeys. These interactions are captured as events. Each event is assigned to a profile that is maintained throughout the customer interaction. Tracardi aggregates customer journey data in the profile using a graphical editor, where the administrator defines the method of attaching data to the profile.</p>"},{"location":"qa/what_is_session/","title":"What is session?","text":"<p>In Tracardi, a session refers to a specific period of time during which a user interacts with a website or application. It is used to track and group the actions and behavior of a user within that timeframe. Sessions are important for analyzing user engagement, understanding user journeys, and providing personalized experiences.</p> <p>When a user visits a website or application integrated with Tracardi, a session ID is assigned to that user. This session ID is typically stored in a cookie on the user's device, or in memory. The session ID allows Tracardi to recognize and associate the user's actions and events within a specific session.</p> <p>Tracardi calculates visits based on the continuity of the session ID. If the session ID remains the same, it indicates that the user is still actively engaged with the website or application, and Tracardi considers it as part of the same visit. However, if the user closes their browser or the session expires, the session ID is deleted, and a new session begins when the user revisits the site.</p> <p>By tracking sessions, Tracardi can provide insights into various aspects of user behavior, such as session duration, page views per session, entry and exit points, and conversion rates. </p>"},{"location":"qa/what_is_the_archtecture_of_tracardi/","title":"What is the architecture of Tracardi?","text":"<p>Tracardi is a distributed system that consists of several components working together to track and analyze customer data. The core components of Tracardi include:</p> <ul> <li>an ElasticSearch database for storing events,</li> <li>a Redis server for caching,</li> <li>a RESTful API,</li> <li>a graphical user interface (GUI) for end-users.</li> </ul> <p>Additionally, Tracardi includes background workers that perform background processes such as importing and segmentation.</p>"},{"location":"qa/what_is_the_archtecture_of_tracardi/#communication","title":"Communication","text":"<p>The GUI connects to the API, which in turn connects to the database. Tracardi components can be installed and run separately, and multiple replicas of each component can be activated to meet the needs of the business.</p> <p>For the system to work fully, at least four elements must be activated, including the database, API, GUI, and the background import worker. The architecture allows for additional elements such as microservices, data bridges and background processes for profile merging and segmentation.</p>"},{"location":"qa/what_is_the_cost_of_tracardi/","title":"What is the cost of Tracardi?","text":"<p>Tracardi's cost varies depending on your usage and requirements. It offers a free open-source version for individuals and small companies, providing comprehensive features and AI-driven insights. If you plan to sell Tracardi as a SaaS platform or for larger-scale operations, there is a commercial open-source version with additional features and tailored support.</p> <p>To get specific pricing information based on your needs, it's best to contact Tracardi directly. However, it's worth noting that Tracardi is generally more cost-effective compared to other commercial platforms, with costs reported to be 5 to 50 times lower. Keep in mind that hosting costs are not included, as Tracardi is an on-premises solution.</p>"},{"location":"qa/what_is_the_difference_between_bridge_and_event_source/","title":"What is the difference between bridge and event source?","text":"<p>In the context of Tracardi, a bridge and an event source are two distinct components that serve different purposes in the data processing workflow:</p> <ol> <li> <p>Bridge:</p> <ul> <li>Purpose: A bridge acts as a connector or intermediary between an external data source and Tracardi's event   processing system.</li> <li>Function: Its main function is to collect data from a specific source, such as an API, queue, email, social media,   or other external systems, and transfer that data to Tracardi's event sources.</li> <li>Data Transfer: The bridge is responsible for transferring data from the external system into Tracardi, making it   available for further processing within the platform.</li> <li>Examples: Tracardi might come with different bridges, such as an API bridge that collects data from an API's   endpoint or a Kafka bridge that collects data from a Kafka message broker.</li> </ul> </li> <li> <p>Event Source:</p> <ul> <li>Purpose: An event source in Tracardi refers to incoming traffic and represents the system or source that sends   data to Tracardi for processing.</li> <li>Function: It is responsible for receiving data from the bridge and providing Tracardi with a unique identifier to   track the origin and behavior of the incoming data.</li> <li>Data Processing: Once the data is received from the bridge, the event source handles the data, allowing Tracardi   to further process and analyze it within its workflows.</li> <li>Configuration: When setting up a new project in Tracardi, users must create a new event source that provides an   identifier to be attached to track calls for data collection.</li> <li>Authentication: Event source creates a token in form if event source id. Which is used to authorize the received data.</li> </ul> </li> </ol> <p>In summary, a bridge serves as a communication link between external data sources and Tracardi, enabling the transfer of data from the external systems into the platform. On the other hand, an event source represents Tracardi's capability to receive data and process it as part of its workflows, allowing for data analysis and real-time processing. The bridge is responsible for bringing the data into Tracardi, while the event source handles the data once it is inside the platform.</p>"},{"location":"qa/what_is_the_difference_between_event_traits_and_properties/","title":"What is the difference between event traits and properties and what is event indexing?","text":"<p>Event traits and properties are both characteristics of an event in Tracardi, but they differ in their structure and purpose.</p> <p>Event properties are the basic characteristics of an event that can be recorded and searched, but they cannot be directly aggregated. Properties have the characteristic of being able to save any data, even if there is a collision in data type. A collision in data types occurs when the data is sent as a number in one instance and as a string in another instance. For example, \"Age\" can be sent as the number 24 or the string \"24 years old.\" Properties are able to store this data even if it is inconsistent or has different data types.</p> <p>Event traits, on the other hand, are structured and have data types. Event traits are used for searching, analyzing, and aggregating events. If the data is inconsistent or has an incorrect data type, such as having \"Age\" as a number but receiving it as a string (\"24 yeas old\"), Tracardi will throw an error and not index it. Data in traits have structure and types, allowing for aggregation, such as calculating the average age based on the \"age\" trait.</p> <p>To summarize, if an event includes a property, that property could be copied to a trait so that all events involving this attribute could be identified and aggregated. Copied property gets removed from properties, and it is moved to traits.  Properties allow for recording and searching, while traits enable analysis and aggregation with structured indexing. Not all data must be moved from properties to traits only the one you think you will need to aggregate the events.</p> <p>This document answers the following questions: - What is event indexing? - What is event indexing used for? - How can I aggregate data in events? - Why I can not aggregate data in events?</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/","title":"What is the difference between Open-source and CCommercial Tracardi.","text":"<p>Tracardi is a powerful customer journey automation tool that offers both an open-source version for internal use and a commercial version tailored for business purposes. The commercial version of Tracardi features a different engine that allows parallel processing of events, making it suitable for enterprise-level applications. In this article, we will delve into the unique features provided by the commercial version, which are designed to streamline customer engagement and optimize workflows.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#unique-features-of-the-commercial-version","title":"Unique Features of the Commercial Version","text":""},{"location":"qa/what_is_the_difference_between_os_and_commercial/#parallel-processing","title":"Parallel Processing","text":"<p>The commercial version of Tracardi offers parallel event processing, enabling it to handle higher traffic volumes efficiently. This advanced capability ensures that multiple events can be processed simultaneously, significantly enhancing the system's performance and scalability. Here's how parallel processing benefits enterprise-level applications:</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#high-throughput","title":"High Throughput","text":"<p>With the ability to process multiple events in parallel, Tracardi can manage a large number of events per second. This high throughput is essential for businesses dealing with vast amounts of customer interactions, ensuring that no event is missed or delayed.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#improved-performance","title":"Improved Performance","text":"<p>Parallel processing reduces the time taken to handle each event, resulting in faster response times. This improved performance is crucial for real-time customer engagement, where timely interactions can lead to higher customer satisfaction and conversion rates.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#scalability","title":"Scalability","text":"<p>The commercial version's parallel processing capabilities allow it to scale seamlessly with growing business needs. As the volume of events increases, Tracardi can efficiently distribute the load across multiple processing units, maintaining optimal performance without requiring significant infrastructure changes.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#streamlined-configuration","title":"Streamlined Configuration","text":"<p>The commercial version of Tracardi offers a simplified configuration process, making it effortless to set up and maintain. With a user-friendly interface, businesses can quickly adapt the tool to their specific requirements, saving time and effort in the long run.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#advanced-time-based-event-handling","title":"Advanced Time-Based Event Handling","text":"<p>Time-based event handling is crucial for effective customer journey automation. The commercial version enhances this capability by enabling users to execute processes triggered by specific time intervals. For instance, you can automatically check if a customer has made a purchase after leaving your page and send personalized follow-up messages, such as a reminder, 20 minutes later.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#expanded-event-collectors","title":"Expanded Event Collectors","text":"<p>Tracardi\u2019s commercial version provides additional event collectors that can gather data from various sources like Kafka, RabbitMQ, IMAP, MQTT, and more. This broadens the scope of data collection, allowing businesses to leverage insights from diverse platforms and systems.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#validating-transforming-and-copying-events","title":"Validating, Transforming, and Copying Events","text":"<p>Events collected through Tracardi can undergo validation, transformation, and automatic copying to customer profiles. This ensures that the data is accurate, consistent, and readily accessible for further analysis and action.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#intelligent-profile-merging","title":"Intelligent Profile Merging","text":"<p>Profiles within the commercial version of Tracardi are automatically merged based on identification points. Even before an event reaches the workflow, relevant profile data is consolidated, providing a comprehensive view of each customer\u2019s journey.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#extensive-action-plugins","title":"Extensive Action Plugins","text":"<p>Tracardi\u2019s commercial version offers an array of action plugins to enhance workflow functionality. Let\u2019s explore a few examples:</p> <ul> <li>Pause and Resume: Temporarily halt a workflow and resume it after a specified time. Useful for contacting   customers later, such as sending reminders about abandoned items in their shopping cart or offering time-limited   discounts.</li> <li>Limiter: Controls the number of workflow launches within a defined period to prevent overloading and manage   resource-intensive plugins efficiently.</li> <li>Load Data Report: Create customized reports focused on customer data, empowering businesses to gain valuable   insights into purchase trends, customer behavior, and aggregated information.</li> <li>Geo Distance or Geo Fencing: Trigger location-based actions tailored to a customer\u2019s geographic position, enabling   geographically targeted marketing campaigns or personalized recommendations.</li> <li>Event Aggregator: Aggregate and analyze data from specific events to gain deeper insights into customer behavior   patterns and trends.</li> <li>Event Counter: Track the number of events in a customer\u2019s history, enabling businesses to identify patterns and   prioritize actions based on event frequency.</li> <li>Multiple Segmentation Plugins: Utilize segmentation plugins to remember past segments and apply them in subsequent   workflows, enabling more sophisticated segmentation algorithms.</li> <li>Event Sequencing Matching: Identify specific sequences of events in a customer\u2019s history to trigger tailored   actions, such as detecting interest in a product without making a purchase and prompting personalized follow-up   offers.</li> </ul>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#enhanced-data-management","title":"Enhanced Data Management","text":"<p>The commercial version enables saving and loading of additional data into the entity\u2019s database. This feature allows businesses to store supplementary information such as email records, product purchases, and more, enhancing data-driven decision-making.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#intelligent-session-handling","title":"Intelligent Session Handling","text":"<p>Automatically closes a customer\u2019s session or visit upon leaving your page. This enables the binding of workflows triggered by a customer\u2019s exit, opening up new possibilities for time-based workflows. Businesses can leverage this feature to deliver targeted messages or offers based on customer behavior and interaction with their website.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#automated-segmentation-and-profile-management","title":"Automated Segmentation and Profile Management","text":"<p>Facilitates automated segmentation of customer profiles. Users can schedule segmentation processes to run at specified intervals, allowing them to move profiles from one segment to another based on profile activity or inactivity.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#archiving-inactive-profiles","title":"Archiving Inactive Profiles","text":"<p>With the commercial version, businesses can archive inactive profiles. This feature helps declutter the active profile list and focus on engaged customers. Archiving inactive profiles also helps streamline workflows and maintain a clean database, ensuring efficient data management.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#retroactive-data-processing","title":"Retroactive Data Processing","text":"<p>Allows businesses to process historical data and copy it to profiles or index event data, even if the events were collected before the corresponding workflows were created. This capability enables businesses to retroactively leverage previously collected data, ensuring comprehensive customer data analysis and personalized communication based on historical information.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#enhanced-user-experience-with-uix-widgets","title":"Enhanced User Experience with UIX Widgets","text":"<p>Offers UIX (User Interface Experience) widgets that enable businesses to inject interactive forms into their customer journey. These widgets can measure customer satisfaction at specific event touchpoints, such as using a rating widget to provide feedback on their experience at different stages of their journey. This valuable data helps businesses understand customer sentiments and improve their overall experience.</p>"},{"location":"qa/what_is_the_difference_between_os_and_commercial/#summary","title":"Summary","text":"<p>Tracardi\u2019s commercial version provides an extensive range of features designed to enhance customer journey automation and streamline business operations. From simplified configuration to advanced time-based event handling, additional event collectors, and a wide array of action plugins, businesses can harness the power of Tracardi to deliver personalized, targeted experiences to their customers. With intelligent profile merging, retroactive data processing, and enhanced user experience through UIX widgets, Tracardi\u2019s commercial version empowers businesses to optimize their workflows, gain deeper insights into customer behavior, and drive meaningful engagement. By leveraging these enhanced features, businesses can elevate their customer journey automation strategies and achieve superior results in today\u2019s competitive landscape.</p>"},{"location":"qa/what_is_the_difference_between_redirect_and_param_link/","title":"What is the difference between redirect link and parametrized link in tracardi?","text":"<p>In Tracardi, redirect links and parameterized links serve similar purposes. They are used to customer journey:</p>"},{"location":"qa/what_is_the_difference_between_redirect_and_param_link/#redirect-links","title":"Redirect Links","text":"<p>Redirect links in Tracardi are used primarily to track user interactions by redirecting them through a specified URL before reaching the final destination. These links help in gathering valuable data about user interactions and link activities.</p> <p>Key Features:</p> <ol> <li>Tracking Clicks: When a user clicks on a predefined link, they are redirected to a designated URL.    Simultaneously, Tracardi receives an event containing information about the redirect and any predefined event    properties.</li> <li>Link Format: The links follow a specific format: <code>http://&lt;tracardi-api-url&gt;/redirect/&lt;redirect-id&gt;</code>.</li> <li>Session Association: It's possible to include a session ID in the redirect link to associate the click with a    specific user session, which allows to retrieve a profile that started the session. This way system identifies the customer/user that clicked the link..</li> <li>Hidden Link URL: Contrary to the next method the Redirect Link hides the target link.</li> </ol> <p>Usage Example:</p> <pre><code>http://&lt;tracardi-api-url&gt;/redirect/&lt;redirect-id&gt;/&lt;session-id&gt;\n</code></pre> <p>This format allows Tracardi to associate the click with the profile that corresponds to the specified session ID.</p>"},{"location":"qa/what_is_the_difference_between_redirect_and_param_link/#parameterized-links","title":"Parameterized Links","text":"<p>Parameterized links in Tracardi include specific parameters in the URL to track and identify user interactions.  These parameters can include profile IDs, source IDs, and other relevant data such as session ID, that help in identifying the user and their session across different interactions.</p> <p>Key Features:</p> <ol> <li>Profile and Source ID: By adding parameters like <code>__tr_pid</code> (profile ID) and <code>__tr_src</code> (source ID) to the URL,    you can ensure that the interactions are tracked with the correct user profile and source. This is useful when redirecting users from emails or other sources and ensuring that the    specific user's activity is tracked by Tracardi.</li> <li>Requires JavaScript tracker on the target page: The parameterized links work only when the target page has JavaScript snippet installed.</li> </ol> <p>Usage Example:</p> <pre><code>http://example.com?__tr_pid=&lt;profile-id&gt;&amp;__tr_src=&lt;source-id&gt;\n</code></pre> <p>This format ensures that the user's activity is tracked and associated with the correct profile and source ID.</p>"},{"location":"qa/what_is_the_difference_between_redirect_and_param_link/#differences","title":"Differences","text":"<p>Both methods are similar, but they differ in who sends the event to the system. In Redirected Links, Tracardi handles the event since the link is within the system and it does not need the Javascript to be installed on web page. In the second method, the script located at the target page is responsible for sending the event.</p>"},{"location":"qa/what_is_the_difference_between_tracardi_and_segment/","title":"What is the difference between Tracardi and Segment.com","text":"<p>Tracardi and Segment.com are both customer data platforms (CDPs) that provide solutions for collecting, managing, and utilizing customer data. While they share some similarities, there are several key differences between the two platforms. Here are five distinctions:</p> <ol> <li> <p>Approach to Data Integration:</p> <ul> <li>Tracardi: Tracardi focuses on real-time data integration, allowing you to capture and process customer data as it   happens, enabling immediate personalization and automation.</li> <li>Segment.com: Segment.com supports batch and real-time data integration, offering more flexibility in terms of how   and when you collect and process customer data.</li> </ul> </li> <li> <p>User Interface and Ease of Use:</p> <ul> <li>Tracardi: Tracardi emphasizes simplicity and ease of use, providing a user-friendly visual interface that allows   marketers and non-technical users to create complex customer journeys without coding.</li> <li>Segment.com: Segment.com provides a comprehensive but more technical user interface, catering to developers.</li> </ul> </li> <li> <p>Automation and Personalization Capabilities:</p> <ul> <li>Tracardi: Tracardi specializes in automation and personalization, offering advanced features such as dynamic   content delivery, real-time decision-making, and predictive analytics to create tailored customer experiences.</li> <li>Segment.com: While Segment.com supports automation and personalization to some extent, its primary focus is on   data collection and management, serving as a powerful data pipeline for downstream systems rather than an   automation-centric platform.</li> </ul> </li> <li> <p>Pricing Structure:</p> </li> <li>Tracardi: Tracardi follows a fixed monthly payment model for its commercial version, regardless of the amount of data collected or the number of customer data points processed.</li> <li> <p>Segment.com: In contrast, Segment.com offers a more flexible pricing structure that takes into account factors such as the volume of data tracked, the number of integrations utilized, and any additional features required. It also provides a free tier specifically designed for low data volumes.</p> </li> <li> <p>Third-Party Integrations:</p> <ul> <li>Tracardi: Tracardi offers a range of native integrations with popular marketing tools and platforms, allowing   seamless connectivity and data exchange.</li> <li>Segment.com: Segment.com boasts an extensive library of over 300 integrations with various third-party tools and   services, enabling easy data sharing and activation across multiple platforms.</li> </ul> </li> <li> <p>Deployment Model:</p> </li> <li>Tracardi: Tracardi provides on-premise deployment options. The on-premise option allows organizations to host      Tracardi on their own servers, providing greater control and customization over the platform.</li> <li> <p>Segment.com: Segment.com primarily operates as a cloud-based SaaS platform. It handles all the infrastructure and      maintenance, allowing users to access and utilize the platform through a web browser without the need for local      installation or management. Certainly! Here are two additional differences between Tracardi and Segment.com:</p> </li> <li> <p>Source Code Availability:</p> </li> <li> <p>Tracardi: Tracardi offers an open-source version of its platform, allowing users to access and modify the source      code according to their specific needs. This provides flexibility and the ability to customize the platform's      functionality and integrations.</p> </li> <li> <p>Segment.com: Segment.com is a closed-source platform, meaning that the source code is not publicly available for      modification. Users rely on the provided functionality and customization options within the platform without the      ability to make direct changes to the underlying codebase.</p> </li> </ol>"},{"location":"qa/what_is_the_difference_between_zapier_and_tracardi/","title":"What is the difference between zapier and tracardi","text":"<p>Zapier and Tracardi are both automation platforms that enable users to connect different apps and services, but they have some notable differences:</p> <ol> <li> <p>Focus and Use Cases:</p> <ul> <li>Zapier: Zapier primarily focuses on task automation and integration between various web applications. It allows   users to create \"Zaps,\" which are automated workflows that trigger actions between different apps based on   specified triggers and actions.</li> <li>Tracardi: Tracardi, on the other hand, is a customer data platform (CDP) that specializes in customer data   management, personalization, and automation. It enables users to collect, analyze, and utilize customer data to   create targeted campaigns, personalized experiences, and automated customer journeys.</li> </ul> </li> <li> <p>Data-centric vs. App-centric:</p> <ul> <li>Zapier: Zapier revolves around integrating and automating actions between apps. It focuses on moving data and   triggering actions across various applications, allowing users to streamline their workflows and eliminate manual   tasks.</li> <li>Tracardi: Tracardi places more emphasis on managing and utilizing customer data. It provides tools for data   collection, segmentation, analysis, and automation based on customer behavior, enabling personalized experiences.</li> </ul> </li> <li> <p>Data Manipulation and Personalization:</p> <ul> <li>Zapier: While Zapier can transfer data between apps, it has limited data manipulation capabilities. It mainly   focuses on passing data from one app to another without extensive data transformations or advanced personalization   features.</li> <li>Tracardi: Tracardi offers robust data manipulation capabilities, including data enrichment, transformation, and   advanced personalization. It enables users to create dynamic customer profiles, leverage real-time data, and   deliver personalized experiences based on customer attributes and behavior.</li> </ul> </li> <li> <p>Integration Options:</p> <ul> <li>Zapier: Zapier has a vast library of pre-built integrations with over 3,000 apps, making it easy to connect   popular services without the need for complex coding or development.</li> <li>Tracardi: Tracardi provides native integrations with popular marketing tools and platforms, allowing seamless   connectivity for data exchange. Additionally, it offers REST API and webhooks, enabling custom integrations with   any application or service.</li> </ul> </li> <li> <p>Workflow Complexity:</p> <ul> <li>Zapier: Zapier is designed for relatively simple automation workflows that involve basic triggers and actions   between different apps. It excels at connecting apps and performing straightforward tasks without complex data   manipulation or conditional logic.</li> <li>Tracardi: Tracardi supports more complex and sophisticated workflows. It allows for the creation of intricate   customer journeys with conditional branching, decision-making based on real-time data, and advanced automation   rules.</li> </ul> </li> <li> <p>Data Processing Capabilities:</p> <ul> <li>Zapier: Zapier focuses on transferring data between applications but doesn't provide extensive data processing   capabilities. It doesn't offer built-in features for data analysis, segmentation, or advanced data   transformations.</li> <li>Tracardi: Tracardi offers robust data processing capabilities. It provides tools for data analysis, segmentation,   and manipulation, allowing users to derive insights, create targeted audience segments, and perform complex data   transformations before triggering actions.</li> </ul> </li> <li> <p>Pricing Structure:</p> <ul> <li>Zapier: Zapier offers tiered pricing based on the number of zaps executed and the frequency of their execution.   Higher-priced plans provide increased usage limits and access to premium features.</li> <li>Tracardi: Tracardi follows a fixed monthly payment model for its commercial version, regardless of the amount of   data collected or the number of customer data points processed.</li> </ul> </li> <li> <p>Target Audience:</p> <ul> <li>Zapier: Zapier caters to a wide range of users, including individuals, small businesses, and teams, who need to   automate tasks and integrate different applications to streamline their workflows.</li> <li>Tracardi: Tracardi targets marketers and businesses that specifically focus on customer data management,   personalization, and automation. It provides tools and features aimed at enhancing customer experiences and   optimizing marketing campaigns.</li> </ul> </li> <li> <p>Open-Source Availability:</p> <ul> <li>Tracardi: Unlike Zapier, Tracardi is an open-source platform, which means that the source code is publicly   available and can be freely accessed, modified, and customized by users. This openness allows for greater   flexibility, customization, and community contributions, empowering users to adapt Tracardi to their specific   needs and integrate it with other systems or applications.</li> </ul> </li> </ol> <p>Overall, while Zapier focuses on app integration and task automation across various applications, Tracardi specializes in customer data management, personalization, and automation to create targeted campaigns and personalized experiences. Tracardi's features are more tailored to marketers and businesses looking to leverage customer data effectively.</p>"},{"location":"qa/what_is_the_differnece_bwtween_segment_and_audience/","title":"What is the difference between the segment and audience?","text":"<p>In the context of Tracardi, \"segment\" and \"audience\" are two terms that are often used, but they refer to different concepts:</p> <ol> <li> <p>Segment: A segment refers to a specific group of people within your broader customer base or database who share    certain characteristics or behaviors. Segmentation involves dividing your market into subsets based on criteria like    demographics (age, gender, income), psychographics (interests, values, lifestyle), behavior (purchase history,    product usage), or geography. The purpose of segmentation in marketing automation is to target these groups with    tailored messages or offers that are more likely to resonate with them. For example, you might have a segment of    customers who have previously purchased a specific product and you want to target them with a promotional offer for a    related product.</p> </li> <li> <p>Audience: An audience, on the other hand, can be thought of as the larger group of people you are trying to reach    with your marketing efforts. This could include your current customers, potential customers, and other stakeholders.    In marketing automation, the term \"audience\" is often used more broadly and can encompass multiple segments. It's    about the total group of people who will be exposed to your marketing campaign. For instance, your audience for a    digital ad campaign could include several different segments, such as new customers, returning customers, and    prospects who have engaged with your content but haven't made a purchase.</p> </li> </ol> <p>Segmentation has a dynamic nature. That means that individuals can move from one segment to another over time. This dynamism is a critical aspect of segmentation and is based on changes in customer behavior, preferences, or other defining characteristics. Here's how it works:</p> <ol> <li> <p>Behavioral Changes: Customers' behaviors can change due to various factors such as life events, changing    interests, or evolving needs. For instance, a customer who was in a segment characterized by infrequent purchases    might start buying more regularly, thus moving to a segment of frequent buyers.</p> </li> <li> <p>Data Updates: As new data is collected, the profiles of customers get updated. This continuous influx of data can    lead to customers being reclassified into different segments. For example, updating demographic information like age    or income can shift a customer into a new segment more aligned with their current status.</p> </li> <li> <p>Engagement Levels: A change in how customers interact with your brand can also trigger a shift in segments. For    example, a customer who increases their engagement with your digital content or marketing emails might move into a    segment characterized by higher engagement levels.</p> </li> <li> <p>Purchase History: Changes in purchasing behavior, such as the types of products bought or the frequency of    purchases, can result in movement between segments. For instance, a customer might move from a \"one-time purchaser\"    segment to a \"repeat customer\" segment.</p> </li> <li> <p>Automated Re-segmentation: Many marketing automation systems are designed to automatically re-segment customers    based on predefined rules or machine learning algorithms. This automation ensures that segments are always up-to-date    and reflective of the latest customer data and behaviors.</p> </li> </ol> <p>From the technical point of view that means the segments are constantly re-evaluated, and a segment is just a tag that tells that some customer belongs to defined segment.</p> <p>In contrast to segments, audiences in the context of marketing automation and data management are generally more static and purpose-specific. Unlike segments, which are continuously updated based on ongoing data collection, time passing, and behavioral changes, audiences are typically created for a specific purpose as a data query at a specific point in time. Here's a detailed look at the audience properties:</p> <ol> <li> <p>Purpose-Specific Creation: An audience is often created for a particular marketing campaign or business    initiative. This means that the data used to define an audience is queried and compiled to meet the specific    requirements of that campaign or initiative. Once the audience is defined, it does not automatically update customer    tags or change    unless manually revised for a new purpose, or when data is queried again.</p> </li> <li> <p>Lack of Automatic Re-evaluation: In contrast to segments that are often re-evaluated and updated automatically as    new data comes in, audiences do not undergo this automatic re-evaluation. The data set for an audience reflects the    criteria and information available at the time of its creation. Basically the audience is the information on how to    query data to compose the required set of customers.</p> </li> <li> <p>Targeted for Specific Campaigns: Audiences are often used for specific, time-bound marketing campaigns, events,    or promotions. For example, an audience might be created for a holiday season marketing campaign, using data relevant    to that particular time period and campaign objective. Audiences are used for customer activation using external    systems. Once sent to external system then stay the ave and do not evolve.</p> </li> <li> <p>Manual Intervention for Updates: If there is a need to update an audience in the external system, such as    including more recent customer data or adjusting the criteria, this usually requires manual intervention. The    marketer would need to re-query the database to create an updated audience. This approach contrasts with the fluid    nature of segments, which are continuously updated and in any give time we can tell if customer belongs to given    segment or not. This is not possible with audiences.</p> </li> </ol> <p>In summary, audiences in a technical marketing context are less dynamic than segments. They are created for specific purposes and remain largely unchanged unless manually updated or redefined. </p>"},{"location":"qa/what_is_the_mimimum_ram_for_es/","title":"What is the minimum RAM for Elasticsearch to run Tracardi?","text":"<p>The absolute minimum RAM for Elasticsearch to run Tracardi is 2GB per node. However, it's crucial to understand that this is far from optimal for production use.</p> <p>Tracardi leverages Elasticsearch for handling big data operations, which demands significant resources for efficient performance. In a production environment, it's highly recommended to deploy at least 3 Elasticsearch nodes for redundancy and data distribution.</p> <p>For optimal performance, each node should have as much memory as you can allocate. A more realistic minimum for a production setup would be:</p> <ul> <li>3 nodes</li> <li>8GB RAM per node (24GB total)</li> </ul> <p>Remember, this is still a conservative estimate. In scenarios dealing with large datasets or high query volumes, you might need 16GB, 32GB, or even more RAM per node. The more memory you can provide, the better Elasticsearch will perform, especially when handling the big data operations that Tracardi requires.</p> <p>Always monitor your Elasticsearch cluster's performance and be prepared to scale up resources as your data volume and processing needs grow.</p>"},{"location":"qa/what_is_the_minimum_ram_for_mysql/","title":"What is the minimum ram mysql needs to run Tracardi?","text":"<p>To determine the minimum memory requirements for MySQL to run stably without restarting, we need to consider a conservative estimate that allows for basic functionality. Here's a breakdown of the minimum memory requirements:</p> <ol> <li> <p>Base MySQL process: 256MB - 512MB</p> </li> <li> <p>InnoDB Buffer Pool: At least 128MB, preferably 256MB or more</p> </li> <li> <p>Operating System: 512MB - 1GB (not strictly for MySQL, but necessary for system stability)</p> </li> <li> <p>Connection handling: Approximately 1MB per connection (assuming a small number of concurrent connections)</p> </li> <li> <p>Query execution: A small buffer for sorting and joins, around 64MB - 128MB</p> </li> <li> <p>Other MySQL buffers and caches: Around 128MB - 256MB</p> </li> </ol> <p>Adding these up, a very minimal setup that could run without frequent restarts might be:</p> <ul> <li>Total minimum: 1GB - 2GB of RAM</li> </ul> <p>However, it's important to note that this is an absolute minimum and not recommended for any production use. With this configuration:</p> <ol> <li>Performance would be poor</li> <li>The system might struggle with complex queries or multiple concurrent connections</li> <li>There would be little room for data growth or increased load</li> </ol> <p>For a small production environment or a test setup that needs to be somewhat stable, I would recommend at least 4GB of RAM as a starting point. This would allow:</p> <ul> <li>2GB for InnoDB Buffer Pool</li> <li>1GB for MySQL process and other buffers</li> <li>1GB for the operating system</li> </ul> <p>Remember, these are very conservative estimates. In a real production environment, especially one running an application like Tracardi, you'd typically want significantly more memory to ensure good performance and stability. The actual requirements would depend on your specific database size, query patterns, and concurrent user load.</p>"},{"location":"qa/what_is_the_sequence_of_event_processing/","title":"What is the sequence of event processing","text":"<p>Event processing depends on the type of processing. There are 2 types: Asynch, and Synch</p> <p>ina synchronous processing event is collected by API and:</p> <ol> <li>Data source is checked</li> <li>Event  is validated. Validation is performed over the raw/original data.</li> <li>Event is reshaped. Now event can changed to the required format.  </li> <li>Profile Id is extracted and profile properties are extracted and matched for profile identification</li> <li>Event is remapped some data may be now indexed</li> <li>Event is saved</li> </ol> <p>Workflow starts Dispatching to destinations start</p>"},{"location":"qa/what_is_the_syntax_of_if_plugin/","title":"What is the syntax of IF plugin condition","text":"<p>Here are some examples of IF action plugin conditions.</p> <ol> <li>Simple condition with equals operator:</li> </ol> <pre><code>payload@field == \"value\"\n</code></pre> <ol> <li>Complex condition with AND:</li> </ol> <pre><code>(payload@field1 == \"value1\" AND payload@field2 != \"value2\")\n</code></pre> <ol> <li>Complex condition with OR:</li> </ol> <pre><code>(payload@field1 &gt; 10 OR payload@field2 &lt;= 5)\n</code></pre> <ol> <li>BETWEEN condition:</li> </ol> <pre><code>payload@age BETWEEN 18 AND 30\n</code></pre> <ol> <li>IS NULL condition:</li> </ol> <pre><code>session@user_id IS NULL\n</code></pre> <ol> <li>EXISTS condition:</li> </ol> <pre><code>profile@email EXISTS\n</code></pre> <ol> <li>NOT EXISTS condition:</li> </ol> <pre><code>memory@key NOT EXISTS\n</code></pre> <ol> <li>Compound value in a function:</li> </ol> <pre><code>event@timestamp &gt; datetime(2023-01-01T00:00:00)\n</code></pre> <ol> <li>Empty condition:</li> </ol> <pre><code>flow@details EMPTY\n</code></pre> <ol> <li>Complex condition with nested parentheses:</li> </ol> <pre><code>(payload@field1 == \"value1\" AND (payload@field2 != \"value2\" OR payload@field3 &gt; 0))\n</code></pre> <ol> <li>Complex condition that uses data functions.</li> </ol> <pre><code>(\n    payload@age &gt; 18 AND \n    (\n        event@event_type == \"click\" OR \n        event@properties.action == \"add_to_cart\"\n    ) AND \n    (\n        profile@data.pii.age &gt; 25 AND \n        (\n            event@action == \"purchase\" OR \n            event@properties.action == \"add_to_cart\"\n        )\n    )\n) OR (\n    (\n        payload@quantity BETWEEN 10 AND 50 OR \n        payload@timestamp BETWEEN 1631233200 AND 1631319600\n    ) AND \n    (\n        payload@description IS NULL OR \n        event@type IS NOT NULL\n    ) AND \n    (\n        event@properties.location EXISTS AND \n        profile@address NOT EXISTS\n    )\n) AND (\n    (\n        memory@notes EMPTY OR \n        payload@items NOT EMPTY\n    ) AND \n    (\n        payload@keywords CONTAINS \"technology\" OR \n        event@tags CONTAINS \"important\"\n    )\n) AND (\n    (\n        payload@name STARTS WITH \"John\" OR \n        event@description ENDS WITH \"exciting event\"\n    ) AND \n    (\n        event@participants[0] == \"Alice\" OR \n        event@ratings[2] &gt;= 4.5\n    )\n) AND (\n    now(\"europe/warsaw\") &gt; datetime(\"2021-01-01 00:00:00\") AND \n    now(\"europe/london\") &lt; now.offset(payload@time, \"+700 days\")\n)\n</code></pre> <ol> <li> <p>CONTAINS Condition (contains string):</p> </li> <li> <p>Check if keywords in payload contain \"technology\": <pre><code>  payload@keywords CONTAINS \"technology\"\n</code></pre></p> </li> <li> <p>Check if event tags contain the word \"important\": <pre><code>  event@tags CONTAINS \"important\"\n</code></pre></p> </li> <li> <p>STARTS WITH/ENDS WITH String Conditions:</p> </li> <li> <p>Check if payload name starts with \"John\": <pre><code>  payload@name STARTS WITH \"John\"\n</code></pre></p> </li> <li> <p>Check if event description ends with \"exciting event\": <pre><code>  event@description ENDS WITH \"exciting event\"\n</code></pre></p> </li> </ol> <p>Remember, these examples follow the syntax you provided and assume that the specified fields like <code>payload@keywords</code> , <code>event@tags</code>, <code>payload@name</code>, and <code>event@participants[0]</code>, etc. exist in the data structure you're working with.</p>"},{"location":"qa/what_is_tms/","title":"What is Tenant Management Service (TMS)?","text":""},{"location":"qa/what_is_tms/#tenant-management-service-tms-in-a-multi-tenant-environment","title":"Tenant Management Service (TMS) in a Multi-Tenant Environment","text":"<p>In a multi-tenant setup, Tenant Management Service (TMS) is a dedicated microservice responsible for efficiently managing the tenants within the system. Tenant Management involves overseeing various aspects related to individual tenants in a platform.</p> <p>The key responsibilities of the Tenant Management Service (TMS) include:</p> <ol> <li> <p>Creating Tenants: TMS is responsible for creating new tenant accounts within the system. It sets up the necessary    infrastructure and resources for each tenant, ensuring their isolation and independence.</p> </li> <li> <p>Retrieving Tenant Information: TMS provides functionality to query and access specific data, settings, and    attributes associated with existing tenants. This allows the system to retrieve tenant-related information whenever    needed.</p> </li> <li> <p>Validating Tenants: TMS ensures that only valid and authorized tenants can access the system. It performs checks    to verify if a tenant is registered and has the required permissions to use the platform.</p> </li> <li> <p>Tracardi Integration: In a multi-tenant environment, where multiple tenants interact with the    system, TMS plays a pivotal role. It validates tenant credentials, ensures they are registered, and handles    operations such as creating or deleting a tenant.</p> </li> </ol> <p>To create a new tenant in Tracardi's multi-tenant setup, developers use the Tenant Management Service (TMS) API. The process involves setting up the TMS, making an API call to create a new tenant, and providing essential information to set up the tenant. The API returns a generated API key, which serves as the authentication token for accessing the Tracardi API on behalf of the tenant. Additionally, TMS facilitates the creation of a tenant domain, installation token, and other essential components for the tenant.</p>"},{"location":"qa/what_is_tms_reponsible_for/","title":"What is tenant management service responsible for?","text":"<p>A tenant management service (TMS) is responsible for managing various aspects related to tenants within a system or platform.  It is a separate microservice. Its responsibilities include:</p> <ol> <li> <p><code>Creating tenants</code>: The TMS handles the creation of new tenant accounts within the system, setting up the necessary    infrastructure and resources for them to operate.</p> </li> <li> <p><code>Returning tenants</code>: The service allows for retrieving information about existing tenants, providing functionality to    query and access tenant-specific data, settings, and attributes.</p> </li> <li> <p><code>Validating tenants</code>: The TMS ensures the validity of tenants, particularly within Tracardi. It checks if a tenant is    registered and authorized to access the system.</p> </li> <li> <p><code>Storing tenant-specific data</code>: The TMS manages the storage of tenant-related data, such as installation tokens, tenant    email addresses, and additional attributes or mappings associated with each tenant. This data may include information    required for integration with partner systems.</p> </li> <li> <p><code>Tracardi integration</code>: The TMS is used by Tracardi, a system operating in a multi-tenant environment where multiple    tenants log in. Tracardi relies on the TMS to validate tenant credentials and ensure they are registered. Other    operations like creating or deleting a tenant are also handled by the TMS.</p> </li> </ol> <p>In summary, a tenant management service is responsible for creating, returning, and validating tenants, storing tenant-specific data, and enabling the integration and management of tenants within platforms like Tracardi.</p>"},{"location":"qa/what_is_tracardi_flusher/","title":"What is Tracardi Flusher?","text":"<p>In the context of Tracardi, a \"Flusher\" is a component or worker responsible for persisting data changes to Apache Pulsar topics. It plays a crucial role in managing data updates and ensuring that these changes are properly recorded and stored.</p> <p>Specifically, the Flusher worker collects updates or changes to data, such as profile updates, and holds these changes in memory. It doesn't immediately write them to a database but instead buffers them for a certain period or until a specified condition is met. This approach is often used to optimize data storage and minimize the number of database writes.</p> <p>After accumulating a set of changes or when a predefined interval or condition is met, the Flusher worker then \"flushes\" or writes these changes to the appropriate data storage, such as a database. This batching of changes helps reduce the overhead of frequent database writes, resulting in more efficient and optimized data storage operations.</p> <p>The Flusher worker is particularly important in scenarios where there are many frequent updates to data, and it helps manage and streamline the process of persisting those updates in a way that is both efficient and practical for the system.</p>"},{"location":"qa/what_is_tracardi_worker_responsible_for/","title":"What does the open source Tracardi worker do?","text":"<p>Just like other Tracardi workers, the open source Tracardi worker handles tasks that run in the background. It takes care of importing data and ensuring that the system data is migrated and upgraded to newer versions. Without this worker, you won't be able to import or upgrade the system. If the worker is not functioning properly, you will notice that all the background processes are in a pending state.</p>"},{"location":"qa/what_it_the_upgrade_process_of_tracardi/","title":"How the progress of Tracardi upgrade looks like.","text":"<ol> <li> <p>Creating a New Instance: During the upgrade process, a new instance of Tracardi is set up with an empty database.    This is a crucial step as it ensures that the upgrade process does not interfere with the existing data and    operations.</p> </li> <li> <p>Data Migration: Once the new instance is set up, the next step is to migrate data from the old version to the new    one. This process is automated within Tracardi, which simplifies the transition.</p> </li> <li> <p>Testing the New Version: After migrating the data to the new instance, it is recommended to test the new version    with the migrated data. This is an important step to ensure that the upgrade has been successful and that the new    version is functioning as expected with the existing data.</p> </li> <li> <p>Switching the Domain: Once the testing is complete and everything is running smoothly, the final step is to    switch the domain (or IP) on your site to point to the new version of Tracardi. This step redirects all the    operations from the old version to the upgraded version on the new instance.</p> </li> </ol> <p>This focused process ensures a smooth transition during an upgrade, minimizing risks of data loss or system downtime.</p>"},{"location":"qa/what_kind_of_segmentation_is_available_in_os/","title":"What segmentation types are in oen-source version.","text":"<p>In comparing the segmentation features of the open-source and commercial versions of Tracardi, several key differences emerge:</p> <p>Open-Source Version:</p> <p>Post-Event Segmentation: This is operational in the open-source version. It initiates once a profile is updated, triggering the segmentation process based on the newly updated profile data.</p> <p>Segmentation in Workflow Using 'Add Segment' Action: This feature is integrated into the workflow of the open-source version, allowing segmentation to be a part of the workflow process. This segmentation is triggered by events meaning, segmentation can only be initiated by an event and a workflow. This process is executed in the backend instances, which may increase the workload on the Tracardi backend.</p> <p>Commercial Version:</p> <p>Independent Workers for Segmentation Tasks: The commercial version employs independent workers dedicated to segmentation tasks, differing from other models.</p> <p>Repetitive Processing Capability: These independent workers allow for repetitive processing, meaning the system can adapt to changes over time.</p> <p>Time-Based Segmentation: Due to its advanced setup, the commercial version can perform segmentation based on the passage of time, offering a more dynamic and responsive segmentation process.</p> <p>Overall, the commercial version of Tracardi offers more advanced segmentation capabilities, including time-based segmentation and reduced load on backend processes, thanks to its independent worker system. The open-source version, while offering basic segmentation features, has limitations compared to its commercial counterpart.</p>"},{"location":"qa/what_plugins_has_tracardi/","title":"What plugins has Tracardi?","text":"<p>Here is a list of Tracardi plugins:</p> <ul> <li>Enrich profile: This plugin retrieves data about the provided e-mail from FullContact service. (Version: v0.6.1)</li> <li>HTML fetcher: Fetches HTML page. (Version: v0.6.1)</li> <li>MSN Weather service: Retrieves weather information. (Version: v0.6.1)</li> <li>Remote API call: Sends a request to a remote API endpoint. (Version: v0.8.0)</li> <li>Send e-mail via SMTP: This plugin sends mail via the defined SMTP server. (Version: v0.7.3)</li> <li>Send tweet: Create and send a tweet to your Twitter wall. (Version: v0.8.0)</li> <li>Whois: Checks the domain in the WHOIS service. (Version: v0.8.0)</li> <li>Assign profile id: Assigns a new profile id to the event. (Version: v0.6.2)</li> <li>Create empty profile: Adds a new profile to the event. An empty profile gets created with a random id. (Version: v0.8.0)</li> <li>Create empty session: Adds a new session to the event. An empty session gets created with a random id. (Version: v0.7.0)</li> <li>Delayed event: Raises an event that is delayed X seconds after the customer visit ends. (Version: v0.6.2)</li> <li>Discard profile update: Stops the update of the profile in storage. (Version: v0.7.3)</li> <li>Generate password: Generates a new password according to user input. (Version: v0.7.1)</li> <li>Get OAuth2 token: Gets OAuth2 token from the given endpoint, using the given username and password. (Version: v0.6.1)</li> <li>Get field type: This plugin returns the type and length (if it exists) of the given field. (Version: v0.7.1)</li> <li>Hash data: Hashes defined data, e.g., profile traits. (Version: v0.7.0)</li> <li>Join: Joins input data into one payload. (Version: v0.7.1)</li> <li>Load profile by ...: Loads and replaces the current profile in the workflow. It also assigns the loaded profile to the current event. It basically replaces the current profile with the loaded one. (Version: v0.7.2)</li> <li>Mask data: Masks defined data, e.g., profile traits. (Version: v0.7.0)</li> <li>Merge profiles: Merges profiles in storage when the flow ends. This operation is expensive, so use it with caution, only when there is new PII information added. (Version: v0.8.0)</li> <li>Payload collector: Collects input payloads in the workflow memory object. (Version: v0.7.1)</li> <li>Reduce array: Reduces the given array. (Version: v0.6.2)</li> <li>Sort dictionary: Sorts the referenced dictionary and returns it as a list of tuples of key and value. (Version: v0.7.3)</li> <li>Sort list: Plugin that sorts (ascending, descending) a referenced array/list. (Version: v0.7.3)</li> <li>Tag event: Adds a tag to the current event. (Version: v0.8.0)</li> <li>UUID4: Generates a random UUID. (Version: v0.6.2)</li> <li>Update event: Updates the event in storage. (Version: v0.6.0.1)</li> <li>Update profile: Updates the profile in storage. (Version: v0.6.0.1)</li> <li>Update session: Updates the session in storage. (Version: v0.6.2)</li> <li>Data exists: Checks if the data property exists and is not null or empty. (Version: v0.8.0)</li> <li>If: This is a conditional action that conditionally runs a branch of the workflow. (Version: v0.7.4)</li> <li>Is it a new profile: If new profile then it returns true on TRUE output, otherwise returns false on FALSE port. (Version: v0.6.0.1)</li> <li>Is it a new visit: If new visit then it returns true on TRUE output, otherwise returns false on FALSE port. (Version: v0.6.0.1)</li> <li>Limiter: This node throttles the workflow execution. (Version: v0.7.3)</li> <li>Resolve conditions: That plugin creates an object with results from resolved condition set. (Version: v0.6.2.1)</li> <li>Resolve conditions into profile fields: This plugin resolves a set of conditions and assigns it to the profile fields. (Version: v0.6.2)</li> <li>Value change: This plugin will stop the workflow if the defined value did not change. (Version: v0.6.1)</li> <li>Discard Event: Discards the current event - Current event will not be saved if this action is used. (Version: v0.7.1)</li> <li>Event aggregator: This plugin collects and tallies up the occurrences of a specific category of information during a certain period of time for the current profile. (Version: v0.8.0)</li> <li>Event counter: This plugin reads how many events of the defined type were triggered within the defined time. (Version: v0.8.0)</li> <li>Get previous event: Injects the previous event for the current profile into the payload, according to the event type and offset value. (Version: v0.6.2)</li> <li>Inject event: This node will inject an event of a given ID into the payload. (Version: v0.6.0.1)</li> <li>Add interest: Adds interest to the profile. (Version: v0.8.0)</li> <li>Add segment: Adds a segment to the profile. (Version: v0.7.3)</li> <li>Conditional segmentation: This plugin will add/remove a segment from the profile. (Version: v0.6.0.1)</li> <li>Decrease interest: Decreases interest in the profile and returns the payload. (Version: v0.8.0)</li> <li>Delete segment: Deletes a segment from the profile. (Version: v0.7.3)</li> <li>Force segmentation: Segment profile when flow ends. This action forces segmentation on the profile after the flow ends. See documentation for more information. (Version: v0.6.0.1)</li> <li>Has segment: Checks if the profile is in the defined segment. (Version: v0.7.3)</li> <li>Increase interest: Increases interest in the profile and returns the payload. (Version: v0.8.0)</li> <li>Memorize segment: Memorize profile segments in workflow memory. (Version: v0.7.3)</li> <li>Move segment: Moves the profile from one segment to another segment. (Version: v0.7.3)</li> <li>Recall segment: Loads memorized profile segments into the output payload. (Version: v0.7.3)</li> <li>Create entity: Adds or updates an entity. (Version: v0.7.3)</li> <li>Delete entity: Deletes an entity by its ID. (Version: v0.7.2)</li> <li>Load entity: Loads an entity by its ID. (Version: v0.7.3)</li> <li>Get event source: This plugin reads the source that the event came from. (Version: v0.6.0.1)</li> <li>Inject: Injects data into the selected object (e.g., payload, event properties, session context, etc). (Version: v0.6.2)</li> <li>Inject payload: Creates a new payload from the provided data. Configuration defines where the data should be copied. (Version: v0.8.0)</li> <li>Load report data: Loads the results of a given report into the payload. (Version: v0.7.2)</li> <li>Load report data: Loads the results of a given report into the payload. (Version: v0.7.2)</li> <li>Novu notifications: Create and send notifications to chosen recipients. (Version: v0.7.2)</li> <li>Add to audience: Adds a contact to MailChimp audience. (Version: v0.6.0.1)</li> <li>Remove from audience: Removes or archives a contact from the MailChimp audience. (Version: v0.6.0.1)</li> <li>Send e-mail: Sends transactional e-mail via MailChimp API. (Version: v0.6.0.1)</li> <li>Count records: Counts event, profile, or session records. Records can be filtered by a query string. (Version: v0.6.2)</li> <li>Decrement counter: Decrements the profile stats.counters value and returns the payload. (Version: v0.1)</li> <li>Increase views: Increases the view field in the profile and returns the payload. (Version: v0.1)</li> <li>Increase visits: Increases the visit field in the profile and returns the payload. (Version: v0.1)</li> <li>Increment counter: Increments the given field in the payload and returns the payload. (Version: v0.1)</li> <li>Key counter: Counts keys and saves them in the profile. (Version: v0.6.0.1)</li> <li>Contains pattern: Checks if a field contains the defined pattern. (Version: v0.7.2)</li> <li>Contains string: Checks if a field contains the defined string. (Version: v0.7.2)</li> <li>Data validator: Validates data such as email, URL, IPv4, date, time, int, float, phone number, EAN code. (Version: v0.6.0.1)</li> <li>Ends with: Checks if a string ends with the defined prefix. (Version: v0.7.2)</li> <li>Join string list: Joins each element in the list by the given delimiter. (Version: v0.7.3)</li> <li>Starts with: Checks if a string starts with the defined prefix. (Version: v0.7.2)</li> <li>String properties: Performs string transformations like lowercase, remove spaces, split, and more. (Version: v0.6.0.1)</li> <li>String similarity: Compares two strings according to the chosen algorithm. (Version: v0.7.3)</li> <li>String splitter: Splits a string into a list of strings by the defined delimiter. (Version: v0.6.0.1)</li> <li>Append/Remove data: Appends or removes a trait to/from the given destination. (Version: v0.1)</li> <li>Calculator: Calculates new values by adding, subtracting, dividing, and multiplying values. (Version: v0.6.0.1)</li> <li>Copy data: Copies event properties to a profile trait. (Version: v0.6.0)</li> <li>Create response: Creates a new response from the provided data. Configuration defines where the data should be copied. (Version: v0.7.2)</li> <li>Cut out data: Returns a part of referenced data as payload. (Version: v0.8.0)</li> <li>Delete data: Deletes data from the internal state of the workflow. (Version: v0.1)</li> <li>Detect device: Parses a user agent string and detects the browser, operating system, and device used. (Version: v0.6.1)</li> <li>Merge event properties: Automatically merges all event properties to profile traits. (Version: v0.6.2)</li> <li>Random item: Returns a random value from the list given in the configuration. (Version: v0.6.1)</li> <li>Template: Returns a string where placeholders are replaced with given values. (Version: v0.6.0.1)</li> <li>Value mapping: Returns a matching value from the set of data. (Version: v0.6.1)</li> <li>XPATH HTML Scrapper: Scrapes data from HTML content. (Version: v0.6.1)</li> <li>Log message: Logs a message to the flow log. (Version: v0.6.1)</li> <li>Throw error: Throws an error and stops the workflow. (Version: v0.6.0.1)</li> <li>Geo distance: Determines if the test geo location coordinates are within the radius threshold from the center point coordinates. (Version: v0.6.1)</li> <li>Geo fence: Determines if the test geo location coordinates are within the radius threshold from the center point coordinates. (Version: v0.6.1)</li> <li>GeoIp service: Converts IP to location information. (Version: v0.6.1)</li> <li>Discard Profile: Discards the current profile - the current profile will not be saved if this action is used. (Version: v0.8.0)</li> <li>Discard Session: Discards the current session - the current session will not be saved if this action is used. (Version: v0.8.0)</li> <li>Get previous session: Loads previous sessions for the current profile and injects them into the payload. (Version: v0.6.2)</li> <li>Regex match: Uses regex matching and returns matched data. (Version: v0.6.0.1)</li> <li>Regex replace: Replaces a substring that matches a regex pattern with the given replacement string. (Version: v0.6.1)</li> <li>Regex validator: Validates data with a regex pattern. (Version: v0.6.0.1)</li> <li>JSON schema validator: Validates objects using the provided JSON validation schema. (Version: v0.7.4)</li> <li>Regex validator: Validates data with a regex pattern. (Version: v0.6.0.1)</li> <li>Parse URL: Reads URL parameters from the context, parses them, and returns the result on the output. (Version: v0.6.0.1)</li> <li>Day/Night: Splits the workflow based on whether it is day or night at the given latitude and longitude. (Version: v0.6.0.1)</li> <li>If it's a weekend: Checks the current date and flags it if it's a weekend or not. (Version: v0.7.2)</li> <li>Is time between dates: Checks if the current time is within a defined time span. (Version: v0.6.0.1)</li> <li>Last profile visit time: Returns the time difference between the last profile visit and the current time. (Version: v0.7.3)</li> <li>Pause and Resume: Waits for X seconds and then restarts the workflow at this node. (Version: v0.8.0)</li> <li>Profile live time: Returns how long ago a profile was registered in the system. (Version: v0.8.0)</li> <li>Sleep: Stops the workflow for a given time. (Version: v0.1.2)</li> <li>Time difference: Returns the time difference between two dates. (Version: v0.6.0.1)</li> <li>Today: Returns information about the current time, month, day, etc. It consists of the day of the week, date, and current time. (Version: v0.1.1)</li> <li>Custom widget: Shows a custom JavaScript widget. (Version: v0.8.0)</li> <li>OpenReplay: Injects the OpenReplay tracing script on the webpage. (Version: v0.8.0)</li> <li>Rating widget: Shows a rating widget with a defined title and content. (Version: v0.8.1)</li> <li>Request demo widget: Shows a request demo widget. (Version: v0.8.1)</li> <li>Show consent bar: Shows a consent pop-up on the frontend. (Version: v0.6.1)</li> <li>YouTube widget: Shows a YouTube video widget. (Version: v0.8.1)</li> <li>Telegram message: Sends a Telegram message via the bot. (Version: v0.8.0)</li> <li>Google Analytics 4 event: Send your custom event to the Google Analytics 4 event tracker. (Version: v0.7.3)</li> <li>Google Spreadsheet: This plugin connects Tracardi to Google Sheets. (Version: v0.6.1)</li> <li>Google Translate: Translates text. (Version: v0.7.2)</li> <li>Google UA events: Send your customized event to the Google Universal Analytics event tracker. (Version: v0.8.0)</li> <li>End: Ends the workflow. (Version: v0.1)</li> <li>Start: Starts the workflow and returns event data on the payload port. (Version: v0.8.0)</li> <li>Add contact: Creates or updates a contact in ActiveCampaign, according to the provided configuration. (Version: v0.6.3)</li> <li>Fetch contact: Fetches ActiveCampaign contact info based on the given email address. (Version: v0.6.3)</li> <li>Register event: Sends the current event to Matomo. (Version: v0.6.2)</li> <li>Data to JSON: Converts objects to JSON. (Version: v0.6.0.1)</li> <li>Decode Base64: Decodes a base64-encoded input to plain text. (Version: v0.7.3)</li> <li>Encode Base64: Encodes input text to base64. (Version: v0.7.3)</li> <li>JSON to data: Converts JSON to data objects. (Version: v0.6.2)</li> <li>Discord push: Sends a message to a Discord webhook. (Version: v0.7.4)</li> <li>Post to Slack Channel: Posts a defined message to a Slack channel. (Version: v0.6.1)</li> <li>Pushover push: Connects to the Pushover app and pushes a message. (Version: v0.7.1)</li> <li>Microservice: Runs a remote microservice plugin. (Version: v0.7.2)</li> <li>Add consent: This plugin adds consents to the profile. (Version: v0.6.3)</li> <li>Require consents: Checks if defined consents are granted by the current profile. (Version: v0.6.2)</li> <li>Get Issue: Get single GitHub issue details. (Version: v0.7.4)</li> <li>List Issues: Lists GitHub issues. (Version: v0.7.4)</li> <li>Query data: Query local Elasticsearch database. (Version: v0.8.0)</li> <li>Send SMS: Sends an SMS using the Twilio gateway. (Version: v0.8.1)</li> <li>Event sequence: This plugin returns an events sequence from the database for a defined time range and context. (Version: v0.8.0)</li> <li>Event sequence match: This action will look for a sequence of events in a delivered list of events. (Version: v0.8.0)</li> <li>ChatGPT prompt: Sends a request to ChatGPT and returns the response. (Version: v0.8.0)</li> </ul>"},{"location":"qa/what_prefixes_in_the_ids_mean/","title":"There are prefixes in the profile IDS what they mean?","text":"<p>The prefixes <code>emm-</code>, <code>emb-</code>, <code>emp-</code>, <code>phm-</code>, <code>phw-</code>, <code>phb-</code>, and <code>pho-</code> in <code>profile.ids</code> are used to denote specific types of profile identifiers based on the data source they represent. Here's what each prefix means:</p> <ol> <li> <p><code>emm-</code>:</p> <ul> <li>Email Main: This prefix is used for the main email address of the profile. It typically refers to the primary   email address a user provides.</li> </ul> </li> <li> <p><code>emb-</code>:</p> <ul> <li>Email Business: This prefix is used for the business email address of the profile. It's typically used in   professional or business contexts.</li> </ul> </li> <li> <p><code>emp-</code>:</p> <ul> <li>Email Private: This prefix is used for the private email address of the profile. It usually refers to a   personal email address.</li> </ul> </li> <li> <p><code>phm-</code>:</p> <ul> <li>Phone Main: This prefix is used for the main phone number of the profile. It typically refers to the primary   contact number provided by the user.</li> </ul> </li> <li> <p><code>phw-</code>:</p> <ul> <li>Phone WhatsApp: This prefix is used for the WhatsApp phone number of the profile. It refers to the phone   number used for WhatsApp communications.</li> </ul> </li> <li> <p><code>phb-</code>:</p> <ul> <li>Phone Business: This prefix is used for the business phone number of the profile. It refers to a phone number   used in a professional or business setting.</li> </ul> </li> <li> <p><code>pho-</code>:</p> <ul> <li>Phone Other: This prefix is used for any other phone numbers associated with the profile. It can include   secondary numbers, home phones, or other contact numbers not categorized as main, WhatsApp, or business.</li> </ul> </li> </ol>"},{"location":"qa/what_prefixes_in_the_ids_mean/#purpose-of-these-prefixes","title":"Purpose of These Prefixes","text":"<p>These prefixes help in identifying and categorizing the sources of profile data. When profiles are merged, these identifiers ensure that data from different sources is correctly attributed and merged into the corresponding profile fields.</p>"},{"location":"qa/what_staging_means/","title":"What does staging mean in tracardi version?","text":"<p>In Tracardi, staging refers to a server environment used to test and debug configuration changes before they are deployed to a production server. The purpose of staging is to ensure that new configurations can be thoroughly tested in a controlled environment without impacting the live production website or application.</p> <p>When connected to the staging API, it means that you are using the API version specifically designed for collecting test data. This allows you to perform tests without affecting the production data. The staging environment keeps the test data separate from the production data, ensuring that any changes or experiments you make are isolated and do not interfere with the live system.</p> <p>In terms of the graphical user interface (GUI), it is possible for it to connect to both the staging and production APIs. However, it is advisable to connect to the staging API with the GUI when performing tests. The production API should be reserved for actual usage by webpages or mobile phones, as it needs to be exposed to the internet to receive real user data.</p> <p>By connecting to the staging API with the GUI, you can safely experiment and validate new configurations without affecting the production environment. Also, Production data is visible in a read only mode.</p>"},{"location":"qa/what_things_should_i_consider_setting_up_prodution/","title":"What should I pay attention to when setting up production ready Tracardi.","text":"<p>When setting up Tracardi for production, it's crucial to consider several factors that can impact its performance and efficiency. These factors include:</p> <ol> <li> <p>Event Volume and Traffic Spikes:    Analyze the anticipated event volume and potential traffic spikes to determine if Tracardi should be deployed behind    a queue. Queues effectively manage surges in traffic, ensuring smooth event processing and preventing system    overload.</p> </li> <li> <p>Event Payload Size:    Assess the average size of event payloads. Larger payloads require more resources and may result in slower processing    compared to smaller events. Optimize event payloads by eliminating unnecessary data to enhance performance.</p> </li> <li> <p>Event Storage and Retention:    Consider the number of events stored per day and its impact on other processes, such as segmentation. Determine the    desired data retention period, as longer retention increases query size and segmentation complexity.</p> </li> <li> <p>Index Granularity and Data Partitioning:    Decide how to partition event data into indices. Default quarterly indices create four indices per year, while    monthly splits require more indices and may impact query performance. Monthly splits offer more granular data storage    and archiving.</p> </li> <li> <p>Customer Volume and Segmentation:    Evaluate the number of customers that Tracardi will handle. Customer volume can affect segmentation performance.    Elasticsearch excels at data aggregation, but storing profile data can be time-consuming.</p> </li> </ol> <p>By carefully considering these factors, you can optimize Tracardi's performance and ensure it meets your production requirements.</p>"},{"location":"qa/what_type_of_triggers_event_has/","title":"What are event options, how the impact triggering of events from javascript?","text":""},{"location":"qa/what_type_of_triggers_event_has/#introduction","title":"Introduction","text":"<p>This documentation is designed to clarify the concept of event options and their influence on event triggering within JavaScript. When working with a JavaScript snippet on your webpage, you have the capability to dispatch events using the <code>window.tracker.track</code> method, and these events can be tailored by employing a range of options. The documentation offers insight into different event types and the options associated with each.</p>"},{"location":"qa/what_type_of_triggers_event_has/#event-triggering-in-javascript","title":"Event Triggering in JavaScript","text":"<p>In JavaScript, you can trigger events using the following syntax:</p> <pre><code>window.tracker.track(&lt;event-type&gt;, &lt;properties&gt;, &lt;options&gt;)\n</code></pre> <p>Here, <code>&lt;event-type&gt;</code> represents the type of event you want to trigger, <code>&lt;properties&gt;</code> define the specific event properties, and <code>&lt;options&gt;</code> configure how the event is triggered.</p>"},{"location":"qa/what_type_of_triggers_event_has/#available-event-types","title":"Available Event Types","text":""},{"location":"qa/what_type_of_triggers_event_has/#1-collected","title":"1. Collected","text":"<p>The \"Collected\" event type is the default setting, and events of this type are collected and sent in bulk when the page finishes loading. This type of event does not require any specific options. The default settings for \"Collected\" events are as follows:</p> <pre><code>{\n  \"fire\": false,\n  \"asBeacon\": false\n}\n</code></pre>"},{"location":"qa/what_type_of_triggers_event_has/#2-fired-immediately","title":"2. Fired Immediately","text":"<p>The \"Fired Immediately\" event type sends the event immediately without waiting for the page to finish loading. This is particularly useful for events triggered by user interactions like clicks or mouseovers. To use this type, set the following option:</p> <pre><code>{\n  \"fire\": true\n}\n</code></pre>"},{"location":"qa/what_type_of_triggers_event_has/#3-fired-even-if-the-page-is-unloaded","title":"3. Fired Even if the Page is Unloaded","text":"<p>In some cases, an event needs to be sent even when a user clicks a link and gets redirected to another page. This scenario may prevent the script from executing, but you can ensure the event is sent using the following option:</p> <pre><code>{\n  \"asBeacon\": true\n}\n</code></pre>"},{"location":"qa/what_type_of_triggers_event_has/#4-process-event-async-on-the-server","title":"4. Process Event Async on the Server","text":"<p>By default, the commercial installation of Tracardi processes events asynchronously on the server. However, the open-source version sends events synchronously, meaning the server must complete event processing before sending a response. In certain cases, you may need to switch from asynchronous to synchronous processing, such as when you require the event to return data or a widget to be presented on the page. To enable synchronous processing, use the following option:</p> <pre><code>{\n  \"async\": false\n}\n</code></pre>"},{"location":"qa/what_types_of_segmentation_has_tracardi/","title":"How segmentation is triggered in Tracardi?","text":"<p>Segmentation in Tracardi is the process of grouping profiles together. To perform segmentation, you need a profile, which is identified by a unique profile ID in Tracardi. There are different ways to do segmentation.</p> <ol> <li> <p>Real-time Segmentation: This method involves categorizing customers in real time based on specific events or actions    they take. For example, when a customer answers an email or visits a page a certain number of times, their profile is    automatically moved to a particular segment. Tracardi provides actions like \"add segment\" or \"delete segment\" in    workflows to perform real-time segmentation based on defined conditions real-time when the data changes.</p> </li> <li> <p>Time-triggered Segmentation: This method starts the segmentation process based on the absence of certain events or    actions. For instance, if a customer hasn't made a purchase or visited your page for a specified period, a    time-triggered segmentation process is initiated. Tracardi runs this process periodically, such as every hour, to    check if the defined condition is met.</p> </li> <li> <p>Ad hoc Segmentation: This method involves segmenting customers based on existing data. It includes selecting profiles    using available data, such as demographic information (age, shoe size, location), to create segments. While this    method is less sophisticated compared to the others, it can still be useful for filtering based on aggregated values    like the number of specific events or the most recent event type. However, adhoc segmentation is limited when it    comes to segmenting based on event sequences or external data.</p> </li> </ol> <p>At present, Tracardi exclusively provides first two segmentation methods. However, numerous scenarios that involve the third method can be accomplished by employing the first two methods or post event segmentation. For instance, when segmenting based on existing data such as gender, one can identify the event responsible for altering the gender and segment the profile in real-time as the data changes. This can be achieved by using post event segmentation or executing an if statement and utilizing the \"add segment\" action to assign the relevant segment to the profile in the workflow.</p>"},{"location":"qa/what_upfront_decisions_do_i_have_to_make_before_install/","title":"What upfront decisions do I have to make before I install production ready Tracardi.","text":"<p>Before installing Tracardi, there are several upfront decisions you need to make to ensure a smooth setup and operation.</p> <p>Here are the key considerations:</p>"},{"location":"qa/what_upfront_decisions_do_i_have_to_make_before_install/#1-decide-on-deployment-type","title":"1. Decide on Deployment Type","text":"<ul> <li>Open Source vs. Commercial: Choose between the open-source version of Tracardi or the commercial version,   depending on your requirements and budget.   See what are the differences between Open-source and Commercial version?</li> <li>Deployment Environment: Decide whether you will deploy on Docker, Kubernetes (K8s), or another environment.</li> </ul>"},{"location":"qa/what_upfront_decisions_do_i_have_to_make_before_install/#2-infrastructure-and-dependencies","title":"2. Infrastructure and Dependencies","text":"<ul> <li>Essential Services: Tracardi relies on several dependencies, including Redis, Elasticsearch, MySQL, and optionally   Apache Pulsar for event streaming. It is crucial to ensure these services are set up correctly or to plan their   installation. Scaling these services is particularly important, especially for Elasticsearch, which is quite demanding   in terms of the number of shards that cannot be changed later. For detailed instructions,   see how to configure number of shards.</li> <li>Storage and Persistence: Plan for data persistence by ensuring storage solutions for Elasticsearch and Redis, and   understand their configurations for production use.</li> </ul>"},{"location":"qa/what_upfront_decisions_do_i_have_to_make_before_install/#3-configuration","title":"3. Configuration","text":"<ul> <li>User Authentication: Configure authentication mechanisms for accessing Tracardi services, such as secure   credentials for databases and API endpoints.</li> <li>Environment Variables: Set up the necessary environment variables for configuring Tracardi components,   especially <code>INSTALLATION_TOKEN</code> and <code>AUTO_PROFILE_MERGING</code>. For detailed guidance,   see Which environment variables should I set before production installation.</li> <li>Multi-Tenancy: Decide if you will enable multi-tenancy features to manage different clients or divisions within   your organization. See How to start Tracardi in multi-tenant mode?</li> <li>Data Partitioning: Configure data partitioning strategies for events, profiles, and sessions to optimize   performance and storage.</li> <li>Custom Settings: Customize settings like logging levels, API documentation, and workflow enablement according to   your operational needs.</li> </ul>"},{"location":"qa/what_upfront_decisions_do_i_have_to_make_before_install/#4-licensing-and-access","title":"4. Licensing and Access","text":"<ul> <li>Commercial Licensing: If using the commercial version, ensure you have the necessary license keys and DockerHub   access tokens.</li> </ul>"},{"location":"qa/what_upfront_decisions_do_i_have_to_make_before_install/#5-monitoring-and-telemetry","title":"5. Monitoring and Telemetry","text":"<ul> <li>Monitoring Tools: Integrate monitoring tools to keep track of system performance and health.</li> <li>Telemetry Configuration: Set up telemetry to gather metrics and logs, helping in proactive issue resolution and   performance tuning.</li> </ul>"},{"location":"qa/what_upfront_decisions_do_i_have_to_make_before_install/#6-backup-and-disaster-recovery","title":"6. Backup and Disaster Recovery","text":"<ul> <li>Backup Plans: Establish regular backup schedules for critical data stored in Elasticsearch and MySQL.</li> <li>Disaster Recovery: Develop a disaster recovery plan to restore services in case of system failures.</li> </ul>"},{"location":"qa/what_variable_controls_api_endpoints/","title":"What env variable controls which API private and which public.","text":"<p>The environment variable that controls whether the Tracardi API is private or public is EXPOSE_GUI_API.</p> <ul> <li>When EXPOSE_GUI_API=true: The API is private, allowing access to all endpoints, including those for controlling   Tracardi and accessing the GUI.</li> <li>When EXPOSE_GUI_API=false: The API is public, restricting access to only the data collection endpoints, without   providing GUI or management capabilities.</li> </ul> <p>This variable determines the scope of the API's functionality and exposure.</p> <p>Here is a short explanation what public and private API means:</p> <p>Public API:</p> <ul> <li>The public API is exposed to the internet and is used for collecting data only. No GUI operations are available in   this API.</li> <li>This API is enabled by default for data collection purposes only.</li> </ul> <p>Private API:</p> <ul> <li>The private API is not exposed to the internet and is used for controlling Tracardi, including access to data, GUI   operations, and management.</li> <li>This API should be protected and accessible only through VPN or internal network configurations.</li> <li>Private API is used to configurate and control tracardi.</li> </ul>"},{"location":"qa/what_versions_of_dependencies/","title":"What are the recommended versions of dependencies for Tracardi","text":""},{"location":"qa/what_versions_of_dependencies/#elasticsearch-docker-installation","title":"Elasticsearch Docker Installation","text":"<p>The recommended Elasticsearch version for Docker installation is up to 8.11.3. However, the search results mention using version 7.13.1 to maintain compatibility with an existing application using the Elasticsearch library version 7.</p>"},{"location":"qa/what_versions_of_dependencies/#redis-docker-installation","title":"Redis Docker Installation","text":"<p>Any version of Redis should work with Tracardi. The recently tested version is 7.2.4.</p>"},{"location":"qa/what_versions_of_dependencies/#apache-pulsar-docker-installation","title":"Apache Pulsar Docker Installation","text":"<p>The recommended Apache Pulsar version for Docker installation is 3.1.0.</p>"},{"location":"qa/what_versions_of_dependencies/#mysql-docker-installation","title":"MySQL Docker Installation","text":"<p>For MySQL, the recommended version is 8.3. Tracardi also works with the Percona version tested on 8.0.36.</p>"},{"location":"qa/when_can_i_use_tracardi_for_free/","title":"When can I use Tracari for free?","text":"<p>Tracardi offers a free open-source version that allows individuals and small companies to use the system at no cost.</p> <p>However, if your intention is to create a software-as-a-service (SAAS) platform that involves selling or reselling Tracardi to customers, you would need to consider the commercial open-source version. This version is specifically designed for marketing agencies and larger corporations, offering additional features and tailored support to meet the needs of businesses operating at a larger scale.</p> <p>In summary, Tracardi can be used for free by individuals and small companies. For commercial purposes involving selling or reselling Tracardi, the commercial open-source version is recommended.</p>"},{"location":"qa/when_i_know_if_the_event_was_processed/","title":"When will I know that my event was processed?","text":"<p>You will know that your event was processed when its status changes from \"collected\" (blue) to \"processed\" (green). If there are no additional statuses such as errors or warnings, then it indicates that your event has been successfully processed.</p>"},{"location":"qa/when_loading_i_have_the_error/","title":"When loading I Have the error <code>Redis Authentication</code>?","text":"<p>This error is related to the connection to Redis. It indicates that Tracardi was unable to log in to the Redis server.</p>"},{"location":"qa/when_loading_i_have_the_error/#when-loading-i-have-the-error-redis-authentication-error-auth-password-called-without-any-password-configured-for-the-default-user-are-you-sure-your-configuration-is-correct","title":"When loading I Have the error <code>Redis authentication error: AUTH &lt;password&gt; called without any password configured for the default user. Are you sure your configuration is correct?</code>?","text":"<p>The Tracardi application is configured to use a Redis password, but the Redis server does not require a password. As a result, Tracardi is sending a password to Redis, but Redis is not using it.</p>"},{"location":"qa/when_profile_is_marked_for_merging/","title":"When profiles are marked for merging?","text":"<p>In Tracardi, profiles are \"marked for merging\" when certain conditions are met, indicating that multiple profiles should be consolidated into a single profile. Here\u2019s a more detailed explanation:</p>"},{"location":"qa/when_profile_is_marked_for_merging/#profiles-marked-for-merging","title":"Profiles Marked for Merging","text":"<p>Tracardi monitors the specified fields (e.g., email addresses, phone numbers) for changes or updates. If it finds that one of the field that is marked as merging key is changed, it \"marks\" the profile as candidates for merging.</p>"},{"location":"qa/when_profile_is_marked_for_merging/#what-are-the-merging-keys-fields","title":"What are the merging keys (fields)","text":"<ul> <li>The following profile fields are used as merging keys:</li> <li><code>data.contact.email.main</code></li> <li><code>data.contact.email.business</code></li> <li><code>data.contact.email.private</code></li> <li><code>data.contact.phone.main</code></li> <li><code>data.contact.phone.business</code></li> <li><code>data.contact.phone.whatsapp</code></li> <li><code>data.contact.phone.mobile</code></li> </ul>"},{"location":"qa/when_profile_is_marked_for_merging/#when-profiles-are-marked-for-merging_1","title":"When Profiles are Marked for Merging","text":"<p>Profiles are typically marked for merging under the following conditions:</p> <ol> <li> <p>Matching Fields Updates:</p> <ul> <li>When Tracardi detects that the values in the merging key fields (such as email addresses or phone numbers) have   changed.</li> </ul> </li> <li> <p>Profile Creation/Update:</p> <ul> <li>Whenever a new profile is created or an existing profile is updated with data in the monitored fields.</li> </ul> </li> <li> <p>Periodic Checks:</p> <ul> <li>The APM worker periodically reviews profiles to identify if there are profile duplicates that have the same values   for merging keys.</li> </ul> </li> </ol>"},{"location":"qa/when_profile_is_marked_for_merging/#example-workflow","title":"Example Workflow","text":"<ol> <li> <p>Profile Update:</p> <ul> <li>A user updates their email address in their profile. The system hashes the new email value and puts it   into <code>profile.ids</code>.</li> </ul> </li> <li> <p>Mark for Merging:</p> <ul> <li>System marks this profile for merging. This can be see in the GUI togather with the estimated number of profiles   to merge.</li> </ul> </li> <li> <p>APM Worker:</p> <ul> <li>The APM worker runs at regular intervals, reviewing profiles marked for merging. It merges the profiles,   consolidating all data into a single profile.</li> </ul> </li> <li>Watch Dog Process:<ul> <li>A Watch Dog process runs periodically (by default every 15 minutes) to ensure there are no missing hashes in   the <code>profile.ids</code> field. This means it checks for the presence of emails or phone numbers without corresponding   hashes in <code>profile.ids</code>. If any missing hashes are found, they are computed and added to <code>profile.ids</code>.   Subsequently, the regular APM Worker merges the profiles.</li> </ul> </li> </ol>"},{"location":"qa/where_can_i_find_report_id/","title":"Where can I find report id.","text":"<p>Report id can be found on report detail page or via API GET <code>/reports</code>.</p>"},{"location":"qa/where_can_i_save_list_visit_time_etc/","title":"Where can I save in profile such timestamp like last visit, last message send, last contact, etc ?","text":"<p>To store additional timestamps except last_visit, eg. last message sent, or last contact in a profile in Tracardi, you can use the <code>profile@metadata.aux</code> field. This field is specifically designed to hold additional information, including various timestamps.</p> <p>You can create a <code>timestamp</code> subfield under <code>metadata.aux</code> and save any relevant timestamp data there. For instance, to record the time of the last chat or the last sent email, you might use fields like <code>metadata.aux.timestamp.last_chat</code> and <code>metadata.aux.timestamp.last_send_email</code>, respectively, and assign the corresponding dates to them.</p> <p>Here's an example of how you might structure this:</p> <ul> <li><code>metadata.aux.timestamp.last_chat</code> = [date/time of last chat]</li> <li><code>metadata.aux.timestamp.last_send_email</code> = [date/time of last sent email]</li> </ul> <p>This approach allows you to neatly organize and store various timestamp-related data within the profile structure. The <code>metadata.aux</code> is indexed but can not be aggregated.</p>"},{"location":"qa/where_is_profile_visits_are_counted/","title":"Where profile visits are stored?","text":"<p>Tracardi stores profile visits in the customer profile in <code>metadata.time.visit.count</code>. Visits are automatically increased when user/customer starts new session.</p> <p>This document also answer the following questions: - Where can I found customer visits? - Where Tracardi counts visits?</p>"},{"location":"qa/where_to_place_the_javascript_integration_codes/","title":"Where to place javascript integration code?","text":"<p>When integrating JavaScript code for a REST API event source in a webpage, you'll need to place the code in the appropriate sections of your HTML document. Here's a general guide on where to place the integration code:</p> <ol> <li>First Part of Code (Header):    The first part of the integration code, which is typically used for initialization or setup, should be placed in    the <code>&lt;head&gt;</code> section of your HTML document. This ensures that the required scripts and configurations are loaded    before the rest of the page content.</li> </ol> <p>Here's an example of where you should place the first part of the code:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Your Webpage Title&lt;/title&gt;\n    &lt;!-- Place the first part of the integration code here --&gt;\n    &lt;script&gt; &lt;!-- code HERE --&gt; &lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;!-- Your webpage content goes here --&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <ol> <li>Second Part of Code (Particular Pages):    The second part of the integration code, which is specific to certain pages or actions, should be placed in the    relevant sections of your HTML where you want the events to be triggered and sent to Tracardi. This code is often    placed within <code>&lt;script&gt;</code> tags at the bottom of the page, just before the closing <code>&lt;/body&gt;</code> tag. This ensures that the    page content is loaded first before the script executes.</li> </ol> <p>Here's an example of where you should place the second part of the code:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Your Webpage Title&lt;/title&gt;\n    &lt;script src=\"path/to/your-first-part-code.js\"&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;!-- Your webpage content goes here --&gt;\n\n&lt;!-- Place the second part of the integration code within the script tag below --&gt;\n&lt;script&gt;\n        // Your second part of the integration code here\n        // This code will be specific to certain pages or actions\n        // and will send events to Tracardi as intended.\n\n&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>In the code above, the second part of the integration code is placed within the"},{"location":"qa/where_to_store_custom_properties/","title":"Where can I store custom profile properties.","text":"<p>Custom attributes of a profile are typically stored in the traits field. It is designed to accommodate additional, custom information about a profile that doesn't fit into the predefined schema. This field allows for structured storage and easy retrieval of specific attributes associated with a profile.</p>"},{"location":"qa/which_dockers_are_needed/","title":"Which dockers are needed for single and multitenant installation?","text":"<p>For a single-tenant installation, the following Docker containers must be enabled:</p> <ol> <li> <p>Tracardi API:</p> <ul> <li>Private API: Required for communication with the GUI.</li> <li>Public API: Required for data collection.</li> </ul> </li> <li> <p>Tracardi GUI:</p> <ul> <li>The graphical user interface must be enabled to interact with the system.</li> </ul> </li> <li> <p>Worker Services:</p> <ul> <li>Background Worker: Handles background tasks like message bulking.</li> <li>APM (Auto Profile Merging): Manages profile merging.</li> </ul> </li> <li> <p>TMS (Tenant Management Service):</p> <ul> <li>Not required in a single-tenant installation.</li> </ul> </li> </ol> <p>For a multi-tenant installation, the following Docker containers must be enabled:</p> <ol> <li> <p>Tracardi API:</p> <ul> <li>Private API: Required for GUI communication.</li> <li>Public API: Required for data collection.</li> </ul> </li> <li> <p>Tracardi GUI:</p> <ul> <li>The GUI must be enabled for tenant interaction.</li> </ul> </li> <li> <p>Worker Services:</p> <ul> <li>Background Worker: Handles background tasks like bulking.</li> <li>APM (Auto Profile Merging): Manages profile merging across tenants.</li> </ul> </li> <li> <p>TMS (Tenant Management Service):</p> <ul> <li>Required to manage multiple tenants.</li> </ul> </li> </ol>"},{"location":"qa/which_dockers_are_needed/#how-to-enable-multitenant-installation","title":"How to enable multitenant installation?","text":"<p>To enable a multi-tenant installation of Tracardi using Docker and Helm chart, you will need to perform the following steps based on the guidelines provided in the documentation:</p>"},{"location":"qa/which_dockers_are_needed/#multi-tenant-setup-with-docker","title":"Multi-Tenant Setup with Docker:","text":"<ol> <li> <p>Install the Tenant Management System (TMS):</p> <ul> <li>TMS is required to manage tenants in a multi-tenant setup.</li> <li>Run the TMS <code>tracardi/tms:&lt;latest-version&gt;</code>    ```</li> </ul> </li> <li> <p>Enable Multi-Tenancy in Tracardi:</p> <ul> <li>Multi-tenancy should be enabled in the <code>values.yaml</code> or the <code>.env-docker</code> configuration.</li> <li>Modify the configuration to set multi-tenant mode by adding:</li> </ul> </li> </ol> <pre><code>config:\n  multiTenant:\n    multi: \"yes\"\n</code></pre>"},{"location":"qa/which_dockers_are_needed/#multi-tenant-setup-with-helm-chart","title":"Multi-Tenant Setup with Helm Chart:","text":"<ol> <li> <p>Prerequisites:</p> <ul> <li>You will need Helm and Kubernetes (K8s) to proceed with the multi-tenant installation.</li> <li>Ensure you have the following dependencies installed:<ul> <li>MySQL</li> <li>Elasticsearch</li> <li>Redis</li> <li>Apache Pulsar</li> </ul> </li> <li>These services should be set up in their own namespaces as recommended for managing upgrades and isolation.</li> </ul> </li> <li> <p>Customize <code>values.yaml</code> for Multi-Tenancy:</p> <ul> <li>You need to customize the <code>values.yaml</code> file for the multi-tenant installation. Key settings for enabling   multi-tenancy are as follows:</li> </ul> </li> </ol> <pre><code>config:\n  multiTenant:\n    multi: \"yes\"  # Enable multi-tenancy\n</code></pre> <ol> <li>Install TMS and Configure API/GUI:<ul> <li>Configure the TMS and install it using the Helm chart or Docker as described above for Docker installation.</li> <li>Ensure that both the Public API (for data collection) and Private API (for communication with the GUI) are   configured to handle multi-tenancy. Use the following structure for your <code>values.yaml</code>:</li> </ul> </li> </ol> <pre><code>api:\n  private:\n    enabled: true\n    replicas: 1\n    service:\n      port: 8686\n  public:\n    enabled: true\n    replicas: 1\n    service:\n      port: 8585\n</code></pre> <ol> <li>Run the Installation:<ul> <li>After making the necessary modifications, you can deploy the Tracardi multi-tenant setup using Helm:</li> </ul> </li> </ol> <pre><code>helm install tracardi -f values.yaml &lt;path-to-helm-chart&gt;\n</code></pre>"},{"location":"qa/which_env_variabes_to_tweak_before_install/","title":"Which environment variables should I set before production installation?","text":"<p>Sure, here is the list including the new environment variables that can not be changed later or will require significant effort after installation:</p>"},{"location":"qa/which_env_variabes_to_tweak_before_install/#environment-variables","title":"Environment Variables","text":"<ol> <li> <p>EVENT_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for event data. Determines how event data is organized over   time.</li> <li>Default Value: <code>quarter</code></li> </ul> </li> <li> <p>PROFILE_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for profile data. Determines how profile data is organized   over time.</li> <li>Default Value: <code>quarter</code></li> </ul> </li> <li> <p>SESSION_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for session data. Determines how session data is organized   over time.</li> <li>Default Value: <code>quarter</code></li> </ul> </li> <li> <p>ENTITY_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for entity data. Determines how entity data is organized over   time.</li> <li>Default Value: <code>quarter</code></li> </ul> </li> <li> <p>ITEM_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for item data. Determines how item data is organized over   time.</li> <li>Default Value: <code>year</code></li> </ul> </li> <li> <p>LOG_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for general logs. Determines how log data is organized over   time.</li> <li>Default Value: <code>month</code></li> </ul> </li> <li> <p>DISPATCH_LOG_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for dispatch logs. Determines how dispatch log data is   organized over time.</li> <li>Default Value: <code>month</code></li> </ul> </li> <li> <p>CONSOLE_LOG_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for console logs. Determines how console log data is   organized over time.</li> <li>Default Value: <code>month</code></li> </ul> </li> <li> <p>USER_LOG_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for user logs. Determines how user log data is organized over   time.</li> <li>Default Value: <code>year</code></li> </ul> </li> <li> <p>FIELD_CHANGE_LOG_PARTITIONING</p> <ul> <li>Explanation: Specifies the partitioning strategy for field change logs. Determines how field change log data   is organized over time.</li> <li>Default Value: <code>month</code></li> </ul> </li> <li> <p>AUTO_PROFILE_MERGING</p> <ul> <li>Explanation: Sets the secret key for hashing data during the automatic profile merging process. This is used   to ensure secure merging of profiles.</li> <li>Default Value: <code>s&gt;a.d-kljsa87^5adh</code></li> </ul> </li> <li> <p>INSTALLATION_TOKEN</p> <ul> <li>Explanation: Token used for the installation process. It is required for setting up and initializing Tracardi.</li> <li>Default Value: <code>tracardi</code></li> </ul> </li> <li> <p>ELASTIC_INDEX_REPLICAS</p> <ul> <li>Explanation: Specifies the number of replica shards for Elasticsearch indices. Determines the number of copies   of each shard.</li> <li>Default Value: <code>1</code></li> </ul> </li> <li> <p>ELASTIC_INDEX_SHARDS</p> <ul> <li>Explanation: Specifies the number of primary shards for Elasticsearch indices. Determines how the index is   divided.</li> <li>Default Value: <code>3</code></li> </ul> </li> <li> <p>ELASTIC_CONF_INDEX_SHARDS</p> <ul> <li>Explanation: Specifies the number of primary shards for Elasticsearch configuration indices. Used for specific   configurations of the Elasticsearch setup.</li> <li>Default Value: <code>1</code></li> </ul> </li> </ol>"},{"location":"qa/who_is_tracardi_for/","title":"Who is Tracardi for? How can I benefit from installing Tracardi?","text":"<p>Are you searching for a powerful tool to automate your customer journey? Look no further than Tracardi! Designed to cater to a wide range of individuals and companies, Tracardi offers both a free open-source version and a commercial open-source version, ensuring there's something for everyone.</p> <p>If you're an individual or a small company, the free open-source version of Tracardi is perfect for you. With its comprehensive features, it covers all aspects of customer journey automation. Enjoy the benefits of automating your processes without any cost attached.</p> <p>For marketing agencies and larger corporations, the commercial open-source version of Tracardi is specifically designed to meet your needs. This version includes advanced functionalities like the integration of a Customer Data Platform ( CDP) and a Digital Experience Platform (DXP). Seamlessly incorporate these platforms into your existing systems to enhance your marketing strategies and improve customer experiences.</p> <p>One of Tracardi's standout features is its incorporation of LLM Orchestration in the commercial version. This means you can effortlessly leverage the power of Artificial Intelligence (AI) in your customer journey. With Tracardi, you can take advantage of AI-driven insights and automation to optimize your marketing campaigns and enhance customer engagement.</p> <p>Tracardi also offers a partner program tailor-made for agencies and resellers. If you're interested in reselling Tracardi or integrating it into your own product lineup, we welcome you to join our partner program. Get in touch with us today, and our team will provide you with all the information you need to become a Tracardi partner.</p> <p>Don't miss out on the convenience and efficiency that Tracardi brings to your customer journey. Install Tracardi now and experience the seamless automation of your customer interactions like never before. Take control of your marketing efforts with Tracardi today!</p>"},{"location":"qa/why_background_task_in_pending_state/","title":"Why is my background task in a pending state?","text":"<p>The most likely reason for this is that you either haven't started the Tracardi worker or it's not functioning properly.</p> <p>This document also answers the queries / questions: - My import is not working, Why? - Can not migrate data - I see always state pending in background tasks</p>"},{"location":"qa/why_can_not_conenct_to_lcoalhost/","title":"I can not connect to http://localhost:8686 when using docker.","text":"<p>You are unable to connect to localhost when using a Docker container because Docker has its own network, and when you refer to \"localhost\" inside a Docker container, it points to the container's local environment, not your laptop's. To connect to the services running on your laptop from the Docker container, you need to use your laptop's IP address instead of \"localhost.\"</p> <p>Try this:</p> <ol> <li> <p>Make sure the API is working correctly. If it's accessible at http://localhost:8686/docs, that's a good sign.</p> </li> <li> <p>Instead of using \"localhost\", find your laptop's IP address. You can do this by checking    your laptop's network settings or using a command like <code>ipconfig</code> (on Windows) or <code>ifconfig</code> (on Linux/macOS).    Replace \"localhost\" with your laptop's IP address in the URL.</p> </li> <li> <p>Check http://:8686 in the browser. It should return <code>{\"detals\": \"Not found\"}</code>, that means it works correctly. <li> <p>Type Tracardi API as http://:8686 in the GUI by using the URL with your laptop's IP address. For example, if your laptop's IP is    192.168.1.100, you would use http://192.168.1.100:8686/. <p>By following these steps, you should be able to connect to your laptop's services from within the Docker container and resolve the connection error.</p>"},{"location":"qa/why_do_I_have_session-opened/","title":"Why do I have session-opened when first event is collected?","text":"<p>In Tracardi, the session-opened event is triggered when the first event is collected due to the platform's built-in event types that automatically activate for specific actions. When the first event is collected, Tracardi checks if the user has an existing session. If there is no session associated with the user, Tracardi creates a new one, and this action triggers the session-opened event.</p> <p>Similarly, this logic is applied to profile and visit events. If there is no existing profile or visit for the user, Tracardi generates new ones and raises the respective events. This functionality is beneficial as it allows users to associate additional workflows or actions with the event of a session being opened or a new user profile being created. This way, users can implement custom behaviors or processes triggered by these events within the Tracardi platform.</p>"},{"location":"qa/why_i_do_not_see_the_event_from_my_code/","title":"'m using my own code to send an event with window.tracker.track, but it's not showing up in Tracardi. What should I do?","text":"<p>To ensure your event is recognized in Tracardi when using <code>window.tracker.track</code> after the page has loaded, you need to add <code>fire: true</code> to your call. Your code should look like this:</p> <pre><code>window.tracker.track('event-type', properties, {fire: true});\n</code></pre>"},{"location":"qa/why_live_segmentation_does_not_work/","title":"Why my live segmentation does not work?","text":"<p>There could be several reasons why your live segmentation is not working as expected. Here are some possible explanations:</p> <ul> <li> <p>Docker Configuration: Ensure that the required Docker containers, such as tracardi/com-tracardi-segmentation-job and   tracardi/com-tracardi-segmentation-worker, are properly installed and running. Check their status and logs to identify   any potential issues or errors that could be preventing the live segmentation from working.</p> </li> <li> <p>Schedule and Frequency: Verify the schedule and frequency at which the live segmentation is set to run. If the   schedule is not properly configured or the frequency is too low, it may result in the live segmentation not being   triggered as frequently as desired. Adjust the schedule or frequency if necessary.</p> </li> <li> <p>Workflow Enablement: Check if the live segmentation workflow is enabled in your system. Navigate to the processing   and find <code>live segments</code> section and ensure that the segmentation workflow is properly connected and enabled. If   it is not enabled, the live segmentation will not be executed.</p> </li> <li> <p>Complex Segmentation Conditions: Live segmentation can involve complex conditions and logic. Review the segmentation   conditions defined in your workflow and ensure they accurately reflect the criteria for segmenting profiles. If the   conditions are too strict or not properly configured, it may result in profiles not meeting the segmentation criteria   and thus not being segmented.</p> </li> </ul> <p>By addressing these aspects, you should be able to identify the underlying cause of the live segmentation not working and take appropriate steps to resolve the issue.</p> <ul> <li>How ot debug live segmentation?</li> </ul>"},{"location":"qa/why_my_debuging_fails/","title":"Why does debugging fail to function even though the workflow runs correctly during normal execution?","text":"<p>Debugging might not work while the workflow executes correctly due to the way the debugging environment is set up. In a typical workflow execution, the system automatically handles loading the internal state of workflow, which includes the relevant event and profile data. However, in a debugging environment, this automatic setup doesn't occur by default.</p> <p>The key issue here is the setup of the workflow's internal state for debugging:</p> <ol> <li> <p>Selecting the Event for Debugging: You can manually specify which event you want to debug. This is typically done    by finding the event in a list of events and clicking the debug button. This action    should load the selected event into the workflow for debugging.</p> </li> <li> <p>Setting Event and Profile IDs: By default, when you enter the workflow in debug mode, it starts with an empty    event and profile. This means that the debugger does not have any specific data to work with, leading to ineffective    debugging. To counter this, you need to manually set the <code>event_id</code> and <code>profile_id</code> in the start node. This action    instructs the system to load the relevant data first, creating an environment that mirrors the actual workflow    execution.</p> </li> </ol> <p>In summary, debugging may not work because the debugger doesn't automatically know which event to process. You need to manually set up the event and profile information in the workflow's internal state for the debugger to function correctly. This setup discrepancy between normal execution and debugging can lead to situations where the workflow runs fine normally but encounters issues in the debug mode.</p>"},{"location":"qa/why_my_migration_do_not_start/","title":"Why my migration do not start?","text":"<p>Most probably the issue with your Tracardi migration is related to the Migration and Import Worker not being started. The Migration and Import Worker is essential for system upgrades and data import tasks in Tracardi, as it handles these processes in the background.</p> <p>To resolve the issue, you should start the Migration and Import Worker. You can do this by executing the following Docker command:</p> <pre><code>docker run \\\n-e REDIS_HOST=redis://&lt;redis-ip&gt;:6379 \\\ntracardi/update-worker:0.8.1\n</code></pre> <p>Make sure to replace  with the actual IP address of your Redis instance. This command will initiate the Migration and Import Worker, which should facilitate the migration process. <p>Tip</p> <p>This migration process is valid for systems before version 0.9.0</p>"},{"location":"qa/why_my_script_is_not_sending_events/","title":"Why my script is not sending events","text":""},{"location":"qa/why_my_script_is_not_sending_events/#why-is-my-script-on-the-page-not-sending-events","title":"Why Is My Script on the Page Not Sending Events?","text":"<p>I placed the Tracardi script but do not see any events.</p> <p>There can be several reasons why your JavaScript script on the page is not sending events to Tracardi. Here are some common issues and troubleshooting steps:</p> <ol> <li> <p>Incorrect Script Placement:    Ensure that the Tracardi integration script is correctly placed on your webpage. The script should be placed in    the <code>&lt;head&gt;</code> section of your HTML file to ensure it is loaded correctly. It should be before    the <code>window.tracker.track(\"page-view\", {});</code> commands.</p> </li> <li> <p>Script Errors:    Check the browser console for any JavaScript errors. Any errors in your script can prevent it from executing    correctly. Make sure that you got the right Javascript snippet for your event source. To get the correct snippet go    to <code>Event sources</code>. Select the event source then click <code>Javascript and use</code> tab and there is the script.</p> </li> <li> <p>Network Issues:    Verify that your network is allowing requests to Tracardi's endpoint. Sometimes, network policies or ad blockers can    prevent the script from sending data. If your page is protected by SSL (https), then your Tracardi API should also be    SSL. Other potential network issues include firewall restrictions and DNS problems.</p> </li> <li> <p>Configuration Issues:    Ensure that the configuration for your Tracardi instance is correct, including the endpoint URL and any necessary    authentication tokens such as the source ID. If the source ID is incorrect, you should see an error message.</p> </li> <li> <p>Event Source Settings:    Check the event source settings in Tracardi to ensure that it is configured to accept events from your script. This    includes checking if the configuration of the event source does not forbid events from outside the configured list of    domains.</p> </li> <li> <p>Tracker Payload Schema:    Check if the tracker payload schema is correct. This issue typically arises when collecting through the API and    setting the schema manually. If you use JavaScript, this should not be an issue.</p> </li> <li> <p>Browser Compatibility:    Ensure that the script is compatible with the browsers being used. Some features may not work in older or unsupported    browsers.</p> </li> </ol>"},{"location":"qa/why_my_script_is_not_sending_events/#steps-to-troubleshoot","title":"Steps to Troubleshoot","text":"<ol> <li> <p>Check Script Placement:    Ensure the script tag is correctly placed and the Tracardi endpoint is reachable.</p> </li> <li> <p>Console Logs:    Open the browser console (F12 or right-click -&gt; Inspect -&gt; Console) to check for any errors or messages.</p> </li> <li> <p>Network Tab:    Use the Network tab in the browser developer tools to check if the requests to the Tracardi endpoint are being sent    and if they receive a response.</p> </li> <li> <p>Review Documentation:    Consult the Tracardi documentation for any recent changes or updates that might affect how events should be sent.</p> </li> <li> <p>Check Event Source Configuration:    Verify that the event source configuration in Tracardi is correct and matches the script settings.</p> </li> </ol> <p>By following these steps, you should be able to identify and resolve the issue preventing your JavaScript script from sending events to Tracardi.</p>"},{"location":"qa/why_post_event_segmentation_does_not%20work/","title":"Why my post event segmentation does not work?","text":"<p>There could be several reasons why your post event segmentation is not being triggered. Here are some possible explanations:</p> <ul> <li> <p>Event Not Occurring: Post event segmentation relies on specific events to trigger the segmentation process. If the   expected event is not occurring or not being sent to the system, the segmentation won't be triggered. Make sure that   the relevant events are being generated and properly captured by your system.</p> </li> <li> <p>Profile Not Updated: Post event segmentation is based on changes or updates to the profile data. If there are no   changes to the profile, the segmentation conditions won't be evaluated. Ensure that the events being received are   properly updating the profile data, triggering the segmentation process.</p> </li> <li> <p>Segmentation Conditions Not Met: Each segmentation has specific conditions that profiles must meet to be assigned to a   segment. If the conditions are not being met, the segmentation won't occur. Double-check your segmentation conditions   to ensure they are correctly defined and aligned with the profile data being updated by the events. For example, if   you have a condition that checks if the number of visits is greater than 10, make sure that the profile data reflects   this change and satisfies the condition.</p> </li> </ul> <p>To troubleshoot the issue, you can:</p> <ul> <li>Review your event data and check if the expected events are being received and processed.</li> <li>Monitor the profile data to ensure that it is being updated correctly in response to the events. Check if the workflow   uses <code>Update Profile</code> after the profile data was changed.</li> <li>Verify that the segmentation conditions are properly defined and align with the updated profile data.</li> </ul> <p>By analyzing these factors, you should be able to identify the cause of the post event segmentation not working as expected and take appropriate steps to resolve the issue.</p> <p>This document answers the following questions:</p> <ul> <li>When post event segmentation is triggered.</li> </ul>"},{"location":"qa/why_should_you_always_use_https_api/","title":"Why should you always use HTTPS as tracardi endpoint.","text":"<p>Using HTTPS as the endpoint for your Tracardi API is essential for several reasons:</p> <ol> <li>Avoiding CORS Errors During Preflight Requests:    When making cross-origin requests in modern web browsers, the browser first performs a preflight request using    the <code>OPTIONS</code> method to check if the actual request is safe to send. If the preflight request results in a 307    redirect (which occurs when a temporary redirect is made), certain browsers like Chrome will block the request if    the redirect involves switching between <code>http</code> and <code>https</code> protocols. This is due to security concerns.</li> </ol> <p>Specifically, a CORS error can occur when a preflight request is redirected to another domain, especially when    switching from <code>http</code> to <code>https</code>. Chrome, in particular, is very strict with its CORS policy and will block this    redirection, resulting in no data being collected from the Tracardi API.</p> <ol> <li>Preventing 307 Redirect Issues:    A 307 redirect in a preflight call can happen if your Tracardi API is hosted on an <code>http</code> endpoint and the    browser tries to redirect it to an <code>https</code> endpoint. This can confuse the browser\u2019s CORS handling, causing it to    block the request. Browsers like Chrome do not allow redirects during preflight <code>OPTIONS</code> requests, leading to the    API call being completely blocked.</li> </ol> <p>By using HTTPS as the endpoint, you avoid the need for such redirects, ensuring that all preflight requests and    actual API calls are successfully completed. This leads to smoother, uninterrupted data flow and API communication.</p> <ol> <li> <p>Security Considerations:    Apart from avoiding CORS issues, using HTTPS ensures that your data is encrypted during transit. This means that any    sensitive data, such as user information or analytics data, is securely transferred between your client and the    Tracardi API, reducing the risk of interception by malicious actors.</p> </li> <li> <p>Browser Compatibility and Best Practices:    Modern browsers like Chrome, Firefox, and Safari increasingly prioritize security and privacy. Using HTTPS aligns    with best practices recommended by browsers, ensuring that your application remains compatible with browser updates    and prevents potential issues with blocked requests due to insecure endpoints.</p> </li> </ol> <p>Summary:</p> <p>By always using HTTPS for Tracardi API endpoints, you avoid CORS-related issues, especially those caused by 307 redirects in preflight requests. Chrome\u2019s strict policies on redirect handling can prevent data from being collected if an insecure <code>http</code> endpoint is used. To ensure smooth operation, proper data collection, and secure communication, always opt for HTTPS.</p>"},{"location":"qa/why_some_of_the_update_timestamp_on_profile_fields_are_different/","title":"Why are some of the update timestamps on profile fields different?**","text":"<p>Each field in a profile may be updated at different times during the customer's journey. Some fields are filled earlier, while others may be updated later. Additionally, the timestamp of a field can change during the process of profile merging, depending on the system's merging rules and the specific interactions or events that trigger updates to the profile.</p>"},{"location":"qa/why_this_is_a_security_risk_to_use_simple_profile_and_session_id/","title":"Why this is a security risk to use simple profile and session id?","text":"<p>Using simple profile and session IDs can pose a security risk for your system. Complex IDs, such as UUID4, are difficult to guess and provide a higher level of uniqueness. However, using simple and predictable IDs can enable malicious actors to exploit vulnerabilities in your system. Here's why:</p> <ol> <li> <p>Fake Event Injection: If an attacker is aware of the event source ID (which is often publicly available) and has    knowledge of either the session ID or profile ID, they can send a fake event that will be falsely associated with a    legitimate profile. This can lead to data corruption and manipulation of your system.</p> </li> <li> <p>Brute Force Attacks: When using numeric IDs, an attacker can perform brute force attacks by generating IDs within a    defined range and attempting to register events in your system. Similarly, if simple session IDs are used, an    attacker can try various combinations to gain access to profile session. Session is connected with profile so events    with correct session will also be registered.</p> </li> <li> <p>External System Vulnerabilities: When sending IDs from external systems, it becomes even more crucial to avoid using    simple numeric profile or session IDs. This is because external systems may not have robust security measures in    place, making them more susceptible to attacks. By using complex and unpredictable IDs, you enhance the security of    your system and reduce the risk of unauthorized access.</p> </li> </ol> <p>To mitigate these security risks, it is recommended to implement complex and randomly generated IDs, such as UUID4, for both profile and session identification. These IDs are difficult to guess, ensuring a higher level of security for your system.</p> <p>By following this best practice and avoiding the use of simple numeric IDs, you can significantly reduce the likelihood of unauthorized access, fake event injection, and data corruption in your Tracardi workflow. By default, Tracardi use UUID4 ids.</p>"},{"location":"qa/why_tracardi_acts_differently_when_pulsar_id_disabled/","title":"Why tracardi acts differently when I have pulsar disabled and enabled with PULSAR_DISABLED env variable?","text":"<p>Tracardi behaves differently when Pulsar is enabled versus when it is disabled due to the role Pulsar plays in managing event streams and background tasks in the system. Here's how it affects the behavior:</p> <ol> <li> <p>Event Streaming and Message Queuing: Pulsar is used to handle high-throughput, low-latency message streams,    including event streaming and background workflows. When Pulsar is enabled, Tracardi can offload tasks to the    messaging system, ensuring asynchronous processing of events, which improves scalability and performance.</p> </li> <li> <p>Workflow Asynchrony: Tracardi workflows are designed to benefit from asynchronous processing when Pulsar is    enabled. With Pulsar active, workflows can handle tasks asynchronously, allowing more complex tasks to be handled    without blocking other operations. This results in faster responses for events processed in real-time, especially    when heavy background tasks are involved.</p> </li> <li> <p>Distributed Systems and Scaling: Pulsar enables Tracardi to scale horizontally by distributing the load across    multiple nodes. When Pulsar is disabled, Tracardi falls back to synchronous processing or in-memory queues, which may    be less efficient, especially in high-load scenarios.</p> </li> <li> <p>Handling of Background Tasks: With Pulsar enabled, background workers can handle large queues of tasks    effectively by leveraging Pulsar's capabilities. When it\u2019s disabled, tasks that would otherwise be queued for    background processing may be executed synchronously, potentially slowing down real-time event processing.</p> </li> <li> <p>Configuration Inconsistency: Another reason for the different behavior between Tracardi when Pulsar is enabled or    disabled could be due to configuration consistency between Tracardi API and Tracardi Worker. Tracardi API and    Worker are separate Docker containers, and both need to be configured identically for the system to function    correctly, especially when it comes to integrations like Pulsar.</p> </li> </ol> <p>If you are using Helm charts for installation, they automatically track changes and apply those changes consistently    to both the API and Worker configurations. This ensures that the same settings, such as Pulsar's host, port, and    authentication tokens, are applied to both components. However, if you are managing the installation manually, you    must ensure that any configuration changes, particularly related to Pulsar, are applied manually to both the API and    Worker. Inconsistent configurations can lead to one component (e.g., the API) being able to communicate with Pulsar    while the Worker cannot, resulting in unexpected behaviors, including failures in event handling or background task    processing.</p> <p>This manual setup requires attention to configuration files such as environment variables for    Pulsar's <code>host</code>, <code>port</code>, and authentication, which need to be replicated exactly between both Docker containers.</p> <p>If you skip this step or have a mismatch between the API and Worker, Tracardi will behave inconsistently, especially    when handling events or background workflows that rely on Pulsar.</p>"},{"location":"qa/why_webhook_events_do_not_have_session_and_profile/","title":"Why webhook events dot not have session and profile?","text":"<p>By default, webhook events do not include session and profile information. This design choice is based on the fact that most external systems are unaware of the Tracaardi Profile ID and session ID. Although it is possible to create a webhook URL that incorporates an encoded session ID, it is rarely used due to the difficulty of passing session information through a URL in external systems. In practice, approximately 99% of the time, the profile ID or session ID is transmitted within the webhook payload data.</p> <p>To address this limitation, we provide an option to replace or set the profile ID or session ID of the event collected by the webhook URL using the payload data. This allows users to customize and manage the session and profile information associated with webhook events effectively.</p> <p>When configuring webhook integrations, it is important to keep in mind that the default behavior does not include session and profile information. However, by extracting and manipulating the relevant data from the payload, users can integrate their desired session and profile details into webhook events seamlessly.</p>"},{"location":"qa/bulk/available_extensions_with_description/","title":"What extensions are in Tracardi ?","text":"<ul> <li>ActiveCampaign: Customer Experience Automation Platform for sending email campaigns, automating features, and managing contacts.</li> <li>Airtable: Cloud collaboration service with spreadsheet-database hybrid features for managing data.</li> <li>Amplitude: Cloud-based analytical system for better understanding of customer behavior.</li> <li>AWS IAM: AWS connector that opens Tracardi to AWS services.</li> <li>Civi CRM: Web-based suite for managing information about an organization's constituents, donors, members, and more.</li> <li>ElasticEmail: All-in-one email delivery platform with tools for managing contacts, templates, campaigns, and reports.</li> <li>ElasticSearch: Distributed, free, and open search and analytics engine for various types of data.</li> <li>Full contact: Cloud-based contact identity resolution platform for accurately identifying people and optimizing experiences.</li> <li>HubSpot: Integrated CRM platform with marketing, sales, service, operations, and website-building software.</li> <li>InfluxDB: Open-source time series database with APIs for storing, querying, processing, and visualizing data.</li> <li>Mailchimp MA: Marketing automation platform and email marketing service.</li> <li>Matomo: Free and open-source web analytics application for tracking online visits and generating reports.</li> <li>Mautic MA: Open-source marketing automation platform with lead management, campaign management, and email features.</li> <li>Meaning Cloud: Machine learning services for sentiment analysis, language detection, text classification, and more.</li> <li>Microservice: Handles Tracardi plugin microservices for accessing a growing set of services with zero maintenance cost.</li> <li>Mixpanel: Business analytics service for tracking user interactions and measuring engagement and retention.</li> <li>MongoDB: Cross-platform document-oriented database program with JSON-like documents and optional schemas.</li> <li>MQTT: Messaging protocol for the Internet of Things (IoT) that is lightweight and ideal for remote devices.</li> <li>MySQL: Relational database management system based on structured query language (SQL).</li> <li>Novu messaging: Open-source notification infrastructure for developers to send messages to different providers.</li> <li>PostgreSQL: Free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.</li> <li>Pushover: Real-time notification service for Android, iPhone, iPad, Desktop, Android Wear, and Apple Watch.</li> <li>RabbitMq: Connector for RabbitMQ, a message broker that allows distributed data processing outside Tracardi server.</li> <li>Redis: Open-source, in-memory data structure store used as a database, cache, and message broker.</li> <li>Salesforce: Cloud-based customer relationship management platform and marketing automation system.</li> <li>Scheduler: Handles scheduled events for delivering messages or performing actions at specific times.</li> <li>SendGrid: Cloud-based SMTP provider for sending emails without maintaining email servers.</li> <li>Sms77: Professional SMS solutions for sending and receiving SMS messages via API, email, or directly in your app.</li> <li>Zapier: Product for integrating web applications and automating workflows.</li> </ul>"},{"location":"qa/bulk/available_extenstions/","title":"What extensions are in Tracardi","text":"<p>List of available Tracardi extensions:</p> <ul> <li>ActiveCampaign</li> <li>Airtable</li> <li>Amplitude</li> <li>AWS IAM</li> <li>Civi CRM</li> <li>ElasticEmail</li> <li>ElasticSearch</li> <li>Full contact</li> <li>HubSpot</li> <li>InfluxDB</li> <li>Mailchimp MA</li> <li>Matomo</li> <li>Mautic MA</li> <li>Meaning Cloud</li> <li>Microservice</li> <li>Mixpanel</li> <li>MongoDB</li> <li>MQTT</li> <li>MySQL</li> <li>Novu messaging</li> <li>PostgreSQL</li> <li>Pushover</li> <li>RabbitMq</li> <li>Redis</li> <li>Salesforce</li> <li>Scheduler</li> <li>SendGrid</li> <li>Sms77</li> <li>Zapier</li> </ul>"},{"location":"qa/bulk/extension_questions/","title":"Can Tracardi use ActiveCampaign ?","text":"<p>Yes. To use ActiveCampaign, install the extension ActiveCampaign in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-airtable","title":"Can Tracardi use Airtable ?","text":"<p>Yes. To use Airtable, install the extension Airtable in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-amplitude","title":"Can Tracardi use Amplitude ?","text":"<p>Yes. To use Amplitude, install the extension Amplitude in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-aws-iam","title":"Can Tracardi use AWS IAM ?","text":"<p>Yes. To use AWS IAM, install the extension AWS IAM in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-civi-crm","title":"Can Tracardi use Civi CRM ?","text":"<p>Yes. To use Civi CRM, install the extension Civi CRM in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-elasticemail","title":"Can Tracardi use ElasticEmail ?","text":"<p>Yes. To use ElasticEmail, install the extension ElasticEmail in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-elasticsearch","title":"Can Tracardi use ElasticSearch ?","text":"<p>Yes. To use ElasticSearch, install the extension ElasticSearch in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-full-contact","title":"Can Tracardi use Full contact ?","text":"<p>Yes. To use Full contact, install the extension Full contact in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-hubspot","title":"Can Tracardi use HubSpot ?","text":"<p>Yes. To use HubSpot, install the extension HubSpot in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-influxdb","title":"Can Tracardi use InfluxDB ?","text":"<p>Yes. To use InfluxDB, install the extension InfluxDB in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mailchimp","title":"Can Tracardi use Mailchimp ?","text":"<p>Yes. To use Mailchimp MA, install the extension Mailchimp MA in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-matomo","title":"Can Tracardi use Matomo?","text":"<p>Yes. To use Matomo, install the extension Matomo in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mautic","title":"Can Tracardi use Mautic ?","text":"<p>Yes. To use Mautic MA, install the extension Mautic MA in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-meaning-cloud","title":"Can Tracardi use Meaning Cloud ?","text":"<p>Yes. To use Meaning Cloud, install the extension Meaning Cloud in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-microservice","title":"Can Tracardi use Microservice ?","text":"<p>Yes. To use Microservice, install the extension Microservice in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mixpanel","title":"Can Tracardi use Mixpanel ?","text":"<p>Yes. To use Mixpanel, install the extension Mixpanel in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mongodb","title":"Can Tracardi use MongoDB ?","text":"<p>Yes. To use MongoDB, install the extension MongoDB in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mqtt","title":"Can Tracardi use MQTT ?","text":"<p>Yes. To use MQTT, install the extension MQTT in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mysql","title":"Can Tracardi use MySQL ?","text":"<p>Yes. To use MySQL, install the extension MySQL in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-novu-messaging","title":"Can Tracardi use Novu messaging ?","text":"<p>Yes. To use Novu messaging, install the extension Novu messaging in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-postgresql","title":"Can Tracardi use PostgreSQL ?","text":"<p>Yes. To use PostgreSQL, install the extension PostgreSQL in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-pushover","title":"Can Tracardi use Pushover ?","text":"<p>Yes. To use Pushover, install the extension Pushover in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-rabbitmq","title":"Can Tracardi use RabbitMq ?","text":"<p>Yes. To use RabbitMq, install the extension RabbitMq in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-redis","title":"Can Tracardi use Redis ?","text":"<p>Yes. To use Redis, install the extension Redis in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-salesforce","title":"Can Tracardi use Salesforce ?","text":"<p>Yes. To use Salesforce, install the extension Salesforce in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-scheduler","title":"Can Tracardi use Scheduler ?","text":"<p>Yes. To use Scheduler, install the extension Scheduler in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-sendgrid","title":"Can Tracardi use SendGrid ?","text":"<p>Yes. To use SendGrid, install the extension SendGrid in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-sms77","title":"Can Tracardi use Sms77 ?","text":"<p>Yes. To use Sms77, install the extension Sms77 in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-zapier","title":"Can Tracardi use Zapier ?","text":"<p>Yes. To use Zapier, install the extension Zapier in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-activecampaign-a-customer-experience-automation-platform-for-sending-email-campaigns-automating-features-and-managing-contacts","title":"Can Tracardi use ActiveCampaign, a Customer Experience Automation Platform for sending email campaigns, automating features, and managing contacts?","text":"<p>Yes. To use ActiveCampaign, install the extension ActiveCampaign in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-airtable-a-cloud-collaboration-service-with-spreadsheet-database-hybrid-features-for-managing-data","title":"Can Tracardi use Airtable, a cloud collaboration service with spreadsheet-database hybrid features for managing data?","text":"<p>Yes. To use Airtable, install the extension Airtable in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-amplitude-a-cloud-based-analytical-system-for-better-understanding-customer-behavior","title":"Can Tracardi use Amplitude, a cloud-based analytical system for better understanding customer behavior?","text":"<p>Yes. To use Amplitude, install the extension Amplitude in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-aws-iam-an-aws-connector-that-opens-tracardi-to-aws-services","title":"Can Tracardi use AWS IAM, an AWS connector that opens Tracardi to AWS services?","text":"<p>Yes. To use AWS IAM, install the extension AWS IAM in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-civi-crm-a-web-based-suite-for-managing-information-about-an-organizations-constituents-donors-members-and-more","title":"Can Tracardi use Civi CRM, a web-based suite for managing information about an organization's constituents, donors, members, and more?","text":"<p>Yes. To use Civi CRM, install the extension Civi CRM in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-elasticemail-an-all-in-one-email-delivery-platform-with-tools-for-managing-contacts-templates-campaigns-and-reports","title":"Can Tracardi use ElasticEmail, an all-in-one email delivery platform with tools for managing contacts, templates, campaigns, and reports?","text":"<p>Yes. To use ElasticEmail, install the extension ElasticEmail in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-elasticsearch-a-distributed-free-and-open-search-and-analytics-engine-for-various-types-of-data","title":"Can Tracardi use ElasticSearch, a distributed, free, and open search and analytics engine for various types of data?","text":"<p>Yes. To use ElasticSearch, install the extension ElasticSearch in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-full-contact-a-cloud-based-contact-identity-resolution-platform-for-accurately-identifying-people-and-optimizing-experiences","title":"Can Tracardi use Full contact, a cloud-based contact identity resolution platform for accurately identifying people and optimizing experiences?","text":"<p>Yes. To use Full contact, install the extension Full contact in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-hubspot-an-integrated-crm-platform-with-marketing-sales-service-operations-and-website-building-software","title":"Can Tracardi use HubSpot, an integrated CRM platform with marketing, sales, service, operations, and website-building software?","text":"<p>Yes. To use HubSpot, install the extension HubSpot in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-influxdb-an-open-source-time-series-database-with-apis-for-storing-querying-processing-and-visualizing-data","title":"Can Tracardi use InfluxDB, an open-source time series database with APIs for storing, querying, processing, and visualizing data?","text":"<p>Yes. To use InfluxDB, install the extension InfluxDB in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mailchimp-ma-a-marketing-automation-platform-and-email-marketing-service","title":"Can Tracardi use Mailchimp MA, a marketing automation platform and email marketing service?","text":"<p>Yes. To use Mailchimp MA, install the extension Mailchimp MA in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-matomo-a-free-and-open-source-web-analytics-application-for-tracking-online-visits-and-generating-reports","title":"Can Tracardi use Matomo, a free and open-source web analytics application for tracking online visits and generating reports?","text":"<p>Yes. To use Matomo, install the extension Matomo in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mautic-ma-an-open-source-marketing-automation-platform-with-lead-management-campaign-management-and-email-features","title":"Can Tracardi use Mautic MA, an open-source marketing automation platform with lead management, campaign management, and email features?","text":"<p>Yes. To use Mautic MA, install the extension Mautic MA in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-meaning-cloud-a-machine-learning-service-for-sentiment-analysis-language-detection-text-classification-and-more","title":"Can Tracardi use Meaning Cloud, a machine learning service for sentiment analysis, language detection, text classification, and more?","text":"<p>Yes. To use Meaning Cloud, install the extension Meaning Cloud in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-microservice-which-handles-tracardi-plugin-microservices-for-accessing-a-growing-set-of-services-with-zero-maintenance-cost","title":"Can Tracardi use Microservice, which handles Tracardi plugin microservices for accessing a growing set of services with zero maintenance cost?","text":"<p>Yes. To use Microservice, install the extension Microservice in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mixpanel-a-business-analytics-service-for-tracking-user-interactions-and-measuring-engagement-and-retention","title":"Can Tracardi use Mixpanel, a business analytics service for tracking user interactions and measuring engagement and retention?","text":"<p>Yes. To use Mixpanel, install the extension Mixpanel in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mongodb-a-cross-platform-document-oriented-database-program-with-json-like-documents-and-optional-schemas","title":"Can Tracardi use MongoDB, a cross-platform document-oriented database program with JSON-like documents and optional schemas?","text":"<p>Yes. To use MongoDB, install the extension MongoDB in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mqtt-a-messaging-protocol-for-the-internet-of-things-iot-that-is-lightweight-and-ideal-for-remote-devices","title":"Can Tracardi use MQTT, a messaging protocol for the Internet of Things (IoT) that is lightweight and ideal for remote devices?","text":"<p>Yes. To use MQTT, install the extension MQTT in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-mysql-a-relational-database-management-system-based-on-structured-query-language-sql","title":"Can Tracardi use MySQL, a relational database management system based on structured query language (SQL)?","text":"<p>Yes. To use MySQL, install the extension MySQL in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-novu-messaging-an-open-source-notification-infrastructure-for-developers-to-send-messages-to-different-providers","title":"Can Tracardi use Novu messaging, an open-source notification infrastructure for developers to send messages to different providers?","text":"<p>Yes. To use Novu messaging, install the extension Novu messaging in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-postgresql-a-free-and-open-source-relational-database-management-system-rdbms-emphasizing-extensibility-and-sql-compliance","title":"Can Tracardi use PostgreSQL, a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance?","text":"<p>Yes. To use PostgreSQL, install the extension PostgreSQL in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-pushover-a-real-time-notification-service-for-android-iphone-ipad-desktop-android-wear-and-apple-watch","title":"Can Tracardi use Pushover, a real-time notification service for Android, iPhone, iPad, Desktop, Android Wear, and Apple Watch?","text":"<p>Yes. To use Pushover, install the extension Pushover in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-rabbitmq-a-connector-for-rabbitmq-a-message-broker-that-allows-distributed-data-processing-outside-tracardi-server","title":"Can Tracardi use RabbitMq, a connector for RabbitMQ, a message broker that allows distributed data processing outside Tracardi server?","text":"<p>Yes. To use RabbitMq, install the extension RabbitMq in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-redis-an-open-source-in-memory-data-structure-store-used-as-a-database-cache-and-message-broker","title":"Can Tracardi use Redis, an open-source, in-memory data structure store used as a database, cache, and message broker?","text":"<p>Yes. To use Redis, install the extension Redis in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-salesforce-a-cloud-based-customer-relationship-management-platform-and-marketing-automation-system","title":"Can Tracardi use Salesforce, a cloud-based customer relationship management platform and marketing automation system?","text":"<p>Yes. To use Salesforce, install the extension Salesforce in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-scheduler-which-handles-scheduled-events-for-delivering-messages-or-performing-actions-at-specific-times","title":"Can Tracardi use Scheduler, which handles scheduled events for delivering messages or performing actions at specific times?","text":"<p>Yes. To use Scheduler, install the extension Scheduler in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-sendgrid-a-cloud-based-smtp-provider-for-sending-emails-without-maintaining-email-servers","title":"Can Tracardi use SendGrid, a cloud-based SMTP provider for sending emails without maintaining email servers?","text":"<p>Yes. To use SendGrid, install the extension SendGrid in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-sms77-a-professional-sms-solution-for-sending-and-receiving-sms-messages-via-api-email-or-directly-in-your-app","title":"Can Tracardi use Sms77, a professional SMS solution for sending and receiving SMS messages via API, email, or directly in your app?","text":"<p>Yes. To use Sms77, install the extension Sms77 in Resource/Extensions.</p>"},{"location":"qa/bulk/extension_questions/#can-tracardi-use-zapier-a-product-for-integrating-web-applications-and-automating-workflows","title":"Can Tracardi use Zapier, a product for integrating web applications and automating workflows?","text":"<p>Yes. To use Zapier, install the extension Zapier in Resource/Extensions.</p>"},{"location":"qa/bulk/generic_tracardi_qa/","title":"What is Tracardi?","text":"<p>Tracardi is a Customer Data Platform (CDP) that offers a low-code/no-code solution for businesses to leverage customer data for various purposes.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#what-are-the-key-features-of-tracardi","title":"What are the key features of Tracardi?","text":"<p>Tracardi has the following key features:</p> <ol> <li>Ingesting, aggregating, and storing customer data from multiple sources in real-time.</li> <li>Managing and modeling customer data, including defining rules for data shaping and segmentation.</li> <li>Personalizing the user experience through real-time customer segmentation and targeting.</li> <li>Unifying customer data from various sources into a single profile, including de-duplication and blending of customer    accounts.</li> <li>Serving as a framework for creating marketing automation apps.</li> </ol>"},{"location":"qa/bulk/generic_tracardi_qa/#how-does-tracardi-handle-customer-data","title":"How does Tracardi handle customer data?","text":"<p>Tracardi allows businesses to ingest, aggregate, and store customer data from multiple sources in real-time. It also provides tools for managing and modeling customer data, allowing businesses to define rules for shaping the data and segmenting customers into custom groups.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#what-benefits-does-tracardi-offer-businesses","title":"What benefits does Tracardi offer businesses?","text":"<p>Tracardi offers the following benefits to businesses:</p> <ol> <li>Improved access to up-to-date and comprehensive customer information.</li> <li>Effective customer segmentation and targeting for personalized experiences.</li> <li>Enhanced customer experience through relevant and targeted content delivery.</li> <li>Unified view of customer data, making it easier to manage and understand.</li> <li>Framework for creating marketing automation apps, streamlining processes and data integration with other systems.</li> </ol>"},{"location":"qa/bulk/generic_tracardi_qa/#can-tracardi-be-integrated-with-existing-systems","title":"Can Tracardi be integrated with existing systems?","text":"<p>Yes, Tracardi is an API-first platform designed to be easily integrated into a wide range of systems, both new and legacy.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#how-does-tracardi-support-browsing-events","title":"How does Tracardi support browsing events?","text":"<p>Tracardi provides a feature to browse events, allowing businesses to view and analyze customer interaction data.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#how-does-tracardi-handle-workflows","title":"How does Tracardi handle workflows?","text":"<p>Tracardi offers a workflow feature that enables businesses to design and automate processes involving customer data.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#what-is-the-test-console-in-tracardi","title":"What is the test console in Tracardi?","text":"<p>The test console in Tracardi provides a testing environment where businesses can validate and debug their workflows and data processing.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#where-can-i-find-video-introductions-to-tracardi","title":"Where can I find video introductions to Tracardi?","text":"<p>Video introductions to Tracardi can be found on the Tracardi YouTube channel.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#what-are-the-screenshots-provided-for-in-the-documentation","title":"What are the screenshots provided for in the documentation?","text":"<p>The screenshots included in the documentation showcase various aspects of Tracardi, such as browsing events, workflows, and the test console, giving users a visual representation of the platform's interface.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#how-can-tracardi-help-businesses-with-data-management","title":"How can Tracardi help businesses with data management?","text":"<p>Tracardi helps businesses manage and model customer data, allowing them to define rules for shaping the data, segmenting customers, and unifying data from various sources.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#how-does-tracardi-enable-personalized-user-experiences","title":"How does Tracardi enable personalized user experiences?","text":"<p>Tracardi enables personalized user experiences through real-time customer segmentation and targeting, ensuring that businesses can deliver more relevant and targeted content to their customers.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#can-tracardi-handle-data-deduplication-and-blending-of-customer-accounts","title":"Can Tracardi handle data deduplication and blending of customer accounts?","text":"<p>Yes, Tracardi provides tools for unifying customer data, including features for de-duplicating customer records and blending multiple customer accounts into a single unified profile.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#how-does-tracardi-facilitate-marketing-automation","title":"How does Tracardi facilitate marketing automation?","text":"<p>Tracardi serves as a powerful framework for creating marketing automation apps, allowing businesses to easily send data to other systems and automate various processes.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#does-tracardi-offer-a-low-codeno-code-solution","title":"Does Tracardi offer a low-code/no-code solution?","text":"<p>Yes, Tracardi offers a low-code/no-code solution, making it accessible and user-friendly for businesses to work with customer data.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#how-can-businesses-access-up-to-date-customer-information-with-tracardi","title":"How can businesses access up-to-date customer information with Tracardi?","text":"<p>Tracardi allows businesses to ingest and store customer data from multiple sources in real-time, ensuring they have access to the most up-to-date and comprehensive customer information.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#can-tracardi-help-businesses-improve-their-overall-customer-experience","title":"Can Tracardi help businesses improve their overall customer experience?","text":"<p>Yes, Tracardi's personalized user experiences, targeted content delivery, and comprehensive customer data management capabilities contribute to improving the overall customer experience.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#what-is-the-purpose-of-the-tracardi-customer-data-platform","title":"What is the purpose of the Tracardi Customer Data Platform?","text":"<p>The purpose of the Tracardi Customer Data Platform is to provide businesses with the tools and functionality to effectively manage, understand, and utilize customer data for various business purposes.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#how-can-businesses-integrate-tracardi-into-their-existing-systems","title":"How can businesses integrate Tracardi into their existing systems?","text":"<p>Tracardi is designed as an API-first platform, making it easy for businesses to integrate it into their existing systems, whether they are brand new or legacy systems.</p>"},{"location":"qa/bulk/generic_tracardi_qa/#can-businesses-create-custom-workflows-in-tracardi","title":"Can businesses create custom workflows in Tracardi?","text":"<p>Yes, Tracardi allows businesses to create custom workflows to automate processes and utilize customer data in a way that aligns with their specific business requirements.</p>"},{"location":"qa/bulk/other_qa/","title":"Other Q&amp;A","text":"<p>Q: Is it possible to segment data based on leads' attributes such as lead added date, lead source, lead ID, opens, clicks, sold/not sold, click/open dates, etc.?</p> <p>A: Yes, segmentation can be done in regular Tracardi workflows. You can segment data based on any internal or external data or conditions set within the workflow.</p> <p>Q: How many customer interactions can Tracardi log, including opens, clicks, and sales over the life of the lead?</p> <p>A: Tracardi has been tested to store 10 million events per profile, but the limit ultimately depends on the storage size. Tracardi is designed to handle large volumes of data efficiently, as evidenced by instances with 0.3 billion events loading in a fraction of a second. The scalability is mainly due to the storage capabilities of Elasticsearch.</p> <p>__Q: Can Tracardi import customer interactions from external email marketing software like Mailwizz? Is it streamed live or can it be scheduled? __</p> <p>A: To import customer interactions from Mailwizz or similar software, you can set up a trigger in the software's table to copy the interaction records to another table. Then, a script can move the copied records to Tracardi using the Tracardi API and remove the duplicated records. This process can be scheduled using cron jobs, Kubernetes jobs, or other scheduling mechanisms. If Mailwizz supports webhooks, real-time importing can be achieved through webhooks. Additionally, you can include pixels in emails for further tracking if required.</p> <p>Q: Can newly added data be analyzed for duplicates or used to enrich current profiles if it's the same lead? Are leads assigned a unique ID?</p> <p>A: Tracardi's main purpose is to maintain a single profile that includes data copied from events or external systems. The profiles are automatically merged and deduplicated at identification points if configured to do so. Tracardi assigns unique IDs to leads, and it also keeps a history of previous IDs. This allows Tracardi to track customers across different devices and merge their profiles.</p> <p>Q: Does Tracardi need to be integrated with a data warehouse tool to store all the data? Are there any recommendations for such integration?</p> <p>A: Tracardi uses Elasticsearch and Kibana for simple analytics, providing a comprehensive overview of individual profiles. However, Tracardi is not designed as an analytical tool for aggregate analysis of all customers. For in-depth analysis, it is recommended to use an external system of your choice. Tracardi can send event data to external systems if necessary, allowing integration with data warehouse tools or other analytical platforms.</p>"},{"location":"qa/bulk/plugins_questions/","title":"Can Tracardi retrieve data about a provided email from the FullContact service?","text":"<p>Yes, it can with the \"Enrich profile\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-fetch-an-html-page","title":"Can Tracardi fetch an HTML page?","text":"<p>Yes, it can with the \"HTML fetcher\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-retrieve-weather-information","title":"Can Tracardi retrieve weather information?","text":"<p>Yes, it can with the \"MSN Weather service\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-a-request-to-a-remote-api-endpoint","title":"Can Tracardi send a request to a remote API endpoint?","text":"<p>Yes, it can with the \"Remote API call\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-an-email-via-smtp","title":"Can Tracardi send an email via SMTP?","text":"<p>Yes, it can with the \"Send e-mail via SMTP\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-create-and-send-a-tweet-to-a-twitter-wall","title":"Can Tracardi create and send a tweet to a Twitter wall?","text":"<p>Yes, it can with the \"Send tweet\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-a-domain-in-the-whois-service","title":"Can Tracardi check a domain in the WHOIS service?","text":"<p>Yes, it can with the \"Whois\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-assign-a-new-profile-id-to-an-event","title":"Can Tracardi assign a new profile ID to an event?","text":"<p>Yes, it can with the \"Assign profile id\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-a-new-profile-to-an-event","title":"Can Tracardi add a new profile to an event?","text":"<p>Yes, it can with the \"Create empty profile\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-a-new-session-to-an-event","title":"Can Tracardi add a new session to an event?","text":"<p>Yes, it can with the \"Create empty session\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-raise-an-event-that-is-delayed-after-the-customer-visit-ends","title":"Can Tracardi raise an event that is delayed after the customer visit ends?","text":"<p>Yes, it can with the \"Delayed event\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-stop-the-update-of-a-profile-in-storage","title":"Can Tracardi stop the update of a profile in storage?","text":"<p>Yes, it can with the \"Discard profile update\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-generate-a-new-password-according-to-user-input","title":"Can Tracardi generate a new password according to user input?","text":"<p>Yes, it can with the \"Generate password\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-get-an-oauth2-token-from-a-given-endpoint-using-a-username-and-password","title":"Can Tracardi get an OAuth2 token from a given endpoint using a username and password?","text":"<p>Yes, it can with the \"Get OAuth2 token\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-the-type-and-length-of-a-given-field","title":"Can Tracardi return the type and length of a given field?","text":"<p>Yes, it can with the \"Get field type\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-hash-defined-data-such-as-profile-traits","title":"Can Tracardi hash defined data, such as profile traits?","text":"<p>Yes, it can with the \"Hash data\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-join-input-data-into-one-payload","title":"Can Tracardi join input data into one payload?","text":"<p>Yes, it can with the \"Join\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-load-and-replace-the-current-profile-in-the-workflow","title":"Can Tracardi load and replace the current profile in the workflow?","text":"<p>Yes, it can with the \"Load profile by...\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-mask-defined-data-such-as-profile-traits","title":"Can Tracardi mask defined data, such as profile traits?","text":"<p>Yes, it can with the \"Mask data\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-merge-profiles-in-storage-when-the-flow-ends","title":"Can Tracardi merge profiles in storage when the flow ends?","text":"<p>Yes, it can with the \"Merge profiles\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-collect-input-payloads-in-the-workflow-memory-object","title":"Can Tracardi collect input payloads in the workflow memory object?","text":"<p>Yes, it can with the \"Payload collector\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-reduce-the-given-array","title":"Can Tracardi reduce the given array?","text":"<p>Yes, it can with the \"Reduce array\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-sort-the-referenced-dictionary-and-return-it-as-a-list-of-key-value-tuples","title":"Can Tracardi sort the referenced dictionary and return it as a list of key-value tuples?","text":"<p>Yes, it can with the \"Sort dictionary\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-sort-a-referenced-arraylist","title":"Can Tracardi sort a referenced array/list?","text":"<p>Yes, it can with the \"Sort list\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-a-tag-to-the-current-event","title":"Can Tracardi add a tag to the current event?","text":"<p>Yes, it can with the \"Tag event\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-generate-a-random-uuid","title":"Can Tracardi generate a random UUID?","text":"<p>Yes, it can with the \"UUID4\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-update-the-event-in-storage","title":"Can Tracardi update the event in storage?","text":"<p>Yes, it can with the \"Update event\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-update-the-profile-in-storage","title":"Can Tracardi update the profile in storage?","text":"<p>Yes, it can with the \"Update profile\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-update-the-session-in-storage","title":"Can Tracardi update the session in storage?","text":"<p>Yes, it can with the \"Update session\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-a-data-property-exists-and-is-not-null-or-empty","title":"Can Tracardi check if a data property exists and is not null or empty?","text":"<p>Yes, it can with the \"Data exists\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-conditionally-run-a-branch-of-the-workflow","title":"Can Tracardi conditionally run a branch of the workflow?","text":"<p>Yes. It can with the If plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-determine-if-its-a-new-profile","title":"Can Tracardi determine if it's a new profile?","text":"<p>Yes. It can with the Is it a new profile plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-determine-if-its-a-new-visit","title":"Can Tracardi determine if it's a new visit?","text":"<p>Yes. It can with the Is it a new visit plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-throttle-workflow-execution","title":"Can Tracardi throttle workflow execution?","text":"<p>Yes. It can with the Limiter plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-create-an-object-with-results-from-resolved-condition-set","title":"Can Tracardi create an object with results from resolved condition set?","text":"<p>Yes. It can with the Resolve conditions plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-resolve-a-set-of-conditions-and-assign-it-to-profile-fields","title":"Can Tracardi resolve a set of conditions and assign it to profile fields?","text":"<p>Yes. It can with the Resolve conditions into profile fields plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-stop-the-workflow-if-a-defined-value-did-not-change","title":"Can Tracardi stop the workflow if a defined value did not change?","text":"<p>Yes. It can with the Value change plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-discard-the-current-event-and-prevent-it-from-being-saved","title":"Can Tracardi discard the current event and prevent it from being saved?","text":"<p>Yes. It can with the Discard Event plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-collect-and-tally-up-occurrences-of-a-specific-category-of-information-during-a-certain-period-of-time-for-the-current-profile","title":"Can Tracardi collect and tally up occurrences of a specific category of information during a certain period of time for the current profile?","text":"<p>Yes. It can with the Event aggregator plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-read-how-many-events-of-a-defined-type-were-triggered-within-a-defined-time","title":"Can Tracardi read how many events of a defined type were triggered within a defined time?","text":"<p>Yes. It can with the Event counter plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-inject-the-previous-event-for-the-current-profile-into-the-payload","title":"Can Tracardi inject the previous event for the current profile into the payload?","text":"<p>Yes. It can with the Get previous event plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-inject-an-event-of-a-given-id-into-the-payload","title":"Can Tracardi inject an event of a given ID into the payload?","text":"<p>Yes. It can with the Inject event plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-interest-to-a-profile","title":"Can Tracardi add interest to a profile?","text":"<p>Yes. It can with the Add interest plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-a-segment-to-a-profile","title":"Can Tracardi add a segment to a profile?","text":"<p>Yes. It can with the Add segment plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-or-remove-a-segment-from-a-profile","title":"Can Tracardi add or remove a segment from a profile?","text":"<p>Yes. It can with the Conditional segmentation plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-decrease-interest-in-a-profile-and-return-the-payload","title":"Can Tracardi decrease interest in a profile and return the payload?","text":"<p>Yes. It can with the Decrease interest plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-delete-a-segment-from-a-profile","title":"Can Tracardi delete a segment from a profile?","text":"<p>Yes. It can with the Delete segment plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-force-segmentation-on-the-profile-after-the-flow-ends","title":"Can Tracardi force segmentation on the profile after the flow ends?","text":"<p>Yes. It can with the Force segmentation plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-a-profile-is-in-a-defined-segment","title":"Can Tracardi check if a profile is in a defined segment?","text":"<p>Yes. It can with the Has segment plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-increase-interest-in-a-profile-and-return-the-payload","title":"Can Tracardi increase interest in a profile and return the payload?","text":"<p>Yes. It can with the Increase interest plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-memorize-profile-segments-in-workflow-memory","title":"Can Tracardi memorize profile segments in workflow memory?","text":"<p>Yes. It can with the Memorize segment plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-move-a-profile-from-one-segment-to-another-segment","title":"Can Tracardi move a profile from one segment to another segment?","text":"<p>Yes. It can with the Move segment plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-load-memorized-profile-segments-into-the-output-payload","title":"Can Tracardi load memorized profile segments into the output payload?","text":"<p>Yes. It can with the Recall segment plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-or-update-an-entity","title":"Can Tracardi add or update an entity?","text":"<p>Yes. It can with the Create entity plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-delete-an-entity-by-its-id","title":"Can Tracardi delete an entity by its ID?","text":"<p>Yes. It can with the Delete entity plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-load-an-entity-by-its-id","title":"Can Tracardi load an entity by its ID?","text":"<p>Yes. It can with the Load entity plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-an-api-request","title":"Can Tracardi send an API request?","text":"<p>Yes. It can with the Remote API call plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-read-the-source-that-the-event-came-from","title":"Can Tracardi read the source that the event came from?","text":"<p>Yes. It can with the Get event source plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-inject-data-into-the-selected-object","title":"Can Tracardi inject data into the selected object?","text":"<p>Yes. It can with the Inject plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-create-a-new-payload-from-the-provided-data","title":"Can Tracardi create a new payload from the provided data?","text":"<p>Yes. It can with the Inject payload plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-load-the-results-of-a-given-report-into-the-payload","title":"Can Tracardi load the results of a given report into the payload?","text":"<p>Yes. It can with the Load report data plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-create-and-send-notifications-to-chosen-recipients","title":"Can Tracardi create and send notifications to chosen recipients?","text":"<p>Yes. It can with the Novu notifications plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-a-contact-to-a-mailchimp-audience","title":"Can Tracardi add a contact to a MailChimp audience?","text":"<p>Yes. It can with the Add to audience plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-remove-or-archive-a-contact-from-a-mailchimp-audience","title":"Can Tracardi remove or archive a contact from a MailChimp audience?","text":"<p>Yes. It can with the Remove from audience plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-transactional-emails-via-the-mailchimp-api","title":"Can Tracardi send transactional emails via the MailChimp API?","text":"<p>Yes. It can with the Send e-mail plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-count-event-profile-or-session-records","title":"Can Tracardi count event, profile, or session records?","text":"<p>Yes. It can with the Count records plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-decrement-the-profile-statscounters-value-and-return-the-payload","title":"Can Tracardi decrement the profile stats.counters value and return the payload?","text":"<p>Yes. It can with the Decrement counter plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-increase-the-view-field-in-the-profile-and-return-the-payload","title":"Can Tracardi increase the view field in the profile and return the payload?","text":"<p>Yes. It can with the Increase views plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-increase-the-visit-field-in-the-profile-and-return-the-payload","title":"Can Tracardi increase the visit field in the profile and return the payload?","text":"<p>Yes. It can with the Increase visits plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-increment-the-given-field-in-the-payload-and-return-the-payload","title":"Can Tracardi increment the given field in the payload and return the payload?","text":"<p>Yes. It can with the Increment counter plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-count-keys-and-save-them-in-the-profile","title":"Can Tracardi count keys and save them in the profile?","text":"<p>Yes. It can with the Key counter plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-a-field-contains-the-defined-pattern","title":"Can Tracardi check if a field contains the defined pattern?","text":"<p>Yes. It can with the Contains pattern plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-a-field-contains-the-defined-string","title":"Can Tracardi check if a field contains the defined string?","text":"<p>Yes. It can with the Contains string plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-validate-data-such-as-email-url-ipv4-date-time-int-float-phone-number-ean-code","title":"Can Tracardi validate data such as email, URL, IPv4, date, time, int, float, phone number, EAN code?","text":"<p>Yes. It can with the Data validator plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-a-string-ends-with-the-defined-prefix","title":"Can Tracardi check if a string ends with the defined prefix?","text":"<p>Yes. It can with the Ends with plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-join-each-element-in-the-list-by-the-given-delimiter","title":"Can Tracardi join each element in the list by the given delimiter?","text":"<p>Yes. It can with the Join string list plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-a-string-starts-with-the-defined-prefix","title":"Can Tracardi check if a string starts with the defined prefix?","text":"<p>Yes. It can with the Starts with plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-perform-string-transformations-like-lowercase-remove-spaces-split-and-more","title":"Can Tracardi perform string transformations like lowercase, remove spaces, split, and more?","text":"<p>Yes. It can with the String properties plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-compare-two-strings-according-to-the-chosen-algorithm","title":"Can Tracardi compare two strings according to the chosen algorithm?","text":"<p>Yes. It can with the String similarity plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-split-a-string-into-a-list-of-strings-by-the-defined-delimiter","title":"Can Tracardi split a string into a list of strings by the defined delimiter?","text":"<p>Yes. It can with the String splitter plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-append-or-remove-a-trait-tofrom-the-given-destination","title":"Can Tracardi append or remove a trait to/from the given destination?","text":"<p>Yes. It can with the Append/Remove data plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-an-api-request_1","title":"Can Tracardi send an API request?","text":"<p>Yes, Tracardi can send an API request using the \"Remote API call\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-copy-event-properties-to-a-profile-trait","title":"Can Tracardi copy event properties to a profile trait?","text":"<p>Yes, Tracardi can copy event properties to a profile trait using the \"Copy data\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-create-a-new-response-from-provided-data","title":"Can Tracardi create a new response from provided data?","text":"<p>Yes, Tracardi can create a new response from the provided data using the \"Create response\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-a-part-of-referenced-data-as-payload","title":"Can Tracardi return a part of referenced data as payload?","text":"<p>Yes, Tracardi can return a part of referenced data as payload using the \"Cut out data\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-delete-data-from-the-internal-state-of-the-workflow","title":"Can Tracardi delete data from the internal state of the workflow?","text":"<p>Yes, Tracardi can delete data from the internal state of the workflow using the \"Delete data\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-parse-a-user-agent-string-and-detect-the-browser-operating-system-and-device-used","title":"Can Tracardi parse a user agent string and detect the browser, operating system, and device used?","text":"<p>Yes, Tracardi can parse a user agent string and detect the browser, operating system, and device used using the \"Detect device\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-automatically-merge-all-event-properties-to-profile-traits","title":"Can Tracardi automatically merge all event properties to profile traits?","text":"<p>Yes, Tracardi can automatically merge all event properties to profile traits using the \"Merge event properties\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-a-random-value-from-a-given-list","title":"Can Tracardi return a random value from a given list?","text":"<p>Yes, Tracardi can return a random value from a given list using the \"Random item\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-replace-placeholders-in-a-string-with-given-values","title":"Can Tracardi replace placeholders in a string with given values?","text":"<p>Yes, Tracardi can replace placeholders in a string with given values using the \"Template\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-a-matching-value-from-a-set-of-data","title":"Can Tracardi return a matching value from a set of data?","text":"<p>Yes, Tracardi can return a matching value from a set of data using the \"Value mapping\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-scrape-data-from-html-content","title":"Can Tracardi scrape data from HTML content?","text":"<p>Yes, Tracardi can scrape data from HTML content using the \"XPATH HTML Scrapper\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-log-a-message-to-the-flow-log","title":"Can Tracardi log a message to the flow log?","text":"<p>Yes, Tracardi can log a message to the flow log using the \"Log message\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-throw-an-error-and-stop-the-workflow","title":"Can Tracardi throw an error and stop the workflow?","text":"<p>Yes, Tracardi can throw an error and stop the workflow using the \"Throw error\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-determine-if-test-geo-location-coordinates-are-within-a-radius-threshold-from-the-center-point-coordinates","title":"Can Tracardi determine if test geo location coordinates are within a radius threshold from the center point coordinates?","text":"<p>Yes, Tracardi can determine if test geo location coordinates are within a radius threshold from the center point coordinates using the \"Geo distance\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-determine-if-test-geo-location-coordinates-are-within-a-radius-threshold-from-the-center-point-coordinates_1","title":"Can Tracardi determine if test geo location coordinates are within a radius threshold from the center point coordinates?","text":"<p>Yes, Tracardi can determine if test geo location coordinates are within a radius threshold from the center point coordinates using the \"Geo fence\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-convert-ip-to-location-information","title":"Can Tracardi convert IP to location information?","text":"<p>Yes, Tracardi can convert IP to location information using the \"GeoIp service\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-discard-the-current-profile","title":"Can Tracardi discard the current profile?","text":"<p>Yes, Tracardi can discard the current profile using the \"Discard Profile\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-discard-the-current-session","title":"Can Tracardi discard the current session?","text":"<p>Yes, Tracardi can discard the current session using the \"Discard Session\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-load-previous-sessions-for-the-current-profile-and-inject-them-into-the-payload","title":"Can Tracardi load previous sessions for the current profile and inject them into the payload?","text":"<p>Yes, Tracardi can load previous sessions for the current profile and inject them into the payload using the \"Get previous session\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-use-regex-matching-and-return-matched-data","title":"Can Tracardi use regex matching and return matched data?","text":"<p>Yes, Tracardi can use regex matching and return matched data using the \"Regex match\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-replace-substrings-that-match-a-regex-pattern-with-a-given-replacement-string","title":"Can Tracardi replace substrings that match a regex pattern with a given replacement string?","text":"<p>Yes, Tracardi can replace substrings that match a regex pattern with a given replacement string using the \"Regex replace\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-validate-data-with-a-regex-pattern","title":"Can Tracardi validate data with a regex pattern?","text":"<p>Yes, Tracardi can validate data with a regex pattern using the \"Regex validator\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-validate-objects-using-a-json-validation-schema","title":"Can Tracardi validate objects using a JSON validation schema?","text":"<p>Yes, Tracardi can validate objects using a JSON validation schema using the \"JSON schema validator\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-parse-url-parameters-parse-them-and-return-the-result-on-the-output","title":"Can Tracardi parse URL parameters, parse them, and return the result on the output?","text":"<p>Yes, Tracardi can parse URL parameters, parse them, and return the result on the output using the \"Parse URL\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-split-the-workflow-based-on-whether-it-is-day-or-night-at-the-given-latitude-and-longitude","title":"Can Tracardi split the workflow based on whether it is day or night at the given latitude and longitude?","text":"<p>Yes, Tracardi can split the workflow based on whether it is day or night at the given latitude and longitude using the \" Day/Night\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-the-current-date-is-a-weekend-or-not","title":"Can Tracardi check if the current date is a weekend or not?","text":"<p>Yes, Tracardi can check if the current date is a weekend or not using the \"If it's a weekend\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-the-current-time-is-within-a-defined-time-span","title":"Can Tracardi check if the current time is within a defined time span?","text":"<p>Yes, Tracardi can check if the current time is within a defined time span using the \"Is time between dates\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-the-time-difference-between-the-last-profile-visit-and-the-current-time","title":"Can Tracardi return the time difference between the last profile visit and the current time?","text":"<p>Yes, Tracardi can return the time difference between the last profile visit and the current time using the \"Last profile visit time\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-wait-for-x-seconds-and-then-restart-the-workflow-at-this-node","title":"Can Tracardi wait for X seconds and then restart the workflow at this node?","text":"<p>Yes, Tracardi can wait for X seconds and then restart the workflow at this node using the \"Pause and Resume\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-when-a-profile-was-registered-in-the-system","title":"Can Tracardi return when a profile was registered in the system?","text":"<p>Yes, Tracardi can return how long ago a profile was registered in the system using the \"Profile live time\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-stop-the-workflow-for-a-given-time","title":"Can Tracardi stop the workflow for a given time?","text":"<p>Yes, Tracardi can stop the workflow for a given time using the \"Sleep\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-the-time-difference-between-two-dates","title":"Can Tracardi return the time difference between two dates?","text":"<p>Yes, Tracardi can return the time difference between two dates using the \"Time difference\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-information-about-the-current-time-month-day-etc","title":"Can Tracardi return information about the current time, month, day, etc.?","text":"<p>Yes, Tracardi can return information about the current time, month, day, etc. using the \"Today\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-show-a-custom-javascript-widget","title":"Can Tracardi show a custom JavaScript widget?","text":"<p>Yes, Tracardi can show a custom JavaScript widget using the \"Custom widget\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-inject-the-openreplay-tracing-script-on-the-webpage","title":"Can Tracardi inject the OpenReplay tracing script on the webpage?","text":"<p>Yes, Tracardi can inject the OpenReplay tracing script on the webpage using the \"OpenReplay\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-show-a-rating-widget-with-a-defined-title-and-content","title":"Can Tracardi show a rating widget with a defined title and content?","text":"<p>Yes, Tracardi can show a rating widget with a defined title and content using the \"Rating widget\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-show-a-request-demo-widget","title":"Can Tracardi show a request demo widget?","text":"<p>Yes, Tracardi can show a request demo widget using the \"Request demo widget\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-show-a-consent-pop-up-on-the-frontend","title":"Can Tracardi show a consent pop-up on the frontend?","text":"<p>Yes, Tracardi can show a consent pop-up on the frontend using the \"Show consent bar\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-show-a-youtube-video-widget","title":"Can Tracardi show a YouTube video widget?","text":"<p>Yes, Tracardi can show a YouTube video widget using the \"YouTube widget\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-a-telegram-message-via-the-bot","title":"Can Tracardi send a Telegram message via the bot?","text":"<p>Yes, Tracardi can send a Telegram message via the bot using the \"Telegram message\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-a-custom-event-to-the-google-analytics-4-event-tracker","title":"Can Tracardi send a custom event to the Google Analytics 4 event tracker?","text":"<p>Yes, Tracardi can send a custom event to the Google Analytics 4 event tracker using the \"Google Analytics 4 event\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-connect-to-google-sheets","title":"Can Tracardi connect to Google Sheets?","text":"<p>Yes, Tracardi can connect to Google Sheets using the \"Google Spreadsheet\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-translate-text-using-google-translate","title":"Can Tracardi translate text using Google Translate?","text":"<p>Yes, Tracardi can translate text using Google Translate using the \"Google Translate\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-a-customized-event-to-the-google-universal-analytics-event-tracker","title":"Can Tracardi send a customized event to the Google Universal Analytics event tracker?","text":"<p>Yes, Tracardi can send a customized event to the Google Universal Analytics event tracker using the \"Google UA events\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-end-the-workflow","title":"Can Tracardi end the workflow?","text":"<p>Yes, Tracardi can end the workflow using the \"End\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-start-the-workflow-and-return-event-data-on-the-payload-port","title":"Can Tracardi start the workflow and return event data on the payload port?","text":"<p>Yes, Tracardi can start the workflow and return event data on the payload port using the \"Start\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-create-or-update-a-contact-in-activecampaign","title":"Can Tracardi create or update a contact in ActiveCampaign?","text":"<p>Yes, Tracardi can create or update a contact in ActiveCampaign using the \"Add contact\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-fetch-contact-information-from-activecampaign-based-on-the-given-email-address","title":"Can Tracardi fetch contact information from ActiveCampaign based on the given email address?","text":"<p>Yes, Tracardi can fetch ActiveCampaign contact info based on the given email address using the \"Fetch contact\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-the-current-event-to-matomo","title":"Can Tracardi send the current event to Matomo?","text":"<p>Yes, Tracardi can send the current event to Matomo using the \"Register event\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-convert-objects-to-json","title":"Can Tracardi convert objects to JSON?","text":"<p>Yes, Tracardi can convert objects to JSON using the \"Data to JSON\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-decode-a-base64-encoded-input-to-plain-text","title":"Can Tracardi decode a base64-encoded input to plain text?","text":"<p>Yes, Tracardi can decode a base64-encoded input to plain text using the \"Decode Base64\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-encode-input-text-to-base64","title":"Can Tracardi encode input text to base64?","text":"<p>Yes, Tracardi can encode input text to base64 using the \"Encode Base64\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-convert-json-to-data-objects","title":"Can Tracardi convert JSON to data objects?","text":"<p>Yes, Tracardi can convert JSON to data objects using the \"JSON to data\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-a-message-to-a-discord-webhook","title":"Can Tracardi send a message to a Discord webhook?","text":"<p>Yes, Tracardi can send a message to a Discord webhook using the \"Discord push\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-post-a-defined-message-to-a-slack-channel","title":"Can Tracardi post a defined message to a Slack channel?","text":"<p>Yes, Tracardi can post a defined message to a Slack channel using the \"Post to Slack Channel\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-connect-to-the-pushover-app-and-push-a-message","title":"Can Tracardi connect to the Pushover app and push a message?","text":"<p>Yes, Tracardi can connect to the Pushover app and push a message using the \"Pushover push\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-run-a-remote-microservice-plugin","title":"Can Tracardi run a remote microservice plugin?","text":"<p>Yes, Tracardi can run a remote microservice plugin using the \"Microservice\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-add-consents-to-the-profile","title":"Can Tracardi add consents to the profile?","text":"<p>Yes, Tracardi can add consents to the profile using the \"Add consent\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-check-if-defined-consents-are-granted-by-the-current-profile","title":"Can Tracardi check if defined consents are granted by the current profile?","text":"<p>Yes, Tracardi can check if defined consents are granted by the current profile using the \"Require consents\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-get-single-github-issue-details","title":"Can Tracardi get single GitHub issue details?","text":"<p>Yes, Tracardi can get single GitHub issue details using the \"Get Issue\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-list-github-issues","title":"Can Tracardi list GitHub issues?","text":"<p>Yes, Tracardi can list GitHub issues using the \"List Issues\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-query-data-from-a-local-elasticsearch-database","title":"Can Tracardi query data from a local Elasticsearch database?","text":"<p>Yes, Tracardi can query data from a local Elasticsearch database using the \"Query data\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-an-sms-using-the-twilio-gateway","title":"Can Tracardi send an SMS using the Twilio gateway?","text":"<p>Yes, Tracardi can send an SMS using the Twilio gateway using the \"Send SMS\" plugin</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-return-an-events-sequence-from-the-database-for-a-defined-time-range-and-context","title":"Can Tracardi return an events sequence from the database for a defined time range and context?","text":"<p>Yes, Tracardi can return an events sequence from the database for a defined time range and context using the \"Event sequence\" plugin.</p>"},{"location":"qa/bulk/plugins_questions/#can-tracardi-send-a-request-to-chatgpt-and-receive-a-response","title":"Can Tracardi send a request to ChatGPT and receive a response?","text":"<p>Yes, Tracardi can send a request to ChatGPT and return the response using the \"ChatGPT prompt\" plugin </p>"},{"location":"qa/bulk/questions_about_event_data/","title":"Where do I store the unique identifier for each event?","text":"<p>The unique identifier for each event is stored in the <code>id</code> field of the event metadata.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-metadata-information-associated-with-an-event","title":"Where do I store metadata information associated with an event?","text":"<p>Metadata information associated with an event is stored in the <code>metadata</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-time-related-information-for-an-event","title":"Where do I store time-related information for an event?","text":"<p>Time-related information for an event is stored in the <code>metadata.time</code> sub-field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-status-of-an-event","title":"Where do I store the status of an event?","text":"<p>The status of an event is stored in the <code>metadata.status</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-channel-from-which-the-event-originated","title":"Where do I store the channel from which the event originated?","text":"<p>The channel from which the event originated is stored in the <code>metadata.channel</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-ip-address-associated-with-the-event","title":"Where do I store the IP address associated with the event?","text":"<p>The IP address associated with the event is stored in the <code>metadata.ip</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-information-about-the-processing-of-the-event","title":"Where do I store information about the processing of the event?","text":"<p>Information about the processing of the event is stored in the <code>metadata.processed_by</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-whether-the-event-is-associated-with-a-profile-or-not","title":"Where do I store whether the event is associated with a profile or not?","text":"<p>Whether the event is associated with a profile or not is stored in the <code>metadata.profile_less</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-validity-status-of-the-event","title":"Where do I store the validity status of the event?","text":"<p>The validity status of the event is stored in the <code>metadata.valid</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-presence-of-warnings-associated-with-the-event","title":"Where do I store the presence of warnings associated with the event?","text":"<p>The presence of warnings associated with the event is stored in the <code>metadata.warning</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-presence-of-errors-associated-with-the-event","title":"Where do I store the presence of errors associated with the event?","text":"<p>The presence of errors associated with the event is stored in the <code>metadata.error</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-information-about-the-instance-of-tracardi-where-the-event-was-processed","title":"Where do I store information about the instance of Tracardi where the event was processed?","text":"<p>Information about the instance of Tracardi where the event was processed is stored in the <code>metadata.instance</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-event-type","title":"Where do I store the event type?","text":"<p>The event type is stored in the <code>type</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-human-readable-event-name","title":"Where do I store the human-readable event name?","text":"<p>The human-readable event name is stored in the <code>name</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-reference-to-the-source-from-which-the-event-was-collected","title":"Where do I store the reference to the source from which the event was collected?","text":"<p>The reference to the source from which the event was collected is stored in the <code>source</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-information-about-the-device-from-which-the-event-was-collected","title":"Where do I store information about the device from which the event was collected?","text":"<p>Information about the device from which the event was collected is stored in the <code>device</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-information-about-the-operating-system-from-which-the-event-was-collected","title":"Where do I store information about the operating system from which the event was collected?","text":"<p>Information about the operating system from which the event was collected is stored in the <code>os</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-information-about-the-application-from-which-the-event-was-collected","title":"Where do I store information about the application from which the event was collected?","text":"<p>Information about the application from which the event was collected is stored in the <code>app</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-information-about-the-page-or-screen-from-which-the-event-was-collected","title":"Where do I store information about the page or screen from which the event was collected?","text":"<p>Information about the page or screen from which the event was collected is stored in the <code>hit</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-information-about-the-marketing-campaign-that-the-event-originated-from","title":"Where do I store information about the marketing campaign that the event originated from?","text":"<p>Information about the marketing campaign that the event originated from is stored in the <code>utm</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-history-of-hits-for-the-event","title":"Where do I store the history of hits for the event?","text":"<p>The history of hits for the event is stored in the <code>history</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-reference-to-the-session-associated-with-the-event","title":"Where do I store the reference to the session associated with the event?","text":"<p>The reference to the session associated with the event is stored in the <code>session</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-reference-to-the-profile-associated-with-the-event","title":"Where do I store the reference to the profile associated with the event?","text":"<p>The reference to the profile associated with the event is stored in the <code>profile</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-reference-to-a-specific-entity-related-to-the-event","title":"Where do I store the reference to a specific entity related to the event?","text":"<p>The reference to a specific entity related to the event is stored in the <code>entity</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-auxiliary-data-associated-with-the-event","title":"Where do I store auxiliary data associated with the event?","text":"<p>Auxiliary data associated with the event is stored in the <code>aux</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-data-that-is-marked-for-removal-at-some-point","title":"Where do I store data that is marked for removal at some point?","text":"<p>Data that is marked for removal at some point is stored in the <code>trash</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-configuration-specific-to-the-event","title":"Where do I store configuration specific to the event?","text":"<p>Configuration specific to the event is stored in the <code>config</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-context-of-the-event","title":"Where do I store the context of the event?","text":"<p>The context of the event is stored in the <code>context</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-tags-associated-with-the-event","title":"Where do I store tags associated with the event?","text":"<p>Tags associated with the event are stored in the <code>tags</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-positioning-of-the-event-within-the-customer-journey","title":"Where do I store the positioning of the event within the customer journey?","text":"<p>The positioning of the event within the customer journey is stored in the <code>journey</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-actual-event-data-used-for-reporting-and-describing-the-profile","title":"Where do I store the actual event data used for reporting and describing the profile?","text":"<p>The actual event data used for reporting and describing the profile is stored in the <code>data</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-request-headers-associated-with-the-event","title":"Where do I store the request headers associated with the event?","text":"<p>The request headers associated with the event are stored in the <code>request</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-properties-of-the-event","title":"Where do I store the properties of the event?","text":"<p>The properties of the event are stored in the <code>properties</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_event_data/#where-do-i-store-the-traits-of-the-event","title":"Where do I store the traits of the event?","text":"<p>The traits of the event, which include custom profile attributes/properties, are stored in the <code>traits</code> field of the event.</p>"},{"location":"qa/bulk/questions_about_profile_data/","title":"Where do I store the unique identifier for each profile?","text":"<p>You store the unique identifier for each profile in the <code>id</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-previous-profile-ids-and-ids-from-external-systems","title":"Where do I store previous profile IDs and IDs from external systems?","text":"<p>You store previous profile IDs and IDs from external systems in the <code>ids</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-metadata-information-such-as-time-time-zone-visits-and-auxiliary-metadata","title":"Where do I store metadata information such as time, time zone, visits, and auxiliary metadata?","text":"<p>You store metadata information such as time, time zone, visits, and auxiliary metadata in the <code>metadata</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-additional-auxiliary-metadata-associated-with-the-profile","title":"Where do I store additional auxiliary metadata associated with the profile?","text":"<p>You store additional auxiliary metadata associated with the profile in the <code>metadata.aux</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-various-time-related-information-such-as-profile-insertion-timestamp-update-timestamp-and-segmentation-timestamp","title":"Where do I store various time-related information, such as profile insertion timestamp, update timestamp, and segmentation timestamp?","text":"<p>You store various time-related information, including profile insertion timestamp, update timestamp, and segmentation timestamp, in the <code>metadata.time</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-the-actual-profile-data-used-for-reporting-and-describing-personal-information","title":"Where do I store the actual profile data used for reporting and describing personal information?","text":"<p>You store the actual profile data used for reporting and describing personal information in the <code>data</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-media-related-information-such-as-images-webpages-and-social-media-handles","title":"Where do I store media-related information such as images, webpages, and social media handles?","text":"<p>You store media-related information such as images, webpages, and social media handles in the <code>data.media</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-personally-identifiable-information-pii-such-as-name-birthday-gender-and-education-level","title":"Where do I store personally identifiable information (PII) such as name, birthday, gender, and education level?","text":"<p>You store personally identifiable information (PII) such as name, birthday, gender, and education level in the <code>data.pii</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-various-identifiers-associated-with-the-profile-such-as-id-badge-passport-and-credit-card","title":"Where do I store various identifiers associated with the profile, such as ID, badge, passport, and credit card?","text":"<p>You store various identifiers associated with the profile, such as ID, badge, passport, and credit card, in the <code>data.identifier</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-contact-information-like-email-phone-number-messaging-app-handles-and-address-details","title":"Where do I store contact information like email, phone number, messaging app handles, and address details?","text":"<p>You store contact information like email, phone number, messaging app handles, and address details in the <code>data.contact</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-job-related-information-such-as-position-salary-and-company-details","title":"Where do I store job-related information such as position, salary, and company details?","text":"<p>You store job-related information such as position, salary, and company details in the <code>data.job</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-profile-preferences-such-as-purchases-colors-sizes-devices-and-channels","title":"Where do I store profile preferences such as purchases, colors, sizes, devices, and channels?","text":"<p>You store profile preferences such as purchases, colors, sizes, devices, and channels in the <code>data.preferences</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-device-related-information-such-as-device-names-and-geographic-details","title":"Where do I store device-related information such as device names and geographic details?","text":"<p>You store device-related information such as device names and geographic details in the <code>data.devices</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-loyalty-related-information-such-as-loyalty-codes-and-loyalty-card-details","title":"Where do I store loyalty-related information such as loyalty codes and loyalty card details?","text":"<p>You store loyalty-related information such as loyalty codes and loyalty card details in the <code>data.loyalty</code> sub-field.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-additional-statistics-associated-with-the-profile-such-as-the-number-of-emails-sentreceived-and-error-count","title":"Where do I store additional statistics associated with the profile, such as the number of emails sent/received and error count?","text":"<p>You store additional statistics associated with the profile in the <code>stats</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-custom-profile-attributesproperties-that-do-not-fit-into-the-predefined-profile-data-schema","title":"Where do I store custom profile attributes/properties that do not fit into the predefined profile data schema?","text":"<p>You store custom profile attributes/properties that do not fit into the predefined profile data schema in the <code>traits</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-collections-related-to-the-profile-allowing-the-storage-of-one-to-many-relationships-with-other-objects","title":"Where do I store collections related to the profile, allowing the storage of one-to-many relationships with other objects?","text":"<p>You store collections related to the profile, allowing one-to-many relationships with other objects, in the <code>collections</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-segments-to-which-the-profile-belongs","title":"Where do I store segments to which the profile belongs?","text":"<p>You store a set of segments to which the profile belongs in the <code>segments</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-a-list-of-consents-given-by-the-profile","title":"Where do I store a list of consents given by the profile?","text":"<p>You store a list of consents given by the profile in the <code>consents</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-indicate-whether-the-profile-is-active-or-inactive-from-a-business-perspective","title":"Where do I indicate whether the profile is active or inactive from a business perspective?","text":"<p>You indicate whether the profile is active or inactive from a business perspective in the <code>active</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-key-value-pairs-representing-the-interests-of-the-profile","title":"Where do I store key-value pairs representing the interests of the profile?","text":"<p>You store key-value pairs representing the interests of the profile in the <code>interests</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-auxiliary-data-related-to-conflicts-or-data-discrepancies-allowing-temporary-preservation-of-obsolete-or-migrating-data","title":"Where do I store auxiliary data related to conflicts or data discrepancies, allowing temporary preservation of obsolete or migrating data?","text":"<p>You store auxiliary data related to conflicts or data discrepancies, allowing temporary preservation of obsolete or migrating data, in the <code>aux</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-data-that-should-be-removed-at-some-point-such-as-obsolete-or-data-created-during-the-migration-process","title":"Where do I store data that should be removed at some point, such as obsolete or data created during the migration process?","text":"<p>You store data that should be removed at some point, such as obsolete or data created during the migration process, in the <code>trash</code> field of profile.</p>"},{"location":"qa/bulk/questions_about_profile_data/#where-do-i-store-data-that-does-not-need-to-be-searched-or-indexed-such-as-operational-flags-or-non-groupingindexing-data","title":"Where do I store data that does not need to be searched or indexed, such as operational flags or non-grouping/indexing data?","text":"<p>You store data that does not need to be searched or indexed, such as operational flags or non-grouping/indexing data, in the <code>misc</code> field of profile.</p>"},{"location":"qa/bulk/staging_server_qa/","title":"How to test workflows?","text":"<p>To test workflows in Tracardi, a staging server is used. The staging server allows developers to test and debug new settings or configuration changes before they are deployed to a production server.</p>"},{"location":"qa/bulk/staging_server_qa/#what-is-a-staging-server","title":"What is a staging server?","text":"<p>A staging server is a separate server environment used to test and refine new settings and configurations without impacting the live production environment. It provides a controlled environment for testing and debugging before deploying changes to the production server.</p>"},{"location":"qa/bulk/staging_server_qa/#what-is-the-process-of-staging-in-tracardi","title":"What is the process of staging in Tracardi?","text":"<p>The process of staging in Tracardi involves installing a separate copy of the system designated for staging. The \"PRODUCTION\" environment variable is set to \"no,\" creating a new set of Elasticsearch indices. The staging server should be exposed on a different port than the production server and ideally not accessible from the internet.</p>"},{"location":"qa/bulk/staging_server_qa/#do-i-need-a-separate-license-for-the-staging-server-if-i-have-a-commercial-version-of-tracardi","title":"Do I need a separate license for the staging server if I have a commercial version of Tracardi?","text":"<p>No, you do not need a separate license for the staging server if you have a commercial version of Tracardi. The commercial licenses cover both staging and production servers.</p>"},{"location":"qa/bulk/staging_server_qa/#how-should-changes-be-made-in-tracardi-to-minimize-the-risk-of-disruptions-in-the-production-environment","title":"How should changes be made in Tracardi to minimize the risk of disruptions in the production environment?","text":"<p>Changes in Tracardi should be made on the staging server rather than directly on the production server. This allows thorough testing of the changes before deploying them to the production system. By following this practice, the risk of errors or disruptions in the live production environment is minimized.</p>"},{"location":"qa/bulk/staging_server_qa/#how-can-changes-be-deployed-from-the-staging-server-to-the-production-server","title":"How can changes be deployed from the staging server to the production server?","text":"<p>To deploy changes from the staging server to the production server, the data from the staging server is copied to the production server. However, certain data such as events, profiles, or error logs will not be copied over to ensure the integrity of the production server data.</p>"},{"location":"qa/bulk/staging_server_qa/#what-should-be-the-role-of-accounts-on-the-production-server-for-better-security","title":"What should be the role of accounts on the production server for better security?","text":"<p>On the production server, it is recommended to have a single admin account and marketing accounts that can view data but not change any settings. This helps to prevent unauthorized access or changes that could potentially disrupt the production environment.</p>"},{"location":"qa/bulk/staging_server_qa/#how-can-i-find-more-information-about-tracardi-staging-server-deployment","title":"How can I find more information about Tracardi staging server deployment?","text":"<p>More information about Tracardi staging server deployment can be found at https://youtu.be/10W7OzezF_k.</p>"},{"location":"qa/bulk/tracardi_installation/","title":"How can Tracardi be installed as a Docker container?","text":"<ul> <li>Tracardi can be easily installed as a Docker container by following the provided instructions.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#what-are-the-dependencies-for-running-tracardi","title":"What are the dependencies for running Tracardi?","text":"<ul> <li>Tracardi requires Elasticsearch, Redis, Tracardi API, and Tracardi GUI to run. Docker containers need to be started   for each of these services.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-start-the-elasticsearch-database-for-tracardi","title":"How can I start the Elasticsearch database for Tracardi?","text":"<ul> <li>The Elasticsearch database for Tracardi can be started by pulling and running the Elasticsearch single-node Docker   image with the provided command.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-start-the-redis-instance-for-tracardi","title":"How can I start the Redis instance for Tracardi?","text":"<ul> <li>The Redis instance for Tracardi can be started by running the Redis Docker container with the provided command.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-start-the-tracardi-api","title":"How can I start the Tracardi API?","text":"<ul> <li>The Tracardi API can be started by pulling and running the Tracardi API Docker image with the provided command. Make   sure to set the necessary environment variables, such as the Elastic host and Redis host.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-connect-tracardi-to-elasticsearch-via-ssl","title":"How can I connect Tracardi to Elasticsearch via SSL?","text":"<ul> <li>If you have an Elasticsearch instance and want to connect to it via HTTPS, you can use the provided command with the   necessary environment variables set accordingly.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-start-the-tracardi-gui","title":"How can I start the Tracardi GUI?","text":"<ul> <li>The Tracardi GUI can be started by pulling and running the Tracardi GUI Docker image with the provided command.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-run-the-import-worker-in-tracardi","title":"How can I run the import worker in Tracardi?","text":"<ul> <li>To run the import worker in Tracardi, you can use the provided command to start the worker Docker container. Make sure   to set the Redis host accordingly.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-access-the-tracardi-graphical-user-interface-gui","title":"How can I access the Tracardi Graphical User Interface (GUI)?","text":"<ul> <li>The Tracardi GUI can be accessed by visiting the provided URL and following the instructions for Tracardi setup. Make   sure to specify the Tracardi API URL correctly.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#where-can-i-find-the-system-documentation-for-tracardi","title":"Where can I find the system documentation for Tracardi?","text":"<ul> <li>The system documentation for Tracardi can be accessed by visiting the provided URL. Make sure the documentation Docker   is started.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#where-can-i-find-the-api-documentation-for-tracardi","title":"Where can I find the API documentation for Tracardi?","text":"<ul> <li>The API documentation for Tracardi can be accessed by visiting the provided URL.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-specify-a-specific-version-when-installing-tracardi","title":"How can I specify a specific version when installing Tracardi?","text":"<ul> <li>To install a specific version of Tracardi, you can add a version tag to the Docker image name in the command, such   as <code>tracardi/tracardi-api:&lt;version&gt;</code> or <code>tracardi/tracardi-gui:&lt;version&gt;</code>.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#what-is-the-purpose-of-running-multiple-instances-of-elasticsearch-in-tracardi","title":"What is the purpose of running multiple instances of Elasticsearch in Tracardi?","text":"<ul> <li>Running multiple instances of Elasticsearch in Tracardi is not a production solution but can be done for testing   purposes. For production use, it is recommended to run an Elasticsearch cluster. Documentation is available for   connecting Tracardi to an Elasticsearch cluster.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-troubleshoot-issues-with-tracardi-installation","title":"How can I troubleshoot issues with Tracardi installation?","text":"<ul> <li>For troubleshooting solutions during Tracardi installation, you can refer to the provided documentation section on   troubleshooting.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#can-i-run-tracardi-without-starting-the-redis-instance","title":"Can I run Tracardi without starting the Redis instance?","text":"<ul> <li>No.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#can-i-use-tracardi-with-an-existing-elasticsearch-instance","title":"Can I use Tracardi with an existing Elasticsearch instance?","text":"<ul> <li>Yes, you can connect Tracardi to an existing Elasticsearch instance. Documentation is available for connecting   Tracardi to Elasticsearch via SSL.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-access-the-tracardi-api-documentation","title":"How can I access the Tracardi API documentation?","text":"<ul> <li>The Tracardi API documentation can be accessed by visiting the provided URL.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-access-the-local-copy-of-the-tracardi-documentation","title":"How can I access the local copy of the Tracardi documentation?","text":"<ul> <li>The local copy of the Tracardi documentation can be accessed by visiting the provided URL. Make sure the documentation   Docker is started.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#can-i-access-tracardi-api-and-gui-from-different-ip-addresses","title":"Can I access Tracardi API and GUI from different IP addresses?","text":"<ul> <li>Yes, you can access the Tracardi API and GUI from different IP addresses by replacing \"localhost\" with the appropriate   IP in the configuration.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#can-i-specify-a-different-version-for-the-tracardi-worker","title":"Can I specify a different version for the Tracardi worker?","text":"<ul> <li>Yes, you can specify a different version for the Tracardi worker by adding a version tag to the Docker image name in   the command, such as <code>tracardi/update-worker:&lt;version&gt;</code>. Make sure to keep the worker version the same as the Tracardi   API version.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#what-are-the-software-prerequisites-for-installing-tracardi-from-source","title":"What are the software prerequisites for installing Tracardi from source?","text":"<p>The software prerequisites for installing Tracardi from source are:</p> <ul> <li>Docker</li> <li>Python version 3.9 or 3.10 (for version 0.8.1+)</li> <li>Pip</li> <li>Python Virtual Environment</li> <li>PyCharm</li> <li>Git</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#what-are-the-options-for-launching-elasticsearch-on-ubuntu","title":"What are the options for launching Elasticsearch on Ubuntu?","text":"<p>There are two options for launching Elasticsearch on Ubuntu:</p> <ol> <li>Installing Elasticsearch as a service</li> <li>Installing Elasticsearch as a Docker container</li> </ol>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-install-elasticsearch-as-a-service-on-ubuntu","title":"How can I install Elasticsearch as a service on Ubuntu?","text":"<p>To install Elasticsearch as a service on Ubuntu, follow these steps:</p> <ul> <li>Import the Elasticsearch public GPG key using cURL and add the Elastic package source list.</li> <li>Update the package lists and install Elasticsearch using APT.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-install-elasticsearch-as-a-docker-container-on-ubuntu","title":"How can I install Elasticsearch as a Docker container on Ubuntu?","text":"<p>To install Elasticsearch as a Docker container on Ubuntu, use the following command:</p> <pre><code>docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:7.13.2\n</code></pre>"},{"location":"qa/bulk/tracardi_installation/#how-do-i-download-the-tracardi-source-code","title":"How do I download the Tracardi source code?","text":"<p>To download the Tracardi source code, use the following commands:</p> <pre><code>git clone https://github.com/Tracardi/tracardi\ngit clone https://github.com/Tracardi/tracardi-api\n</code></pre>"},{"location":"qa/bulk/tracardi_installation/#how-do-i-create-virtual-environments-for-tracardi-source","title":"How do I create virtual environments for Tracardi source?","text":"<p>To create virtual environments for Tracardi, follow these steps:</p> <ul> <li>Navigate to the respective directory (<code>tracardi-api</code> or <code>tracardi</code>).</li> <li>Use the <code>python3.10 -m venv venv</code> command to create a virtual environment.</li> </ul>"},{"location":"qa/bulk/tracardi_installation/#how-do-i-install-the-dependencies-for-tracardi-when-installing-form-source","title":"How do I install the dependencies for Tracardi when installing form source?","text":"<p>The installation steps for dependencies vary depending on the operating system:</p>"},{"location":"qa/bulk/tracardi_installation/#linux","title":"Linux","text":"<pre><code>cd tracardi-api\nsource venv/bin/activate\npip3 install wheel\npip install -r app/requirements.txt\n</code></pre>"},{"location":"qa/bulk/tracardi_installation/#windows","title":"Windows","text":"<pre><code>cd tracardi-api\nvenv\\Scripts\\activate\npip install -r app/requirements.txt\n</code></pre>"},{"location":"qa/bulk/tracardi_installation/#mac-os","title":"Mac OS","text":"<pre><code>cd tracardi-api\nsource venv/bin/activate\npip install -r app/requirements.txt\n</code></pre>"},{"location":"qa/bulk/tracardi_installation/#how-can-i-test-access-to-the-tracardi-documentation","title":"How can I test access to the Tracardi documentation?","text":"<p>To test access to the Tracardi documentation, visit http://0.0.0.0:8686/docs.</p>"},{"location":"qa/bulk/workflow/","title":"How can I add new action nodes to Tracardi?","text":"<p>Tracardi is designed to be an extendable system, allowing users to add new action nodes easily via plugin classes. By adding the module name of the desired plugin, Tracardi can install the plugin code, making it available for use within the workflow. More information on how to write plugins is available in the documentation.</p>"},{"location":"qa/bulk/workflow/#how-are-actions-installed-in-tracardi","title":"How are actions installed in Tracardi?","text":"<p>Actions in Tracardi are installed by adding the module name of the desired plugin. Tracardi will automatically read the plugin code and install it, making the actions available for use in workflows.</p>"},{"location":"qa/bulk/workflow/#what-is-the-configuration-process-for-actions-in-tracardi","title":"What is the configuration process for actions in Tracardi?","text":"<p>Most actions in Tracardi require configuration. The configuration is done by filling out a configuration file in JSON format. For the convenience of non-technical users, Tracardi provides plain forms that automatically populate the JSON configuration based on the data entered in the form. This eliminates the need for manual editing of JSON files.</p>"},{"location":"qa/bulk/workflow/#how-can-i-access-the-json-configuration-file-for-an-action","title":"How can I access the JSON configuration file for an action?","text":"<p>While most users can configure actions using the provided forms in Tracardi's Graphical User Interface, IT personnel or advanced users may want to inspect the JSON configuration directly. Tracardi allows access to the JSON configuration file within the action's configuration, providing visibility and flexibility for advanced configuration requirements.</p>"},{"location":"qa/bulk/workflow/#is-there-additional-documentation-available-for-configuring-actions","title":"Is there additional documentation available for configuring actions?","text":"<p>Yes, this documentation provides detailed workflow actions documentation, including instructions on how to use and configure each plugin. The documentation covers configuring the plugin using the JSON configuration file. Configuration via forms is designed to be self-explanatory, so no additional documentation is necessary for that aspect.</p>"},{"location":"qa/bulk/workflow/#what-are-the-different-stages-of-a-workflow-in-tracardi","title":"What are the different stages of a workflow in Tracardi?","text":"<p>Workflows in Tracardi have two different stages: production stage and development stage. The production stage is a copy of the working workflow that is actively running and processing data. It cannot be changed. The development stage is a copy of the workflow that users can edit and make changes to.</p>"},{"location":"qa/bulk/workflow/#how-does-tracardi-handle-workflow-changes-to-prevent-breaking-the-system","title":"How does Tracardi handle workflow changes to prevent breaking the system?","text":"<p>Tracardi automatically saves workflow changes to ensure the integrity of the system. This means that any change or error in a workflow could potentially break the running system. To mitigate this risk, Tracardi uses a staging mechanism where workflows are maintained in two different stages: development and production. The development workflow is editable and serves as a sandbox for making changes, while the production workflow is the stable and running version. Users can deploy the development workflow to production once they are confident that the changes are ready to be implemented.</p>"},{"location":"qa/bulk/workflow/#how-can-i-change-the-state-of-a-workflow-from-development-to-production","title":"How can I change the state of a workflow from development to production?","text":"<p>Changing the state of a workflow from development to production in Tracardi is a simple process. Users can click the \" deploy\" button in the workflow editor to initiate the deployment. This action copies the current workflow from the development stage to the production stage. The previously deployed production workflow is saved, allowing for the possibility of reverting back to it if needed.</p>"},{"location":"qa/bulk/workflow/#what-happens-to-the-old-production-workflow-when-a-new-one-is-deployed","title":"What happens to the old production workflow when a new one is deployed?","text":"<p>When a new workflow is deployed in Tracardi, the previous production workflow is saved. This allows for easy reversion in case there is a need to revert back to the previously deployed workflow. The saved old production workflow ensures that the system remains stable and functional, providing a safety net for managing workflow changes.</p>"},{"location":"qa/bulk/workflow/#what-is-the-internal-state-of-a-workflow-in-tracardi","title":"What is the internal state of a workflow in Tracardi?","text":"<p>Each workflow in Tracardi has an internal state that is referenced in each action node. The internal state has the profile, event, session, flow, and internal memory. Each workflow run in a context of current profile and its event and session.</p>"},{"location":"qa/code/plugins/","title":"How to write some simple code of tracardi plugin","text":"<p>The purpose of writing code for a Tracardi plugin is to extend Tracardi's base functionalities by introducing new actions or nodes to the existing workflow. By creating plugins, we can add features or functionality that control and process the flow of data within Tracardi. These plugins can perform various tasks, such as data transformation, decision making based on data properties, communication with external resources, or any custom functionality required by the user.</p> <p>Essentially, a plugin acts as an independent module within the Tracardi workflow system, representing a unit of work. A plugin would have an input, a program that processes this input, and an output. In addition, plugins also have a configuration that defines how they should behave, including information like how to connect to an external database.</p> <p>Here's an example of a simple plugin:</p> <p>This is a Python class representing a Tracardi plugin. The FlowWalker plugin scans the execution flow and processes each node accordingly.</p> <pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData, Documentation, PortDoc\nfrom tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\n\n\nclass FlowWalker(ActionRunner):\n\n    def __init__(self):\n        pass\n\n    async def set_up(self, config):\n        pass\n\n    async def run(self, payload: dict):\n        input_data = payload.get('input', {})\n        # process input_data here\n        processed_data = {\"output\": \"value\"}\n        return Result(port=\"payload\", value=processed_data)\n\n    async def close(self):\n        pass\n\n\ndef register() -&gt; Plugin:\n    return Plugin(\n        start=False,\n        spec=Spec(\n            module=__name__,\n            className=FlowWalker.__name__,\n            inputs=[\"payload\"],\n            outputs=[\"payload\"],\n            version='0.7.1',\n            license=\"MIT\",\n            author=\"Author\"\n        ),\n        metadata=MetaData(\n            name='FlowWalker',\n            desc='Does nothing.',\n            icon='error',\n            group=[\"Events\"],\n            documentation=Documentation(\n                inputs={\n                    \"payload\": PortDoc(desc=\"This port takes payload object.\")\n                },\n                outputs={\n                    \"payload\": PortDoc(desc=\"This port returns given payload without any changes.\")\n                }\n            )\n        )\n    )\n</code></pre> <p>Explanation of the code:</p> <ol> <li>The <code>__init__</code> method initializes the plugin object. In this case, it does nothing.</li> <li>The <code>set_up</code> method is used to set up and initialize resources. In this case, it's empty because no setup is    required.</li> <li>The <code>run</code> method is the main method of the plugin that is triggered in the workflow. It takes an input dictionary,    processes it and returns the result. In this example, it simply reads the 'input' key from the dictionary, ignores    it, and returns a new dictionary with an 'output' key and 'value' value.</li> <li>The <code>close</code> method is used to close and clean up any resources. In this case it's empty because there are no    resources to close.</li> <li><code>register</code> function registers delivers the information on how to register the plugin in the system.</li> </ol> <p>Remember that as a developer, you can customize all of these methods to perform whatever actions you want, based on the needs of your project or workflow.</p>"},{"location":"qa/code/plugins/#how-to-register-a-custom-plugin-in-the-system","title":"How to register a custom plugin in the system?","text":"<p>When you finished coding you custom plugin go to <code>tracardi/service/setup/setup_plugins.py</code> and add to</p> <pre><code>installed_plugins: Dict[str, PluginMetadata] \n</code></pre> <p>the following line:</p> <pre><code>\"module-where-the-plugin-code-is-saved\": PluginMetadata(\n    test=PluginTest(\n        init={},  # here your init data from spec\n        resource={}  # here resource init data if exists\n    ),\n    plugin_registry=\"module-where-the-plugin-code-is-saved\"\n)\n</code></pre> <p>Replace the <code>module-where-the-plugin-code-is-saved</code> with the full path to module like <code>tracardi.process_engine.action.v1.flow_walker</code> where the flow_walker is the python file.</p> <p>Then click install plugin in the <code>Maintainace/Action Plugin-Ins</code> the button Plugins or Reinstall plugins.</p>"},{"location":"qa/code/plugins/#write-an-example-of-plugin-form","title":"Write an example of plugin form","text":"<p>An exemplary plugin form in Tracardi could be the \"Event type plugin configuration\" that has been described in the provided document. Here is its structure:</p> <pre><code>Form(groups=[\n    FormGroup(\n        name=\"Event type plugin configuration\",\n        description=\"Define required event type\",\n        fields=[\n            FormField(\n                id=\"resource\",\n                name=\"Resource\",\n                description=\"Select your API resource.\",\n                component=FormComponent(type=\"resource\", props={\"label\": \"API Resource\", \"tag\": \"api\"})\n            ),\n            FormField(\n                id=\"event_type\",\n                name=\"Event type\",\n                description=\"Event type to check\",\n                component=FormComponent(type=\"text\", props={\"label\": \"Event type\"})\n            )\n        ]\n    )\n])\n</code></pre> <p>The plugin form contains two main fields:</p> <ol> <li> <p><code>Resource</code> - This allows users to select the API resource for their plugin. This field is created using a    FormComponent with a type of \"resource\". The \"label\" and \"tag\" properties for this field indicate the way the field    will be displayed in the GUI.</p> </li> <li> <p><code>Event type</code> - This field enables users to specify the event type their plugin should target. It is created using    another FormComponent but with a type of \"text\". This component also has a \"label\" property which determines how the    field will be presented in the GUI.</p> </li> </ol> <p>By extending the plugin form with these fields, users can specify a resource and event type for their plugin, tailoring it to their specific use case.</p> <p>The form array should be referenced in <code>register</code> function in Plugin object property <code>spec.form</code> like this:</p> <pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData\nfrom tracardi.service.plugin.domain.register import Form, FormGroup, FormField, FormComponent  # \n\n# this is the function that will be called to get the data of plugin when it is registered.\ndef register() -&gt; Plugin:\n    return Plugin(\n\n        start=False,\n        spec=Spec(\n            module=__name__,\n            className='MyPlugin',\n            init={\n                \"event_type\": \"\"\n            },\n            form=Form(groups=[\n                FormGroup(\n                    name=\"Event type plugin configuration\",\n                    description=\"Define required event type\",\n                    fields=[\n                        FormField(\n                            id=\"resource\",\n                            name=\"Resource\",\n                            description=\"Select your API resource.\",\n                            component=FormComponent(type=\"resource\", props={\"label\": \"API Resource\", \"tag\": \"api\"})\n                        ),\n                        FormField(\n                            id=\"event_type\",\n                            name=\"Event type\",\n                            description=\"Event type to check\",\n                            component=FormComponent(type=\"text\", props={\"label\": \"Event type\"})\n                        )\n                    ]\n                )\n            ]),\n            inputs=[\"payload\"],\n            outputs=[\"MyEvent\", \"NotMyEvent\"],\n            version='0.1',\n            license=\"MIT\",\n            author=\"Your Name\"\n        ),\n        metadata=MetaData(\n            name=\"My first plugin\",\n            desc='Checks if the event type is equal to my-event.',\n            group=[\"Test plugin\"]\n        )\n    )\n</code></pre>"},{"location":"qa/code/plugins/#what-is-plugin-form","title":"What is plugin form?","text":"<p>The plugin form is part of plugin code where you define the configuration of the plugin. Basically plugins can be configured with JSON objects. Forms map the form fields with the JSON. When changes are made within the form, it is reflected in the JSON configuration and vice-versa.</p> <p>For instance, when we have a form like this</p> <pre><code>form = Form(groups=[\n   FormGroup(\n      name=\"Event type plugin configuration\",\n      description=\"Define required event type\",\n      fields=[\n         FormField(\n            id=\"resource\",\n            name=\"Resource\",\n            description=\"Select your API resource.\",\n            component=FormComponent(type=\"resource\", props={\"label\": \"API Resource\", \"tag\": \"api\"})\n         ),\n         FormField(\n            id=\"event_type\",\n            name=\"Event type\",\n            description=\"Event type to check\",\n            component=FormComponent(type=\"text\", props={\"label\": \"Event type\"})\n         )\n      ]\n   )\n]),\n</code></pre> <p>and JSON configuration like this:</p> <pre><code>init={\n   \"resource\": {\n      \"id\": \"\",\n      \"name\": \"\"\n   },\n   \"event_type\": {\n      \"id\": \"\",\n      \"name\": \"\"\n   }\n}\n</code></pre> <p>That means the <code>FormGroup</code> \"Event type plugin configuration\" is created with two <code>FormField</code>s: \"Resource\" and \"Event type\". The <code>id</code> of a <code>FormField</code> must match with a configuration property in <code>init</code>, allowing for a connection between the form value and the configuration value. This is explained as \"This is how you bind configuration with the form field.\" in the documentation.</p>"},{"location":"qa/code/plugins/#what-is-a-simple-code-template-for-custom-plugin","title":"What is a simple code template for custom plugin?","text":"<pre><code>from tracardi.service.plugin.domain.register import Plugin, Spec, MetaData, Documentation, PortDoc\nfrom tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\n\n\nclass FlowWalker(ActionRunner):\n\n   def __init__(self):\n      # Init data here \n      pass\n\n   async def set_up(self, config):\n      # setup resource if needed\n      pass\n\n   async def run(self, payload: dict):\n      # process and return data\n      return Result(port=\"payload\", value=payload)\n\n   async def close(self):\n      # close all open connections\n      pass\n\n# Register plugin\ndef register() -&gt; Plugin:\n    return Plugin(\n        start=False,\n        spec=Spec(\n            module=__name__,  # Module name\n            className=FlowWalker.__name__,  # Class Name\n            inputs=[\"payload\"],  # input ports, must be one\n            outputs=[\"payload\"],  # output ports, may be many\n            version='0.7.1',\n            license=\"MIT\",\n            author=\"Author\"\n        ),\n        metadata=MetaData(\n            name='FlowWalker',  # Plugin name\n            desc='Does nothing.',  # Plugin description\n            icon='error',  # Icon\n            group=[\"Events\"],  # Group in the menu\n            documentation=Documentation(  # Port documentation\n                inputs={  # Documentation for input port. We defined that input port is named 'payload`\n                    \"payload\": PortDoc(desc=\"This port takes payload object.\")\n                },\n                outputs={ # Documentation for output port. We defined that output port is also named 'payload`\n                    \"payload\": PortDoc(desc=\"This port returns given payload without any changes.\")\n                }\n            )\n        )\n    )\n</code></pre> <p>Notice that <code>outputs=[\"payload\"]</code> matches the <code>return Result(port=\"payload\", value=payload)</code> and </p> <pre><code>outputs={ \"payload\": PortDoc(desc=\"This port returns given payload without any changes.\") }\n</code></pre> <p>The same with <code>inputs=[\"payload\"]</code> that matches: </p> <pre><code>inputs={  \"payload\": PortDoc(desc=\"This port takes payload object.\") }\n</code></pre> <p>in the documentation propery of object metadata.</p>"},{"location":"qa/code/plugins1/","title":"Basic code template for tracardi plugin?","text":"<p>To write a plugin in Tracardi, you typically follow a certain pattern in your Python code. Here's an example of what a simple code template for a custom plugin may look like:</p> <pre><code>from tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\n\n\nclass FlowWalker(ActionRunner):\n\n    def __init__(self):\n        # Init data here \n        pass\n\n    async def set_up(self, config):\n        # setup resource if needed\n        pass\n\n    async def run(self, payload: dict):\n        # process and return data\n        return Result(port=\"payload\", value=payload)\n\n    async def close(self):\n        # close all open connections\n        pass\n</code></pre> <p>Here's a breakdown of the main components of a plugin:</p> <ol> <li> <p>First, import the required modules from the Tracardi package.</p> </li> <li> <p>Then, create a class for your plugin that inherits from <code>ActionRunner</code>. This makes your class a plugin, capable of    being run by Tracardi.</p> </li> <li> <p>The <code>__init__</code> method is the initializer for your class. You can do any necessary setup here.</p> </li> <li> <p><code>set_up</code> method is for setting up resources if needed.</p> </li> <li> <p>The <code>run</code> method is where the processing of data will happen. This function accepts a payload argument which is a    dictionary and returns the result of the operation as a <code>Result</code> object.</p> </li> <li> <p>The <code>close</code> method is for cleaning up, closing connections or any necessary teardown.</p> </li> </ol> <p>Remember, the plugin template above is a basic structure. Depending on your goals, your plugin might have additional methods or an altered structure.</p> <p>Note that plugins should b register in the system. Check the documentation on how to register the plugin.</p> <p>This document answers the questions: - How to write a custom plugin?</p>"},{"location":"qa/code/plugins1/#where-should-i-place-plugins-in-tracardi-code","title":"Where should I place plugins in tracardi code?","text":"<p>In Tracardi, you should place your plugins in the <code>tracardi/process_engine/action/v1</code> folder. The recommended way to structure the code for your plugin is to create a folder with the plugin name and place the <code>plugin.py</code> file inside it.</p> <p>Here's an example of how you can organize your plugin files:</p> <ol> <li> <p>Create a folder with your plugin name. For example, <code>my_plugin</code>.</p> </li> <li> <p>Inside the <code>my_plugin</code> folder, place the <code>plugin.py</code> file. This file will contain the code for your plugin.</p> </li> </ol> <p>The file structure would look like this:</p> <pre><code>tracardi/\n\u2514\u2500\u2500 process_engine/\n    \u2514\u2500\u2500 action/\n        \u2514\u2500\u2500 v1/\n            \u2514\u2500\u2500 my_plugin/\n                \u2514\u2500\u2500 plugin.py\n</code></pre> <p>By following this structure, you ensure that your plugin is placed in the appropriate directory within the Tracardi codebase. This makes it easier to manage and maintain your plugins in a standardized manner.</p> <p>This document answers the questions: - How to write a custom plugin?</p>"},{"location":"qa/code/plugins1/#my-plugin-is-not-visible-on-plugin-list","title":"My plugin is not visible on plugin list?","text":"<p>If your plugin is not visible on the plugin list in Tracardi, it is possible that you forgot to register the plugin in the <code>tracardi/service/setup/setup_plugins.py</code> file. To resolve this issue, follow these steps:</p> <ol> <li>Open the <code>setup_plugins.py</code> file in a text editor.</li> <li>Locate the section where other plugins are registered.</li> <li>Add the following code snippet to register your plugin:</li> </ol> <pre><code>\"module-where-the-plugin-code-is-saved\": PluginMetadata(\n    test=PluginTest(\n        init={},  # Here, provide the initialization data for your plugin from the specification\n        resource={}  # Here, provide the resource initialization data if it exists\n    ),\n    plugin_registry=\"module-where-the-plugin-code-is-saved\"\n)\n</code></pre> <ol> <li>Replace <code>\"module-where-the-plugin-code-is-saved\"</code> with the actual module name or file path where your plugin code is    saved.</li> <li>Provide the necessary initialization data for your plugin in the <code>init</code> and <code>resource</code> fields.</li> <li>Save the <code>setup_plugins.py</code> file.</li> <li>Restart the Tracardi service for the changes to take effect.</li> <li>After restarting, your plugin should be visible on the plugin list in Tracardi.</li> </ol> <p>By adding the plugin registration code to the <code>setup_plugins.py</code> file, you inform Tracardi about the existence of your plugin and make it accessible through the user interface.</p>"},{"location":"qa/code/plugins1/#give-me-a-fully-working-example-of-the-tracardi-class-with-description","title":"Give me a fully working example of the tracardi class with description?","text":"<p>Here's the whole code with descriptions for easier understanding:</p> <pre><code>from pydantic import field_validator\nfrom tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\nfrom tracardi.service.plugin.domain.register import Plugin, Spec, MetaData, Documentation, PortDoc, Form, FormGroup, FormComponent, FormField\nfrom tracardi.service.plugin.domain.config import PluginConfig\nfrom password_generator import PasswordGenerator\n\n\n# Configuration class for the plugin\nclass Config(PluginConfig):\n    max_length: int\n    min_length: int\n    uppercase: int\n    lowercase: int\n    special_characters: int\n\n    # Validator to ensure that the minimum length is not greater than the maximum length\n    @field_validator(\"min_length\")\n    def check_min_max_value(cls, value, values):\n        if value &gt; values[\"max_length\"]:\n            raise ValueError(\n                f\"Minimal length {value} cannot be bigger than given maximal length {values['max_length']}\")\n        return value\n\n\n# Function to validate the plugin configuration\ndef validate(config: dict) -&gt; Config:\n    return Config(**config)\n\n\n# Action runner class for the plugin\nclass PasswordGeneratorAction(ActionRunner):\n    config: Config\n    pgo: PasswordGenerator\n\n    async def set_up(self, init):\n        self.pgo = PasswordGenerator()\n        self.config = validate(init)\n        self.pgo.minlen = self.config.min_length\n        self.pgo.maxlen = self.config.max_length\n        self.pgo.minuchars = self.config.uppercase\n        self.pgo.minlchars = self.config.lowercase\n        self.pgo.minschars = self.config.special_characters\n\n    async def run(self, payload: dict, in_edge=None) -&gt; Result:\n        password = self.pgo.generate()\n        return Result(port=\"password\", value={\"password\": password})\n\n\n# Function to register the plugin\ndef register() -&gt; Plugin:\n    return Plugin(\n        start=False,\n        spec=Spec(\n            module=__name__,\n            className='PasswordGeneratorAction',\n            inputs=[\"payload\"],\n            outputs=[\"password\"],\n            version='0.7.1',\n            license=\"MIT\",\n            author=\"Mateusz Zitaruk\",\n            init={\n                \"min_length\": 8,\n                \"max_length\": 13,\n                \"uppercase\": 2,\n                \"lowercase\": 4,\n                \"special_characters\": 2\n            },\n            manual=\"password_generator_action\",\n            form=Form(\n                groups=[\n                    FormGroup(\n                        name=\"Password generator configuration\",\n                        fields=[\n                            FormField(\n                                id=\"max_length\",\n                                name=\"Password maximum length\",\n                                description=\"Please provide maximum length of password.\",\n                                component=FormComponent(\n                                    type=\"text\",\n                                    props={\n                                        \"label\": \"Maximum password length\"\n                                    }\n                                )\n                            ),\n                            FormField(\n                                id=\"min_length\",\n                                name=\"Password minimum length\",\n                                description=\"Please provide minimum length of password.\",\n                                component=FormComponent(\n                                    type=\"text\",\n                                    props={\n                                        \"label\": \"Minimum password length\"\n                                    }\n                                )\n                            ),\n                            FormField(\n                                id=\"uppercase\",\n                                name=\"Uppercase characters\",\n                                description=\"Please provide number of uppercase characters.\",\n                                component=FormComponent(\n                                    type=\"text\",\n                                    props={\n                                        \"label\": \"Number of uppercase letters\"\n                                    }\n                                )\n                            ),\n                            FormField(\n                                id=\"lowercase\",\n                                name=\"Lowercase characters\",\n                                description=\"Please provide number of lowercase characters.\",\n                                component=FormComponent(\n                                    type=\"text\",\n                                    props={\n                                        \"label\": \"Number of lowercase letters\"\n                                    }\n                                )\n                            ),\n                            FormField(\n                                id=\"special_characters\",\n                                name=\"Special characters\",\n                                description=\"Please provide number of special characters.\",\n                                component=FormComponent(\n                                    type=\"text\",\n                                    props={\n                                        \"label\": \"Number of special characters\"\n                                    }\n                                )\n                            ),\n                        ]\n                    )\n                ]\n            )\n        ),\n        metadata=MetaData(\n            name='Generate password',\n            desc='Generate new password according to user input',\n            icon='password',\n            group=[\"Operations\"],\n            documentation=Documentation(\n                inputs={\n                    \"payload\": PortDoc(desc=\"This port takes payload object.\")\n                },\n                outputs={\"password\": PortDoc(desc=\"This port returns generated password.\")}\n            )\n        )\n    )\n</code></pre> <p>This code defines a Tracardi plugin that generates passwords based on user-defined configuration. Here's a breakdown of the code:</p> <ol> <li>Import Statements:</li> </ol> <pre><code>from pydantic import field_validator\nfrom tracardi.service.plugin.runner import ActionRunner\nfrom tracardi.service.plugin.domain.result import Result\nfrom tracardi.service.plugin.domain.register import Plugin, Spec, MetaData, Documentation, PortDoc, Form, FormGroup,\n    FormComponent, FormField\nfrom tracardi.service.plugin.domain.config import PluginConfig\nfrom password_generator import PasswordGenerator\n</code></pre> <p>The import statements bring in the necessary modules and classes for the plugin. These include Pydantic for configuration validation, Tracardi classes for plugin registration, result handling, and form generation, and the PasswordGenerator class for generating passwords.</p> <ol> <li>Configuration Class:</li> </ol> <pre><code>class Config(PluginConfig):\n    max_length: int\n    min_length: int\n    uppercase: int\n    lowercase: int\n    special_characters: int\n\n    @field_validator(\"min_length\")\n    def check_min_max_value(cls, value, values):\n        if value &gt; values[\"max_length\"]:\n            raise ValueError(\n                f\"Minimal length {value} cannot be bigger than given maximal length {values['max_length']}\")\n        return value\n</code></pre> <p>The <code>Config</code> class defines the plugin configuration using the <code>PluginConfig</code> base class. It includes attributes for maximum length, minimum length, uppercase characters, lowercase characters, and special characters. The <code>check_min_max_value</code> method is a validator that ensures the minimum length is not greater than the maximum length.</p> <ol> <li>Configuration Validation Function:</li> </ol> <pre><code>def validate(config: dict) -&gt; Config:\n    return Config(**config)\n</code></pre> <p>The <code>validate</code> function takes a dictionary representing the plugin configuration and returns an instance of the <code>Config</code> class after validating the values.</p> <ol> <li>Action Runner Class:</li> </ol> <pre><code>class PasswordGeneratorAction(ActionRunner):\n    config: Config\n    pgo: PasswordGenerator\n\n    async def set_up(self, init):\n        self.pgo = PasswordGenerator()\n        self.config = validate(init)\n        self.pgo.minlen = self.config.min_length\n        self.pgo.maxlen = self.config.max_length\n        self.pgo.minuchars = self.config.uppercase\n        self.pgo.minlchars = self.config.lowercase\n        self.pgo.minschars = self.config.special_characters\n\n    async def run(self, payload: dict, in_edge=None) -&gt; Result:\n        password = self.pgo.generate()\n        return Result(port=\"password\", value={\"password\": password})\n</code></pre> <p>The <code>PasswordGeneratorAction</code> class is the action runner for the plugin. It inherits from the <code>ActionRunner</code> class provided by Tracardi. It has two main methods:</p> <ul> <li>The <code>set_up</code> method is called during the setup phase of the action and initializes the password generator with the   provided configuration.</li> <li> <p>The <code>run</code> method is called when the action is triggered. It generates a password using the configured parameters and   returns the result.</p> </li> <li> <p>Plugin Registration Function:</p> </li> </ul> <pre><code>def register() -&gt; Plugin:\n    return Plugin(\n        start=False,\n        spec=Spec(\n            module=__name__,\n            className='PasswordGeneratorAction',\n            inputs=[\"payload\"],\n            outputs=[\"password\"],\n            version='0.7.1',\n            license=\"MIT\",\n            author=\"Mateusz Zitaruk\",\n            init={\n                \"min_length\": 8,\n                \"max_length\": 13,\n                \"uppercase\": 2,\n                \"lowercase\": 4,\n                \"special_characters\": 2\n            },\n            manual=\"password_generator_action\",\n            form=Form(\n                groups=[\n                    FormGroup(\n                        name=\"Password generator configuration\",\n                        fields=[\n                            FormField(\n                                id=\"max_length\",\n                                name=\"Password maximum length\",\n                                description=\"Please provide maximum length of password.\",\n                                component=FormComponent(\n                                    type=\"text\",\n                                    props={\n                                        \"label\": \"Maximum password length\"\n                                    }\n                                )\n                            ),\n                            # Other form fields...\n                        ]\n                    )\n                ]\n            )\n        ),\n        metadata=MetaData(\n            name='Generate password',\n            desc='Generate new password according to user input',\n            icon='password',\n            group=[\"Operations\"],\n            documentation=Documentation(\n                inputs={\n                    \"payload\": PortDoc(desc=\"This port takes payload object.\")\n                },\n                outputs={\"password\": PortDoc(desc=\"This port returns generated password.\")}\n            )\n        )\n    )\n</code></pre> <p>The <code>register</code> function returns a <code>Plugin</code> instance that represents the plugin registration information. It includes:</p> <ul> <li>Plugin specifications such as the module and class name, input and output ports, version, license, author information,   initialization values, and a manual reference.</li> <li>Form configuration that defines the user interface for configuring the plugin. It includes form groups, form fields,   and their respective properties such as labels and descriptions.</li> <li>Metadata information such as the plugin name, description, icon, group, and documentation details including inputs and   outputs descriptions.</li> </ul> <p>By using this code template, you can create your own Tracardi plugins that generate passwords or perform other custom actions with configurable settings.</p> <p>This document answers the questions: - How to write a custom plugin?</p>"},{"location":"qa/errors/error_1/","title":"What does the error message \"Address already in use\" in Tracardi mean?","text":"<p>The error message \"Address already in use\" in Tracardi indicates that the port (in this case, port 8686) that Tracardi is attempting to use is already being used by another process or service. Reconfigure Tracardi to use other then 8686 port, for example 8687.</p>"},{"location":"qa/errors/error_10/","title":"Why I have this error: Invalid data reference. Dot notation <code>event@...</code> could not access data?","text":"<p>The error message \"Invalid data reference. Dot notation event@... could not access data\" typically indicates that there is an issue with the dot notation used to access data. Here are a few possible reasons for this error:</p> <ol> <li> <p>Typo in the dot notation: Double-check the dot notation used to access the data and ensure that there are no typos or    syntax errors. Even a small mistake, such as a misspelled property name or an incorrect key, can result in this    error.</p> </li> <li> <p>Data does not exist: Verify that the data you are trying to access actually exists. E.g. If the data is not present in the    event properties, you won't be able to access it using dot notation. Make sure the data you are referencing has been    properly set or assigned before attempting to access it.</p> </li> <li> <p>Invalid index or key: If the data you are trying to access is an array or an object, respectively, ensure that the    index or key you are using is valid. For arrays, the index should be within the bounds of the array (e.g., 0 to    length-1). For objects, the key should be a valid property of the object.</p> </li> </ol> <p>To troubleshoot this error, you can review your code or configuration and compare it with the documentation or examples provided by the framework or tool you are using. Pay attention to the syntax and make sure the data you are referencing exists and is accessible at the given location in the event.</p>"},{"location":"qa/errors/error_11/","title":"Error \"The GUI version 0.8.0 does not match the API version\"","text":"<p>The error message \"The GUI version 0.8.0 does not match the API version\" suggests that there is a mismatch between the versions of the Tracardi GUI and API. To resolve this issue, you can follow the steps below:</p> <ol> <li> <p>Check the versions: Click on the Tracardi name in the menu to view the versions of the GUI and API. Ensure that both    versions API and GUI are displayed and note down the numbers. The number should be the same.</p> </li> <li> <p>Verify Docker versions: Make sure that the Docker versions (tags) of both the GUI and API are the same. </p> </li> <li> <p>Update Docker images: If the Docker versions are not the same, update the Docker images for both the GUI and API to    match the desired version. This can typically be done using Docker commands or through a Docker management tool.</p> </li> <li> <p>Restart the services: After updating the Docker images, restart the Tracardi GUI and API services to apply the    changes and ensure that they use the correct versions.</p> </li> </ol> <p>By ensuring that the GUI and API versions are in sync and using the same Docker images, you should be able to resolve the error message and have a consistent Tracardi environment. </p>"},{"location":"qa/errors/error_12/","title":"I have error No plugin for id xxx. What could be a reason for this?","text":"<p>This could happen when after migration new system does not have installed some plugins. To resolve this issue fgo to Resources/extensions and install the missing plugin. Sometimes you also need to click button plugins in the workflow to reinstall missing plugins. </p>"},{"location":"qa/errors/error_13/","title":"I have error \"Tenant not allowed\"","text":"<p>It appears that you are facing an error related to multi-tenancy in your system. Multi-tenancy is a software architecture where a single instance of the software serves multiple clients, known as tenants, while keeping their data and configurations separate.</p> <p>The specific error message \"Tenant not allowed\" suggests that the URL you are trying to access is associated with a tenant that is not registered or allowed within the system. To resolve this issue, you can follow these steps:</p> <ol> <li> <p>Verify Tenant Registration: Check if the tenant you are trying to access is properly registered in the system.</p> </li> <li> <p>Add New Tenant: If the tenant is not registered, you need to add them to the system. This process typically    involves creating a new tenant profile with the necessary configurations and settings.</p> </li> <li> <p>Tenant URL Configuration: Double-check that the URL you are using to access the API corresponds to the registered    tenant.</p> </li> <li> <p>Documentation and Support: Review the documentation or seek support from the platform or service provider you are    using. They might have specific guidelines or troubleshooting steps to resolve multi-tenancy-related issues.</p> </li> </ol>"},{"location":"qa/errors/error_14/","title":"Troubleshooting \"Network Error\" when Selecting the API URL","text":"<p>If you encounter the error message \"Status: undefined, Message: undefined, Details Error: Network Error\" while trying to access the API URL, it indicates that there might be an issue with the connection to the Tracardi API. To troubleshoot this problem, follow these steps:</p> <ol> <li> <p>Double-check the API URL: Ensure that the API URL you are using is accurate and correctly points to the Tracardi    API. A mistyped or incorrect URL could lead to a 404 response or similar errors.</p> </li> <li> <p>Test the API URL in the browser: To confirm if the URL is correct, enter the API URL directly into your web    browser and see if you receive a response. A valid response should look like this:    <pre><code>{\n  \"details\": \"Not found\"\n}\n</code></pre>    The \"Not found\" message is expected since you are providing the API URL only, not the full endpoint URL.</p> </li> <li> <p>Check API logs: Examine the logs of the API server to identify any errors related to the connection between the    API and the Elasticsearch server. If there are issues with the connection, it could result in the \"Network Error\"    mentioned in the original message.</p> </li> <li> <p>Verify Elasticsearch connectivity: Ensure that the Elasticsearch server is operational and accessible. The API    should be able to establish a connection to the Elasticsearch server for proper functionality. If there are any    problems with Elasticsearch, it may prevent the API from functioning correctly. Please note that connection    to <code>localhost:9200</code> is not possible when running docker. Use IP instead.</p> </li> <li> <p>Verify Redis connectivity: Ensure that the Redis server is operational and accessible. The API should be able to    establish a connection to the Redis server for proper functionality. If there are any problems with Redis, it may    prevent the API from functioning correctly. Please note that connection to <code>localhost:6379</code> is not possible when    running docker. Use IP instead.</p> </li> </ol> <p>By following these steps, you can effectively troubleshoot and identify the cause of the \"Network Error\" when selecting the API URL. If you still experience issues please look for <code>Docker container installation</code> in documentation. </p> <p>This document also answers the questions:</p> <ul> <li>I see error: Status: undefined, Message: undefined, Details Error: Network Error, when selecting the API URL</li> <li>I see error: Error connection to localhost:6379</li> </ul>"},{"location":"qa/errors/error_15/","title":"I have this error: tracardi.exceptions.exception.StorageException: NotFoundError(404, 'index_not_found_exception', 'no such index [01506.tracardi-event-validation]', 01506.tracardi-event-validation, index_or_alias)","text":"<p>This suggests that the system is either not installed or configured as a multi-tenant instance without the MULTI_TENANT setting set to 'yes.' Please refer to the documentation to learn how to enable multi-tenancy.</p>"},{"location":"qa/errors/error_16/","title":"I have an error when executing report","text":"<p>The error you're encountering during report execution is likely linked to the query specified in your reports. Ensure that your query is compatible with Elasticsearch by testing it directly in Elasticsearch. For assistance, consult the Elasticsearch documentation to understand how queries should be structured. Additionally, be aware that injected data might sometimes interfere with the query's integrity, so it's important to check for any issues caused by such data.</p>"},{"location":"qa/errors/error_17/","title":"In version 0.8.2.1 I got this error what should I do","text":"<p><code>2024-02-08 11:51:05,011: ERROR: Update of index prod-0820.ffe49.tracardi-log-2024-2 mapping failed with error RequestError(400, 'illegal_argument_exception', {'error': {'root_cause': [{'type': 'illegal_argument_exception', 'reason': 'mapper [level] cannot be changed from type [text] to [keyword]'}], 'type': 'illegal_argument_exception', 'reason': 'mapper [level] cannot be changed from type [text] to [keyword]'}, 'status': 400}): (tracardi.service.setup.setup_indices:log_handler.py:51)</code></p> <p>This error typically occurs when the Elasticsearch (ES) log index is automatically created without a pre-existing template for that index. Although Tracardi aims to avoid this issue, it may still arise under certain circumstances, such as after system installation followed by an ES cluster failure and subsequent restart with a new instance. To resolve this problem, you should delete the affected log indexes (for instance, 0820.ffe49.tracardi-log-2024-2 and prod-0820.ffe49.tracardi-log-2024-2) and then refresh your system console in the browser. This action will prompt a reinstallation process that should correct the error.</p>"},{"location":"qa/errors/error_18/","title":"When I start multi-tenant installation I get the error: \"Installation forbidden. Tenant XXX not allowed\"","text":"<p>To successfully start a multi-tenant installation, it's essential to first authorize the new tenant in the Tenant Management System (TMS). This is accomplished through the TMS API by following these steps:</p> <ol> <li>Create the Tenant:</li> <li>Use the <code>POST /tenant</code> endpoint.</li> <li> <p>Provide all required data in the request body to register the new tenant.</p> </li> <li> <p>Install the System:</p> </li> <li>After creating the tenant, access its specific API.</li> <li>Initiate the installation process.</li> <li>Ensure that you include the correct installation token specifically assigned to the newly created tenant.</li> </ol> <p>By following these instructions, the tenant will be correctly set up and authorized, allowing the multi-tenant installation to proceed without issues.</p> <p>Related documents:</p> <ul> <li>What is TMS</li> <li>What is TMS responsible for</li> <li>Who to setup multi-tenant installation</li> <li>How to automate new tenant creation in TMS</li> <li>How to create new tenant</li> <li>What are the pros and cons of mutli-tenant setup</li> <li>How to integrate TMS with tracardi</li> </ul>"},{"location":"qa/errors/error_19/","title":"Referrer Policy: Ignoring the less restricted referrer policy \u201cno-referrer-when-downgrade\u201d for the cross-site request: https://mydomain.com/track","text":"<p>The message you're seeing in the console log is related to the Referrer Policy of the browser. The **Referrer Policy ** controls what information is sent in the <code>Referer</code> header when navigating between pages or making HTTP requests.</p> <p>Here\u2019s a breakdown of the key parts of the message:</p> <ol> <li> <p>Referrer Policy: This is the browser setting that specifies how much information about the current page (the \"    referrer\") is sent when making requests (like when you click a link or load resources from another site).</p> </li> <li> <p>Ignoring the less restricted referrer policy: This part means the browser is overriding a less secure or less    restrictive policy that it deems inappropriate for the request being made.</p> </li> <li> <p>\u201cno-referrer-when-downgrade\u201d: This is the specific policy in question. It means that the browser should send    the <code>Referer</code> header (which can include the URL of the current page) unless the request is being made to a less    secure context (e.g., from HTTPS to HTTP).</p> </li> <li> <p>Cross-site request: This indicates that the request is being made from one domain (your site) to another domain (    in this case, <code>mydomain.com</code>). Cross-site requests have stricter rules due to potential security risks.</p> </li> </ol> <p>In your case, the browser is ignoring the <code>no-referrer-when-downgrade</code> policy for security reasons, likely because it involves a cross-site request, which could introduce security risks if too much information about the referring page is shared.</p>"},{"location":"qa/errors/error_19/#solutions","title":"Solutions:","text":"<ul> <li> <p>Connect tracardi to some subdomain of your website domain, if you domain is abc.com create a subdomain   tracardi.abc.com and point it to tracardi API. This way there will be no cross-site requests.</p> </li> <li> <p>You can change the Referrer Policy in your HTTP headers or meta tags to a more restrictive policy, such   as <code>strict-origin-when-cross-origin</code> or <code>no-referrer</code>, to avoid sending referrer information in cross-site requests.   This is the solution that will work only with your browser.</p> </li> <li> <p>Ensure that the domains involved in the requests are using secure HTTPS protocols.</p> </li> </ul>"},{"location":"qa/errors/error_2/","title":"How can the \"Address already in use\" issue in Tracardi be resolved?","text":"<p>To resolve the \"Address already in use\" issue in Tracardi, you can remap the port that Tracardi is running on. By changing the port mapping in the Docker run command, you can assign a different port for Tracardi to use, such as changing from 8686 to 8888. Additionally, if you are using Tracardi's GUI, you will also need to update the API URL to reflect the new port.</p>"},{"location":"qa/errors/error_20/","title":"Why do I get a CORS error in Chrome when collecting data using the HTTP protocol, and how can I fix it?","text":""},{"location":"qa/errors/error_20/#answer","title":"Answer:","text":"<p>CORS (Cross-Origin Resource Sharing) errors occur in Chrome because some browsers are more restrictive regarding preflight OPTIONS requests. When collecting data via HTTP, if a service enforces HTTPS, it needs to redirect to the HTTPS version of the Tracardi API. Some browsers, like Chrome, do not allow AJAX calls to be redirected, which results in a CORS error.</p>"},{"location":"qa/errors/error_20/#how-to-fix-this","title":"How to fix this:","text":"<ol> <li> <p>Ensure HTTPS is used directly: Avoid the HTTP to HTTPS redirect by directly sending requests to the HTTPS version    of the API. This eliminates the need for a browser to handle the redirect, preventing the CORS issue from occurring.</p> </li> <li> <p>Use the same protocol: Ensure the website collecting the data and the API are both served over HTTPS to avoid    mixed-content issues and CORS problems due to protocol differences.</p> </li> </ol>"},{"location":"qa/errors/error_3/","title":"What could be the cause of the \"Index index 'INDEX_NAME' was NOT CREATED\" error during Tracardi update?","text":"<p>The \"Index index 'INDEX_NAME' was NOT CREATED\" error during Tracardi update occurs when the Elasticsearch server has reached its maximum limit for open shards, preventing the creation of new indices. To resolve this error, it is necessary to remove unused indices from Elasticsearch to free up resources for new indices.</p>"},{"location":"qa/errors/error_4/","title":"What does the error message \"Cannot connect to host elasticsearch:9200 ssl:default [Connection refused]\" indicate in Tracardi?","text":"<p>The error message \"Cannot connect to host elasticsearch:9200 ssl:default [Connection refused]\" suggests that the Elasticsearch server is not running or not accessible. This message is typically displayed when Tracardi starts before Elasticsearch is ready. Tracardi will automatically resume when Elasticsearch becomes available.</p>"},{"location":"qa/errors/error_5/","title":"Why does the Tracardi API connection with Elasticsearch fail when using \"localhost\" as the ELASTIC_HOST?","text":"<p>When running Tracardi API within docker container with \"localhost\" as the ELASTIC_HOST, it means that the connection is being made within the Docker container itself. However, Elasticsearch is not present within the Docker container, leading to connection failure. To resolve this, it is necessary to provide the external IP address of the Elasticsearch server, such as the laptop's IP address when running Tracardi locally.</p>"},{"location":"qa/errors/error_6/","title":"What causes the \"Failed to index document\" error in Tracardi, and how can it be solved?","text":"<p>The \"Failed to index document\" error occurs when there is a conflict in the schema between the data being sent to Tracardi and the existing data in Tracardi. This conflict arises when the data type being sent conflicts with the existing data type. To resolve this error, ensure that the data being sent matches the expected data type defined in the Tracardi schema.</p>"},{"location":"qa/errors/error_7/","title":"What is the reason for the \"Failed connection with error: CORS request did not succeed\" error in Tracardi API connection?","text":"<p>The \"Failed connection with error: CORS request did not succeed\" error indicates that the HTTP request, which utilizes Cross-Origin Resource Sharing (CORS), has failed at the network or protocol level. This error is not directly related to CORS but rather signifies a fundamental network issue. Possible causes include browser plugins blocking the request or attempting to access an HTTP resource from an HTTPS origin.</p>"},{"location":"qa/errors/error_8/","title":"What issue can occur when using the \"/track/\" endpoint with HTTPS connection in Tracardi?","text":"<p>When using the \"/track/\" endpoint with an HTTPS connection in Tracardi, there can be an issue with the redirection. The system redirects \"/track/\" to \"/track,\" but this redirection may cause the HTTPS connection to be lost. It is recommended to avoid using a trailing backslash in API calls to prevent this issue.</p>"},{"location":"qa/facebook/account_id/","title":"Where can I find AD ACCOUNT ID.","text":"<p>To obtain your Facebook Ad Account ID, follow these steps:</p> <ol> <li> <p>Go to Facebook Ads Manager:</p> <ul> <li>Navigate to the Facebook Ads Manager.</li> <li>Log in with your Facebook account that is associated with your advertising account.</li> </ul> </li> <li> <p>Find Your Ad Account ID:</p> <ul> <li>Once you're in the Ads Manager, your Ad Account ID can typically be found in the top left corner of the page.</li> <li>It usually appears as a series of numbers, sometimes preceded by 'act_' (e.g., '123456789012345').</li> <li>Alternatively click <code>Account Overview</code>, where you should be abel to see AD ACCOUNT ID.</li> </ul> </li> <li> <p>If You Have Multiple Ad Accounts:</p> <ul> <li>If you manage multiple ad accounts, you can find all of them listed under the \u201cAccounts\u201d section in the Ads   Manager.</li> <li>Select the specific ad account you want to use, and its ID will be displayed.</li> </ul> </li> </ol> <p>Remember, you need to have administrative access to the ad account to use it with the Facebook SDK. If you're part of a team or company, ensure that the account's admin has granted you the necessary permissions.</p>"},{"location":"qa/facebook/facebook_integration/","title":"How to start with Facebook integration","text":"<p>To get started with the Facebook SDK and create the necessary credentials like <code>YOUR_APP_ID</code>, <code>YOUR_APP_SECRET</code>, and <code>YOUR_ACCESS_TOKEN</code>, you'll need to follow these steps:</p> <ol> <li> <p>Create a Facebook Developer Account:</p> <ul> <li>If you don't already have one, you'll need to create a Facebook Developer account. Go to   the Facebook Developers website and sign up.</li> </ul> </li> <li> <p>Create a New App:</p> <ul> <li>Once logged in, go to the 'My Apps' menu and select 'Create App'.</li> <li>Choose the app type that best suits your needs (e.g., 'For Everything Else' if your app doesn't fit into the other   categories).</li> <li>Fill in the required information (like the name of your app, purpose: Business, connect business account if   needed.) and click 'Create'.</li> </ul> </li> <li> <p>Get Your App ID and App Secret:</p> <ul> <li>After creating your app, you'll be redirected to the App Dashboard.</li> <li>Here, you can find your 'App ID' and 'App Secret'. Go to <code>App Settings/Basic</code>. You will find the APP_ID and APP_SECRET. Keep these confidential.</li> <li>You may need to click on 'Show' and enter your password to see the App Secret.</li> </ul> </li> <li> <p>Generate an Access Token:</p> <ul> <li>In the App Dashboard, look for the <code>App Settings/Advanced</code> section.</li> <li>You can generate a User Access Token, which is tied to a specific user and allows the app to do things on behalf   of that user.</li> <li>For server-to-server calls, you might need an 'App Access Token' (which represents the app itself) or a 'Page   Access Token' (for managing Facebook Pages).</li> </ul> </li> <li> <p>Source Audience ID:</p> <ul> <li>For the <code>source_audience_id</code>, you need an existing Custom Audience ID or any other valid source audience ID based   on your requirements.</li> </ul> </li> </ol> <p>Ensure you adhere to Facebook's policies and guidelines while using their SDK and APIs, especially regarding user data and privacy. If you're planning to use the app in a production environment, you might also need to go through Facebook's App Review process.</p>"},{"location":"qa/facebook/get_access_token/","title":"How to get access token.","text":"<p>Go to: https://developers.facebook.com/tools/accesstoken/ YO can see APP TOKEN and can generate USER TOKEN</p>"},{"location":"qa/plugins/mailchimp/","title":"Does tracardi integrate with Mailchimp?","text":"<p>Yes, Tracardi offers two plugins for sending emails to MailChimp:</p> <ul> <li> <p>Send transactional e-mail plugin: This plugin utilizes the MailChimp Mandrill API to deliver transactional emails.   It requires a Mandrill account with an API key and proper domain configuration in MailChimp settings. The plugin   accepts any payload as input and returns a response from the MailChimp API. Depending on the response, it triggers   either the payload port (for successful delivery) or the error port (for failed delivery).</p> </li> <li> <p>Add to MailChimp audience plugin: This plugin integrates with the MailChimp API to add contacts to a specified   audience. It requires a MailChimp account with a marketing API key and a pre-created MailChimp audience. The plugin   accepts a JSON-like payload as input and returns the MailChimp API response. Upon successful addition of a contact,   the response is sent to the response port; otherwise, an error message is routed to the error port.</p> </li> </ul>"},{"location":"trouble/","title":"Troubleshooting","text":"<p>Known issues that may come up while running Tracardi.</p>"},{"location":"trouble/#address-already-in-use","title":"Address already in use","text":"<p>If you experience:</p> <pre><code>ERROR: for tracardi_tracardi_1  Cannot start service \ntracardi: driver failed programming external connectivity \non endpoint tracardi_tracardi_1 \nError starting userland proxy: listen tcp4 0.0.0.0:8686: \nbind: address already in use\n</code></pre> <p>That means you have something running on port 8686. It may be another copy of Tracardi or other service.</p> <p>The solution to this is to remap the port Tracardi is running. If you run Tracardi API like this change the port mapping from <code>8686:80</code> to some other port <code>8888:80</code>.</p> <p>Change:</p> <pre><code>docker run -p 8686:80 -e ELASTIC_HOST=http://&lt;your-laptop-ip&gt;:9200 tracardi/tracardi-api\n</code></pre> <p>To:</p> <pre><code>docker run -p 8888:80 -e ELASTIC_HOST=http://&lt;your-laptop-ip&gt;:9200 tracardi/tracardi-api\n</code></pre> <p>Remember that when you change API port then you have it included in GUI as GUI uses API to access data.</p> <p>So tak a look at lunch command for GUI:</p> <p>So change default docker run command for Tracardi GUI</p> <pre><code>docker run -p 8787:80 -e API_URL=//127.0.0.1:8686 tracardi/tracardi-gui\n</code></pre> <p>To (notice: API_URL=//127.0.0.1:8888, this the where the Tracardi API is running)</p> <pre><code>docker run -p 8787:80 -e API_URL=//127.0.0.1:8888 tracardi/tracardi-gui\n</code></pre>"},{"location":"trouble/#installation-errors","title":"Installation errors","text":"<pre><code>Index index `INDEX_NAME` was NOT CREATED. The following result was returned {'error': \n{'root_cause': [{'type': 'validation_exception', 'reason': 'Validation Failed: 1: this action would add [10] shards, \nbut this cluster currently has [1000]/[1000] maximum normal shards open;'}], 'type': 'validation_exception', 'reason': \n'Validation Failed: 1: this action would add [10] shards, but this cluster currently has [1000]/[1000] maximum normal \nshards open;'}, 'status': 400} [Exception]\n</code></pre> <p>This error can pop up if you have your elasticsearch full of indices. This means there are no shards open for new indices. Remove unused indices. This error is usually shown during Tracardi update. </p>"},{"location":"trouble/#connecting-to-elasticsearch","title":"Connecting to Elasticsearch","text":"<pre><code>aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host elasticsearch:9200 ssl:default [Connection refused]\n</code></pre> <p>This information may come up if elasticsearch is not running. When elasticsearch starts Tracardi will resume automatically. This information is usually displayed when Tracardi starts before elastic is ready. Tracardi waits for elastic to start and checks if it's ready every 5 seconds.</p> <p>The above error log may look like this:</p> <pre><code>INFO:     Started server process [10864]\nINFO:uvicorn.error:Started server process [10864]\nINFO:     Waiting for application startup.\nINFO:uvicorn.error:Waiting for application startup.\n</code></pre> <p>This means Tracardi is waiting for Elastic to start. You will see TimeOut messages if Tracardi could not connect to Elastic long enough.</p>"},{"location":"trouble/#elastic-at-localhost-error","title":"Elastic at localhost error","text":"<p>When you run Tracardi API like this:</p> <pre><code>docker run -p 8686:80 -e ELASTIC_HOST=http://localhost:9200 tracardi/tracardi-api\n</code></pre> <p>Notice that you try to connect to Elastic on localhost. When you run it like this means that you're connecting to the docker itself as localhost means local in docker. Obviously elastic is not there, so Tracardi will never connect. Pass external ip for elastic. This may be your laptop IP if you are running Tracardi locally.</p>"},{"location":"trouble/#failed-to-index-document","title":"Failed to index document","text":"<p>Document will fail to index if its schema is conflicting with other documents in Tracardi. It this happens you may see this message:</p> <pre><code>Could not save event. Error: 1 document(s) failed to index. - failed to parse field [properties.id] of type [float] \nin document with id '052df0ed-e719-457c-9de1-3b197c44b44e'. Preview of field's value: 'consent-type'\"\n</code></pre> <p>Why this happens and how to solve it. It happens when the type of data that is already in Tracardi is conflicting with data that's being sent to be saved.</p> <p>For example. Consider to following scenario. You have saved age as an integer number for example: 34, 25, 15, 67. It is saved in properties.age. You 100 documents that are saved this way. You can easily search for anyone underage 21. But now someone wants to send an age as a string e.g. \"21 years old\". This type of data is conflicting with existing data so Tracardi will raise the error.</p> <pre><code>Could not save event. Error: 1 document(s) failed to index. - failed to parse field [properties.age] of type [string] \nin document with id '052df0ed-e719-457c-9de1-3b197c44b44e'. Preview of field's value: '21 years old'\"\n</code></pre>"},{"location":"trouble/#issues-with-api-connection","title":"Issues with API connection","text":"<p>Failed connection with error: CORS request did not succeed</p> <p>Why this happens.</p> <p>The HTTP request which makes use of CORS failed because the HTTP connection failed at either the network or protocol level. The error is not directly related to CORS, but is a fundamental network error of some kind.</p> <p>In many cases, it is caused by a browser plugin (e.g. an ad blocker or privacy protector) blocking the request.</p> <p>Other possible causes include:</p> <ul> <li>Trying to access an https resource that has an invalid certificate will cause this error.</li> <li>Trying to access an http resource from a page with an https origin will also cause this error.</li> <li>As of Firefox 68, https pages are not permitted to access http://localhost, although this may be changed by Bug   1488740.</li> <li>The server did not respond to the actual request (even if it responded to the Preflight request). One scenario might   be an HTTP service being developed that panicked without returning any data.</li> </ul>"},{"location":"trouble/#missing-track-endpoint","title":"Missing /track endpoint","text":"<p>Track endpoint with trailing backslash may fail if you use HTTPS connection. If you, by mistake, use URL <code>/track/</code> instead of <code>/track</code> with https connection, the system will redirect <code>/track/</code> to <code>/track</code>. But it will lose https connection. This is a know error in fastAPI: https://github.com/tiangolo/fastapi/issues/4990. Please do not use backslash at the end of any API call.</p>"},{"location":"trouble/#other-issues","title":"Other issues","text":"<p>Sometimes you can see the log like this:</p> <pre><code>[2021-10-06 08:35:35 +0000] [1] [INFO] Handling signal: winch\n</code></pre> <p>This can be ignored. Signal winch is thrown when you resize console. </p>"},{"location":"upgrade/upgrades/","title":"Tracardi Upgrades before version 0.9.0","text":"<p>This documentation provides information on how to upgrade Tracardi and perform data migration between versions. It also covers the process of updating the system and the precautions to take during the upgrade process.</p>"},{"location":"upgrade/upgrades/#upgrades","title":"Upgrades","text":"<p>Tracardi is still in active development, and upgrading to a new version may introduce compatibility issues due to changes in workflow persistence. Workflows created in one version may not work properly with all available plugins in a newer version, or the plugins may behave differently.</p> <p>To upgrade the open-source version of Tracardi to the latest development version, pull the new docker image:</p> <pre><code>docker pull tracardi/tracardi-api:&lt;version&gt;\ndocker pull tracardi/tracardi-gui:&lt;version&gt;\n</code></pre> <p>Then you can run it the same way as written in the installation guide.</p> <p>Warning</p> <p>Upgrades of minor or development versions of Tracardi may cause data loss. Each development version is marked with a <code>-dev</code> suffix.</p>"},{"location":"upgrade/upgrades/#prerequisites-for-upgrading","title":"Prerequisites for Upgrading","text":"<p>Before upgrading, it is crucial to ensure that you only install dockers with a tagged version. Installing the latest version without proper tagging may lead to incorrect data, resulting in the loss of continuity during the upgrade process. Therefore, it is essential to install the appropriate tagged version to facilitate a smooth system upgrade.</p>"},{"location":"upgrade/upgrades/#automated-system-upgrades","title":"Automated System Upgrades","text":"<p>Starting from version 0.7.0, Tracardi offers automated system upgrades. Unlike previous versions, which could only upgrade the code, version 0.7.0 and above maintain information about the indexes used. Access to data is achieved through aliases, which function like symbolic links.</p>"},{"location":"upgrade/upgrades/#the-upgrade-process","title":"The Upgrade Process","text":"<p>When performing an upgrade, Tracardi leaves the old version indexes unchanged and designates them as the previous version. Simultaneously, new empty indexes are created, along with new aliases (each prefixed with version number). If the schema of the old index remains unchanged, the data pointer is switched from the old index to the new one. However, if there are schema changes, the data is migrated using a script that rewrites the data between indexes and copies the data from the old fields to the new ones accordingly. This process ensures a seamless transition during the upgrade.</p>"},{"location":"upgrade/upgrades/#upgrades-post-version-072","title":"Upgrades post version 0.7.2","text":"<p>In Tracardi version 0.7.2, a feature was introduced that allows for data migration between versions. Each new Tracardi installation creates a new, empty database, and the data from an old version can be migrated to the new one. To perform this migration, follow these steps:</p> <ol> <li>Navigate to the maintenance/migration page.</li> <li>Locate the migration script from the old version.</li> <li>Follow the instructions provided in the script to complete the data migration.</li> </ol> <p>Note that this feature is only available in Tracardi version 0.7.2 and higher. If you are using an older version, you will need to upgrade to at least 0.7.2 to access this functionality.</p> <p>Warning</p> <p>If you perform multiple upgrades of Tracardi, the system will create a large number of new indices, which may cause you to reach the Elasticsearch limit of 1000 indices. To resolve this issue, you can either increase the limit in the Elasticsearch configuration or delete the indices used by old Tracardi versions. Tracardi version 0.8.0 includes a feature in the GUI to delete old indices. If you are using an older version, you can use the API to delete old indices, such as issuing an HTTP DELETE call to <code>/indices/version/0.7.2</code> to delete the 0.7.2 version indices. However, be cautious when deleting old data, as there is no way to revert the system to an older version once the data has been deleted. It is important to thoroughly test your new Tracardi installation before deleting any old data.</p>"},{"location":"upgrade/upgrades/#installation-prior-version-070","title":"Installation prior Version 0.7.0","text":"<p>Versions prior to 0.7.0 are not aware of previous data schemas. Therefore, the system does not know what indexes were used previously and is not able to check the changes that have occurred in their schemas. This means that manual data migration by re-indexing is necessary. If the collected data in previous versions is not important and it is possible to lose it, a fresh installation is recommended.</p>"},{"location":"upgrade/upgrades/#manual-transfer","title":"Manual Transfer","text":"<p>To transfer data, first check what indexes you have in Elasticsearch. This can be done by going to Monitoring / Elasticsearch indices in Tracardi. Indexes marked as Connected are currently in use and are prefixed with a version number. Old indexes from system e.g. version 0.6.0, do not have a prefix and are marked as Not Connected.</p> <p>To transfer data, use the reindex function available in Elasticsearch. Documentation of this functionality can be found here. Reindexing data is nothing more than copying it from one index to another.</p> <p>This documentation answers the following questions:</p> <ul> <li>How can I upgrade Tracardi?</li> <li>What is data migration?</li> <li>How to migrate Tracardi to a new version?</li> <li>What's the minimum version required for automated system upgrades in Tracardi?</li> <li>What was the limitation with system data upgrades in versions before 0.7.0?</li> <li>How does Tracardi handle indexes when upgrading to a new version?</li> <li>Why is it important to install dockers with a tagged version during system upgrades?</li> <li>Do you need to manually migrate data when upgrading from a version before 0.7.0 to version 0.7.0?</li> <li>How can you check your indexes in Elasticsearch when transferring data?</li> </ul>"}]}